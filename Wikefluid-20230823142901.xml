<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.11/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.11/ http://www.mediawiki.org/xml/export-0.11.xsd" version="0.11" xml:lang="fr">
  <siteinfo>
    <sitename>Wikefluid</sitename>
    <dbname>wikefluid</dbname>
    <base>https://wikefluid.efluid.uem.lan/index.php/Accueil</base>
    <generator>MediaWiki 1.35.7</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Média</namespace>
      <namespace key="-1" case="first-letter">Spécial</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Discussion</namespace>
      <namespace key="2" case="first-letter">Utilisateur</namespace>
      <namespace key="3" case="first-letter">Discussion utilisateur</namespace>
      <namespace key="4" case="first-letter">wikefluid</namespace>
      <namespace key="5" case="first-letter">Discussion wikefluid</namespace>
      <namespace key="6" case="first-letter">Fichier</namespace>
      <namespace key="7" case="first-letter">Discussion fichier</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">Discussion MediaWiki</namespace>
      <namespace key="10" case="first-letter">Modèle</namespace>
      <namespace key="11" case="first-letter">Discussion modèle</namespace>
      <namespace key="12" case="first-letter">Aide</namespace>
      <namespace key="13" case="first-letter">Discussion aide</namespace>
      <namespace key="14" case="first-letter">Catégorie</namespace>
      <namespace key="15" case="first-letter">Discussion catégorie</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Liste des listes de diffusion</title>
    <ns>0</ns>
    <id>2312</id>
    <revision>
      <id>3291525</id>
      <parentid>25080</parentid>
      <timestamp>2017-08-29T15:34:12Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <comment>/* Emplacement */</comment>
      <origin>3291525</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1053" sha1="l5vo656vmisko5scjcpcilsp74hid9v" xml:space="preserve">[[Category:coordination]]
== Liste des listes de diffusion ==

=== Emplacement ===
Toutes les listes de diffusion sont décrites dans le document '''[http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_c4efb Listes de diffusion efluid.xlsm]''' disponible dans la room '''[http://wperoom1/eRoom/Production/GestionProjetEfluid efluid - Gestion de Projet]'''

=== Fonctionnement ===
Le contenu de ce document est généré à la demande par requête sur le LDAP d'UEM, ce qui implique que :
* il faut être dans le réseau UEM pour le mettre à jour,
* il ne se met pas à jour tout seul, pensez à le faire quand vous demandez des modifications de liste de diffusion et/ou constatez qu'il commence à se faire vieux.

=== Mise à jour ===

Difficile de faire plus simple :
* télécharger puis ouvrir le document,
* activez les macros,
* sélectionner la feuille "Listes de diffusion" et cliquer sur "Actualiser les données" :
[[Fichier:Actualiser_la_liste_des_listes_de_diffusion.png]]
* sauvegarder,
* uploader vers l'emplacement de départ.</text>
      <sha1>l5vo656vmisko5scjcpcilsp74hid9v</sha1>
    </revision>
  </page>
  <page>
    <title>Lotissement</title>
    <ns>0</ns>
    <id>3963</id>
    <revision>
      <id>25157</id>
      <parentid>25096</parentid>
      <timestamp>2013-03-15T07:52:10Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <comment>/* Procédure de lotissement générique d'une anomalie */</comment>
      <origin>25157</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1421" sha1="g4yaj54qhn2le5qsnsuwhe0z2bsahmj" xml:space="preserve">[[Category:coordination]]

= Procédure de lotissement générique d'une anomalie =

* un évènement d'anomalie est crée (client, recette, même développeur, peu importe),
** dans un domaine / contrat / version donnée
** avec pour statut ouvert ("ouvert interne" ou par un client)
* une double qualification est réalisée :
** de portée fonctionnelle (gravité) par l’expertise,
** de portée technique (nb de classes, risque de regr.) par le développement,
* avec ces deux éléments, la coordination réalise le lotissement, annonce la version prévisionnelle et affecte au développement.

== Cas d'un évènement ouvert par un client ==
Ces évènements sont qualifiés par l'expertise; se reporter au paragraphe correspondant.

== Cas d'un évènement ouvert par l’expertise ==
* l’expertise fait la qualification fonctionnelle (gravité) et contacte la coordination,
* la coordination relaie vers le développement pour qualification technique (classes)
* le développement transmet son évaluation,
* la coordination loti, affect à une équipe de développement 

== Cas d'un évènement ouvert par le dev ==
* le développement fait la qualification technique (classes, risque) et contacte la coordination,
* la coordination relaie vers l’expertise pour qualification technique (classes)
* le développement transmet son évaluation,
* la coordination loti, affect à une équipe de développement</text>
      <sha1>g4yaj54qhn2le5qsnsuwhe0z2bsahmj</sha1>
    </revision>
  </page>
  <page>
    <title>Portail de la Coordination</title>
    <ns>0</ns>
    <id>13647</id>
    <revision>
      <id>3824850</id>
      <parentid>1091620</parentid>
      <timestamp>2018-01-16T14:28:49Z</timestamp>
      <contributor>
        <username>Thiry</username>
        <id>13</id>
      </contributor>
      <origin>3824850</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="276" sha1="g467gw2cha93r1oqaslaqg85sp0znph" xml:space="preserve">[[Catégorie:Coordination]]

* [[projets et plannings clients]]
* [[tableaux de bord D&amp;T|tableaux de bord]]
* [[logistique]]
* [[communication]]
* [[:Catégorie:Formation|formations]]
* [[organisation]]
* [[:Catégorie:Procédure|procédures]]
* [[chantiers]]
* [[ramassages]]</text>
      <sha1>g467gw2cha93r1oqaslaqg85sp0znph</sha1>
    </revision>
  </page>
  <page>
    <title>Projets et plannings clients</title>
    <ns>0</ns>
    <id>4115</id>
    <revision>
      <id>1394264</id>
      <parentid>1394263</parentid>
      <timestamp>2016-02-26T10:34:45Z</timestamp>
      <contributor>
        <username>Morsli</username>
        <id>86</id>
      </contributor>
      <origin>1394264</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2122" sha1="80hr242fbmc9a8azzlh1u3iz4xg7vsw" xml:space="preserve">[[Catégorie:Coordination]]
== Planning ==
* [http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_6693e/diagramme%20des%20versions.xlsx Diagramme des versions (eroom)] 
* [[Planning Client]]
* [[:Catégorie:client|Liste des clients]]

[[Catégorie:Projets]]

= Tirs à Blanc et Mises en production =
Lors de chaque Tir à Blanc / Mise en Production, le pôle développement propose la mise à disposition d'une [[Cellule Assistance TaB MeP|cellule d'assistance dédiée]].

'''En cours :'''

* MULTIELD
**[[SALLANCHES/BONNEVILLE - Tir à blanc Bascule]]
**[[MULTIELD - Tir à blanc Migration n°3]]
**[[MULTIELD - TAB MEP 1 - Sallanches et Bonneville]]
**[[MULTIELD - Tir à blanc Migration n°4]]
**[[MULTIELD - Tir à blanc Migration n°5 interne]]
**[[MULTIELD - TAB MEP 3 - Enercom connexion]]
**[[MULTIELD - Tir à blanc Migration n°6 interne]]
**[[MULTIELD - Tir à blanc Migration n°7]]
**[[MULTIELD - Tir à blanc efluid.net]]

&lt;br /&gt;
* VIALIS
** [[Vialis - Tir à blanc lot 2 n°1]]
** [[Vialis - Tir à blanc lot 2 n°2]]
** [[Vialis - Tir à blanc lot 2 n°3 et n°4]]
** [[Vialis - Tir à blanc lot 2 MEP]]&lt;br /&gt;
&lt;br /&gt;


'''Terminé :'''

* GEDIA
**[[GEDIA - Tir à blanc V12 à isofonctionnalité]]

* RSEIPC
**[[RSEIPC - Tir à blanc V12 à isofonctionnalité]]
**[[RSEIPC - Tir à blanc Bascule n°1]]
**[[RSEIPC - Tir à blanc Bascule n°2]]
**[[RSEIPC - Mise en production Bascule]]

* VIALIS
** [[Vialis - Tir à blanc lot 1 n°1]]
** [[Vialis - Tir à blanc lot 1 n°2]]
** [[Vialis - Tir à blanc lot 1 n°3]]

* GEDIA EAU
** [[GEDIA EAU - Tir à blanc]]
** [[GEDIA EAU - Tir à blanc 2]]
** [[GEDIA EAU - Mise en production]]
* ES
** [[ES - Montée de version efluid 11.11]]
* GEG
** [[GEG - Recette RECOFLUX GAZ du 4 et mars 2013]]
** [[GEG - Tir à blanc lot 2 n°2]]
** [[GEG - Tir à blanc lot 2 n°3]]
** [[GEG - Tir à blanc lot 2 n°4]]
** [[GEG - Tir à blanc lot 2 n°5]]
** [[GEG - Mise en production lot 2]]
* UEM
** [[UEM - Tir à blanc SEPA]]

= Autres =

La [[:Catégorie:Projets]] contient également l'intégralité des pages référencées dans cette catégorie.</text>
      <sha1>80hr242fbmc9a8azzlh1u3iz4xg7vsw</sha1>
    </revision>
  </page>
  <page>
    <title>Tableaux de bord D&amp;T</title>
    <ns>0</ns>
    <id>4336</id>
    <revision>
      <id>2488904</id>
      <parentid>2488903</parentid>
      <timestamp>2017-01-26T08:43:03Z</timestamp>
      <contributor>
        <username>Thiry</username>
        <id>13</id>
      </contributor>
      <comment>/* Historique de l'activité par mois */</comment>
      <origin>2488904</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2228" sha1="bwbw576wrsx8rkqvsyb0bl0icjh6g7b" xml:space="preserve">[[Catégorie:Coordination]]
= projet efluid =

== Nouveaux développement et capacitaire ==

Ces tableaux sont orientés groupe de développement : le but est de visualiser et de suivre l''''activité''' d'un groupe et de planifier les nouveaux développements.

Pour l'estimation du capacitaire basé sur l'évolution dans le temps de :
- la composition des groupes de développement
- l'évolution des congés
- le pourcentage d'activité associé aux nouveaux développement
&lt;br /&gt;
[http://WPEROOM3.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_19c673 Prevision_Capacitaire_efluid.xlsm]

La notice du fonctionnement du fichier se trouve dans l'onglet ReadMe.
Il est mis à jour tous les matins à partir des données issues de suivefluid.

== Historique de l'activité par mois et par année ==

Ces tableaux de bord permette de suivre l'activité :&lt;br /&gt;
* des anomalies de production par groupe, client, origine
* des anomalies par groupe
* des anomalies en cours par groupe
* des temps passés par groupe pour les activités : qualité, nouveau développement, anomalie, anomalie de production et études et prestations
* des tâches des agents du groupe
&lt;br /&gt;
La documentation du fonctionnement du fichier se trouve dans l'onglet ReadMe.
Le tableau de bord est mis à jour toutes les fin de mois pour établir les statistiques mensuelles de suivi de l'activité.&lt;br /&gt;

Le tableau de bord est disponible pour :&lt;br /&gt;

* Le suivi de la v13 sur 2016/2017 : [http://WPEROOM3.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_19b127 tdb_mensuel_efluid.xlsm] 
* L'année 2013 qui est homogène avec l'année 2016 : [http://WPEROOM3.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_1a37d2 tdb_mensuel_efluid_201312.xlsm]
* L'année 2015 qui est homogène avec l'année 2018 : [http://WPEROOM3.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_19f916 tdb_mensuel_efluid_201512.xlsm]

== Requêtes de contrôle de cohérence ==

Pour s'assurer que les données de suivefluid sont correctement renseignées, des requêtes de contrôle de cohérence sont réalisées à des rythmes hebdomadaire ou mensuel.
L'ensemble de ces requêtes est présenté dans la page suivante : &lt;br /&gt;
[[Contrôles de cohérence]]</text>
      <sha1>bwbw576wrsx8rkqvsyb0bl0icjh6g7b</sha1>
    </revision>
  </page>
  <page>
    <title>Logistique</title>
    <ns>0</ns>
    <id>4065</id>
    <revision>
      <id>1091456</id>
      <parentid>202473</parentid>
      <timestamp>2015-10-15T15:31:12Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <comment>/* Intégration nouvelles ressources */</comment>
      <origin>1091456</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="472" sha1="kdya4icxfatvm1vx69iqiswjn2z5ahj" xml:space="preserve">[[Catégorie:Coordination]]
= Se déplacer chez de clients =
* Voir [http://wperoom1/eRoomReq/Files/Production/RecetteEfluid/0_108b3b/se%20d%E9placer%20avec%20efluid%20SAS.pptx se déplacer avec efluid SAS.pptx] dans [http://wperoom1/eRoom/Production/RecetteEfluid/0_103588 eroom] 

= UEM Pontiffroy =
* [[Plans des locaux UEM Pontiffroy]]
* [[Salles de réunion UEM Pontiffroy]]

= CGI Carré Playel =
* [[Accès CGI Carré Pleyel]]

= audio et visio =
* [[Salles_Visio]]</text>
      <sha1>kdya4icxfatvm1vx69iqiswjn2z5ahj</sha1>
    </revision>
  </page>
  <page>
    <title>Communication</title>
    <ns>0</ns>
    <id>7577</id>
    <revision>
      <id>114933</id>
      <parentid>46206</parentid>
      <timestamp>2013-12-23T11:11:09Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <origin>114933</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="73" sha1="a9m0v04f2jd9me53czqp6b60sp4w0y9" xml:space="preserve">[[Catégorie:Coordination]]
[[Ecrire Un Courriel - Les Bonnes Pratiques]]</text>
      <sha1>a9m0v04f2jd9me53czqp6b60sp4w0y9</sha1>
    </revision>
  </page>
  <page>
    <title>Organisation</title>
    <ns>0</ns>
    <id>10989</id>
    <revision>
      <id>114935</id>
      <parentid>88827</parentid>
      <timestamp>2013-12-23T11:11:27Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <origin>114935</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="300" sha1="qnvno03vh0ky9as2lh3sv66q9v82exg" xml:space="preserve">[[Catégorie:Coordination]]
= Organigrammes = 

Les organigrammes de la société efluid SAS sont disponible sur [[Organigramme|cette page]].

= Responsables de projets client =

La liste des responsables des projets pour chacun des clients est disponible sur [[Chefs de projets clients|cette page]].</text>
      <sha1>qnvno03vh0ky9as2lh3sv66q9v82exg</sha1>
    </revision>
  </page>
  <page>
    <title>Procédure de livraison partielle</title>
    <ns>0</ns>
    <id>11482</id>
    <revision>
      <id>2333055</id>
      <parentid>2333041</parentid>
      <timestamp>2016-12-19T14:02:34Z</timestamp>
      <contributor>
        <username>Lecas</username>
        <id>30</id>
      </contributor>
      <origin>2333055</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="293" sha1="3sgl2gnjunwww758f3jcij7pr0etzk4" xml:space="preserve">[[category:coordination]]
[[category:procédure]]
Document pour les réserves (RESERVE) disponible [http://WPEROOM2.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_19c655 sur eroom], dans Mes eRooms &gt; efluid - Qualité Développement &gt; Guides et procédures &gt; procédures &gt; coordination.</text>
      <sha1>3sgl2gnjunwww758f3jcij7pr0etzk4</sha1>
    </revision>
  </page>
  <page>
    <title>Modèle de livraison de script SQL</title>
    <ns>0</ns>
    <id>13956</id>
    <revision>
      <id>259286</id>
      <parentid>197962</parentid>
      <timestamp>2014-06-12T12:20:48Z</timestamp>
      <contributor>
        <username>Andrian</username>
        <id>267</id>
      </contributor>
      <origin>259286</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="811" sha1="q3xb8u9pqbu10f7ztd1uysdooryn700" xml:space="preserve">[[Category:Coordination]]
Ce modèle est à utiliser uniquement dans le cadre de la livraison de script(s) SQL '''ponctuel(s)'''. Dans le cas où plusieurs scripts doivent être livrés par un même développeur, il faut envoyer un mail par script.

== Modèle de mail ==

Bonjour,

pouvez vous livrer le script de référence '''&lt;référence ebuild&gt;''' attaché à l'événement '''&lt;référence suivefluid&gt;''' pour validation par la recette ?
* Niveau d’urgence : '''&lt;priorité&gt;''' ;
* Environnement de recette : '''&lt;environnement cible : INT REC MACHIN, PROD BIDULE etc... &gt;''' ;
* Volumétries attendues : '''&lt;nombre de références mises à jour : 123, plusieurs milliers, etc ...&gt;''' ;
* Durée prévisionnelle du script : '''&lt;ordre de grandeur : quelques secondes, plusieurs heures etc ...&gt;''' ;

Merci.</text>
      <sha1>q3xb8u9pqbu10f7ztd1uysdooryn700</sha1>
    </revision>
  </page>
  <page>
    <title>Modèle de demande de report de code</title>
    <ns>0</ns>
    <id>184438</id>
    <revision>
      <id>2736795</id>
      <parentid>1392991</parentid>
      <timestamp>2017-04-04T09:32:46Z</timestamp>
      <contributor>
        <username>Leoutre</username>
        <id>41</id>
      </contributor>
      <origin>2736795</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="702" sha1="rx8gidisqsesbxfz8ft32ktplyxt25h" xml:space="preserve">[[Category:Coordination]]
[[Category:Report de code]]

Vous trouverez ci-dessous une demande de report concernant l’évènement '''XXXXXX'''.

* Version(s) souhaitée(s) de correction : v12.x.y.RCz
* Classes modifiées : 
** repo '''toto''' : 
*** aaa/bbb/ccc.java
*** aaa/bbb/ddd.java
** repo '''titi''' : 
*** eee/fff/ggg.java
*** eee/fff/hhh.java
* Raisons de cette demande : 
** Impact client de l’évènement : ''(à compléter)''
** Existence d’une solution de contournement : ''(à compléter)''
** Volumétrie des cas concernés (le cas échéant) : ''(à compléter)''
* Origine de la demande : ''(à compléter)''
* Risques de régression : ''(à compléter)''
* Concerne ERDF : Oui/Non</text>
      <sha1>rx8gidisqsesbxfz8ft32ktplyxt25h</sha1>
    </revision>
  </page>
  <page>
    <title>Gestion des versions</title>
    <ns>0</ns>
    <id>366</id>
    <revision>
      <id>4052258</id>
      <parentid>3881891</parentid>
      <timestamp>2019-04-29T12:35:11Z</timestamp>
      <contributor>
        <username>Costem</username>
        <id>373</id>
      </contributor>
      <comment>/* Convention de nommage des versions */</comment>
      <origin>4052258</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9204" sha1="8vvriw6uu1g50nppqbcv5za0305ihdm" xml:space="preserve">[[category:coordination]]
[[category:versions]]

La gestion des versions dans Maven peut se faire de plusieurs façons, voici notre manière de procéder pour la suite efluid :

= Schéma global des branches et versions =
[[Fichier:Gestion des branches et versions.png]]

Visio : http://wperoom2.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_107a60  =&gt; Gestion_des_branches_et_versions.vsd

== Gel d'une branche ==

Lorsqu'une branche est gelée (dans Gerrit le bouton submit sur le changeSet n'apparait pas), il faut suivre le procéssus suivant : 
[[Gerrit#Workflow_de_soumission_de_code_en_cas_de_code-freeze]]

Quand une branche est-elle gelée ? Généralement dans les cas de figure suivant, mais cela peut changer en concertation entre UL et coordination afin de bloquer le moins possible les commits tout en garantissant au mieux les livraisons clients.
* branche de production (exemple : maintenance_13.8.300) : gelées de manière permanente
* branche de maintenance (exemple : maintenance_13.8) dont dérivent des branches de production : gelée dès besoin de stabilisation
* branche de développement (develop) : gel dès besoin de stabilisation (souvent entre RC1 et RC2, puis dans les dernières RC)

Un gel peut être également positionné à la demande.

== Correspondance entre branche des composants et suite efluid ==
* [[Matrice des briques efluid|Matrice des branches utilisées dans les composants efluid]]

= Correspondance version lotie / branche git =
Un événement est doté d'un lot prévisionnel ''majeur'' et d'un lot prévisionnel ''mineur''.

Le majeur indique ''où'' livrer, :
* un événement loti "''efluid xxx''" est à livrer sur la branche ''develop'',
* un événement loti "''efluid '''maint.''' yyy''" est à livrer sur la branche de '''maint'''enance ''"'''maint'''enance_yyy"'',

Le mineur indique ''quand'' livrer :
* un événement avec version mineure doit être livré après que la version mineure précédente ait été ramassée, mais avant que la version mineur cible ne soit ramassée (évidemment).
* un événement sans version mineur peut être livré à tout moment sur la branche correspondant à la version majeur.

Les versions majeures et mineures d'une branche sont indiquée par la version renseignée dans le pom de la branche. On ne peut pas livrer sur une branche donnée des événements dont les versions prévisionnelles majeures et mineures ne sont pas exactement égales à celles du pom (ou éventuellement non précisées dans le cas de la version mineure).

= Convention de nommage des versions  =
* La convention à respecter est la suivante :
** Les 3 premiers digit doivent être des entiers positifs uniquement (pas lettre, pas de 0 devant le chiffre, exemple : 01, pas de caractères spéciaux)
** A partir du 4eme digit on peut utiliser ce que l'on veut, car il s'agit du "qualifier". Exemple : 12.1.10.RC1, 12.1.10.beta1
** Les digits sont séparés par des point

== Nomenclature de version de développement ==
* Une version développement est de la forme : '''12.1.100.RC1-SNAPSHOT'''
** Les numéro sont identiques aux version release et release candidate
** On suffixe en plus par la mention -SNAPSHOT

== Nomenclature de version release candidate ==
* Une version release candidate est de la forme : '''12.1.100.RC1'''
** Les 3 premiers numéro sont identiques à la version release
** Le 4eme numéro est le numéro de release candidate, toujours préfixé de RC

== Nomenclature de version release ==
* Une version release est de la forme : '''12.1.100'''
** Le premier numéro correspond au lot Majeur
** Le second numéro correspond au lot Mineur
** Le troisième numéro correspond à la Maintenance

== Nomenclature de version proto ==
* Une branche suiteEfluid pour un proto : proto_&lt;nomProto&gt;_&lt;version&gt;
** Numéro de version suiteEfluid pour un proto : &lt;version&gt;-PROTO-&lt;nomProto&gt;-SNAPSHOT
** Même chose pour les briques

= Cycle de vie d'une version =

== Version SNAPSHOT ==
* Les versions SNAPSHOT sont des versions qui indiquent que l'on est en cours de développement (à la différence d'une version release)
* On nomme une version SNAPSHOT de la manière suivante : '''12.1.100-SNAPSHOT'''
* On conserve le numéro de version dans le SNAPSHOT de manière à savoir quelle version on est en train de construire

== Version RELEASE ==
* Une version release est une version ramassée et tagguée, et elle ne bougera plus
* La convention Maven indique qu'on ne modifiera jamais une version Release
* Celle-ci porte donc un numero de version unique

== Edition d'une version de production ==

La création d'une nouvelle version de production se déroule en trois principales étapes :
* création de l'événement support de l'assemblage et information de l'UL pour planification
* information des développeurs pour développement / intégration des patchs selon le process de publication de code lorsqu'une branche est gelée (car une branche de production est '''toujours''' gelée); cf [[Gerrit#Workflow_de_soumission_de_code_en_cas_de_code-freeze]] pour le process détaillé
* suivi de l'avancement par la coordination puis go d'assemblage quand la version est conforme aux attentes.

Dans les détails :
[[Fichier:Assemblage version de production.png]]
&lt;br /&gt;
&lt;sub&gt;([http://WPEROOM2.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_15c2b1 Soumission patch code freeze.vsd] dans Mes eRooms &gt; efluid - Qualité Développement &gt; Guides et procédures &gt; guide environnement de développement &gt; schéma visio)&lt;/sub&gt;

= Périmètres et responsabilités =

== Préparation ==
La Coordination définis les jalons d’assemblage des versions de l’application par via une série d’événements suivefluid, en accord avec l’équipe UL (requête suivefluid 1787).
L’équipe UL est chargée de positionner le ramassage des briques correspondantes selon les pratiques habituelles.
La Coordination transmet/confirme au responsable d’application la liste des événements attendus dans le lot.

== Planification des assemblages ==

=== Source de l'information ===
Suivefluid est réputé référence de la planification des assemblages.

Pour éviter une duplication de l’information, il est prévu d’abandonner la maintenance du planning eroom. En attenandant la mise en place d'un éventuel système de représentation du planning dans le wiki, utiliser les threads du forum dédiés aux assemblages et/ou aux points hebdomadaires.

=== Diffusion de l'information ===
* '''Périodiquement via le point hebdomadaire du lundi''' : réalisation des slides avec le planning UL général (toutes version) et détaillé (y.c. briques) de la semaine comme entrant, report dans le forum post tenue du point (exemple : http://eforum.uem.lan/viewtopic.php?f=42&amp;t=1492 )
* '''Spécifiquement via forum / wiki pour la feuille de route d’une version donnée''' avec le planning UL d’une version spécifique comme entrant (exemple : http://eforum.uem.lan/viewtopic.php?f=42&amp;t=1477 / http://wikefluid/index.php/Cycle_de_vie_des_versions http://wikefluid/index.php/Tableaux_de_bord_D%26T) 

=== Maintenance de l'informaiton ===
Réalisation par l’UL et/ou Coordination.
L’UL est le point d’entrée « planification » vis-à-vis de la Coordination, et communique avec NRU en cas de création/modification/annulation.

== Suivi ==
Le responsable d’application réalise la supervision de l’avancement du lot.
== Assemblage ==
Synchronisation préalable entre Coordination et le responsable d’application pour évaluer la complétion du lot.
La Coordination demande l’assemblage à l’UL via l’événement d’assemblage suivefluid. Assemblage demandé de manière à ce qu’il soit réalisé au plus prêt de l’heure prévue.

== Cas des ramassages exceptionnels ==
Il s’agit des versions demandées pour déploiement immédiat (anomalie bloquante en recette, etc …).
La synchronisation est gérée en direct entre UL et Coordination :
* La Coordination se rapproche de l’UL pour présenter le contexte et définir la stratégie de ramassage
* La Coordination formalise le besoin via un événement d’assemblage confirmant la stratégie et le périmètre
* L’UL s’assure de la livraison des changetSets attendus, assemble dès que le périmètre est complété


= Points à remettre dans la documentation =
* Le nommage du numéro de maintenance débute toujours par 100
* La suite du numéro de maintenance 900 est 1000
** Exemple : on release 12.10.900, alors la prochaine version est 12.10.1000, puis la prochaine sera 12.10.1100 et ainsi de suite.
* On conserve 2 niveaux de branches de maintenance maximum
* Le second niveau de branche de maintenance ne doit être utilisé qu'en cas de force majeure :
** Événement bloquant (qui bloque le fonctionnement nominal de l'application)
** Le client ne souhaite pas la version de maintenance suivante
* Si un client possède la version 12.10.100 et un autre la version 12.10.101, alors si les deux souhaitent une correction de bug bloquant, ils ne pourront avoir que la version 12.10.102, il n'est pas possible d'avoir une version intermédiaire. (Note : ils peuvent aussi avoir une 12.10.200)
* Schéma à ajouter</text>
      <sha1>8vvriw6uu1g50nppqbcv5za0305ihdm</sha1>
    </revision>
  </page>
  <page>
    <title>Modèles de documents</title>
    <ns>0</ns>
    <id>384709</id>
    <revision>
      <id>699773</id>
      <parentid>699772</parentid>
      <timestamp>2015-03-17T07:07:59Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>699773</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="226" sha1="6qdjvmvncdms6kim45vqsu2h6t1savt" xml:space="preserve">* les [http://wperoom2.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_2327f modèles de documents] sont disponible sous eRoom
* diagrammes fréquemment utilisés
** [[diagramme des robinets]]
[[Catégorie:Coordination]]</text>
      <sha1>6qdjvmvncdms6kim45vqsu2h6t1savt</sha1>
    </revision>
  </page>
  <page>
    <title>Le planning de ramassage pour les nuls</title>
    <ns>0</ns>
    <id>507097</id>
    <revision>
      <id>4066127</id>
      <parentid>1217084</parentid>
      <timestamp>2021-11-04T08:55:29Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <origin>4066127</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3470" sha1="slbsrxzcqic9e9y34yf4pno4sngv1fv" xml:space="preserve">[[Category:coordination]]

'''[DEPRECATED]'''

&lt;s&gt;
Les contraintes guidant la conception du [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_b81fc planning de ramassage eroom].

= Découpage des journées =

Chaque journée est découpée en 8 créneau d'assemblage :
* matin
** 8h -&gt; 9h
** 9h -&gt; 10h
** 10h -&gt; 11h
** 11h -&gt; 12h
* après-midi
** 14h -&gt; 15h
** 15h -&gt; 16h
** 16h -&gt; 17h
** 17h -&gt; 18h

Il ne peut y avoir qu'un assemblage par créneau.

= Demande d'assemblage =

Les assemblages passent par un événement suivefluid dédié. Ces événements peuvent être retrouvés via la requête n°1787 "SMC - livraison à venir".

= Planification des assemblages spécifiques à une version =

On appelle :
* '''jalon principal''' : la RC1 d'une version.
* '''jalon de stabilisation''' : les RCx d'une version.
* '''jalon briques''' : toute release de brique en lien avec un jalon primaire ou secondaire.

== Timing ==
=== timing de positionnement des jalons principaux ===

On positionne dès qu'ils sont connus. Horaires selon ce qui est décrit dans la section "Ramassages périodiques".

=== timing de positionnement des jalons de stabilisation ===

On positionne dès qu'ils sont connus, ce qui arrive généralement une à deux semaine avant l’occurrence du jalon principal de référence. Horaires selon ce qui est décrit dans la section "Ramassages périodiques".
Les jalons de stabilisation se terminent tous en "RCx" de manière à ne pas avoir à les modifier en cas de ramassage non programmé d'une RC.

=== timing de positionnement des jalons brique ===

On ne positionne les jalons briques (décrits ci dessous) que pour la prochaine RC1 d'une branche donnée de manière à ne pas trop anticiper la planification. Exemple sur la develop : la prochaine RC1 est la 12.13.100.RC1, je positionne les jalons secondaires de cette RC1 , mais pas ceux de la 12.14.100.RC1 ni de la 12.15.100.RC1.

== Planification ==

=== jalons pré RC1 ===

==== toute version ====

Positionnement de l'intégralité des jalons des briques selon la section "Ramassages périodiques".

==== cas RC1 sur develop ====
* J-1 : jalon "nettoyage de suivefluid (cohérence événements livrés / version prévisionelle)" et "stabilisation de l'appli (TI, NB)". 
* J-2 : jalon "gel des dépots de code" (18h00). 
* J-3 : jalon "ramassage des briques embarquées dans la version" selon les horaires suivants :
** archi/fmk : 9h00
** EDK : 11h00
** ecore : 14h00

==== cas RC1 sur la maintenance ====
Pas de jalon spécifique, juste préciser que les dernier ramassages de briques concernant la branche seront celles embarquées dans la version.

==== cas RC1 sur une branche de production ====
Pas de jalon spécifique, ramassage des briques selon les besoins et disponibilités.

=== jalons post RC1 ===

==== toute version ====

Positionnement de l'intégralité des jalons des briques selon la section "Ramassages périodiques" jusqu'à la dernière RCx ("FINALE") de la branche.
Positionnement de l'intégralité des jalons des briques selon la section "Ramassages périodiques" jusqu'à la prochaine RC1 de la branche d'où est issue la RC1 courante.

= Ramassages périodiques =
Rappel du cycle de vie des RC sur la page dédiée [[Gestion des versions]].

== efluid ==

* par composants
** archi : lundi
** EDK : mardi
** ecore : mercredi
** efluid : jeudi
* par version
** develop : 14h00
** stabilisation develop : 10h00
** maintenance_12.10 : 16h00

&lt;/s&gt;</text>
      <sha1>slbsrxzcqic9e9y34yf4pno4sngv1fv</sha1>
    </revision>
  </page>
  <page>
    <title>Cursus d'intégration</title>
    <ns>0</ns>
    <id>7910</id>
    <revision>
      <id>1499090</id>
      <parentid>1093503</parentid>
      <timestamp>2016-04-13T12:08:50Z</timestamp>
      <contributor>
        <username>Back</username>
        <id>82</id>
      </contributor>
      <comment>/* Livrables */</comment>
      <origin>1499090</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="816" sha1="fkjw46569855gsokqv9670qcwlgma24" xml:space="preserve">[[Category:coordination]]
[[Category:intégration]]
[[Category:procédure]]

Cette page décrit l'organisation des cursus d'intégration des nouveaux arrivants.

= Entrants =
* Nom, prénom
* date de début et de fin de contrat (le cas échéant)
* Cadre ou non
* entreprise (efluid sas, CGI, autre prestataire)
* Poste occupé

= Livrables =

'''une checklist d'intégration'''&lt;br /&gt;
Son but est de piloter les différents acteurs (sysres, 6000, formateurs) dans les créations, réservation de PC (virtuel ou pas), habilitations, opérations du nouvel arrivant.&lt;br /&gt;
Procédure de création : [[Checklist nouvel embauche]].

'''un planning d'intégration'''&lt;br /&gt;
Il décrit jour par jour les formations suivies par le nouvel arriavnt au sein d'efluid.&lt;br /&gt;
Procédure de création : [[Planning d'intégration]].</text>
      <sha1>fkjw46569855gsokqv9670qcwlgma24</sha1>
    </revision>
  </page>
  <page>
    <title>Procédure de mise à disposition d'une instance de base de donnée privée pour test</title>
    <ns>0</ns>
    <id>538581</id>
    <revision>
      <id>1027753</id>
      <timestamp>2015-09-15T15:46:15Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <comment>Page créée avec « [[category:coordination]] [[category:procédure]]  = Contexte = La division étude et performances peut, à la demande, mettre à la disposition d'un groupe de travail une... »</comment>
      <origin>1027753</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2305" sha1="h8jjxgo2qyul6t7b679sjjn8cc5alft" xml:space="preserve">[[category:coordination]]
[[category:procédure]]

= Contexte =
La division étude et performances peut, à la demande, mettre à la disposition d'un groupe de travail une instance "privée" (les accès ne sont pas publiés) et lui permettre de réaliser des développements/tests/validation sans perturber les autres groupes. Cette facilité reste assez lourde à mettre en oeuvre, aussi elle n'est généralement réalisée que pour des développements longs, structurants ou ou ayant besoin de contextes maîtrisés.

= Interlocuteur étude et performances =
Ces mises à disposition sont gérée par [[Renaud Wozniak]], et [[Mickael Back]] en son absence.

= Prérequis =
Les entrants de cette procédure sont les suivants :
* Le besoin ''précis'', qui sert à évaluer la pertinence de la demande
* La source de donnée à utiliser comme base pour l'instance; il peut s'agir d'une copie de base client sous condition d'être autorisé à la sortir de chez le client, et qu'elle soit d'une taille ''raisonnable''. 
* Le responsable de l'instance, auquel seront communiqué les accès et qui sera sollicité quand l'instance arrivera à expiration,
* La date de fin du besoin.

= Procédure à suivre =
* Créer une demande via suivefluid (voir modèle ci-dessous),
* La transmettre à un des interlocuteurs,
* Si la demande est réalisable, l'interlocuteur monte l'instance et communique au responsable les modalités d'accès,
* A la date de fin, l'interlocuteur contacte le responsable pour prolongation éventuelle, ou destruction.

= Modèle d'événement suivefluid =
* type : livraison d'environnement
* statut : affecté développement
* groupe fonctionnel : (non applicable)
* groupe technique : étude et performances
* domaine : (non applicable)
* analyste : la personne réalisant la demande
* développeur : non renseigné
* recetteur : le futur responsable de l'instance
* contrat, projet, application : selon besoin
* version prévisionnelle : sans
* description :
  &lt;décrire le besoin de manière approfondie&gt;
  
  Base source : &lt;indiquer la base source&gt;
  A héberger sur LDBDDEDT1, instance DTSTEDT.
  Durée de vie : &lt;indiquer la date de fin du besoin&gt;.
  Responsable : &lt;indiquer le responsable&gt;.
  Nom : &lt;indiquer un nom à utiliser pour l'instance&gt;
  Usage : &lt;indiquer le besoin&gt;</text>
      <sha1>h8jjxgo2qyul6t7b679sjjn8cc5alft</sha1>
    </revision>
  </page>
  <page>
    <title>Procédure d'établissement du périmètre fonctionnelle d'un lotissement</title>
    <ns>0</ns>
    <id>11483</id>
    <revision>
      <id>1091509</id>
      <parentid>1047617</parentid>
      <timestamp>2015-10-15T15:33:59Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <origin>1091509</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2015" sha1="7go59galwob1j56cu9pwo88grckwqns" xml:space="preserve">[[category:procédure]]
[[category:coordination]]
= Procédure d'établissement du périmètre fonctionnelle d'un lotissement =

== Première phase : collecte des besoins ==

Les superviseurs recette et responsables de groupes de développement soumettent à la coordination fonctionnelle les besoins de report, au fil de l'eau.

== Deuxième phase : consolidation ==

La coordination fonctionnelle lotit dans suivefluid les demandes de report :
* en précisant la version prévisionnelle,
* en ajoutant un commentaire dans l'événement.

Durant cette phase qui peut durer quelques jours, des événements peuvent être lotis sans que les personnes en charge (développeurs, recetteurs) n'en soient notifiées.

== Troisième phase : validation ==

La coordination extrait de suivefluid un fichier consistant un premier périmètre. Ce fichier et la date de ramassage souhaitée sont transmis aux superviseurs recette et responsables de groupe pour validation :
* de faisabilité technique,
* de livraison dans les temps impartis,
* de complétude par rapport aux attentes client. 

Coté fonctionnel, chaque superviseur est responsable de s'assurer que le périmète contient les événements attendus.

Coté développement, chaque responsable de groupe s'engage sur la faisabilité dans les temps impartis, propose un délais supplémentaire si ça ne passe pas dans les délais attendus, et les événements sur lesquels aucun engagement ne peut être pris du fait d'un obstacle technique.

Les retours sont attendus sous 24h et soumis à la coordination. Des itérations supplémentaires peuvent être programmées si besoin.

== Quatrième phase : évolution ==

Des anomalies peuvent éventuellement être ajoutées au fil de l'eau post-validation. Le principe reste le même, à deux exceptions :
* le fichier de périmètre n'est pas à nouveau transmis,
* les responsables sont notifiés par email par la coordination.
Les autres points (en particulier faisabilité technique et temporelle) s'appliquent.</text>
      <sha1>7go59galwob1j56cu9pwo88grckwqns</sha1>
    </revision>
  </page>
  <page>
    <title>Checklist nouvel embauche</title>
    <ns>0</ns>
    <id>7829</id>
    <revision>
      <id>2479311</id>
      <parentid>2205637</parentid>
      <timestamp>2017-01-24T14:06:32Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <comment>/* Résumé */</comment>
      <origin>2479311</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2037" sha1="jbdn8zyvcmhih4sha0roychwe4l94xh" xml:space="preserve">[[Category:coordination]]
[[Category:intégration]]
[[Category:procédure]]

= Résumé =

Ce document est édité pour chaque nouvel arrivant, et décrit les étapes à suivre pour configurer le SI pour l'accueillir.

Les fiches sont ([http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_8dddd stockées ici] : Mes eRooms &gt; efluid - Gestion de Projet &gt; Intégration nouvelles ressources &gt; Droits d'accès).
Les différents droits d'accès sont codifiés par une [http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_112e0a note de cadrage] rédigée par le chef du service EF.

Il existe 5 répertoires dans cet emplacement :

* Principes =&gt; les process et modèles d'accueil 
* 01 – à préparer =&gt; les checklists en cours de création ;
* 02 – à traiter =&gt; les checklists à diffuser ;
* 03 – En cours =&gt; les checklists dont il faut suivre le renseignement des dates de réalisation ;
* 04 – Déjà traité =&gt; les checklists dont le suivi est terminé

[http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_19a860 Se reporter au process pour plus d'information].

= Quelques recommandations sur les champs à renseigner =

'''S'assurer que tous les champs sont renseignés, en particulier les dates.'''

== Mission ==
Le trigramme final peux différer; pour limiter le risque le rechercher dans l'annuaire Exhcnage, s'il n'existe pas c'est qu'il est disponible.

== Affectation ==
RAS

== Suivefluid ==
CDR : dans le doute, se rapprocher du chef du service concerné.

== eldap ==
Bien renseigner le profil de référence, c'est lui qui conditionne l'accès aux autres systèmes, en particulier les dépôts gerrit, les listes de diffusion.
S'il manque des groupes au profil par défaut, les indiquer via "Groupes additionnels".

== gerrit ==
S'il manque des dépôts par rapport au profil par défaut (ecore, edk etc ...) les indiquer via "Dépôts additionnels".

== eroom ==
S'il manque des rooms par rapport au profil par défaut (ethaque, etc ... ) les indiquer via "Rooms additionnelles".</text>
      <sha1>jbdn8zyvcmhih4sha0roychwe4l94xh</sha1>
    </revision>
  </page>
  <page>
    <title>Planning d'intégration</title>
    <ns>0</ns>
    <id>555345</id>
    <revision>
      <id>2479283</id>
      <parentid>2479252</parentid>
      <timestamp>2017-01-24T14:00:59Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <origin>2479283</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6325" sha1="dyma7onlo3t2w9p4axfkha10wzghh30" xml:space="preserve">[[Category:coordination]]
[[Category:intégration]]
[[Category:procédure]]

Le programme se déroule sur 8 semaines.

Le cursus est ([http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_42d0e stocké ici] : Mes eRooms &gt; efluid - Gestion de Projet &gt; Intégration nouvelles ressources). Sous-répertoire "Profil *" selon le profil de la personne.

Le modèle de cursus est stocké [http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_19bd18 ici] (Mes eRooms &gt; efluid - Gestion de Projet &gt; Intégration nouvelles ressources).

== accueil ==
* SPRH
* récupération / installation du poste de travail

== présentation ==
sur 1 jour :
* de la société (par le directeur général)
* de l'activité (par le chef de service)
* du groupe (par le supérieur)
* des équipes (par le supérieur)

== formations fonctionnelles ==
=== immersion métier ===
A organiser avec V. Mizzon pour compléter son inscription dans le [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_efef0 fichier adéquat]. 

sur 3.5 jours :
{| class="wikitable"
|-
! Métier
! Interlocuteur
! Téléphone
! Bureau
! Consignes
|-
| UEM : accueil physique et téléphonique
| Angélique Toutain
| 3186
| Accueil
| Max 2 participants par session (deux casques d'écoute)
|-
| URM : gestion du matériel
| Jean-Luc Schmitt
| 4570
| 309
| Max 5 participants par session
|-
| URM : gestion relève
| Jean-Luc Becker
| 4572
| 309
| Max 6 participants par session, uniquement domaines techniques
|-
| UEM : référentiel / mise à jour BT 
| Lionel Fiacre
| 4458
| 138
| /
|-
| URM : gestion intervention
| Roland Dorr
| 4521
| 307
| Max 5 participants par session
|-
| UEM : gestion facturation /principes généraux/facturation BT
| Claude Martin
| 3913
| 139
| /
|-
| UEM : recouvrement cac
| Francine Bariatti
| 4414
| 147
| /
|}

=== socle commun efluid ===
Compléter son inscription dans le [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_efef0 fichier adéquat].

Modules plus ou moins obligatoires selon cursus, durée de 1 jour sauf mention contraire. '''Les modules en gras''' constituent le socle commun et sont obligatoires. Les autres modules peuvent être suivis plus tard.

12.5 jours répartis ainsi :

* '''ergonomie/référentiel'''
* '''contrat'''
* '''matériel/relève'''
* '''intervention'''
* facturation (2 jours)
* cac/réglement
* relance/contentieux (1/2 journée)
* éditions perso
* ael (1/2 journée)
* efluid.net / portail GRD
* workflow
* offre
* requeteur
* suivi via suivefluid (1/2 journée)

=== immersion recette ===
Une semaine en immersion dans le groupe de recette correspondant au domaine de travail.

Le point d'entrée est le superviseur du groupe recette.

== formations techniques ==
=== outillage ===
sur 2.0 jours :
* [[Fiche de formation - gerrit|gerrit]]
* [[Fiche de formation - maven|maven]]
* [[Fiche de formation - suivefluid et gestion doc|suivefluid et gestion doc]]

=== framework ===
Sur 5 jour.

[[Fiche de formation - framework efluid]]

=== formation tests unitaires ===
Sur une journée. à réaliser après minimum 3 mois après la date d'entrée.

[[Fiche de formation - tests unitaires]]

=== formation batch ===
Selon besoins. Sur 3 jours. à réaliser après minimum 6 mois après la date d'entrée.

[[Fiche de formation - batch v3]]

=== autoformation efluid ===
Se fait en deux jours pleins, peut être fait en temps masqué (retour de formation par ex.)

[[Fiche de formation - autoformation efluid]]

== assistance dev / lecture d'AFD ==
Géré par le resp. de l'équipe de dev. Entre 5 et 15 jours selon domaine.

== suivi sur 18 mois ==
10 entretiens :
* entretien n°1 : date d’entrée + 1 mois
* entretien n°2 : date d’entrée + 2 mois
* entretien n°3 : date d’entrée + 3 mois
* entretien n°4 : date d’entrée + 4 mois
* entretien n°5 : date d’entrée + 5 mois
* entretien n°6 : date d’entrée + 6 mois
* entretien n°7 : date d’entrée + 9 mois
* entretien n°8 : date d’entrée + 12 mois
* entretien n°9 : date d’entrée + 15 mois
* entretien n°10 : date d’entrée + 18 mois

Les imputations se font sur un événement créé pour l'occasion :

== événement de suivi ==
à créer.

* intitulé "DEV accompagnement nouveau développeur - XXX (Prénom NOM)"
* type conduite du changement
* statut ouvert en interne
* groupe technique selon groupe d'accueil
* contrat selon qui prend en charge (titulaire/régie : efluid, forfait : CGI par ex.); idem pour le client
* contenu : 
  Evénement support pour l'accompagnement et la montée en compétence de TBE (Tom BESNARD), à utiliser pendant le programme de suivi,
  c'est à dire jusqu'aux 18 mois d'ancienneté.
  
  A imputer sur cet événement
  
  - Assistance : Par exemple, pour le cas d'un événement d'une anomalie ou d'une nouvelle fonction affecté au développement accompagné,
    la charge d'assistance de l'accompagnant ne sera pas imputée sur l'anomalie ou la nouvelle fonction, mais sur l'événement d'accompagnement. 
  - La revue de code : 
    - Le relecteur imputera le temps nécessaire à la revue de code d'un nouvel arrivant sur l'événement d'accompagnement. 
    - Le temps passé par le nouvel arrivant à corriger les retours de la revue de code sera imputé comme développement sur l'anomalie ou le
      nouveau développement associé. 
  - Entretiens de suivi mensuels puis trimestriels 
    - L'encadrant imputera le temps passé à préparer et à réaliser ces entretiens sur l'événement d'accompagnement. 
    - Le nouvel arrivant imputera le temps consacré à ces entretien sur un autre événement, a priori de type pilotage 
  
  Contrexemples de travaux qui ne doivent pas être imputés sur cet événement
  - Les charges du développeur nouvellement arrivé : Cet événement est dédié aux accompagnants, il ne doit pas être utilisé par l'accompagné. 
  - La formation interne, notamment les formations du parcours d'intégration : Par exemple, la formation Git / Maven / Suivefluid, ainsi que
    les formations fonctionnelles du parcours d'intégration seront imputés parle nouvel arrivant et par le formateur sur un événement de formation,
    et non sur l'événement d'accompagnement du nouvel arrivant.
  
  cf http://WPEROOM2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_f11</text>
      <sha1>dyma7onlo3t2w9p4axfkha10wzghh30</sha1>
    </revision>
  </page>
  <page>
    <title>Points hebdomadaires développement</title>
    <ns>0</ns>
    <id>646570</id>
    <revision>
      <id>2484934</id>
      <parentid>2474246</parentid>
      <timestamp>2017-01-25T13:18:50Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <comment>/* à mettre sur les slides */</comment>
      <origin>2484934</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2961" sha1="dztsnvuravq2j25ptpy61798nacgs6l" xml:space="preserve">[[Category:Réunions]]
[[Category:Coordination]]

= Concept =
Cette réunion vise à distribuer aux différents groupes techniques :
* l'activité des branches : prochain jalon de chaque branche active,
* des nouveautés sur le développement proprement dit,
* l'actualité client,
* des informations sur l'actualité formation / RH,
* d'éventuels points d'information divers.

= Participants =
L'information est relayée par les chefs de filières ou pôles des services Développement et Technologie, qui peuvent choisir de déléguer. Actuellement (juin 2016) :
* Présence obligatoire :
** THIBAUT, Christophe
** DEBLOUWE, Nicolas
** DAMESTOY, Brice
** BACK, Mickael
** POCHAT, Benjamin
** DMYTRYK, Alexis
** PROUVE, Julie
** WEBER, Pierre
** GUILLEMOT, Christelle
** COLLIGNON, Thomas
** GRZEJSZCZAK, Didier
* Présence facultative :
** GUY, Grégoire
** BODIN, David
** ABDELKAFI, Khaled

= Préparation =
La partie "Ramassage" et la partie "Technique" du support de réunion sont rédigés par l'UL, et doivent être livrées le jour de la réunion pour 8h00.
Les autres parties (client, RH, divers) sont rédigés par NRU.
Les slides sont uploadés sur eroom (Mes eRooms &gt; efluid - Gestion de Projet &gt; Planification : http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_b2dab).

= Déroulement =
La réunion dure 15 minutes, le premier jour de chaque semaine, de 8h45 à 9h00. Elle a lieu à Metz, généralement en salle efluid R3 Cube.&lt;br /&gt;
Pour les personnes ne pouvant être présentes, une conférence téléphonique est mise à disposition : 0 800 105 080 code 29 62 56 89.&lt;br /&gt;
Accès organisateur : 0 800 105 080 code 40 17 58 14.&lt;br /&gt;
5 minutes avant le démarrage de la réunion, les slides sont transmis par email aux participants.&lt;br /&gt;
Les slides sont relayés sur le forum post-réunion (cf "Débrief").&lt;br /&gt;

La présentation est assurée par [[TCO]] (planning / actualité technique) et [[JLT]] (autres parties).

= Débrief =
Ils sont relayés avant 10h00 sur le forum (dans Index du forum ‹ équipes ‹ équipes de développement : http://eforum.uem.lan/viewforum.php?f=42), s'inspirer des postes précédents ("[POINT HEBDO] Semaine YYYY-WW) pour le formalisme.

Méthode rapide pour l'injection dans le forum :
* récupérer l'URL des slides de la semaine ("copier un lien" sur les slides dans eroom)
* créer un nouveau topic nommé "[POINT HEBDO] Semaine YYYY-WW" dans Index du forum ‹ équipes ‹ équipes de développement
* y indiquer le texte suivant : 
  Bonjour à tous,
  
  les slides de cette semaine sont disponibles sur [url=http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_b2dab]eroom[/url] (Mes eRooms &gt; efluid - Gestion de Projet &gt;   Planification) : &lt;url des slides&gt;
  
  Nicolas.
* publier

= à mettre sur les slides =

semaine 2016-05
* formation tu 2017 : http://eforum.uem.lan/viewtopic.php?f=42&amp;t=2042
* formation batch 2017 : http://eforum.uem.lan/viewtopic.php?f=42&amp;t=2043</text>
      <sha1>dztsnvuravq2j25ptpy61798nacgs6l</sha1>
    </revision>
  </page>
  <page>
    <title>Contrôles de cohérence</title>
    <ns>0</ns>
    <id>684736</id>
    <revision>
      <id>2567636</id>
      <parentid>2505502</parentid>
      <timestamp>2017-02-15T10:24:52Z</timestamp>
      <contributor>
        <username>Thiry</username>
        <id>13</id>
      </contributor>
      <origin>2567636</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5521" sha1="bn04nswyf4cg16qzi0qlucqkqqq569t" xml:space="preserve">[[Catégorie:Coordination]]

Requêtes définies dans le requêteur pour les contrôles de cohérence ('''suivi CC'''), suivi opérationnel ('''suivi OP''') et pour analyse ('''suivi AN''').

{| class="wikitable sortable"
|-
! quand
! requête
! exécution différée
! nom
! description
|-
| 1er de chaque mois
| 2139
| 327
| Suivi CC - livrés recette sans recetteur
| Recherche d'événements livrés recette avec trigramme recetteur vide
|-
| hebdomadaire
| 3084
| ''n'existe pas''
| VersionsEnCours
| mise à jour de la liste des versions par extraction suivefluid des LivraisonEnvironnement
|-
| lundi
| 3101
| ''n'existe pas''
| Suivi CC - Livraison d'AFD - 13.x
| Requete de suivi des livraisons d'AFD pour evts lotis 13.x : date de rédaction de l'AFD vide ou &lt; date du jour
|-
| lundi
| 1895
| 329
| Suivi CC - événements avec charge à 0 - 13.x
| Recherche des développements lotis 13.x dont la charge prévisionnelle est à zéro.
|-
| lundi
| 3107
| 322
| Suivi OP - quantités imputées de J-7 à J-1
| Recherche des agents ayant des trous d'imputations la semaine précédente. L'agent est indiqué s'il n'a pas imputé 5 jours complets (=&gt; attention aux semaines ave jours fériés). Le champs "référence" contient la durée imputée.
|-
| lundi
| 3131
| 330
| Suivi CC - affectés dev 13 et 13plus
| affecté développeurs et lotis efluid-13 ou efluid-13+ =&gt; A partir du moment où ils sont affecté développeur c?est qu?on peut les développer et il faut à ce moment là les lotir.
|-
| vendredi
| 3147
| 324
| Suivi AN - prod bloquant 
| bloquants prod créés il y a moins de 7 jours qui sont au statut différent de pris en charge, abandonné ou ouvert client
|-
| lundi
| 3148
| 331
| Suivi OP - Reports non traités
| Extraction des evts livrés dans la version principale et avec un rôle statut à livrer dans d'autres versions
|-
| lundi
| 2876
| ''n'existe pas''
| Suivi CC - Ano production origine non renseignee
| anomalies de production dont l'origine n'est pas renseignée
|-
| quotidien
| 1661
| 159
| Suivi OP - Congés du jour 
| Indique les agents absents au moins une partie de la journée.
|-
| lundi
| 3166
| 333
| Suivi OP - Refus de livraison Enedis
| Trace les refus de livraison enedis, en se basant sur les étiquettes positionnées manuellement (équipe maint.) "refus livraison enedis".
|-
| quotidien
| 3200
| 337
| Suivi CC - Livrés sans accord coordination
| ces événements correspondent à la recherche « livrés sur une version (onglet version) autre que develop sans validation coordination ». On s?est concentré sur les événements au statut « livré IT ? assemblage » dans un premier temps. 
|-
| hebdomadaire
| 3226
| 342
| Suivi CC - événements dev avec RAF nul et charge non nulle
| événements avec une charge prévi de dev non nulle (=&gt; il a été prévu de livrer quelque chose), RAF à zero (=&gt; il n'y a plus rien à livrer) mais restant affecté dev
|-
| hebdomadaire
| 3322
| 343
| Suivi CC - nc interne de plus de 7 jours
| Permet d'identifier les NC internes (statut transitoire) stagnants.
|-
| hebdomadaire
| 3323
| 344
| Suivi CC - affectés développement avec développeur
| Recherche les événements affectés équipe de développement avec développeur positionné.
|-
| ponctuel
| 3391
| 
| Evenements 12-13 - chiffrage
| Extraction des evts de type nouveau développement lotis v13 à lotir dans sous version ou avec chiffrage prévisionnel à 0.
|-
| ponctuel
| 3399
| 
| Evenements a livrer pour une version/ramassage
| Extraction des evts a livrer pour une version.
|-
| quotidien
| 3424
| 360
| suivi integration continue
| suivi des anomalies remontées par l'intégration continue QTP
|}
 



=&gt; 3147 : filtrer le statut pour ne pas partir trop tôt dans l'analyse.

=== Tous les mois ===
* Validation de la structure des groupes techniques pour les 3 mois à venir
* Validation du pourcentage affecté au nouveaux développement pour chaque groupe

=== à faire ===
* suivre l'évolution de la charge prévisionnelle et du RAF par version (hebdo) =&gt; besoin historisation (RAF ou charge selon):
** table d'histo : DateAnalyse / Version / Groupe / ouvert / analyse / affecte dev
** collecte : Requête insert into select… pour ajout des données dans la table toutes les semaines Lancée le lundi
** analyse : Requête select pour lecture des valeurs sur les 2 dernières semaines (where dateAanalyse = Now -14j.) lancée le mardi
* requête des événements livré avec version non à jour dans toutes les versions
* requête qui regarde quels sont les événements détectés en production qui passe par le statut « non conforme client » avec la date de passage dans ce statut 

=== Idées ===
* Découpages techniques dont le projet n'est pas le même que le projet de l'événement parent
* Evenements ouverts lotis dans une version qui n'est plus en prod
* au status 'à corriger en production' depuis plus d'un mois
* au statut 'non conforme client' depuis plus d'un mois
* au statut 'non conforme interne' depuis plus d'un mois
* au statut 'AFD validée' depuis plus d'un mois
* Gravité 'bloquant' depuis plus d'un mois
* Permanent dont la dernière imputation remonte à plus d'un an
* Permanent sans imputation
* Evenements ouverts interne présentant des imputations de type développement
* en cas de report : demande systématique pour maintenance_12
* livrés IT avec RAF &gt; 0
* livrés sur une version de lotissement
* 3107 : prise en compte des jours fériés
* événements avec chiffrage non détaillé</text>
      <sha1>bn04nswyf4cg16qzi0qlucqkqqq569t</sha1>
    </revision>
  </page>
  <page>
    <title>Analyse bloquants de production</title>
    <ns>0</ns>
    <id>690894</id>
    <revision>
      <id>4060432</id>
      <parentid>4060431</parentid>
      <timestamp>2020-08-13T16:35:09Z</timestamp>
      <contributor>
        <username>Pochat</username>
        <id>27</id>
      </contributor>
      <origin>4060432</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1401" sha1="ha4sm7itnesgahyx1xyq12e6ob9yek4" xml:space="preserve">[[Catégorie:Coordination]]

''' /!\ PAGE OBSOLETE /!\

''' - LE PROCESSUS D'ANALYSE DES ANOMALIES EST DECRIT ICI : http://wikefluid.uem.lan/index.php/Guide_Suivefluid_:_Analyse_des_anomalies 

''' - LE PROCESSUS D'ANALYSE 5 POURQUOI EST DECRIT ICI : http://wikefluid.uem.lan/index.php/Guide_Suivefluid_:_Analyse_5_pourquoi


-------------------------------

Page décrivant la procédure d'analyse des anomalies bloquantes de production.

= Principe de base =

Le but est de comprendre l'arrivé du bloquant en production, en répondant à deux questions :
* Pourquoi l'anomalie s'est produite ?
* Pourquoi n'est elle pas apparue avant la production ?

Les questions s'analysent via la méthode des "5 pourquoi".

Les réponses permettent de mettre en oeuvre des mécanismes préventifs.

Un point d'attention particulier est accordé à la rapidité de l'analyse : on cherche à avoir un délai minimal entre l'introduction de l'anomalie et son analyse.

= Stockage =
Sur eroom : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_1841de Mes eRooms &gt; efluid - Gestion de Projet &gt; Qualité &gt; Gestion des non-conformités &gt; Analyses].

= Timing =

La collecte des incidents se fait via deux canaux :
* chaque lundi matin durant la réunion de suivi des bloquants de production (CPEY) via les requêtes [A COMPLETER] et 3055 (ouverts par semaine)
* chaque matin (NRU) via la requête 3147.</text>
      <sha1>ha4sm7itnesgahyx1xyq12e6ob9yek4</sha1>
    </revision>
  </page>
  <page>
    <title>Guide suivefluid : Gestion des EDP des anomalies de production</title>
    <ns>0</ns>
    <id>696119</id>
    <revision>
      <id>4065906</id>
      <parentid>4060433</parentid>
      <timestamp>2021-10-17T07:31:32Z</timestamp>
      <contributor>
        <username>Pochat</username>
        <id>27</id>
      </contributor>
      <minor/>
      <comment>Pochat a déplacé la page [[Guide Suivefluid : Gestion des EDP des anomalies de production]] vers [[Guide suivefluid : Gestion des EDP des anomalies de production]]</comment>
      <origin>4065906</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2868" sha1="87tswvjrm5acjqamm0zmzialykndnec" xml:space="preserve">[[Category:suivefluid]]

[[Catégorie:Coordination]]

''' /!\ PAGE OBSOLETE /!\

''' - LE PROCESSUS D'ANALYSE DES ANOMALIES EST DECRIT ICI : http://wikefluid.uem.lan/index.php/Guide_Suivefluid_:_Analyse_des_anomalies 

''' - LE PROCESSUS D'ANALYSE 5 POURQUOI EST DECRIT ICI : http://wikefluid.uem.lan/index.php/Guide_Suivefluid_:_Analyse_5_pourquoi


-------------------------------

Cette page présente l'utilisation de l'onglet "anomalie production" de la page de consultation d'un événement suivefluid.
&lt;br /&gt;&lt;br /&gt;

Il avait été constaté que dans de nombreux cas les champs de cet onglet n'étaient que très partiellement renseignés.&lt;br /&gt;
Nous avons cherché à alléger et redonner de l'intérêt à cet onglet sans pour autant trop forcer la main pour le renseigner.&lt;br /&gt;

L'onglet n'est désormais affiché que si l'événement a été détecté sur un environnement de production et a donc été renommé "anomalie production".
A l'intérieur, tous les champs ont été retravaillés :
* les deux champs "origine de l'erreur" ont été unifié dans un champs "type de problème" dont les valeurs se veulent plus claires,
* les champs "explication technique", "mesures correctives" et "mesures préventives" ont été unifié dans un champ "résumé de l'anomalie",
* afin de lever une ambiguïté, le champ "domaine d'origine" a été divisé en deux champs : le domaine ayant constaté l'anomalie, et le domaine l'ayant généré,
* un nouveau champ "responsable de l'anomalie" (client, éditeur ou intégrateur) fait son apparition,
* le champ "nature de la correction" affiche désormais de nouvelles valeurs
&lt;br /&gt;

[[Fichier:Anomalie production.png|centré]]
               
La valorisation de ces champs n'est plus obligatoire pour pouvoir livrer l'événement.&lt;br /&gt;
Cependant, lorsque l'événement sera livré, si toutes les valeurs ne sont pas saisies, un EDP "suivi explication technique" sera créé. Tant que les données n'ont pas été saisies, celui-ci restera au statut "à analyser".&lt;br /&gt;
&lt;br /&gt;

Pour connaitre la liste des EDP "à analyser" et renseigner l’onglet anomalie production de l’événement :
# Menu "campagne"
# Consulter la campagne "suivi secondaire explication technique"
# Consulter le lot "suivi explication technique"
# Consulter la statistique "à analyser"
# Rechercher les EDP vous concernant (par groupe technique et domaine par exemple)
# Pour consulter l’événement, cliquer sur son libellé dans le tableau de résultat

[[Fichier:Statistique edp anoprod.jpg|centré]]

Une fois les valeurs de l’onglet « anomalie production » renseignées, l'EDP passera au statut "analysé".&lt;br /&gt;
'''Remarque :''' C'est au développeur de s'assurer que les EDP soient traités.&lt;br /&gt;
Nous conseillons de ne pas trop attendre pour renseigner ces valeurs tant que toutes les informations sont encore fraîches.</text>
      <sha1>87tswvjrm5acjqamm0zmzialykndnec</sha1>
    </revision>
  </page>
  <page>
    <title>Portail des développeurs</title>
    <ns>0</ns>
    <id>1999</id>
    <revision>
      <id>4066891</id>
      <parentid>4063845</parentid>
      <timestamp>2022-02-23T11:58:18Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>4066891</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="314" sha1="sqb3z9nnbcmkrkphkhrf91vmkoysho4" xml:space="preserve">[[Category:portail]]

&lt;div style="width:20%;float:left;"&gt;
{{colonne_1}} 
&lt;/div&gt;
&lt;div style="width:20%;"&gt;
{{colonne_2}} 
&lt;/div&gt;
&lt;div style="width:20%;"&gt;
{{colonne_3}} 
&lt;/div&gt;
&lt;div style="width:20%;"&gt;
{{colonne_4}} 
&lt;/div&gt;
&lt;div style="width:20%;float:right;"&gt;
{{colonne_5}}
&lt;/div&gt;

[[Guide de développement efluid]]</text>
      <sha1>sqb3z9nnbcmkrkphkhrf91vmkoysho4</sha1>
    </revision>
  </page>
  <page>
    <title>Intégration Technique</title>
    <ns>0</ns>
    <id>2024</id>
    <revision>
      <id>3916659</id>
      <parentid>3916658</parentid>
      <timestamp>2018-04-12T07:33:53Z</timestamp>
      <contributor>
        <username>Ternet</username>
        <id>103</id>
      </contributor>
      <comment>/* Divers procédures techniques auxquelles peut être confronté un intégrateur */</comment>
      <origin>3916659</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14055" sha1="e3hj102obbq76hx3l440px5ds2mffoj" xml:space="preserve">{{Modèle:GroupeIT
 | responsables= [[MLE]], [[NBL]]
 | domaines= [[ebuild]], [[transverse efluid]]
 | integrateurs= [[AOU]], [[BKA]], [[EMER]], [[FNA]], [[FTE]], [[JAND]] [[KLE]], [[LCA]], [[MTAN]], [[SLEL]]
}}

[[Category:portail]]

=Informations générales=
* [[ebuild]]
* [[suivefluid]]
* [[efluid]]
* [[Maven]]

== Equipe IT ==

12 personnes.
L’IT s’occupe de tout ce qui concerne la génération et le déploiement d'environnements de la suite efluid. 

L'IT est aussi en contact privilégié avec les clients : c’est l’IT qui livre les applications. Les clients n’ont plus qu’à paramétrer et à déployer sur leurs plates-formes techniques.

== Contacts ==

*efluid.it@efluid.fr: mail pour le support sur l'activité IT
*livraisonSQL@efluid.fr: mail pour les scripts ponctuels destinés à être livré aux clients.
* Support IT efluid : 01.53.45.31.99

=Informations clients=
* [[Base de données clients]]
* [http://wperoom1/eRoom/Production/PlanificationIntegrationEfluid/0_ae465 Diagramme des versions]
* [[Plateformes clients à charge de l'IT]]
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_e927d/Cartographie%20Envrionnement-Composants.xlsm Cartographie Client]
* [[Liens aux applications non présents dans la page des environnements]]

=Qualité=
==Processus IT==

'''Processus de fabrication des livrables par "ebuild"

Le document ebuild processus IT couvre l'ensemble des opérations à effectuer par l'intégrateur pour la phase d'assemblage/reassemblage:&lt;br /&gt;
[http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_8e9ae/ebuild%20-%20Processus%20IT.doc ebuild - Processus IT]


'''Processus de fabrication des livrables par "maven"

A partir des versions d'applications suivantes, les livrables produit sont maintenant produit par Maven et passe sous la responsabilité de l'équipe Usine Logicielle :

- efluid 12.1.0

- ethaque 4.2.0

- enercom 2.1.0

- suivfluid 4.1.0

- eldap 11.1.0

- edoc 2.1.0

L'opération d'assemblage traitée par l'IT est décrite dans le document : [http://wperoom1/eRoom/Production/IntegrationEfluid/0_cf7a8 ebuild - assemblage usine logicielle.doc ]


Les livraisons génériques aux clients nécessitent - en pré-requis de la récupération des livrables produit directement d'artifactory - la mise à disposition par l'équipe IT des listes de montée de version SQL / LDIF : [[Usine logicielle - Nouveau processus pour les livraisons génériques]]


Le réassemblage a évolué en conséquence pour récupérer les livrables directement dans maven, tel que décrit dans la documentation : [http://wperoom1/eRoom/Production/IntegrationEfluid/0_d10ce ebuild - réassemblage livrables issus artifactory.doc]

Le paramétrage ebuild sera réalisé à l'aide des outils suivants :

- dictionnaire des propriétés de configuration : [http://wperoom1/eRoom/Production/GestionProjetEfluid/0_d8ec5 Dictionnaire]

- script Installeur : [http://wikefluid/docInstalleur/release-notes.html efluid script installeur]

- circuit de validation du paramétrage technique : [[Demandes d'évolution du paramétrage technique]]


Déploiement et maintenance des environnements de Nightly Build QTP:
* [[Environnements Nightly Builds gérés par l'Intégration Technique]]

==Test de mise a disposition==
===Check-lists et Rapport de livraison===
L'ensemble des checklists/rapport de livraison peuvent être consultés dans la room [http://wperoom1/eRoom/Production/IntegrationEfluid efluid - Intégration] &gt; [http://wperoom1/eRoom/Production/IntegrationEfluid/0_28469 Check-lists]

Les checklists les plus utilisées sont les suivantes :
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_26b64/CheckList%20Assemblage.xls CheckList Assemblage]: CheckList à suivre lors de l'assemblage d'une version.
* CheckList livraison Suite efluid : OBSOLETE - CheckList à suivre lors de la livraison d'un environnement efluid à un client
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_29a70/Rapport%20Livraison%20efluid.xls Rapport de livraison efluid]: Rapport des tests à effectuer après le déploiement d'un '''environnement complet'''. Ce rapport contient les briques efluid,efluid.net, ael, suivefluid, suiveclient, ethaque, etineraire. Lors d'une mis à disposition, joindre uniquement les onglets utiles aux tests.
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_e7ee2/Rapport%20de%20Livraison%20Suivefluid.xls Rapport de livraison suivefluid]: Rapport des tests à effectuer après le déploiement d'un environnement '''suivefluid''' et '''suiveclient'''.
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_e7edd/Rapport%20de%20Livraison%20Ethaque.xls Rapport de livraison ethaque]: Rapport des tests à effectuer après le déploiement d'un environnement '''ethaque'''.
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_e7ed8/Rapport%20de%20Livraison%20eldap.xls Rapport de livraison eldap]: Rapport des tests à effectuer après le déploiement d'un environnement '''eldap'''.
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_74a5d/Rapport%20Livraison%20ebuild.xls Rapport de livraison ebuild]: Rapport des tests à effectuer après le déploiement d'un environnement '''ebuild'''.
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_b8986/Rapport%20Livraison%20edoc.xls Rapport de livraison edoc]: Rapport des tests à effectuer après le déploiement d'un environnement '''edoc'''
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_8fa40/Rapport%20Livraison%20enercom.xls Rapport de livraison enercom]: Rapport des test à effectuer après la mis à disposition d'un environnement '''enercom'''.

'''''Les rapports de livraison sont à joindre à chaque mail de mis à disposition d'un environnement.'''''

===Tests unitaires===
Référencement de différentes procédures devant être déroulé dans les check-list/rapport de livraison avant mise à disposition.
*[[Tests Unitaires efluid/migefluid]]
*[[Tests Unitaires efluidstateless/efluid-ws/efluidpub]]
*[[Tests Unitaires efluid.net]]
*[[Tests Unitaires ael/etineraire/portail partenaire]]
*[[Tests Unitaires suivefluid/suiveclient]]
*[[Tests Unitaires enercom]]
*[[Tests Unitaires ethaque]]
*[[Tests Unitaires edoc]]

==PTI==
* [http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_90aa2/efluid%20-%20PTI%20-%20efluid.doc PTI efluid]
* [http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_8f70d/efluid%20-%20PTI%20-%20efluid.net.doc PTI efluid.net]
* [http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_8ff4f/efluid%20-%20PTI%20-%20ael.doc PTI ael]
* [http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_90068/efluid%20-%20PTI%20-%20eldap.doc PTI eldap]
* [http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_90ade/efluid%20-%20Parametrage%20des%20livrables%20generiques.doc Paramétrage des livrables génériques]
* [http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_94888/efluid%20-%20PTI%20-%20edoc.doc PTI edoc]
==Mails Génériques pour traitement de demandes==
* [http://wperoom1/eRoom/Production/IntegrationEfluid/0_23ca1 liens vers les mails génériques]

N.B: les mails de mise à disposition des environnements sont à envoyées directement et uniquement à la coordination. En cas de sollicitation, rediriger vers la coordination.

==Suivie des anomalies==
* [http://wperoom1/eRoom/Production/IntegrationEfluid/0_e773 Liens vers le fichier de suivie des anomalies suivefluid] 
==PTI et documentation Interne==
Un ensemble de procédures et de guides qui font consensus et qui sont considérés comme indispensables dans le processus de l'IT.
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_d0bbc/efluid%20-%20PTI%20-%20Serveur%20NFS.doc PTI Serveur NFS]
* [http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_d0bbc/efluid%20-%20PTI%20-%20Serveur%20SAMBA.doc PTI Serveur SAMBA]
* [[Administration système LINUX]]
* [[Administration réseau LINUX]]
* [[Installation Python sur serveur AIX]]
* [[Installation et configuration de VSFTPD]]

==Bonnes Pratiques de l'IT==
*[[Bonnes Pratiques Suivefluid]]
*[[Bonnes Pratiques eRoom]]

=Guide du nouvel arrivant=
Guide à suivre pour tous les nouveaux arrivant dans l'équipe IT du projet eFluid
*[[Guide d'installation d'un poste d'intégrateur]]&lt;br /&gt;


Configuration Internet Explorer
*[[Procédure de configuration IE pour fonctionnalités spécifiques ebuild et efluid (Windows 7)]]

=Procédures techniques=
==Divers procédures techniques auxquelles peut être confronté un intégrateur==
*[[Procédure de gestion double sessions]]
*[[Module PHP - Gestion des environnements clients]]
*[[Création d'un partage Windows/Linux ]]
*[[Procédure livraison d'un script ponctuel]]
*[[Création d'une branche (git/maven/ebuild)]]
*[[Utilitaires et scripts]]
*[[Procédure de création d'un nouveau schéma AEL/etineraire/portail partenaire]]
*[[Procédure de création d'un nouveau schéma efluid.net]]
*[[ebuild - Traitements en erreur ne générant plus de logs]]
*[[Déploiement - déploiement d'un environnement batchTesteur par l'IT]]
*[[Installation service StreamServe persuasion]]
*[[Gestion des files JMS avec Joram (JOnAS)]]
*[[Configuration Jonas pour l'application "efluid-ws"]]
*[[Parametrage des surcharges des ID en BDD]]
*[[MAJ parametrages entreprise de toutes les applications]]
*[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_11af15 Activation du cache applicatif pour les versions V11 et V12]
*[[Tache planifiée ordonnanceur]]
*[http://wikefluid/index.php/Usine_logicielle_-_Nouveau_processus_pour_les_livraisons_g%C3%A9n%C3%A9riques Procédure de livraison générique - nouveau processus V12]
*[[Vérification du répertoire d'import export avant réinitialisation]]
*[[Mise en place SATURNE]]
*[[Installation du client Juniper 7.0.0 pour EDF-SEI]]
*[[Récupérer et Mettre à disposition un dump]]
*[[Accès FTP clients]]
*[[Configurer les paramètres de BDD en cas d'une réinitialisation par une copie à froid des fichiers de la BDD de production]]
*[[Modification BDD dans le cas ou un environnement utilise le LDAP d'un autre client]]
*[[Administration MremoteNG]]
*[[CURL - Récupération dumps FTP GEG]]
*[[checkinstall]]
*[[KeepassIT]]
*[[Archivage des scripts de MaJ de TAPPLICATIONINFO ]]
*[[Mise en œuvre de l'authentification multiple annuaires efluid / entreprise]]
*[[Mise en œuvre de la solution d'archivage edoc pour efluid]]
*[[Mise à jour de la configuration apache dans le cadre des communications soap ]]
*[[export/import liste de tables]]
*[[Supervision / Naemon]]
*[[Configurer Nagstamon pour afficher la supervision naemon]]
*[[Suivefluid : Procédure de migration des paramètres des environnements sur suivefluid]]
*[[check liste des scripts de migration et liste des scripts d'assemblage]]
*[[Nouveau processus livraison environnement]]
*[[Mise à jour Annuaire LDAP]]
*[[Ajout version dans ebuild]]
*[[Livraison MCO Editique]]
*[[Génération de Guichet de Paramétrage]]
*[[Ajout d'un dbf à un tablespace]]
*[[augmenter la mémoire alloué à une instance oracle]]
*[[Transfere des comptes AEL dans efluid]]

==Specificité client==
*[[Specificité ethaque]]
*[[Specificité UEM]]
*[[Specificité ERDF]]
*[[Specificité ARGOS]]
*[[Specificité EDF]]
*[[Specificité ES]]
*[[Specificité GEG]]
*[[Specificité MELD]]
*[[Specificité SEOLIS]]
*[[Specificité SMEG]]
*[[Specificité RSEIPC/GEDIA]]
*[[Specificité RDM]]
*[[Specificité migefluid (INT MIG CGI / PARAM MIG CGI)]]
*[[Specificité SUIVEFLUID/SUIVECLIENT]]
*[[Specificité Enercom]]
*[[Specificité VIALIS]]

==Usine logicielle==
*[[Configuration d'un poste de packaging]]

==Ansible==
*[[Suivi : portage des environnemments dans Ansible]]
*[[Configuration Oracle]]
*[[Export et Import]]

=Capitalisation des erreurs IT=
La capitalisation des erreurs rencontrées par l'IT se fait par l'intermédiaire de ce fichier:&lt;br /&gt;
[http://wperoom1/eRoom/Production/IntegrationEfluid/0_23829 Capitalisation erreurs IT]&lt;br /&gt;
'''''Merci à chaque intégrateur de le maintenir à jour en l'alimentant à chaque fois qu'une erreur est rencontrée.'''''

=Pilotage=
==Intégration nouvelles ressources==
Une formation est prévue à l'arrivée de chaque nouvel intégrateur dans le groupe IT selon ce plan d'intégration.
Les outils de suivi des formations se trouvent dans eroom : http://wperoom1/eRoom/Production/GestionProjetEfluid/0_42d0e

Arrivées prévues : aucune pour l'instant.


==Congés==
Les plannings des congés se trouvent dans la room [http://wperoom1/eRoom/Production/GestionProjetEfluid/0_3f49c efluid - Gestion de Projet &gt; Congés].

Actuellement, le fichier ci-après permet de suivre les congés de l'équipe IT : [http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_955b7/Planning%20suivefluid%202013.xls Planning suivefluid 2013.xls].

==Réunions de groupe==

Les compte-rendus de réunions se trouvent dans eroom [http://wperoom1/eRoom/Production/IntegrationEfluid/0_e9e9 efluid - Intégration &gt; Compte-Rendus].
Les réunions de groupe sont actuellement planifiées toutes les deux semaines en alternance :
* Réunions d'équipe : semaines impaires (lundi)
* Réunions techniques : semaines paires (mardi)

=Boite à idées=
[http://wperoom1/eRoomReq/Files/Production/IntegrationEfluid/0_be581/Wikefluid%20IT.xls idées wikefluid]

=Liens=
* Convertir un fichier XLS en tableau mediawiki : http://excel2wiki.net/index.php
* Liste de diffusion efluid: [http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_c4efb/Listes%20de%20diffusion%20efluid.xls Mes eRooms &gt; efluid - Gestion de Projet &gt; Listes de diffusion efluid.xls]
* Création d'un point de montage entre un windows et un linux: http://www.pintaric.net/index.php?post/2009/05/08/Montage-d-un-dossier-partag%C3%A9-Windows-sous-Linux
* artifactory pour les clients http://wikefluid/index.php/Artifactory_frontal#Artifacts_disponibles
* Auto-formation GIT : http://pcottle.github.io/learnGitBranching/</text>
      <sha1>e3hj102obbq76hx3l440px5ds2mffoj</sha1>
    </revision>
  </page>
  <page>
    <title>Portail des recetteurs</title>
    <ns>0</ns>
    <id>3000</id>
    <revision>
      <id>4069456</id>
      <parentid>4063651</parentid>
      <timestamp>2023-06-06T09:44:05Z</timestamp>
      <contributor>
        <username>Delapor</username>
        <id>761</id>
      </contributor>
      <origin>4069456</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5441" sha1="gdzfeb64linmyy7w7puknk4ko2ufd40" xml:space="preserve">[[Category:portail]]
[[Category:recetteur]]
[[Category:formateur]]
[[Category:Chefs de projet]]
[[Category:client]]

=== Coordination ===


* Suivi des [http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_6693e dates de MEP clients] en production
**onglet "mise en production" : liste les '''différentes montées en version des environnements de production client''' (diagramme des versions client) 
**onglet "situation projet client" : liste des versions de production, recette et versions à venir par client + actualités projet
* [[Superviseurs recette et responsable prestation client]] : à qui s'adresser ?

=== Relations client===

* Liste des chefs de projet :  [[Liste CDP Client]]
* Fiche d'identité des clients efluid  : [[fiche Client]] (en cours)

===Utilisation de suivefluid===

L'outil principal utilisé par le recetteur est suivefluid.
Suivefluid est un portail de suivi des travaux de l’équipe efluid SAS / CGI
*Outil de gestion d’anomalies (depuis la déclaration d’une anomalie jusqu’à sa fermeture)
*Outil de gestion des développements des nouvelles fonctionnalités (écarts) 
* etc.

{{astuce|texte=[[Suivefluid - Règles générales]]}}

====Je suis affecté à un travail de recette==== 
(traitement des anomalies provenant du suivi de production client, ou test d'une nouvelle fonctionnalité)

* J'ai besoin d’accéder à un environnement de recette (depuis suivefluid, recherche environnement) mais je n'ai pas les informations
** contacter le responsable de l'environnement par mail et lui demander de mettre à jour depuis suivefluid les informations de connexion

====Je suis affecté à un travail de recette en collaboration avec d'autres recetteur==== 

=====en interne=====


=====avec un client =====


====Je suis affecté à un travail de formation====

=== Formation interne et immersions ===

A tout moment, je peux demander à mon N+1 de m'inscrire aux formations internes proposées par efluid.

Le planning de ces formations sont disponibles dans le calendrier Outlook : formation-interne@efluid.fr

=== Procédures et documents de référence ===

* [[Note de paramétrage]]
* [[Prestation client]]
*[http://wperoom4.uem.lan/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_1b7efe/Charte%20graphique%20efluid%20V13.docx Charte graphique]
*[[Liste des listes de diffusion]]
* [http://wperoom4.uem.lan/eRoomReq/Files/Prod13/ConduiteChangementEfluid/0_a063/%E9crire%20un%20support%20avec%20charte%20graphique%20efluid.pptx Comment écrire un PPT de présentation]
* [https://portail.uem.lan/home.jsp# modèles de documents efluid] : portail UEM / modèles


* '''projet Enedis'''
** [[Enedis - Consignes technico-fonctionnelles pour PTI]]
** [http://wperoom2.uem.lan/eRoomReq/Files/Production/RecetteEfluid/0_199a05/ Règles de gestion évts de paramétrage] pour le client Enedis
** [http://WPEROOM4.uem.lan/eRoom/Production/RecetteEfluid/0_241528 Comment extraire paramétrage via ID DISPENDER]

=== Outils et astuces ===

====Besoin de réserver une conférence téléphonique? ====
*CONFÉRENCE EFLUID : 0 800 105 080&lt;br /&gt;
code organisateur : 40175814#&lt;br /&gt;
Le numéro de la conférence pour nous joindre : 0 800 105 080
Code d’accès : 29625689#
*CONFÉRENCE UEM : 01 58 99 67 22&lt;br /&gt;
Code organisateur : *0967#&lt;br /&gt;
Le numéro de la conférence pour nous joindre : 01 58 99 67 22
*CONFÉRENCE URM : 0 800 105 080&lt;br /&gt;
code organisateur : 49885086#&lt;br /&gt;
Le numéro de la conférence pour nous joindre :0 800 105 080&lt;br /&gt;
Code d’accès : 94537491#
&lt;br /&gt;

[[rejoindre une conférence « Zoom » avec un téléphone ou une « pieuvre » téléphonique]]

====Base de connaissance Footprint====
Depuis Footprint, en cliquant sur "base de connaissance" vous avez accès à des procédures groupe du type : 
*renouvellement certificat Wifi
*renouvellement de mot de passe 
*configuration messagerie Outlook sur Iphone
*etc.

Cette base de connaissance se met à jour, n'hésitez pas à aller y faire un tour!

==== Besoin d'envoyer un gros fichier - impossible par mail?====

Vous avez la possibilité d'utiliser l'interface NextCloud
https://cloud.uem-metz.fr/index.php/login?

==== Je n'ai plus accès à mes lecteurs réseau ====
Depuis le portail UEM https://portail.uem.lan/ , je clique sur '''Aide''' : on m'indique une procédure pour les réactiver.

==== J'ai besoin de réactiver mon plug in eroom ====
* ouvrez le menu Démarrer de Windows
* localisez puis déployez le groupe de programmes Groupe UEM
* cliquer sur "réactivation plug in eroom"

=== RH ===
* accès direct à '''Cantoriel'''
** ouvrez le menu Démarrer de Windows
** localisez puis déployez le groupe de programmes Groupe UEM
** cliquer sur "Cantoriel"
* [http://wperoom4.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_275f6a/Planning%20%20Expertise%20Fonctionnelle.xlsx planning expertise fonctionnelle]
* [http://wperoom4.uem.lan/eRoom/Prod13/ConduiteChangementEfluid/0_18750 procédure des déplacements]
* Formation professionnelle : evt 30989
** Si vous avez suivi la formation « extincteurs », il faut la noter dans suivefluid (Sheila l’a déjà saisie dans cantoriel)
** Si vous avez suivi d’autres formations « FPC », vous devez faire la saisie dans suivefluid mais également dans cantoriel comme indiqué sur votre convocation.
** A l’avenir, si vous avez d’autres FPC en interne, transmettre à Sheila la convocation car le sprh ne le fait pas.</text>
      <sha1>gdzfeb64linmyy7w7puknk4ko2ufd40</sha1>
    </revision>
  </page>
  <page>
    <title>Pôle Prestation</title>
    <ns>0</ns>
    <id>701967</id>
    <revision>
      <id>4054839</id>
      <timestamp>2019-09-27T09:01:39Z</timestamp>
      <contributor>
        <username>Cannic</username>
        <id>72</id>
      </contributor>
      <comment>Page créée avec « [[Category:portail]]  === Pôle Prestation === »</comment>
      <origin>4054839</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="46" sha1="jjii0k6eakxe7a6yfrwiwe4sgs54zj3" xml:space="preserve">[[Category:portail]]

=== Pôle Prestation ===</text>
      <sha1>jjii0k6eakxe7a6yfrwiwe4sgs54zj3</sha1>
    </revision>
  </page>
  <page>
    <title>Eclipse</title>
    <ns>0</ns>
    <id>75</id>
    <revision>
      <id>4056880</id>
      <parentid>4037422</parentid>
      <timestamp>2020-01-27T10:41:36Z</timestamp>
      <contributor>
        <username>Collign</username>
        <id>9</id>
      </contributor>
      <origin>4056880</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1962" sha1="qkz84jir6dseu43p46tbtmg8dso5mcr" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Eclipse
 | logo              = Eclipse juno spash.png
 | siteInternet      = http://www.eclipse.org
 | version           = 2018-09 (4.9.0)
 | plugins           = eGit ({{outil.egit.version}})&lt;br/&gt;m2e ({{outil.m2e.version}})
 | guideInstallation = Guide d'installation d'éclipse
 | supportTechnique  = http://eforum.uem.lan/viewforum.php?f=16
 | faq               = [[FAQ:Eclipse|FAQ Eclipse]]
}}

[[Category:outil]]
[[Category:eclipse]]

= Guide d'installation développeurs =

{{alert|texte=Si il venait à y avoir la release d'une nouvelle version d'Eclipse, cette procédure devra être réitérée.}}

Toute la procédure d'installation qui concerne les développeurs est située sur la page du [[Guide d'installation d'éclipse]]

= Guide d'utilisation =

Pour les néophytes qui ont toujours travaillé avec d'autres IDE où les vétérans qui ont besoin d'un rappel ; deux guides sur l'utilisation d'Eclipse sont disponibles :
* [[Guide d'installation d'un projet git avec eclipse]]
* [[Guide utilisateur Eclipse]]
* [[mettre à jour le JDK dans eclipse]]
* [[Guide Eclipse Photon]]

= Migration d'une version d'Eclipse à une autre (pour Usine Logicielle) =

La procédure de migration à été analysée et simplifiée pour le passage d'une version à un autre. Elle est décrite dans cette page wikipédia : [[Zip d'éclipse]]

= Support développeurs =

Le support est assuré par l'équipe "expert IDE". Elle peut-etre contactée via le forum : http://eforum.uem.lan/viewforum.php?f=16

= TODO Liste =

La [[Eclipse TODO Liste|page suivante]] regroupe la TODO liste des actions à effectuer sur le "packaging" eclipse développeur. Au bon vouloir de la communauté de réaliser ces actions.

= Liens externes =
* {{en}} [http://wiki.eclipse.org/Simultaneous_Release Roadmap]
* {{fr}} [http://thierry-leriche-dessirier.developpez.com/tutoriels/eclipse/raccourcis/ aide-mémoire des raccourcis d'Eclipse]</text>
      <sha1>qkz84jir6dseu43p46tbtmg8dso5mcr</sha1>
    </revision>
  </page>
  <page>
    <title>Git</title>
    <ns>0</ns>
    <id>53</id>
    <revision>
      <id>4069841</id>
      <parentid>4069840</parentid>
      <timestamp>2023-08-23T08:27:40Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <comment>/* Configuration de l'environnement Git */</comment>
      <origin>4069841</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3056" sha1="d6sfu9ipsykfo4mq3n8x6f5n0v4ub8p" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = git
 | logo              = logo_git.png
 | siteInternet      = http://git-scm.com
 | version           = {{outil.git.version}}
 | supportTechnique  = [[Vincent Poutissou]] (Metz) &amp;&amp; [[David Bodin]] (Paris) 
 | guideInstallation = Guide_d'installation_de_Git
 | faq               = [[FAQ:Git|FAQ Git]]
}}

Git est un logiciel de gestion de versions décentralisée. C'est un logiciel libre créé par Linus Torvalds, le créateur du noyau Linux, et distribué sous la GNU GPL version 2.

== Prérequis et Installation == 

Besoin de suivre le [[Guide d'installation de Git]] et [[Gestion des droits des référentiels Git|avoir les droits sur le référentiel Git comme publicateur ou relecteur]].

== Configuration de l'environnement Git ==

Avant de vous lancer dans le développement, vous devez vous assurer que Git est bien opérationnel. Pour se faire, voici la liste des pages que vous devez

* '''[[Guide_de_configuration_du_poste_développeur_pour_Gerrit|Configuration générale GIT/GERRIT]]''' : La configuration globale à mettre en place ;
* Configurer le proxy :
 git config --global http.proxy http://bouthino:password@lpsrvpxy:8080

== Guides ==

* '''[[Guide cas d'utilisation]]''' : liste des cas d'utilisation utiles pour les développeurs efluid ; à ajouter / modifier au fil du temps !
* '''[[Guide_d'installation_d'un_projet_git_avec_eclipse|Guide d'installation d'un projet Git]]''' : comment installer un projet git dans Eclipse (clone du projet, ajout dans Eclipse et configuration)
* [[Utiliser une branche locale]]
* [[Deplacer des sources dans un nouveau repository]]
* [[Guide d'installation sur Linux]] : installation de git sous Linux
* [[Astuces GIT]] astuces git pour utilisateur avancé

== Formation ==

L'assistance Git est prise en charge par les référents gerrit. Ils sont indiqués dans la section [[Gerrit#Formation"|"formation"]] de la page [[Gerrit]].


Voici différents supports pour vous former à utiliser Git :
{{Modèle:formation_git}}

== Mise à jour Usine logicielle ==

# déposé le tar.gz dans artifactory, ext-release-local/git/
# Mise à jour des images dans etools en commençant par socle-jenkins/base
# puis de la version de ces images dans la sharedLibrary (vars/variables.groovy)

== Liens externes ==
* [https://github.com/ineat/refcards/blob/master/git/FR.md guide]
* [http://www.cheat-sheets.org/saved-copy/git-cheat-sheet.pdf http://www.cheat-sheets.org/saved-copy/git-cheat-sheet.pdf]
* [http://www.ndpsoftware.com/git-cheatsheet.html#loc=workspace git-cheatsheet]
* [http://pcottle.github.io/learnGitBranching/ Tutorial graphique]
* [http://www.alexgirard.com/git-book/index.html Documentation en français]
* [http://gitignore.io http://gitignore.io]
* [https://delicious-insights.com/fr/articles/bien-utiliser-git-merge-et-rebase/ Rebase]

== Archives ==
* [[Liste des actions à effectuer lors de la création d'une nouvelle branche de maintenance]]
* [[FAQ:MSysGit#Comment_mettre_des_alias_pr.C3.A9sent_en_permanence_.3F|Les alias GIT]]</text>
      <sha1>d6sfu9ipsykfo4mq3n8x6f5n0v4ub8p</sha1>
    </revision>
  </page>
  <page>
    <title>Maven</title>
    <ns>0</ns>
    <id>141</id>
    <revision>
      <id>4069756</id>
      <parentid>4069751</parentid>
      <timestamp>2023-08-14T11:51:33Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Montée de version dans l'usine logicielle */</comment>
      <origin>4069756</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3843" sha1="c84h5t858kw6r0ab8heqpqxcdjqyg8r" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = maven
 | logo              = logo_maven.png
 | siteInternet      = http://maven.apache.org
 | version           = {{outil.maven.version}}
 | supportTechnique  = {{usinelogicielle|subject=maven}}	
 | guideInstallation = Guide d'installation de maven
 | faq               = [[FAQ:Maven|FAQ Maven]]
}}

[[Category:maven]]

== Guide d'utilisation ==
* [[Guide_d%27installation_de_maven|Guide d'installation]]
* [[Description Maven des projets de la suite efluid|Profils et architecture Maven suite efluid]]
* [[Livraison des briques logicielles]]
* [[artifactory|Le référentiel artifactory]]
* [[Usine logicielle|L'usine logicielle]]

== Les plugins Maven ==
* [[Maven - Description des plugins efluid]]
* [[Synthèse des modifications effectuée sur des plugins maven existants]]

== La gestion des projets avec Maven ==
* [[Gestion des versions|La gestion des versions des applications de la suite efluid]]
* [[Génération automatique des extracteur/injecteur]]
* [[Maven:Synthèse des actions réalisées|Synthèse des actions réalisées]]
* [[Projet_com.efluid:efluid-ear-statefull:ear:12.2.0_%28artifactory%29|Dépendances efluid]]
* [[Guide de migration developpeur pour les projets sur le socle technique V14]]

== Formation ==
{{Modèle:formation_maven}}

== TODO liste ==

* Suivre l'avancée du bug suivant : http://jira.codehaus.org/browse/MASSEMBLY-578
* Suivre l'avancée de la demande pour le plugin dependency : http://jira.codehaus.org/browse/MDEP-135
* Fournir des commandes maven permettant de supprimer des artifacts du referentiel (exemple : supprimer des RC framework qui ne servent plus)
* Mettre en place une politique de suppression des artifacts snapshots qui ne servent plus sur artifactory
* Mettre en place un job de rollback pour les releases sur HUDSON (revert commit GIT, suppression du tag distant + sur local sur le serveur + suppression des artifacts déja uploadé (optionnel) )
* Gérer le lancement de map4J avec des jars de DEV (exemple : ecore-jar-DEV)

== Liens externes ==
* {{fr}} [http://maven-guide-fr.erwan-alliaume.com/maven-guide-fr/site/reference/public-book.html Maven: The definitive Guide]
* {{en}} [http://www.sonatype.com/books/mvnref-book/reference Sonatype Maven book reference]
* {{en}} [http://mvnrepository.com Repository central Maven]
* {{en}} [http://jarfinder.com Jar Finder] - [http://www.findjar.com/plugin.x plugin Eclipse], [https://addons.mozilla.org/de/firefox/addon/11961 plugin Firefox]

== Montée de version dans l'usine logicielle ==

# télécharger le binaire tar.gz pour linux https://maven.apache.org/download.cgi?.
# déposé le binaire dans artifactory : ext-release-local/org/apache/maven/&lt;version&gt; + ext-release-local/socle-provisionning/archive/
# généré un repo minimal maven : https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinelogiciellerelease/job/FjobsUtilitaires/job/Fmaven/job/maven.build-repo-minimal-for-applications-maintenance
# généré un rpm https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinelogiciellerelease/job/Ftools/job/Fetools/job/etools-rpm-apache-maven.release/ peut nécessiter une modification dans etools)
# mettre à jour les images dans etools, par exemple https://gerrit.efluid.uem.lan/c/etools/+/299767 et https://gerrit.efluid.uem.lan/c/etools/+/299795
# mettre à jour le pom parent : https://gerrit.efluid.uem.lan/c/efluidUtilsPom/+/308542
# mettre à jour les images batch et embeddded : https://gerrit.efluid.uem.lan/c/scriptInstalleur/+/300256
# mettre à jour dans le provisionning

== Archives ==
* [[Modification des POM avant livraison d'une application]]
* [[Livraison efluid mode IT]]
* [[Gestion des versions Maven par l'IT|La mise à jour des versions des applications après chaque ramassage par l'IT]]
* [[Matrice d'intégration de Maven dans les projets]]</text>
      <sha1>c84h5t858kw6r0ab8heqpqxcdjqyg8r</sha1>
    </revision>
  </page>
  <page>
    <title>Archive : Hudson</title>
    <ns>0</ns>
    <id>144</id>
    <revision>
      <id>1053757</id>
      <parentid>1053755</parentid>
      <timestamp>2015-09-28T08:34:06Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <minor/>
      <comment>Dmytryk a déplacé la page [[Hudson]] vers [[Archive : Hudson]]</comment>
      <origin>1053757</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1366" sha1="t8g8p8ney70tloizp07y4nt11ieev9b" xml:space="preserve">{{Modèle:Infobox Outil
 | nom              = hudson
 | logo             = logo_hudson.png
 | siteInternet     = http://hudson-ci.org
 | version          = {{outil.hudson.version}}
 | supportTechnique  = [[Thomas COLLIGNON]]
 | guideInstallation = Guide d'installation d'hudson
 | faq               = [[FAQ:Hudson|FAQ Hudson]]
}}
[[Category:archive]]
[[Category:hudson]]

Hudson est un outil d'intégration continue, il permet :
* de compiler de manière régulière le code des différents applications
* de déployer automatique les envirronements [[nightly-build]] 
* de lancer de manière régulière les tests unitaires

= comment lancer le build d'un projet =

Les builds sont lancés automatiquement; il est néanmoins possible de demander un build d'une grande partie des projets de l'usine logicielle; pour celà, voici comment procéder :
# s'authentifier auprès de l'Usine Logicielle (lien [http://usinelogicielle/login?from=%2F S'identifier] en haut à droite de [http://usinelogicielle la page de l'usine logicielle],
# sélectionner le projet sur lequel un build doit être lancé,
# lancer le build.
[[Image:Hudson Build Howto.png]]

= liens =
== externes ==
* {{en}} http://jenkins-ci.org (Suite au rachat de Sun par Oracle, il existe un fork Open Source)
* {{en}} http://hudson-ci.org
* {{en}} [http://www.eclipse.org/hudson/hudsonbook hudson book]</text>
      <sha1>t8g8p8ney70tloizp07y4nt11ieev9b</sha1>
    </revision>
  </page>
  <page>
    <title>Sonar</title>
    <ns>0</ns>
    <id>367</id>
    <revision>
      <id>4065588</id>
      <parentid>3749785</parentid>
      <timestamp>2021-09-07T08:49:10Z</timestamp>
      <contributor>
        <username>Carriers</username>
        <id>234</id>
      </contributor>
      <comment>/* Description */</comment>
      <origin>4065588</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6744" sha1="2w3em24znonb9u2puiqrittl3ecycbv" xml:space="preserve">{{Modèle:Infobox Outil
 | nom              = sonar
 | logo             = logo_sonar.png
 | siteInternet     = http://www.sonarsource.org
 | version          = 3.4.1
}}

== Description ==
Evènement suivefluid permanent : 152972

Sonar est une application de qualimétrie du code source : elle permet d'analyser le code source, de vérifier le respect des bonnes pratiques et d'agréger les résultats de ces analyses. 

Sonar est disponible à cette url : http://especteur/.

Sonar application permet de :
* Connaître les violations des règles de codage détectées dans le code (CheckStyle et PMD)
* Visualiser le code source où chaque violation est détectée
* Suivre dans le temps l’évolution des violations dans le temps

Vous trouverez pour chaque application et chaque domaine fonctionnel d’efluid un tableau de bord réunissant toutes les informations issues de l’analyse du code (Checkstyle et PMD). Sur cette page de synthèse, les fonctions les plus intéressantes sont les suivantes :
* Violation drilldown : qui donne la liste des violations des règles checkstyle et pmd, ainsi qu’une vue vers le code source correspondant
* Time machine : qui donne l’évolution des chiffres du projet, notamment l’évolution du nombre de violations checktyle et pmd dans le temps

Cette application propose d'autres fonctionnalités qui ne sont pas encore mises en œuvre. C’est pourquoi il n'est pas utile de prêter attention aux chiffres suivants sur la page de synthèse de chaque projet :
* Rule compliance : le chiffre avoisine toujours les 100 % quel que soit le nombre de violations
* Duplications : les copiés / collés ne sont pas comptabilisés 

Ci-dessous, voici l’exemple d’un tableau de bord avec en vers ce qui est particulièrement intéressant, et barré en rouge les chiffres à ne pas prendre en compte.

[[Fichier:Sonar_example.jpg]]

== Liste des packages par domaine ==
* efluid/ecore : [[Liste_des_packages_efluid|Efluid package/domaine]]

== Liste des responsables sonar ==

{| align="center"
|&lt;!-- Résultat affiché --&gt;
{| class="wikitable sortable"
|-
! Projet sonar
! Responsable
|-
| efluid efluid
| 
|-
| efluid cac-ic
| [[XBL]]
|-
| efluid consommation
| [[JTA]]
|-
| efluid crm-contrat
| [[TBO]]
|-
| efluid crm-referentiel
| [[KST]]
|-
| efluid echange
| [[CLR]]
|-
| efluid facturation
| [[JFL]],[[DBO]]
|-
| efluid intervention
| [[BDA]]
|-
| efluid offre-moteur
| [[PWE]]
|-
| efluid portail
| [[ADM]]
|-
| efluid relance-contentieux
| 
|-
| efluid technique
| 
|-
| efluid workflow
| [[CBO]]
|}
|&lt;!-- Codage wiki --&gt;
{| class="wikitable sortable"
|-
! Projet sonar
! Responsable
|-
| ecore
| 
|-
| ecore actionpredefinie
| 
|-
| ecore campagne
| 
|-
| ecore courbe
| 
|-
| ecore editique
| [[CLA]]
|-
| ecore referentiel
| [[KST]]
|-
| ecore valorisation
| [[CFO]]
|-
| ecore workflow
| [[CBO]]
|}
|&lt;!-- Codage wiki --&gt;
{| class="wikitable sortable"
|-
! Projet sonar
! Responsable
|-
| efluidEDKWarDebug
| [[CLR]]
|-
| efluidnet
| [[CLR]]
|-
| efluidpub
| [[CLR]]
|-
| ael
| [[ADM]]
|-
| ebuild
| 
|-
| edoc
| [[ADM]]
|-
| eldap
| [[ADM]]
|-
| enercom
| 
|-
| ethaque
| [[CLEM]]
|-
| HermesArchiWarDebug
| 
|-
| suivefluid
| [[DFE]]
|}
|}

== Evolutions Réalisées ==

* [[Utilisateur:Stein|Kilian Stein]] 28 fevrier 2013 à 12:00 (CET) : Migration sonar 2.9 serveur Windows vers 3.4 serveur Linux, voir nouvelles fonctionnalités : [http://eforum.uem.lan/viewtopic.php?f=33&amp;t=579 Annonce forum sonar 3.4]
* [[Utilisateur:Stein|Kilian Stein]] 12 mars 2013 à 09:16 (CET) : Rajout du seuil d'alerte rouge pour les violations : Permet de dissocier les violations des problèmes de Tests unitaires


== À faire ==

=== Projets en cours ===

{| class="wikitable sortable"
|-
! Sujet
! Demande initiée par
! Personne en charge du projet
! Action à mener
! Priorité
|-
|Voir les TU qui ne sont pas à 100%
|[[ADU]]
|[[ADU]]
|
|{{rouge|Haute}}
|-
|Correction des couvertures de code à 0%
|[[ADU]]
|[[ADU]]
|Voir si jacocco fonctionne mieux
|{{rouge|Haute}}
|-
|Correction des domaines sur ecore et énercom
|[[ADU]]
|[[ADU]]
|Voir version Sonar 3.5 pour faire les inclusions (virer les trucs du wiki)
|{{rouge|Haute}}
|-
|Mise à jour des noms des projets "archi" et "EDK"
|[[ADU]]
|[[ADU]]
|Attention aux impacts !
|{{vert|Basse}}
|-
|Ajouter des filtres pour les projets / sous-projets
|[[ADU]]
|[[ADU]]
|Déjà un premier travail de fait sur le filtre avec les métriques manuelles ; à priori ça fonctionne
|{{jaune|Moyenne}}
|-
|Passer l'analyse de couverture de code sur Jacoco
|[[ADU]]
|[[ADU]]
|Voir le job d'énercom qui fonctionne comme ça (d'ailleurs ça ne fonctionne pas...)
|{{jaune|Moyenne}}
|-
|Mettre en place une analyse pour les TI
|[[KST]]
|[[KST]]
|
|{{jaune|Moyenne}}
|-
|Changer le profil "test-unitaire" en "sonar"
|[[ADU]]
|[[ADU]]
|
|{{vert|Basse}}
|-
|Présenter les revues de code via Sonar au CT
|[[ADU]]
|[[ADU]]
|
|{{rouge|Haute}}
|-
|Rajouter les utilisateurs en user dans le LDAP
|[[KST]]
|[[KST]]
|
|{{rouge|Haute}}
|-
|Administrer le bouton des faux-positif
|[[KST]]
|[[KST]]
|Voir [http://jira.codehaus.org/browse/SONAR-2447 http://jira.codehaus.org/browse/SONAR-2447]
|{{jaune|Moyenne}}
|-
|Faire installer le plug-in Sonar dans Eclipse (à présenter CT ?)
|[[KST]]
|[[KST]]
|Pour voir les violations comme des warnings (et par la suite gérer les revues de code !?)
|{{rouge|Haute}}
|-
|Créer une nouvelle instance de Sonar pour s'exécuter sur les branches de dev
|[[KST]]
|[[KST]]
|Pour éviter de commiter des violations
|{{vert|Basse}}
|-
|Tester la version 3.5
|[[KST]]
|[[KST]]
|
|{{vert|Basse}}
|-
|Proposer de nouvelles règles au CT
|[[KST]]
|[[KST]]
|
|{{vert|Basse}}
|}

== FAQ ==

=== Quèsaco qu'un responsable sonar ? ===
C'est la personne qui est chargée de s'assurer de la bonne correction des nouvelles violations sonar. Il se verra octroyer le droit de déclarer dans son domaine des "faux positifs"

=== Comment déclarer un faux positif ? ===
Une fois connecté à sonar, un bouton "faux positif" apparaitra au niveau de la page des violations. Ne pas oublier de remplir la raison de cette déclaration (obligatoire). 

Pour les projets efluid et ecore, il ne faut pas oublier de déclarer les "faux positif" une deuxième fois sur les projets mères : "efluid efluid" et "ecore"

=== Dois-je déclarer tous mes warnings sonar en tant que faux-positif pour faire baisser les statistiques de mon domaine ? ===
Surtout pas, la déclaration en tant que "faux positif" doit être réalisée quand il n'y a pas d'autre solution. C'est souvent due à l’algorithme de la détection des violations : il détecte des violations là où il ne devrait pas.

== Liens ==

* http://especteur/

[[Category:outil]]
[[Category:sonar]]</text>
      <sha1>2w3em24znonb9u2puiqrittl3ecycbv</sha1>
    </revision>
  </page>
  <page>
    <title>Selenium</title>
    <ns>0</ns>
    <id>603</id>
    <revision>
      <id>14737</id>
      <parentid>10407</parentid>
      <timestamp>2012-07-27T14:32:46Z</timestamp>
      <contributor>
        <username>Dubreui</username>
        <id>76</id>
      </contributor>
      <comment>/* Selenium 2 */</comment>
      <origin>14737</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5961" sha1="8quc6w1hmdyrrdorddyxklobp55b255" xml:space="preserve">{{Modèle:Infobox Outil
 | nom              = selenium
 | logo             = big-logo.png
 | siteInternet     = http://seleniumhq.org
 | version          = indigo JEE 3.7
 | plugins          = eGit (V1.0)&lt;br/&gt;m2e (V1.0)
}}

[[Category:outil]]
[[Category:selenium]]
[[Category:test]]

= Documentation =

La documentation pour Selenium est la suivante :

*[[Guide utilisateur Selenium|Guide utilisateur Selenium]]
*Documents disponibles sur eRoom : http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_85c8a

Et pour la documentation sur l'implémentation dans ecore, concernant les classes utilitaires et les bonnes pratiques, est située sous eroom : http://wperoom1/eRoomReq/Files/Production/DocTechniqueEfluid/0_894de/DCTCPT%20-%20Ecore%20-%20Selenium.doc

Pour le forum : http://rphpbb/viewtopic.php?f=24&amp;t=135&amp;sid=720eb981e74fd9d3128cefa1c8b6d39e

= Plugin Firefox : Selenium IDE =

Un plugin Firefox permet d'enregistrer les clicks utilisateur dans l'IHM, puis les convertir en tests Java JUnit. Il est à noter que les tests sont enregistré dans Firefox, mais notre but est de les rejouer dans IE. Les particularités de cette pratique sont mentionnées ici-bas.

http://seleniumhq.org/projects/ide/

'''Pour la compatibilité du plugin sélénium IDE avec firefox 4 il faut installer le plug-in suivant :''' 
https://addons.mozilla.org/en-US/firefox/addon/add-on-compatibility-reporter

{| class="wikitable centre" border="1"
!download
|[http://seleniumhq.org/download/ http://seleniumhq.org/download/]
|-
!plugin eclipse
|[http://cubictest.seleniumhq.org/ http://cubictest.seleniumhq.org/]
|}

== Utilisation plugin ==

* '''IE lors du lancement du test deux fois de suite'''

{|
&lt;pre&gt;
open jsp/arc/commun/images/general/accueilUEM.jpg
open jsp/arc/commun/frame.jsp
&lt;/pre&gt;
|}

* '''Selectionner une Frame'''

{|
&lt;pre&gt;
selectFrame relative=top
selectFrame bas (ou haut selon le cas...)
&lt;/pre&gt;
|}

* '''Attendre l'affichage du bandeau du haut'''

{|
&lt;pre&gt;
waitForElementPresent //a[@id='client']
&lt;/pre&gt;
|}

* '''Sélectionner un élément du menu'''

{|
&lt;pre&gt;
selectFrame relative=top
selectFrame haut
waitForElementPresent //a[@id='menuGeneral']
click //a[@id='menuGeneral']
waitForPopup
selectPopup
clickAndWait //a[@id='rechercheContrat']
selectWindow
selectFrame relative=top
selectFrame bas
&lt;/pre&gt;
|}

* '''Cliquer sur un onglet (exemple pour "service")'''

{|
&lt;pre&gt;
clickAndWait //td[@class='titreOngletOff']/a[contains(text(),'service')]
&lt;/pre&gt;
|}

* '''Sélectionner un lien d'un menu caché (rôle)'''

{|
&lt;pre&gt;
clickAndWait //div[@id='Popup2']/table/tbody/tr[2]/td/a
&lt;/pre&gt;
|}

* '''Emplacement dans CVS pour les fichiers Selenium JUnit'''

{|
&lt;pre&gt;
test/[package fonctionnel]/seleniumTest
&lt;/pre&gt;
|}

== Conversion en tests unitaires ==

Une fois le test enregistré, il suffit de le convertir en Java. Il est aussi possible de tout écrire les tests en Java, sans l'aide du plugin (plus rapide). Dans la classe abstraite SeleniumTestCase, il a plusieurs méthodes qui automatisent les tests. Cette classe se charge de :

* Configurer le serveur sur lequel lancer le test et avec quel navigateur
* Gérer l’authentification à l’application (le login) entre les tests : si l’utilisateur est déjà authentifié, ne refait pas l’authentification, sinon fait le login avec les valeurs définies dans le fichier de propriétés
* Fournir des méthodes utilitaires pour les traitements de base et récurrents

De plus, certaines actions ne sont pas bien gérées par l’enregistrement via le plugin Firefox. Dans ces cas, il faut utiliser ces méthodes préexistantes afin de normaliser l’application des tests. Pour choisir un menu (un bouton) dans la barre supérieure, utiliser :
 
 choisirMenu(String)

Pour choisir un cadre (cadre haut ou cadre bas), utiliser :

 choisirCadre(String)

Pour ouvrir le menu général (bouton « menu ») et naviguer à l’intérieur, utiliser :
 
 ouvrirMenuGeneral()
 choisirOngletDansPopup(String) 
 choisirLienDansPopup(String)

Pour sélectionner un objet dans une page (recherche, tableau, etc.), utiliser : 

 selectionnerBusinessObject(BusinessObject)

Pour faire des clicks sur les boutons standards de l’architecture, utiliser : 

 annuler()
 modifier()
 finaliser()

=== Classe RechercherSeleniumTestCase ===

Classe utilitaire fait le zoom automatique sur la bonne page de recherche automatiquement.

=== Classe ZoomerSeleniumTestCase ===

Cette classe utilitaire fait le zoom automatique sur l'objet en passant par la page de recherche.

= Serveur Selenium : Selenium RC =

Il existe aussi une version serveur Selenium RC (Remote control) qui permet d'exécuter les scripts sur tous les navigateurs.

http://seleniumhq.org/projects/remote-control/

= Selenium 2 =

&lt;span style="background-color:yellow"&gt;TODO ADU&lt;/span&gt; revoir cette page

Screenshots

* http://code.google.com/p/selenium/issues/detail?id=3536
* http://stackoverflow.com/questions/1260106/selenium-run-as-a-windows-service-to-take-screenshots-on-errors
* http://stackoverflow.com/questions/8963045/selenium-2-webdriver-taking-a-screenshot-returns-a-black-image

Ces 3 sites décrivent comment utiliser Selenium 2 avec Maven et du vieux code : 

* http://selftechy.com/2011/06/07/selenium-2-with-junit4-create-tests-generate-reports
* http://seleniumhq.wordpress.com/2010/07/30/how-to-use-selenium-2-with-maven/
* http://seleniumhq.org/download/maven.html
* http://stackoverflow.com/questions/5094598/selenesetestcase-is-deprecated-how-to-call-verify-methods

Impossible de traiter les fenêtres modales, sauf en "hackant" le code de hermes : 

* http://stackoverflow.com/questions/866856/how-do-i-test-modal-dialogs-with-selenium
* http://seleniumdeal.blogspot.com/2009/01/handling-modal-window-with-selenium.html
* Bug : http://code.google.com/p/selenium/issues/detail?id=27

Pour le clic sur le poste de BBU : 

* http://stackoverflow.com/questions/4667048/cant-click-button-which-opens-file-attachment-dialog</text>
      <sha1>8quc6w1hmdyrrdorddyxklobp55b255</sha1>
    </revision>
  </page>
  <page>
    <title>Documentation Eroom</title>
    <ns>0</ns>
    <id>599</id>
    <revision>
      <id>4068941</id>
      <parentid>62214</parentid>
      <timestamp>2023-04-05T12:51:43Z</timestamp>
      <contributor>
        <username>Delapor</username>
        <id>761</id>
      </contributor>
      <minor/>
      <comment>Delapor a déplacé la page [[Eroom]] vers [[Documentation Eroom]]</comment>
      <origin>62214</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1662" sha1="6peqygb44wvb9qwoprnpbcceiw82xag" xml:space="preserve">{{Modèle:Infobox Outil
 | nom              = eroom
}}

[[Category:outil]]
[[Category:eroom]]
[[Catégorie:documentation]]

{{...}}

= FAQ =
===== Comment rechercher le chemin d'un fichier dans eRoom après une recherche ? =====
Après avoir lancer la recherche, cliquer sur "plus d’options", puis depuis la colonne "Trouvé dans", cliquer sur le lien correspondant : &lt;br/&gt;
[[image:eroom.png]]

===== Comment visualiser un calendrier eroom dans outlook ? =====

Pour visualiser les calendriers eroom avec Outlook :

* Tout d'abord s'assurer que le superviseur eroom est installé (installation automatique en se rendant sur eroom) et démarré (icône dans la zone de notification). S'il n'est pas démarré le démarrer. S'il ne démarre pas le désinstaller puis le réinstaller.

* Créer un calendrier dédié (la sync ne marche pas avec le calendrier principal) : en mode Calendrier dans outlook : ficher -&gt; nouveau -&gt; calendrier :
[[Fichier:2013-08-28 15 43 01-Créer un dossier.png]]

* Faire un clic droit sur l’icône Superviseur Eroom puis paramètres : &lt;br/&gt;
[[image:FAQ eroom - Faire un clic droit sur l’icône Superviseur Eroom.png]]

* Puis ajouter et cocher le dossier événement à synchroniser de votre ou vos room(s) : &lt;br/&gt;
[[image:FAQ eroom - Ajouter le dossier événement à synchroniser.png]]
[[image:FAQ eroom - Cocher le dossier événement à synchroniser.png]]

* Puis cliquer sur le bouton Avancé et remplir la partie en rouge : &lt;br/&gt;
[[image:FAQ eroom - Cliquer sur le bouton Avancé.png]]

* Fermer toutes les fenêtre avec le bouton OK.

Les événements seront dupliqués dans l’agenda Outlook.

(merci à Eric Feuvraux)</text>
      <sha1>6peqygb44wvb9qwoprnpbcceiw82xag</sha1>
    </revision>
  </page>
  <page>
    <title>Tomcat</title>
    <ns>0</ns>
    <id>864</id>
    <revision>
      <id>4069674</id>
      <parentid>4069673</parentid>
      <timestamp>2023-07-28T06:46:43Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Mise à jour de la version dans l'Usine logicielle */</comment>
      <origin>4069674</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2338" sha1="d42fs7bm978vuw4hmqhlpfrynswxxi1" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = tomcat
 | siteInternet      = [http://tomcat.apache.org apache tomcat]
 | version           = {{outil.tomcat.version}}
 | guideInstallation = Guide d'installation de tomcat
}}

Le choix de la version de tomcat à utiliser sur le poste de développement est à corréler avec la matrice de compatibilité de la version de l'application concernée.

== Parametrage du serveur tomcat pour les JSP ==

{{tomcat.parametrage.Jsp}}

== Serveur Tomcat ligne de commande ==

=== Démarrage et arrêt ===

Pour démarrer le serveur Tomcat en ligne de commande, il suffit de naviguer jusqu'au dossier d'installation et d'exécuter "startup.sh" ; pour l'arrêter utiliser "shutdown.sh". Le serveur sera démarré par défaut sur le port 8080 (http://localhost:8080).

&lt;source lang="bash"&gt;
cd /home/alexandre.dubreuil/programs/tomcat/apache-tomcat-&lt;TOMCAT_VERSION&gt;/bin
./startup.sh
ps aux | grep java
     5492       1    1192       6576  pty0    17780 10:31:50 /cygdrive/d/programs/jdk/jdk&lt;JDK_VERSION&gt;/bin/java
&lt;/source&gt;

=== Utilisateur ===

Pour utiliser l'IHM, il faut configurer un utilisateur faisant parti du groupe "manager-gui". Il faut éditer le fichier "conf/tomcat-user.xml"

&lt;source lang="bash"&gt;
cd /home/alexandre.dubreuil/programs/tomcat/apache-tomcat-&lt;TOMCAT_VERSION&gt;/conf
vim tomcat-user.xml
&lt;/source&gt;

Ajouter cette ligne dans "tomcat-users" avec un nom d'utilisateur et mot de passe arbitraire.

&lt;source lang="xml"&gt;
&lt;user username="tomcat" password="tomcat" roles="manager-gui"/&gt;
&lt;/source&gt;

= FAQ = 

== Mise à jour de la version dans l'Usine logicielle ==

* déposé le binaire dans artifactory, dépôt ext-releases-local
* Mettre à jour les licences : par exemple https://gerrit.efluid.uem.lan/c/archi/+/239072
* Mettre à jour l'image Docker : par exemple https://gerrit.efluid.uem.lan/c/etools/+/239073
* Mettre à jour le pom parent: par exemple https://gerrit.efluid.uem.lan/c/efluidUtilsPom/+/239074
** Redescendre le pom parent dans archi : par exemple https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinelogiciellerelease/job/Ftools/job/FefluidUtilsPom/job/application.update-version-efluid-parent-pipeline/
** Valider les changes ainsi générés
* Mettre à jour la version dans le wiki : [[Mod%C3%A8le:Outil.tomcat.version]]

[[Category:outil]]
[[Category:tomcat]]</text>
      <sha1>d42fs7bm978vuw4hmqhlpfrynswxxi1</sha1>
    </revision>
  </page>
  <page>
    <title>Map4J</title>
    <ns>0</ns>
    <id>955</id>
    <revision>
      <id>3904005</id>
      <parentid>3904004</parentid>
      <timestamp>2018-03-22T17:28:36Z</timestamp>
      <contributor>
        <username>Abdelka</username>
        <id>208</id>
      </contributor>
      <comment>/* Variables d'environnement */</comment>
      <origin>3904005</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2487" sha1="kf7031f66wmu89e9q2qheshf7zlg6bv" xml:space="preserve">[[Category:outil]]
[[Category:Map4J]]
{{...}}

Map4J est un logiciel servant à automatiser la génération des classes de mapping. Il permet de réaliser rapidement le portage des créations/modifications d'attributs dans les classes d'objet métier efluid vers les classes du [[modèle Edk]].
= Guide d'utilisation = 
== Variables d'environnement ==
Il faut positionner sur son poste les variables suivantes : 
 JAVA_HOME=D:\Programs\jdk\jdk{{outil.jdk.version}}
 --- obsolète ANT_HOME=D:\Programs\ant ---

Sinon map4J ne fonctionnera pas.

== Customisation développeur ==
Si un développeur veut customiser le script de lancement de map4J, il faut créer et valoriser le fichier suivant : 
 &lt;PROJET&gt;/map4j/scripts2/initialiserDev.cmd

== Clone sur emplacement particulier ==
Suite à un clone sur une branche de dev particulière dans un repertoire particulier (différent de developpement_dev), il faut mettre à jour :
* le fichier projet .mpj également avec le bon répertoire (13 remplacements)

= Architecture de map4J-launcher =
* Dans les projets le script Map4J.bat va récupérer la version de map4J-launcher.zip via la variable map4J.version définie dans le POM parent.
* Ensuite Map4J.bat va dézipper map4J-launcher.zip puis va lui donner la main en appelant le script map4J-run.cmd.
* A partir de la map4J-run.cmd va appeler initialiserLibMaven.cmd dans le projet afin de provisionner le dossier &lt;PROJET&gt;/lib dans lequel les fichiers de mapping pourront sourcer les jars (ecore, edk, etc...)
* Ensuite map4J-run.cmd va appeler initialiserSklSql.cmd dans le projet afin de récupérer les fichiers skl, sql et mapping des briques.
* Ensuite map4J-run.cmd va appeler initialiserVersionJdk.cmd permettant de valoriser la bonne version de JDK en fonction de ce qui est défini dans le POM du projet.
* Ensuite map4J-run.cmd va appeler initialiserLibMap4J.cmd afin de provisionner les jars permettant le lancement de map4J.
* Ensuite map4J-run.cmd va appeler scripts2\initialiserDev.cmd s'il existe afin de permettre une customisation du script de lancement par le développeur.
* Enfin map4J-run.cm va construitre le classpath de map4J, et va le démarrer avec les options de JVM par défaut définie dans ce scripts.

= Liens utiles =
* [[Configurer un Maven Build pour l'import de ressources|Tâche maven de récupération des skeleton]]
* [[MAJ_ParametrageDB_MAP4J|Paramétrage DB]]
* [[Mapping]]

= Archives =
* [[Utiliser_Map4J_avec_Maven|Utiliser map4J avec Maven]]</text>
      <sha1>kf7031f66wmu89e9q2qheshf7zlg6bv</sha1>
    </revision>
  </page>
  <page>
    <title>Beyond compare</title>
    <ns>0</ns>
    <id>957</id>
    <revision>
      <id>703172</id>
      <parentid>21934</parentid>
      <timestamp>2015-03-18T09:33:42Z</timestamp>
      <contributor>
        <username>Collign</username>
        <id>9</id>
      </contributor>
      <origin>703172</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1189" sha1="92bqdb9x0g1wycvpju3wjtemfd5lsr9" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = beyond compare
 | siteInternet      = http://www.scootersoftware.com
 | version           = {{outil.beyondCompare.version}}
 | guideInstallation = Guide d'installation de beyond compare
}}

[[Category:outil]]
[[Category:beyond compare]]
Comparateur de fichier.

= Utilisation de beyon compare avec [[msysgit]] =
Pour configurer Beyond compare avec [[msysgit]], il faut ajouter les paramètres suivants dans le fichier &lt;tt&gt;C:\Users\&lt;USER&gt;\.gitconfig&lt;/tt&gt;

Depuis la version '''1.7.4 de''' Git (le paramétrage du merge n'est disponible qu'avec la version PRO de beyond compare) :
&lt;source lang="properties"&gt;
[diff]
	tool = bc3
[difftool "bc3"]
	path = D:/Programs/beyondcompare/bcomp.exe
[merge]
	tool = bc3
[mergetool "bc3"]
	path = D:/Programs/beyondcompare/bcomp.exe
[mergetool]
	keepBackup = false
&lt;/source&gt;
Avec les anciennes versions de git :
&lt;source lang="properties"&gt;
[diff]
    tool = bc3
[difftool]
    prompt = false
[difftool "bc3"]
    cmd = "\"D:/programs/beyondcompare/bcomp.exe\" \"$LOCAL\" \"$REMOTE\""
&lt;/source&gt;

== Liens externes ==
* {{en}} [http://www.scootersoftware.com/support.php?c=kb_vcs.php support de beyond compare]</text>
      <sha1>92bqdb9x0g1wycvpju3wjtemfd5lsr9</sha1>
    </revision>
  </page>
  <page>
    <title>Sql developer</title>
    <ns>0</ns>
    <id>600</id>
    <revision>
      <id>24983</id>
      <parentid>13267</parentid>
      <timestamp>2013-03-13T16:58:16Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>24983</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="730" sha1="8h2z8q8tr16ul2gv6dcisdeviiqpgef" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = sql developper
 | siteInternet      = [http://www.oracle.com/technetwork/developer-tools/sql-developer/overview/index.html sql developper]
 | version           = {{outil.sqldevelopper.version}}
 | guideInstallation = Guide d'installation de Sql developper
}}

[[Category:outil]]
[[Category:sql developper]]

{{...}}

== Liens internes ==
* [[Guide utilisateur SQL Developper]]
* [http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_84617 zip d'installation sur eRoom]
* [http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_1b4dc documentation du eRoom]
== Liens externes ==
* {{fr}} [http://blog.galsungen.net/?p=436 installer le driver MySQL pour SQL Developper]</text>
      <sha1>8h2z8q8tr16ul2gv6dcisdeviiqpgef</sha1>
    </revision>
  </page>
  <page>
    <title>Msysgit</title>
    <ns>0</ns>
    <id>857</id>
    <revision>
      <id>8088</id>
      <parentid>8087</parentid>
      <timestamp>2011-12-27T16:36:42Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <minor/>
      <comment>/* FAQ */</comment>
      <origin>8088</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="417" sha1="ez3yw3zvqzowbkux1fh2r3hzn9qi88z" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = MSysGit
 | guideInstallation = Guide d'installation de Git
 | faq               = [[FAQ:MSysGit|FAQ MSysGit]]
}}

[[Category:git]]
[[Category:msysgit]]

MSysGit est un émulateur Linux qui permet d’exécuter des commandes git dans un environnement Windows.

== Liens externes ==
* {{fr}} [http://abs.traduc.org/abs-5.0-fr/index.html guide d'écriture des scritps Bash]</text>
      <sha1>ez3yw3zvqzowbkux1fh2r3hzn9qi88z</sha1>
    </revision>
  </page>
  <page>
    <title>Artifactory</title>
    <ns>0</ns>
    <id>1043</id>
    <revision>
      <id>4067789</id>
      <parentid>4067644</parentid>
      <timestamp>2022-10-10T12:44:31Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Inventaire */</comment>
      <origin>4067789</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="17254" sha1="418bikmlg853n1h978qr3zg22awoyzc" xml:space="preserve">[[Category:outil]]
[[Category:artifactory]]
{{Modèle:Infobox Outil
 | nom               = artifactory
 | logo              = Artifactory.png
 | siteInternet      = http://www.jfrog.com/
 | version           = {{outil.artifactory.version}}
 | supportTechnique  = [[Samuel MARCAILLE]]
 | guideInstallation = Guide d'installation d'artifactory
 | faq               = [[FAQ:Artifactory|FAQ Artifactory]]
}}

== Description ==

Le logiciel Artifactory de JFrog est un gestionnaire de référentiels de binaires. C'est un des leaders de la gestion des repository pour Apache Maven, mais bien au-delà
de Maven, c'est l'entrepôt unique pour tous les artefacts d'une usine logicielle. Artifactory est capable de conserver de façon pérenne, distribuée et sécurisée tous vos
livrables. La traçabilité complète du cycle de vie des artefacts ainsi que leurs inter-dépendances est également assurée. L'ensemble des fonctions est accessible
nativement par Maven ou par des API type REST. Pour l'utilisateur et l'administrateur, Artifactory propose une application web conviviale pour effectuer toutes les 
opérations possibles sur les référentiels. 

== Inventaire ==

{| class="wikitable sortable"
|-
! Hostname !! Désignation !! Alias &amp; Proxy !! artifactory Version !! OS !! Docker version !! CPU !! RAM !! URL
|-
| lpartedt4[.efluid].uem.lan 
| Artifactory de prod interne
|| eartifact[.efluid].uem.lan : alias vers lrpxyifredt1.uem.lan lui même proxy (apache) vers lpartedt4.uem.lan

partifactorydocker[.efluid].uem.lan : alias de lpartedt4[.efluid].uem.lan (nginx)

|| 6.23.42
|| RH 7.9
|| 18.06.3
|| 12
|| 12 Go
|| https://eartifact.uem.lan/artifactory/
https://partifactorydocker.uem.lan/artifactory/

|-
| lpartedt1[.efluid].uem.lan 
| Artifactory de prod interne
|| eartifact[.efluid].uem.lan : alias vers lrpxyifredt1.uem.lan lui même proxy (apache) vers lpartedt1.uem.lan

partifactorydocker[.efluid].uem.lan : alias de lpartedt1[.efluid].uem.lan (nginx)

|| 7.35.2
|| RH 8.5
|| NA
|| 12
|| 10 Go
|| https://eartifact.uem.lan/artifactory/
https://partifactorydocker.uem.lan/artifactory/

|-
| lpartedt3[.efluid].uem.lan 
| Artifactory de prod public/frontal
|| pfroart1.uem.lan &amp; lpfrosfld1  : reverse proxy vers lpartedt3.uem.lan:8081

partifactorydockerpub.uem.lan : (uniquement UEM) alias de lpartedt3.uem.lan:443
&lt;br/&gt;'''attention''' : accessible depuis la DMZ MLD

depuis EDFSEI : 192.168.170.71 
|| 6.23.42
|| RH 7.5
|| 18.06.3
|| 4
|| 10 Go
|| http://pfroart1.uem.lan/artifactory/ 
https://partifactorydockerpub.uem.lan/

|-
| lpartedt2[.efluid].uem.lan 
| Artifactory de prod public/frontal
|| lpfrosfld3 : reverse proxy client et interne vers lpartedt2.uem.lan:8081/8082

partifactorydockerpub.uem.lan : (uniquement UEM) alias de lpartedt2.uem.lan:443
&lt;br/&gt;'''attention''' : accessible depuis la DMZ MLD

depuis EDFSEI : 192.168.170.71 
|| 7.35.2
|| RH 8.5
|| NA
|| 4
|| 6 Go
|| http://pfroart1.uem.lan/artifactory/ 
https://partifactorydockerpub.uem.lan/

|-
| lrartedt3[.efluid].uem.lan
| Artifactory de recette frontal/interne
|| artifactoryrec.efluid.uem.lan : alias vers lrpxyifredt1 redirection vers lrartedt3[.efluid].uem.lan:8082 
rartifactorydocker.efluid.uem.lan : alias lrartedt3[.efluid].uem.lan:443 
|| 7.41.7
|| RH 8.5
|| NA 
|| 2
|| 6 Go
|| https://artifactoryrec.efluid.uem.lan/artifactory/ 
https://rartifactorydocker.efluid.uem.lan/artifactory/

|}

== Configuration présente ==

sur le nfs du cluster kub

== Exploitation ==

=== Arrêt ===

Se connecter et passer '''artuser''', puis lancer la commande

 docker-compose stop -f /data/artifactory-pro-nginx-derby/docker-compose.yml

=== Démarrage ===

Se connecter et passer '''artuser''', puis lancer la commande

 docker-compose start -f /data/artifactory-pro-nginx-derby/docker-compose.yml

=== Opérations ===

sur [https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usineadministration/job/Fartifactory/ l'usine logicielle]

== Guide d'utilisation ==

* [[Crypter son mot de passe dans Artifactory]]
* [[Artifactory frontal|L'artifactory frontal (pour les clients)]]

== La gestion des repository ==

Voici un état des lieu de la gestion des repository d'artifactory : 

* '''docker-release-local''' : contient les images docker constitué au sein d'efluid
* '''libs-release-local''' : contient les binaires de la suite efluid livrés à l'état de release (ne changeront jamais après leur release - même en cas d'erreur, il faut versionner le jar ; on risque d'avoir des problèmes si la JAR a déjà été remonté sur un autre repository, par exemple un repository local)
* '''libs-snapshot-local''' : contient les binaires de la suite efluid livrés à l'état de snapshot(en cours de développement)
* '''repo1-cache''' : contient les jars extérieurs du repo Maven Central http://mvnrepository.com/ (s'upload automatiquement si l'utilisateur possède les droits adéquats)
* '''jboss-cache, java.net-cache, etc...''' : si artifactory utilise d’autres repo distant, alors les jars vont dans les dossiers XXX–cache d’artifactory correspondants
* '''ext-release-local''' : contient les binaires de projets externe
* '''plugins-release-local''' : plugins Maven en release
* '''plugins-snapshot-local''' : plugins Maven en snapshot

La gestion de ces repositories est interne à artifactory, on ne doit pas intervenir manuellement sur ceux-ci (à part pour libs-releases-local, libs-snapshots-local ; même dans certains cas plugins-release-local et plugins-snapshot-local, puisqu'on écrit maintenant nos propres plugins)

* Cas de l'artifactory de recette : 
2 référentiels distants on été ajouté sur cette artifactory afin de récupérer automatiquement les artifacts provenant de l'artifactory de production. Ces référentiels distants sont liés aux référentiels virtuels libs-release et libs-snapshots.

== LDAP ==

=== LDAPS ===

Il est nécessaire d'ajouter la CA de l'annuaire aux trusstore artifactory, ici cacerts

 openssl s_client -showcerts -connect &lt;host&gt;:&lt;port&gt; /dev/null &gt; ldap.ca
 keytool -import -alias &lt;host&gt; -keystore cacerts -trustcacerts -file ldap.ca -storepass *** -noprompt
 rm ldap.ca

=== Configuration ===

* Dans l'annuaire LDAP : 
** créer l'application : &lt;tt&gt;eartifact&lt;/tt&gt;
** créer les profils nécessaire :
*** &lt;tt&gt;administrateur&lt;/tt&gt; : Profil permettant d'administrer l'outil Artifactory
*** &lt;tt&gt;utilisateur enercom&lt;/tt&gt; : Profil destiné aux développeurs travaillant sur l'application enercom pour accéder en lecture sur l'outil Artifactory
*** &lt;tt&gt;utilisateur ethaque&lt;/tt&gt; : Profil destiné aux développeurs travaillant sur l'application ethaque pour accéder en lecture sur l'outil Artifactory
*** &lt;tt&gt;utilisateur suivefluid&lt;/tt&gt; : Profil destiné aux développeurs travaillant sur l'application énercom pour accéder en lecture sur l'outil Artifactory
*** &lt;tt&gt;utilisateur suite efluid&lt;/tt&gt; : Profil destiné aux développeurs travaillant sur les applications de la suite efluid : efluid, efluidPub, ael, efluid.net, eldap et edoc pour accéder en lecture sur l'outil Artifactory
*** &lt;tt&gt;utilisateur ginko&lt;/tt&gt; : Profil destiné aux intégrateurs ginko/enedis

* Dans "Security" &gt; "LDAP Settings" :
[[Fichier:artifactory_LDAP_settings_1.png]]
&lt;br/&gt;

* Créer le paramétrage à l'annuaire LDAP en cliquant sur "New" à côté du tableau des "LDAP Settings" :
** 
[[Fichier:artifactory_LDAP_settings_2.png]]
&lt;br/&gt;

* Puis créer le paramétrage des groupes en cliquant sur "New" à côté du tableau des "LDAP Groups" :
[[Fichier:artifactory_LDAP_settings_3.png]]
&lt;br/&gt;

* Saisir un login d'utilisateur dans le champ "Filter by Username" puis cliquez sur "refresh", les profils préalablement créé dans l'annuaire LDAP devrait apparaître. Sélectionner l'ensemble des profils puis cliquer sur "import" pour les ajouter dans artifactory.
[[Fichier:artifactory_LDAP_settings_4.png]]
&lt;br/&gt;

* Pour affecter des droits aux profils LDAP, aller dans la catégorie "Security &gt; Permissions", puis selectionner une permission. Sur l'onglet "Groups", il est possible de rattacher des droits à un profil LDAP
[[Fichier:artifactory_LDAP_settings_5.png]]
&lt;br/&gt;

= Configuration =

https://www.jfrog.com/confluence/display/RTF/Managing+Certificates

https://www.jfrog.com/confluence/display/RTF/Using+a+Self-Signed+Certificate

[https://jfrog.com/knowledge-base/how-to-set-a-password-policy-in-artifactory/ Mettre en place une politique de mot de passe dans artifactory]

 security:
   password-policy:    # users' password policy
     uppercase: 1      # minimum number of uppercase letters that the password must contain
     lowercase: 1      # minimum number of lowercase letters that the password must contain
     digit: 1          # minimum number of digits that the password must contain
     length: 12         # minimum length of the password
     not-match-old: true # should access allow setting a new password to the same one currently set for the user
   user-lock-policy:
     attempts: 5                     # number of failed login attempts to allow before locking a user. 0 (default) means the feature is disabled
     seconds-to-unlock: 300          # number of seconds to wait before re-enabling login for a user that has been locked out
     password-expiry-days: 0         # number of days before a password expires. Set by Artifactory
     admin-password-expirable: false # does the access admin password expire


== Proxy ==

https://www.jfrog.com/confluence/display/RTF/Configuring+a+Reverse+Proxy

https://www.jfrog.com/confluence/display/RTF/Configuring+Apache

= Modifier un alias DNS = 

== commun ==

# configuration maven cje et cjeTest
## find /nfstst1/cje-share-dir/tools/ -name 'settings*.xml' -exec grep lrsrv {} +
## find /nfs/cje-share-dir/tools/ -name 'settings*.xml' -exec grep lrsrv {} +

== recette ==

# configuration du job http://lpsrvedt1.uem.lan:8280/job/Finstallation/job/FjobsCommuns/job/scriptsqllauncher.orchestrate-execute-script/configure
# configuration du job http://lpsrvedt1.uem.lan:8480/view/artifactory/job/artifactory.update-rules-non-regression/configure

= Migration =

== Migration de la version 6.x à la version 7.x ==

[[UpgradingArtifactory_fromVersion6.x_to_7.x|Mise à jour de la version 6.x à la version 7.x]]

== Template Migration &lt;serveur A&gt; vers &lt;serveur B&gt; ==

=== Opérations de migration ===

# Création de la VM &lt;serveur B&gt; ([http://suivefluid.uem.lan/suivefluid_UEM/evenement/### evt suivefluid ###]) 
# Installation d'artifactory et nginx via le [http://wikefluid/docInstalleur/documentationScriptsOracleTools/copy/ansible/artifactoryinstall.html playbook]
# Copie des données,
## Créer une clé ssh pour artuser ([[Bonnes Pratiques Sécurité]])
## Echanger la clé pour la copie des données par rsync (entre user artuser)
## Arrêter artifactory et nginx
## Copie de l'arborescence /data/artifactory vers /data/artifactory (1)
## Vérifier qu'il n'y a aucune donnée nginx à récupérer
## Redémarrer artifactory et nginx
# Migration alias &amp; proxy pour pointer dorénavant le &lt;serveur B&gt;
# Vérifier dans artifactory, Admin &gt; General Configuration &gt; Custom Base URL : &lt;nowiki&gt;http://&lt;alias vers reverse proxy&gt;/artifactory&lt;/nowiki&gt;
# Configurer le remote repository docker efluid en https si il est déclaré, Admin &gt; Repository / Remote &gt; docker-remote
# Vérifier que les clients docker utilisent le bon CA
# vérification à l'aide du job [http://cje.efluid.uem.lan/usinerecette/job/FnonRegressionTests/job/Fartifactory/job/artifactory.tests/ de NonReg]

  (1) artuser@&lt;serveur A&gt;$ rsync -e ssh -avz /data/artifactory/ &lt;serveur B&gt;:/data/artifactory

== Migration lrsrvart2 vers lrartedt1 ==

=== Opérations pré migration ===

# Modification de la configuration nginx pour utiliser le dépôt docker-release (virtuel) au lieu de docker-local '''''=&gt; Done'''''
# Modifier suivefluid NB et INT pour utiliser l'alias ([https://gerrit.uem.lan/#/c/88361/ change 88361]) '''''=&gt; Done'''''
# Faire Modifier par UEM suivefluid SUP &amp; VAL pour utiliser l'alias (DI-2152 &amp; DI-2153) '''''=&gt; Done'''''

=== Opérations de migration ===

# Création de la VM lrartedt1 ([http://suivefluid.uem.lan/suivefluid_UEM/evenement/266505 266505]) '''''=&gt; Done''''' 
# Installation d'artifactory et nginx via le [http://wikefluid/docInstalleur/documentationScriptsOracleTools/copy/ansible/artifactoryinstall.html playbook] '''''=&gt; Done'''''
# Copie des données,
## Créer une clé ssh pour artuser '''''=&gt; Done'''''
## Echanger les clé pour la copie des données par rsync (entre user artuser) '''''=&gt; Done'''''
## Arrêter artifactory et nginx '''''=&gt; Done'''''
## Arborescence /dataCIFS10G/artifactory vers /data/artifactory (1) '''''=&gt; Done'''''
## Vérifier qu'il n'y a aucune donnée nginx à récupérer '''''=&gt; Done'''''
## Redémarrer artifactory et nginx '''''=&gt; Done'''''
# Migration alias &amp; proxy =&gt; Jeudi 04/04 avec TAJ
## Modification du host dans la config apache de lrpxyifredt1 '''''=&gt; Done'''''
## Modification du DNS rartiafctorydocker.efluid.uem.lan '''''=&gt; Done'''''
# Vérifier dans artifactory, Admin &gt; General Configuration &gt; Custom Base URL : &lt;nowiki&gt;http://artifactoryrec.efluid.uem.lan/artifactory&lt;/nowiki&gt; '''''=&gt; Done'''''

  (1) artuser@lrsrvart2$ rsync -e ssh -avz /dataCIFS10G/artifactory/ lrartedt1:/data/artifactory

=== Anomalie non détectée plus tôt ===
* correction de lrsrvart1.uem.lan dans le cjeTest : /nfstst1/cje-share-dir/tools/maven/conf/settings-recette.xml
** find /nfstst1/cje-share-dir/tools/ -name 'settings*.xml' -exec grep lrsrv {} +
** find /nfs/cje-share-dir/tools/ -name 'settings*.xml' -exec grep lrsrv {} +
* correction configuration maven de recette sur lpsrvedt1
** sudo find /opt -name 'settings*.xml' -exec grep lrsrvart {} +
* correction de l'url artifactory de recette dans les images de base CJE

== Migration lpsrvart2 vers lpartedt3 ==

=== Opérations pré migration ===

# Modification de la configuration nginx pour utiliser le dépôt docker-release (virtuel) au lieu de docker-local '''''=&gt; Done'''''
# Pas d'opération préalable dans suivefluid '''''=&gt; Done'''''

=== Opérations de migration ===

# Création de la VM lpartedt3 ([http://suivefluid.uem.lan/suivefluid_UEM/evenement/266505 266505]) =&gt; '''''Done'''''
# Installation d'artifactory et nginx via le [http://wikefluid/docInstalleur/documentationScriptsOracleTools/copy/ansible/artifactoryinstall.html playbook] =&gt; '''''Done'''''
# Vérifier qu'il n'y a aucune donnée nginx à récupérer =&gt; '''''Done'''''
# Copie des données,
## Monter le nfs lpnfssan1-edt:/NFS_LPARTEDT3_DTA_A05 sur lpsrvart2.uem.lan '''''=&gt; Done'''''
## Export full system sur le nfs depuis lpsrvart2 '''''=&gt; Done'''''
## Import full system à partir de l'export depuis lpartedt3 '''''=&gt; Done'''''
## Redémarrer artifactory et nginx '''''=&gt; Done'''''
# Migration alias &amp; proxy =&gt; '''DI-3053''' '''''=&gt; Done'''''
## alias : partifactorydockerpub.uem.lan ( attention au CA &amp; certificats) '''''=&gt; Done'''''
## proxy : pfroart1.uem.lan '''''=&gt; Done'''''
## proxy : lpfrosfld1 '''''=&gt; Done'''''
# Vérifier la replication configuré dans eartifact '''''=&gt; Done'''''
# Vérifier que les clients docker utilisent le bon CA (disponible dans notre dépôt ansible) '''''=&gt; Done'''''

=== Opérations post migration ===

# Ne plus répliquer les images docker passer par le cache
# Configurer le remote repository docker en https, Admin &gt; Repository / Remote &gt; docker-remote '''''=&gt; Done'''''

== Migration lpartedt1 vers lpartedt4 ==

=== Opérations pré migration ===

# Pas d'opération préalable dans suivefluid =&gt; '''''Done'''''

=== Opérations de migration ===

# copie du disque /data pour teste de montée de version =&gt; '''DI-3052 / GLE''' =&gt; '''''Done'''''
# Création de la VM lpartedt4 =&gt; '''evt 279311''' =&gt; '''''Done'''''
# Vérifier qu'il n'y a aucune donnée nginx à récupérer =&gt; '''''Done'''''
# jour J 
## Désactiver les réplications docker-releases-local, libs-mobefluid-local et libs-release-local =&gt; '''''Done'''''
## couper le container artifactory sur lpartedt1 =&gt; '''''Done'''''
## clone du disque avec les données de production =&gt; DI-3811 =&gt; '''''Done'''''
## Montée le disque pour l'export site sur (1)  =&gt; '''''Done'''''
## Installation d'artifactory et nginx via le [http://wikefluid/docInstalleur/documentationScriptsOracleTools/copy/ansible/artifactoryinstall.html playbook] =&gt; '''''Done'''''
## Activer les réplications docker-releases-local, libs-mobefluid-local et libs-release-local =&gt; '''''Done'''''
## Migration alias &amp; proxy =&gt; opération sur lrpxyfld1 fichier /etc/httpd/conf.d/eartifact.conf + redémarrage deamon httpd =&gt; '''''Done'''''
## Vérifier que les clients docker utilisent le bon CA =&gt; '''''Done'''''

 (1) lpnfssan1-edt:/NFS_LPARTEDT1_EXT_A04   /ext/export     nfs     defaults        0 0

= Interaction avec artifactory =

Les interactions avec artifactory peuvent se faire soit : 

* Via le CLI : https://www.jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory
* Via les services REST : https://www.jfrog.com/confluence/display/JFROG/Artifactory+REST+API

Il faut faire des tests sur artifactory de recette : https://artifactoryrec.efluid.uem.lan/artifactory/webapp/

Pour cela on peut utiliser un compte de test : '''jenkinsdev''' (mot de passe à demander à l'UL)</text>
      <sha1>418bikmlg853n1h978qr3zg22awoyzc</sha1>
    </revision>
  </page>
  <page>
    <title>Notepad++</title>
    <ns>0</ns>
    <id>1052</id>
    <revision>
      <id>694193</id>
      <parentid>694192</parentid>
      <timestamp>2015-03-13T10:42:18Z</timestamp>
      <contributor>
        <username>Meyerj</username>
        <id>287</id>
      </contributor>
      <origin>694193</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1191" sha1="djlkwia0mxml5chhxcybucl4glh4c86" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = notepad++
 | siteInternet      = http://notepad-plus-plus.org
 | guideInstallation = Guide d'installation de Notepad++
 | version           = {{outil.notepad++.version}}
}}

[[Category:notepad++]]
= Plugin pour la gestion des fichiers xml =
Il existe des plug in pour la gestion des fichiers xml dans notepad++.
Ils permettent en particulier d'utiliser les fichiers xsd.
Une procédure d'installation ainsi qu'un tutoriel sont diponibles sur [http://gradot.wordpress.com/2012/04/10/outils-xml-pour-notepad internet] ou sur [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_c2e7c eRoom].

= Configuration de l'encodage avec Notepad++ =

Il faut bien vérifier que l'encodage soit Cp1252 lorsque vous utilisez Notepad++ pour modifier des fichiers. Pour ce faire, rendez-vous dans le menu puis Encoding et choissisez "ANSI" (c'est ainsi que se nomme Cp1252 dans Notepad++...)

Dans mon exemple, j'ai écris quelques lignes en encodage Cp1252 et je les ai converties en encodage UTF-8 pour observer les différences.

[[image: sampleText1.png | 1000x700px]]
&lt;br /&gt;

Avec un encodage UTF-8...

[[image: sampleText2.png | 1000x700px]]
&lt;br /&gt;</text>
      <sha1>djlkwia0mxml5chhxcybucl4glh4c86</sha1>
    </revision>
  </page>
  <page>
    <title>SoapUI</title>
    <ns>0</ns>
    <id>820</id>
    <revision>
      <id>4064256</id>
      <parentid>3089976</parentid>
      <timestamp>2021-06-02T13:04:45Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>4064256</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2062" sha1="5uxsbtdzho8n904rzmpryy22v02audr" xml:space="preserve">{{Modèle:Infobox Outil
 | logo              = SoapUI-logo.png
 | nom               = SoapUI
 | siteInternet      = http://www.soapui.org
 | version           = {{outil.soapui.version}}
 | faq               = [[FAQ:SOAP UI| FAQ SOAP UI]]
 | guideInstallation = Guide d'installation de SoapUI
 | guideUtilisation  = Guide d'utilisation de SOAP UI
}}

[[Category:SoapUI]]

SoapUI est une application open source permettant le test de web service dans une architecture orientée services (SOA). Ses fonctionnalités incluent l'inspection des web service, l'invocation, le développement,  la simulation, le mocking, les tests fonctionnels, les tests de charge et de conformité. Une version commerciale, SoapUI Pro, qui se concentre principalement sur des fonctionnalités conçues pour améliorer la productivité, a également été mis au point par eviware software. En 2011, eviware a été racheté par SmartBear Software distribué en France par la société KYRIEL (http://www.kyrielsoft.fr).

SoapUI a été publié pour la première fois en septembre 2005 sous Licence publique générale limitée GNU. Depuis sa publication, SoapUI a été téléchargé plus de 2 millions de fois. Il est entièrement basé sur la plate-forme Java et utilise Swing pour l'interface utilisateur. Ce qui signifie que SoapUI est multiplateforme. SoapUI supporte aujourd'hui IDEA, Eclipse et NetBeans.

== Remarques ==

{{avertissement}} Ne plus utilisez la version '''4.6.1''' de l'outil car une erreur d'encodage UTF-8 survient lors de la création d'un nouveau service à partir d'un [[WSDL]] dans le [[domaine service web sge]]

{{avertissement}} La version '''5.3.0''' est recommandé si vous avez besoin de récupérer un jeton OAuth2 avec le profil '''Resource Owner Password Credentials Grant'''

== Articles connexes ==
* [[Guide d'utilisation de SOAP UI]]

== Liens externes ==
* [http://blog.soat.fr/2013/07/le-scripting-dans-soapui-avec-groovy/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=le-scripting-dans-soapui-avec-groovy Le scripting dans Soap UI avec Groovy]</text>
      <sha1>5uxsbtdzho8n904rzmpryy22v02audr</sha1>
    </revision>
  </page>
  <page>
    <title>Filezilla</title>
    <ns>0</ns>
    <id>1113</id>
    <revision>
      <id>8855</id>
      <parentid>8854</parentid>
      <timestamp>2012-01-11T16:54:05Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <minor/>
      <origin>8855</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="320" sha1="2131o7e7vpx29jmjirwae8fk5817bah" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = FileZilla
 | siteInternet      = http://filezilla.fr
 | version           = {{outil.filezilla.version}}
 | guideInstallation = Guide d'installation de FileZilla
}}

Utilisé pour récupérer les fichiers de log sur linux via SFTP.

[[Category:outil]]
[[Category:FileZilla]]</text>
      <sha1>2131o7e7vpx29jmjirwae8fk5817bah</sha1>
    </revision>
  </page>
  <page>
    <title>Navigateurs</title>
    <ns>0</ns>
    <id>1201</id>
    <revision>
      <id>4066533</id>
      <parentid>4037546</parentid>
      <timestamp>2022-01-04T08:02:52Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>4066533</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2133" sha1="5is8131a13efyvrtrtyaxlpimf6kb7f" xml:space="preserve">{{Modèle:Infobox Application
 | nom              = Navigateurs
}}

[[Category:outil]]
[[Category:internet explorer]]

== Machines pour tester '''internet explorer x.x''' ==
* &lt;tt&gt;WRPC764B4&lt;/tt&gt; + IE8 32/64bits + Win7 + Adobe Reader 11 + Favori Portail UEM
* &lt;tt&gt;WRPC764B5&lt;/tt&gt; + IE9 32/64bits + Win7 + Adobe Reader 11 + Favori Portail UEM
* &lt;tt&gt;WRPC764B6&lt;/tt&gt; + IE10 32/64bits + Win7 + Adobe Reader 11 + Favori Portail UEM
* &lt;tt&gt;WRPC764B8&lt;/tt&gt; + IE11 32/64bits + Win7 + Adobe Reader 11 + Favori Portail UEM 
* &lt;tt&gt;WRPC864B2&lt;/tt&gt; + IE11 32/64bits + Win8.1 + Adobe Reader 11 + Favori Portail UEM
* &lt;tt&gt;WRPC1064B1&lt;/tt&gt; + IE11 - Edge + Win 10

Accès depuis CGI StDenis:
* &lt;tt&gt;WRPC764B4&lt;/tt&gt; : 172.23.2.96
* &lt;tt&gt;WRPC764B5&lt;/tt&gt; : 172.23.2.97
* &lt;tt&gt;WRPC764B6&lt;/tt&gt; : 172.23.2.98
* &lt;tt&gt;WRPC764B8&lt;/tt&gt; : 172.23.2.142
* &lt;tt&gt;WRPC864B2&lt;/tt&gt; : ???.???.???.???

Liste des personnes ayant des accès : [[JTA]], [[FDE]], [[CTH]], [[ADM]], [[EFI]], [[RLE]], [[VBO]] et [[BDA]]

== Machines pour tester '''firefox''' et '''chrome''' ==
* &lt;tt&gt;WRPC1064B7&lt;/tt&gt; ou &lt;tt&gt;wrpc1064b7.uem.lan&lt;/tt&gt; ou &lt;tt&gt;192.168.116.8&lt;/tt&gt;
Sur cette VM, on dispose de tout les droits pour installer / désinstaller la bonne version de firefox et/ou chrome. Cette opération étant à la charge de l'utilisateur.

Les accès simultanés sont limité à 2. (A signaler si ça pose problème).

Liste des personnes ayant des accès :
* [[FDE]], [[CTH]], [[ADM]], [[EFI]], [[RLE]], [[VBO]] et [[BDA]]
* pour ajouter un accès '''temporaire''' (pour un besoin ponctuel) ou '''long terme''' : faire une demande au 6000

== FAQ ==

=== [[Comment gérer la double session efluid avec IE 8 ?]] ===

=== Installation d'IE8 sur Windows 7 ===

Il suffit de supprimer la mise à jour d'IE8 vers IE9 qui vient avec Windows 7 SP1. Par contre, il n'est pas possible d'avoir les deux navigateurs côte-à-côte. 

* Aller dans "Panneau de configuration"
* Puis "Programme &gt; Désinstaller un programme"
* À gauche choisir "Afficher les mises à jour installées"
* Dans la liste double-cliquer "Microsoft Internet Explorer 9"
* Valider puis redémarrer

== Liens utiles ==

* [[IECollection]]</text>
      <sha1>5is8131a13efyvrtrtyaxlpimf6kb7f</sha1>
    </revision>
  </page>
  <page>
    <title>IECollection</title>
    <ns>0</ns>
    <id>1190</id>
    <revision>
      <id>6955</id>
      <parentid>6952</parentid>
      <timestamp>2011-11-23T17:22:01Z</timestamp>
      <contributor>
        <username>Collign</username>
        <id>9</id>
      </contributor>
      <minor/>
      <origin>6955</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="892" sha1="h3akf76x1eama2df7azboyuygspaawa" xml:space="preserve">{{Modèle:Infobox Outil
 | nom              = IE Collection
 | siteInternet     = [http://www.01net.com/telecharger/windows/Internet/navigateur/fiches/103828.html telecharger.com]
 | version          = 1.7.1.0
}}

Utilitaire permettant d'installer différentes version d'Internet Explorer dans Windows en même temps.

= Utilité =
Internet Explorer Collection regroupe plusieurs versions du navigateur Internet Explorer pouvant être utilisées simultanément. Grâce à cette application, les développeurs ont la possibilité de tester leurs sites Web sous différentes versions d'IE.

= Version IE supportée =
Internet Explorer Collection installe les versions suivantes : 1.0, 1.5, 2.01, 3.0, 3.01, 3.03, 4.01, 5.01, 5.5, 6.0, 7.0 et 8.0.

= Problème rencontré = 
{{alert|texte=Attention ceci ne fonctionne pas bien avec les applis du genre efluid qui lance une popup au démarrage!}}</text>
      <sha1>h3akf76x1eama2df7azboyuygspaawa</sha1>
    </revision>
  </page>
  <page>
    <title>Ethereal</title>
    <ns>0</ns>
    <id>1339</id>
    <revision>
      <id>258975</id>
      <parentid>8861</parentid>
      <timestamp>2014-06-12T07:19:23Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>258975</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="600" sha1="dx13ymbxgqzc2tip2im13wwvab7f05z" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = ethereal
 | siteInternet      = http://www.ethereal.com
 | version           = {{outil.ethereal.version}}
 | guideInstallation = Guide d'installation d'ethereal
}}
Utilisé pour analyse ce qui transite sur le réseau?

La version {{outil.ethereal.version}} d'ethereal est dispo sur eRoom : http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_75dd7

Au prochain besoin, ne pas hésiter à monter en version et créer le document d'installation.

Nouveau nom de l'application : http://www.wireshark.org/

[[Category:outil]]
[[Category:ethereal]]</text>
      <sha1>dx13ymbxgqzc2tip2im13wwvab7f05z</sha1>
    </revision>
  </page>
  <page>
    <title>Sqlplus</title>
    <ns>0</ns>
    <id>923</id>
    <revision>
      <id>4005681</id>
      <parentid>4005680</parentid>
      <timestamp>2018-08-06T11:06:54Z</timestamp>
      <contributor>
        <username>Weberp</username>
        <id>8</id>
      </contributor>
      <comment>/* Utilisation de sql Plus pour une extraction CSV */</comment>
      <origin>4005681</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1529" sha1="94886ogzwfytxhkzrvo5cjez2942hbm" xml:space="preserve">{{Modèle:Infobox Outil
 | nom = SQL plus
}}
== Lancement ==
* sqlplus hermes_user/h4d3v@ldbddfld4:2483/dnewfld
* sqlplus hermes_user/h4d3v@DBUGFLD @U_VIDEOCOMMUNICATION_83049.sql

== Utilisation de sql Plus pour une extraction CSV ==
* touche &lt;tt&gt;windows + R&lt;/tt&gt; puis taper sqlplus login/mdp@SID pour lancer sqlplus. 
Le SID est celui qui est référencé par votre tnsname.ora&lt;br/&gt;
Par exemple : sqlplus HERMES_USER/h4d3v@DNEWFLD_10G
* vous arrivez sur le prompt SQL&gt; --&gt; il suffit de lancer la requête SQL comme suit : @CHEMIN_REQUETE_SQL\NOM_FICHIER_SQL. 
Exemple : @E:\Users\lagarde\Documents\Scripts\SMEG_EXTRACTION_BRANCHEMENTS_ELEC_GAZ_97988.sql
Vous pouvez également positionner directement les paramètres dans le prompt (ici 8 paramètres attendus):
Exemple : @e:\Users\weberp\Desktop\scriptsSeolis\scriptArticles.sql null null null null e:\Users\weberp\Desktop\scriptsSeolis\ 01/03/2015 31/03/2015 extractionArticleMars2015

== Problèmes dus aux accents ==
Si vous avez des problèmes avec les accents, il faut définir l'encoding :&lt;br&gt;
&lt;source lang="bash"&gt;
SET NLS_LANG=.WE8MSWIN1252
&lt;/source&gt; 
* http://www.dba-ora.fr/article-set-nls_lang-sqlplus-accent-79582454.html

== liens externe ==
* {{fr}} http://www.dba-ora.fr/article-connexion-mode-console-sqlplus-104687208.html
* {{fr}} [http://combot.univ-tln.fr/loris/admin/sqlplus/formatage.html http://combot.univ-tln.fr/loris/admin/sqlplus/formatage.html]
* {{fr}} [http://combot.univ-tln.fr/loris/admin/sqlplus/ http://combot.univ-tln.fr/loris/admin/sqlplus/]</text>
      <sha1>94886ogzwfytxhkzrvo5cjez2942hbm</sha1>
    </revision>
  </page>
  <page>
    <title>Wikefluid</title>
    <ns>0</ns>
    <id>1422</id>
    <revision>
      <id>4068070</id>
      <parentid>4067120</parentid>
      <timestamp>2022-12-20T10:50:04Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <origin>4068070</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1120" sha1="6l4crg4stntx5w1a4ra8d2o9smm1y57" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = wikefluid
 | siteInternet      = http://www.mediawiki.org
 | version           = 1.35.7 de mediawiki 
 | guideInstallation = Guide d'installation de wikefluid
 | faq              = [[FAQ:wikefluid|FAQ wikefluid]]
}}

[[Category:wikefluid]]

== Liens internes ==
* Configuration de MediaWiki : [http://www.mediawiki.org/wiki/Manual:Configuration_settings ici]
* '''Deprecated''' &lt;s&gt;Modifier le fichier common.css : [[MediaWiki:Common.css|ici]]&lt;/s&gt;
* Modification du menu de gauche : [[MediaWiki:Sidebar|ici]]
* Création / Modification des InfoBox V2 : [http://fr.wikipedia.org/wiki/Projet:Infobox/V2 ici]

== Requêtes ==

* Requêtes permettant de récupérer les statistiques d'utilisation
&lt;source lang="sql"&gt;
select COUNT(r.rev_id) as value, COUNT(DISTINCT r.rev_page) as page_value, u.user_name as title
from wikefluid.user u, wikefluid.revision r, wikefluid.page p
where u.user_id = r.rev_user and p.page_id = r.rev_page and p.page_namespace = 0
GROUP BY u.user_name
&lt;/source&gt;

== Release notes et planning des versions ==

https://www.mediawiki.org/wiki/Release_notes</text>
      <sha1>6l4crg4stntx5w1a4ra8d2o9smm1y57</sha1>
    </revision>
  </page>
  <page>
    <title>Eforum</title>
    <ns>0</ns>
    <id>1423</id>
    <revision>
      <id>4063178</id>
      <parentid>13142</parentid>
      <timestamp>2021-02-26T10:14:18Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Requêtes */</comment>
      <origin>4063178</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="193" sha1="az8u2waagykwmjqypk0scr1teo33bp7" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = eforum
 | siteInternet      = http://www.phpbb.com
 | version           = 3.0.10 de phpBB3
 | guideInstallation = Guide d'installation d'eforum
}}</text>
      <sha1>az8u2waagykwmjqypk0scr1teo33bp7</sha1>
    </revision>
  </page>
  <page>
    <title>Vi</title>
    <ns>0</ns>
    <id>1456</id>
    <revision>
      <id>10417</id>
      <parentid>10416</parentid>
      <timestamp>2012-02-27T17:27:56Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>10417</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="87" sha1="bcijjzo6i3m1qs3vudpu60ttvchvvbx" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = vi
}}
[[Aide-mémoire pour utiliser vi]]</text>
      <sha1>bcijjzo6i3m1qs3vudpu60ttvchvvbx</sha1>
    </revision>
  </page>
  <page>
    <title>Firebug</title>
    <ns>0</ns>
    <id>993</id>
    <revision>
      <id>1047870</id>
      <parentid>1047869</parentid>
      <timestamp>2015-09-24T11:23:46Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>1047870</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="149" sha1="ac37vxwyderqzbx03qzhl264r8u7oyy" xml:space="preserve">[[Category:outil]]
[[Category:plugin]]

Plugin de [[Firefox]] pour faire du debug HTML, CSS et Javascript.
= liens externes =
* http://getfirebug.com</text>
      <sha1>ac37vxwyderqzbx03qzhl264r8u7oyy</sha1>
    </revision>
  </page>
  <page>
    <title>Usine logicielle</title>
    <ns>0</ns>
    <id>1464</id>
    <revision>
      <id>4068016</id>
      <parentid>4068015</parentid>
      <timestamp>2022-11-28T07:31:31Z</timestamp>
      <contributor>
        <username>Carriers</username>
        <id>234</id>
      </contributor>
      <comment>/* Serveurs en DMZ */</comment>
      <origin>4068016</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10003" sha1="3ngx6kmmqundwlmkucuyn06rwre0rqu" xml:space="preserve">[[Category:outil]]

= Jobs pour les équipes DEV/REC =

[[Jobs_jenkins_%C3%A0_utilisation_des_d%C3%A9veloppeurs#Job_permettant_de_compiler_.2F_packager_une_version_custom_sur_un_change_Gerrit|Job permettant de compiler / packager une version custom sur un change Gerrit]]

= Schéma global =

[[Fichier:Usine logicielle - architecture - centrale.png]]

Visio : http://wperoom3.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_107a60  =&gt; Usine logicielle - architecture - centrale.vsd


= Proxy devant les applications =
== Gerrit ==
* gerrit.uem.lan =&gt; lppxyifr1 =&gt; lpsrvgit2:8080
* gerritrec.efluid.uem.lan (ou gerritrec) =&gt; lpsrvperf4 =&gt; ldsrvgit3:8081

== Artifactory ==
[[Artifactory#Inventaire|inventaire]]

== Jenkins ==
* usinelogicielle.uem.lan =&gt; XXX =&gt; lpsrvedt1:X
* usinevalidation.uem.lan =&gt; XXX =&gt; lpsrvedt1:X
* usinerec.efluid.uem.lan =&gt; lpsrvperf4 =&gt; lpsrvedt1.uem.lan:8380   (ne gère pas CJOC avec HTTPS donc pas utilisable mais on ne fait pas plus car CJP est fin de vie)
* cje.efluid.uem.lan =&gt; XXX =&gt; XXX

== Sonar ==

* especteur =&gt; XXX =&gt; lpsnredt1:9000
* sonarrec.efluid.uem.lan =&gt; lpsrvperf4 =&gt; lrdocedt1:9000

== Wikefluid ==

== Eforum ==

= Serveurs de l'UL et Outillage IT =
== ldsrvint1 ==

== ldsrvint3 ==
* SEF 371834
* RHEL 7.9
** Activation NFS manuellement pour besoins playbooks IT provisionning :
   # yum install nfs-utils rpcbind
   # systemctl enable nfs-server
   # systemctl enable rpcbind
   # systemctl enable nfs-lock
   # systemctl enable nfs-idmap
   # systemctl start rpcbind
   # systemctl start nfs-server
   # systemctl start nfs-lock
   # systemctl start nfs-idmap
    
== ldsrvint4 ==
* SEF 371834
* RHEL 8.5

= Particularités sur serveurs INT/DEV =

== Serveurs en DMZ ==
Certains serveurs sont en DMZ, ce qui contraint l'accès et les montages Samba, car déconnectés de l'AD.
Dans ce cas, création d'un user technique sur le serveur : fldadmin_ro
 useradd fldadmin_ro
 usermod -a -G fldgrp fldadmin_ro

Ensuite, recopier la clé publique des utiliisateurs souhaitant accéder aux logs des serveurs dans /home/fldadmin_ro/.ssh/authorized_keys

Les serveurs pour le moment concernés sont :
* lds2medt1
* lpdocedt2

= Serveurs UL intégrés au parc de tests S&amp;R sécurité =

&lt;s&gt;* ldsanbld7.uem.lan: serveur NB V12 Weblogic&lt;/s&gt;
* lpdocedt2 : serveur NB docker V13
* ldsrvgit3: serveur gerrit de recette
&lt;s&gt;* lddocedt1 RHEL 7.2/docker 1.10: serveur docker de test&lt;/s&gt;
* lpsrvulo3.uem.lan: swarm/docker RH 7.2
&lt;s&gt;* lrsrvart2.uem.lan: artifactory de recette&lt;/s&gt;
* lrdocedt1 : Serveur applications de recette sous Docker
* lpdoculo3 : Slave UL
* lrmysedt1 : serveur mysql de recette

== Jobs de non régression de l'usine logicielle ==
Les jobs suivants permettent de tester la non regression des fonctions de l'usine logicielle. Ces jobs doivent être complétés au fur et à mesure des anomalies et des nouvelles fonctions mis dans Jenkins. Cela permet de valider les différents upgrade fait sur les serveurs de tests.
* http://lpsrvedt1.uem.lan:8380/job/FtestsNonRegression

== Mise à jour de patchs ==
=== Q1 T10 du 16/08/2016 ===
Aucun serveurs UL n'est présent dans le cadre de ces patchs.

= Travaux temporaires en recette pour site sur =
Sur Jenkins, onglet SiteSur (à rebasculer sur un serveur de production quand répartition des jobs revue et stable)
- 1 job (bindé au master car il monte le NAS) pour cloner efluid sur le NAS qui sera monté
- 1 job qui lance sur lpsrvart1 le script main_sitesur.sh =&gt; récupération de l'archive sur NAS

Sur serveur Artifactory lpsrvart1, user artifactory, ajout dans .ssh/authorized_keys de la clé publique id_rsa.pub de jenkins@lrsrvulo2 =&gt;
 permet au job de lrsrvulo2, lancé en tant que jenkins, de pouvoir lancer une commande ssh sur lpsrvart1 pour faire la procédure d'export.

= Plan de Sauvegarde = 

== Serveurs physiques ==

LPSRVEDT1 : (/etc /opt /home /data/EDT/jenkinsUA /data/EDT/jenkinsUD /data/EDT/jenkinsUL /data/EDT/jenkinsUR /data/EDT/jenkinsUV /data/EDT/migration /data/EDT/interneUL) incremental tous les jours avec rétention 4 semaines + full 1 fois par 2 semaine avec rétention 4 semaines

LPBDDEDT3 : full le samedi rétention 2 semaines

LDBDDEDT1 : full le samedi rétention 2 semaines

LPSRVEDT2 (provisionnement en cours sur le modèle LPSRVEDT1)

== Serveurs virtuels ==

Sauf indication contraire tous les serveur virtuels sont sauvegardée 1 fois par semaine avec rétention 4 semaines,
si le jour n'est pas précisé c'est un dimanche

LDSANBLD[1-7] + LDSAQTP1 : full 1 fois par semaine avec rétention 4 semaines

LDSRVULO1 : full 1 fois par semaine avec rétention 4 semaines

LPDOCEDT1 : incremental tous les jours ouvrés avec rétention 2 semaines + full 1 fois par semaine avec rétention 4 semaines

LPDOCEDT2 : incremental tous les jours ouvrés avec rétention 2 semaines + full 1 fois par semaine avec rétention 4 semaines

LDSRVULO1 : full 1 fois par semaine avec rétention 4 semaines

LDSRVINT1 : full 1 fois par semaine avec rétention 4 semaines

LPSRVULO12 : incremental tous les jours avec rétention 4 semaines + full 1 fois par 2 semaine avec rétention 4 semaines

LPSRVULO4, LPSRVULO6, LPSRVULO7 : incremental tous les jours avec rétention 4 semaines + full 1 fois par 2 semaine avec rétention 4 semaines

LPSRVULO9 : incremental tous les jours avec rétention 4 semaines + full 1 fois par 2 semaine avec rétention 4 semaines

LPSRVEDT2 (provisionnement en cours)

LPMYSEDT1 : incrémental tous les jours ouvrés dont full le vendredi. Interruption de service de 4h45 à 5h30

LPSRVGIT2 : incrémental tous les jours avec rétention 4 semaines + full 1 fois par 2 semaine avec rétention 4 semaines

LPSRVGIT1 : incrémental tous les jours avec rétention 4 semaines + full 1 fois par 2 semaine avec rétention 4 semaines

LDSRVGIT3 : full 1 fois par semaine avec rétention 4 semaines

LDSTRSNB1 : full 1 fois par semaine avec rétention 4 semaines

LRSRVART1 : full le samedi rétention 2 semaines

LRSRVART2 : RH7 avec disque CIFS pour le /data

LPSRVART1 : incremental tous les jours ouvrés avec rétention 2 semaines + full 1 fois par semaine avec rétention 4 semaines

LPSRVART2 : incremental tous les jours ouvrés avec rétention 2 semaines + full 1 fois par semaine avec rétention 4 semaines

= Outils utilisés =

{| class="wikitable"
|'''Outil'''
|'''Version'''
|'''Editeur'''
|'''License'''
|-
|[[Maven]]
|{{outil.maven.version}} 
|Apache Software Foundation
|[http://maven.apache.org/license.html Apache 2.0 License]
|-
|[[Git]] (nécessite curl 7.19.4, expat 2.0.1, zlib 1.2.5)
|{{outil.git.version}} et 1.8.4.4 
|Git
|GNU General Public License v2
|-
|[[Ant]] 
|{{outil.ant.version}} 
|Apache Software Foundation
|[http://www.apache.org/licenses/LICENSE-2.0.html2 Apache 2.0 License]
|-
|[[Jonas]] 
|{{outil.jonas.version}} et 5.2.3
|Bull and OW2
|[http://www.gnu.org/licenses/lgpl.html LGPL]
|-
|[[Hudson]] 
|{{outil.hudson.version}} 
|Eclipse Foundation project and partly as a java.net project.
|[http://www.opensource.org/licenses/mit-license.php actuellement MIT License] - [http://www.opensource.org/licenses/EPL-1.0 prochaine version Eclipse EPL]
|-
|[[Jenkins]] 
|{{outil.jenkins.version}} 
|Jenkins CI
|[https://github.com/jenkinsci/jenkins/blob/master/LICENSE.txt MIT License]
|-
|[[Artifactory]] 
|{{outil.artifactory.version}} 
|JFrog
|License commerciale PRO artifactory accordée à UEM
|-
|[[Weblogic]] (pour la compilation des JSP)
|{{outil.weblogic.version}} 
|Oracle
|License commerciale Oracle
|-
|[[Play]] (c’est pour edoc)
|{{outil.play.version}} 
|guillaume bort &amp; zenexity
|[http://www.apache.org/licenses/LICENSE-2.0.html Apache 2 licence]
|-
|[[Jdk]]
|1.5.0.15 et 1.6.0.27 et 1.7.0.09
|Oracle
|[http://www.oracle.com/technetwork/java/javase/downloads/java-se-archive-license-1382604.html Oracle Binary Code License Agreement for Java SE and JavaFX Technologies]
|-
|[[Sonar]]
|{{outil.sonar.version}}
|Codehaus
|[http://www.sonarsource.org/support/license/ LGPL]
|-
|[[CheckStyle]]
|{{outil.checkstyle.version}}
|SourceForge
|[http://checkstyle.sourceforge.net/license.html LGPL]
|-
|[[PMD]]
|{{outil.pmd.version}}
|SourceForge
|[http://pmd.sourceforge.net/license.html BSD-styleLGPL]
|-
|[[FindBugs]]
|{{outil.findbugs.version}}
|SourceForge
|[http://findbugs.sourceforge.net/ LGPL]
|-
|[[Cobertura]]
|{{outil.cobertura.version}}
|SourceForge
|[http://cobertura.sourceforge.net/license.html Apache Software License, Version 1.1. + GNU General Public License, Version 2.0]
|-
|[[Selenium]]
|{{outil.selenium.version}}
|OpenQA
|[http://seleniumhq.org/about/license.html Apache 2.0 License]
|-
|[[SQLPlus]]
|{{outil.sqlplus.version}} et 11.2.0
|Oracle
|License commerciale oracle
|-
| [HP QC] (pour tests QTP) 
| 10.0 + QC add-in 9.0
| HP
| License commerciale HP
|-
|[[StreamServe_Opentext|StreamServe]]
|{{outil.streamserve.version}}
|Opentext
|License commerciale Opentext
|}

= Projet en cours =
== Évolution Usine Logicielle vers CJE ==
Evènement Suivefluid: 194645&lt;br&gt;
Page wiki : [[CJE]]

=== Nouveaux serveurs physiques ===
* Caractéristiques techniques : B420 M4, quadri-processeurs E5-4650v3 (12 cœurs hyperthreadés, 48 cœurs en tout) avec 192 Go de RAM.
* DI : http://wperoom3.uem.lan/eRoom/Production/DemandesProductionInformatique/0_1a7762
* LPDROGONEDT1
* LPVISERIEDT1
* Espace NAS : 2 To disponible en NFS sur tous les serveurs UL
&lt;br&gt;
* Plus le petit dernier : http://wperoom3.uem.lan/eRoom/Production/DemandesProductionInformatique/0_1ba15e 
* LPRHAEGAEDT1

=== Nouvelles VM ===
* DI: http://wperoom3.uem.lan/eRoom/Production/DemandesProductionInformatique/0_1b96e6

=== Nouvelles VM pour env Recette CJE ===
http://wperoom3.uem.lan/eRoom/Production/DemandesProductionInformatique/0_1bf392

=== Cartographique de la nouvelle plateforme ===

=== Stratégie de migration ===
* Cf http://wperoom3.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_9671

=== Licensing ===
* A l'utilisateur, en comptabilisant le profil LDAP "utilisateur" de l'application "usinelogicielle"</text>
      <sha1>3ngx6kmmqundwlmkucuyn06rwre0rqu</sha1>
    </revision>
  </page>
  <page>
    <title>HMailServer</title>
    <ns>0</ns>
    <id>1309</id>
    <revision>
      <id>19435</id>
      <parentid>13969</parentid>
      <timestamp>2013-01-15T09:07:23Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <minor/>
      <comment>a déplacé [[HMailServer - Utilisation en dev]] vers [[HMailServer]]</comment>
      <origin>19435</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6280" sha1="82pjiug0pnrtr5jesq0hi6amff0ir5a" xml:space="preserve">[[Category:outil]]
[[Category:HMailServer]]
Cette page décrit comment envoyer des mails en dev avec les classes de mail de l'archi (com.imrglobal.framework.mail.Mail et autres). Ceci n'est pas un document de configuration, mais bien d'utilisation rapide. Il y a de la documentation plus complète sur eroom :

[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid efluid - Qualité Développement] &gt; [http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_1df7f Guides et procédures] &gt; [http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_1bb5d guide environnement de développement] &gt; [http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_44b8f outils et serveurs] &gt; [http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_44b92/Installation%20et%20configuration%20serveur%20mail%20et%20FTP.doc Installation et configuration serveur mail et FTP.doc]

== Généralités ==

Il est possible d'utiliser le serveur de mail mailfluid, qui pointe vers Lausanne. Sur ce serveur il y a un serveur de mail de test (hMailServer) qu’on utilise et qui a plusieurs adresses mail de test, par exemple test1@efluid.net, test2@efluid.net, etc. Il est aussi possible d'utiliser un serveur de mail (par exemple hMailServer) installé en local.

'''En utilisant mailfluid, il faut absolument envoyer vers des mails qui se terminent en @efluid.net.'''

Le serveur de mail "mailfluid" est situé à l'IP suivant depuis Paris: 162.70.248.73.

== Configuration projet ==

=== Envoi ===

Dans le framework2.properties, renseigner le nom du serveur mail.

&lt;source lang="bash"&gt;
SERVEUR_MAIL=mailfluid
&lt;/source&gt;

=== Configuration utilisateur ===

Afin de s'envoyer des messages en dev, il est préférable de se créer un utilisateur afin de mettre le bon mail, et cela permet de tester aussi les nom, compléments noms, etc. Il faut d'abord trouver le LDAP sur lequel la connexion est effectuée, disponible dans le framework2.properties :

&lt;source lang="bash"&gt;
LDAP_HOST=hermesldap
&lt;/source&gt;

Ensuite, il faut créer / modifier un utilisateur.

* Se connecter à ELDAP
** Aller à "http://envtsefluid/gestionEnvtsClients/"
** Choisir "LDP", n'importe la version
** Entrer "habilLDP" / "mdp" comme login
* Changer le LDAP avec le menu "changer connexion LDAP"
** Choisir le bon LDAP en fonction de ce qui est paramétré dans l'application de dev, voir ici-haut
* Créer / Modifier une personne
** Aller dans le menu "personne"
** Se créer / chercher
** Modifier l'entrée "mail"
* Ajouter à cette personne des postes
** Aller dans le menu "poste"
** Chercher le bon poste en s'entrant dans la recherche
** Modifier le poste, puis affecter les profils nécessaires pour les applications en dev

L'utilisateur est maintenant correctement configuré, normalement vous devriez pouvoir vous connecter directement à l'application en dev et utiliser votre nouveau mail !

==== Spécificités briques (archi, ecore, edk) ====

Les briques n'ont pas de profil, ils utilisent les profils des applications cibles. Il faut renseigner dans le fichier framework2 de quelle application les profils viennent.

&lt;source lang="bash"&gt;
LDAP_ATT_APPLICATION_HERMES=efluid
&lt;/source&gt;

Par contre, en entrant vos identifiants de connection, c'est la requête suivante qui fera la recherche en base pour tester les habilitations de l'application :

&lt;source lang="sql"&gt;
select ...
from TPROFILHABILITATION A 
where (A.IDENTIFIANTLDAP= 'cn=efluid administrateur,ou=efluid,ou=Profil,o=uem,dc=uem-metz,dc=fr') and mod(A.ETATOBJET,2)=0
&lt;/source&gt;

Il faut donc possiblement rajouter des habilitations pour l'application cible si elles n'existent pas. Par exemple :

&lt;source lang="sql"&gt;
insert into TPROFILHABILITATION ... 
VALUES ('P2','efluid administration',...,'cn=efluid administration super utilisateur,ou=efluid,ou=Profil,o=uem,dc=uem-metz,dc=fr',...);
&lt;/source&gt;

==== Spécificités Paris ====

À Paris, il y a un LDAP différent, il ne sert à rien de faire l'étape ici-haut pour s'ajouter au LDAP de développement, on ne s'y connecte pas normalement. Le plus simple c'est tout simple de se connecter à celui de Metz en ajoutant au fichier framework2 ceci :

&lt;source lang="bash"&gt;
#LDAP_HOST=hermesldap
LDAP_HOST=172.16.1.27
&lt;/source&gt;

== Configuration poste ==

=== Virus Scan ===

Il faut désactiver l’antivirus qui bloque parfois l’accès au port 25 pour limiter la diffusion massive d’email. Il faut ouvrir la console VirusScan.

[[Fichier:Console-virusscan.JPG]]

Puis désactiver les analyseurs à l'accès, comme suit. Attention, les éléments se réactivent après 15 minutes.

[[Fichier:Console-virusscan-2.JPG]]

=== Client mail ===

Il est plus facile d'utiliser Thunderbird afin de ne pas pourrir son Outlook, sinon les configurations sont les mêmes.

* '''Vos nom et prénom''' : test4 (n'importe)
* '''Adresse électronique''' : test4@efluid.net
* '''Mot de passe''' : test4
* Serveur entrant
** '''Protocole''' : IMAP
** '''Nom d'hôte du serveur''' : mailfluid
** '''Port''' : 143
* Serveur sortant
** '''Protocole''' : SMTP
** '''Nom d'hôte du serveur''' : mailfluid
** '''Port''' : 25
* '''Identifiant''' : test4@efluid.net

[[Fichier:Configuration-thunderbird-mailfluid-01.JPG]]

=== Comptes disponibles ===

* test1
** '''UN''' : test1@efluid.net
** '''PW''' : test
* test2
** '''UN''' : test2@efluid.net
** '''PW''' : test
* test3
** '''UN''' : test3@efluid.net
** '''PW''' : test3
* test4
** '''UN''' : test4@efluid.net
** '''PW''' : test4

== Erreurs courantes ==

=== 452 ===

Se produit de manière sporadique lors des premières exécutions, rééexecuter (changer "MAIL_FROM_ADDRESS" pour un truc en "@efluid.net" semble aider).

 com.sun.mail.smtp.SMTPSendFailedException: 452 Insufficient system storage

=== 500 ===

Vous utilisez une adresse où mailfluid ne peut envoyer (l'adresse ne peut pas terminer en autre chose que "@efluid.net").

 com.sun.mail.smtp.SMTPAddressFailedException: 550 Delivery is not allowed to this address.

=== Connection refused ===

Votre client McAffee n'est pas désactivé (il faut tout désactiver sinon le port 25 est bloqué).

 javax.mail.MessagingException: Could not connect to SMTP host: mailfluid, port: 25;
  nested exception is:
   java.net.ConnectException: Connection refused: connect</text>
      <sha1>82pjiug0pnrtr5jesq0hi6amff0ir5a</sha1>
    </revision>
  </page>
  <page>
    <title>Oracle</title>
    <ns>0</ns>
    <id>1631</id>
    <revision>
      <id>4068680</id>
      <parentid>4068679</parentid>
      <timestamp>2023-03-17T08:37:12Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Mettre à jour le drivers dans les applications efluid */</comment>
      <origin>4068680</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6314" sha1="ktmt19az054ek6x7opj2i2dt4kcqz7j" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = oracle
 | logo              = Oracle logo gif.gif
 | siteInternet      = https://www.oracle.com/fr/database/index.html
 | version           = {{outil.oracle.version}}
 | guideInstallation = Guide d'installation du client oracle
 | faq               = [[FAQ:Oracle|FAQ Oracle]]
}}
[[Category:outil]]
[[Category:oracle]]

= Presentation =
= Documentation =
PTI installation moteur et client oracle database 12.1.0.2.0 : http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_6219a

Documentation officielle : http://docs.oracle.com/en/database/database.html

= Patches =
== Procédure installation Patch ==
La documentation se trouve sur eroom : [http://wperoom2.uem.lan/eRoom/Production/AnalyseBatchsEfluid/0_d5cc8 ]

== Oracle Database 12.1.0.2.0 ==
Patch ID 17365043 : [http://suivefluid/suivefluid_UEM//evenement/171716 171716]. Permet de résoudre un problème de dimensionnement de la zone mémoire STREAMS_POOL_SIZE.

= Procédures divers =
== Création trigger pour suivi connexions si paramètre oracle audit_trail=NONE ==
1. Se connecter sur la BDD en tant que SYS/SYSTEM

-&gt; Attention à se placer sur le container souhaité en oracle12c !
&lt;small&gt;
&lt;source lang="bash"&gt;
   alter session set container=&lt;container&gt; ;
&lt;/source&gt;
&lt;/small&gt;

2. Créer le trigger suivant :
&lt;small&gt;
&lt;source lang="bash"&gt;
CREATE OR REPLACE TRIGGER logon_denied_write_alertlog AFTER SERVERERROR ON DATABASE
DECLARE
 l_message varchar2(2000);
BEGIN
 -- ORA-1017: invalid username/password; logon denied
 IF (IS_SERVERERROR(1017)) THEN
 select 'ORA-1017 - Erreur de connexion instance "'
	|| sys_context('USERENV' ,'SERVICE_NAME') 
	|| '" using "'
	|| sys_context('USERENV' ,'AUTHENTICATED_IDENTITY') 
	||'" adresse_ip "'
	|| sys_context('USERENV' ,'IP_ADDRESS') 
	|| '" host "'
	|| sys_context('USERENV' ,'HOST') 
	||'" osuser "'
	|| sys_context('USERENV' ,'OS_USER')
	|| '"'
 into l_message
 from sys .v_$session
 where sid = to_number(substr(dbms_session.unique_session_id,1 ,4), 'xxxx')
 and serial# = to_number(substr(dbms_session.unique_session_id,5 ,4), 'xxxx');
 -- write to alert log
 sys.dbms_system.ksdwrt( 2,l_message );
 END IF;
END;
/
&lt;/source&gt;
&lt;/small&gt;

3. Consulter le fichier alerte_&lt;nom_instance&gt;.log dans le répertoire d'alerte de l'instance avec l'erreur ORA-1017

Exemple erreur générée : 
&lt;small&gt;
&lt;source lang="bash"&gt;
Wed May 10 17:12:41 2017
ORA-1017 - Erreur de connexion instance "ruemedt1" using "TOTO" adresse_ip "192.168.141.158" host "PC2126" osuser "wozniak"
&lt;/source&gt;
&lt;/small&gt;

== Application d'un PSU ==
* Récupérer les binaires d'installation du patch

Rajouter l'entrée suivante dans le fichier /etc/fstab :

lpnfssan1-edt:/NFS_LRBDDTECX_SVG_A04/installation_oracle/patch/

* Vérifier espace disque disponible sur $ORACLE_HOME

Utiliser la commande suivante pour vérifier :
&lt;small&gt;
&lt;source lang="bash"&gt;
[oracle ]$ df -h $ORACLE_HOME
&lt;/source&gt;
&lt;/small&gt;

L'espace disque disponible doit être de 1 Go

* Vérifier la compatibilité avec l'installation
Se placer dans le répertoire du patch, puis lancer l'outil opatch :
&lt;small&gt;
&lt;source lang="bash"&gt;
[oracle ]$ $ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -ph ./
&lt;/source&gt;
&lt;/small&gt;

Le résultat doit indiqué qu'il n'y a aucun conflit. Exemple :
&lt;small&gt;
&lt;source lang="bash"&gt;
Oracle Home       : /opt/oracle/product/11.2.0.4/db
Central Inventory : /opt/oracle/oraInventory
   from           : /opt/oracle/product/11.2.0.4/db/oraInst.loc
OPatch version    : 11.2.0.3.11
OUI version       : 11.2.0.4.0
Log file location : /opt/oracle/product/11.2.0.4/db/cfgtoollogs/opatch/opatch2017-05-31_17-45-37PM_1.log

Invoking prereq "checkconflictagainstohwithdetail"

Prereq "checkConflictAgainstOHWithDetail" passed.

OPatch succeeded.
&lt;/source&gt;
&lt;/small&gt;

* Vérifier que les binaires oracle ne sont plus utilisés
** Les bases de données doivent être éteintes
** Le listener doit être éteint
** Les processus GoldenGate doivent être stoppés

Pour vérifier : 
&lt;small&gt;
&lt;source lang="bash"&gt;
[root ]# lsof $ORACLE_HOME
&lt;/source&gt;
&lt;/small&gt;

* Appliquer le patch
Toujours dans le répertoire du patch
&lt;small&gt;
&lt;source lang="bash"&gt;
[oracle ]$ $ORACLE_HOME/OPatch/opatch apply ;
&lt;/source&gt;
&lt;/small&gt;

Remarque : si blocage, se référer au lien ci-dessous Blocage lancement opatch

* Redémarrer la BDD et lancer le script
Les actions sont différentes suivante la version oracle
- Pour oracle 11g
&lt;small&gt;
&lt;source lang="bash"&gt;
[oracle ]$ cd $ORACLE_HOME/rdbms/admin
[oracle ]$ sqlplus / as sysdba
SQL&gt; startup open
SQL&gt; @catbundle.sql psu apply
&lt;/source&gt;
&lt;/small&gt;

* Pour oracle 12c
Action supplémentaire à réaliser pour oracle 12c
Important : Vérifier que toutes les PDB sont en mode OPEN (la PDB PDB$SEED reste en read-only)
&lt;small&gt;
&lt;source lang="bash"&gt;
[oracle ]$ cd $ORACLE_HOME/OPatch/opatch
[oracle ]$ ./datapatch -verbose
&lt;/source&gt;
&lt;/small&gt;

* Vérifier le niveau de patch PSU
: Avec l'utilitaire OPatch
Permet de savoir si les binaires sont patchés, mais pas la BDD oracle.
&lt;small&gt;
&lt;source lang="bash"&gt;
[oracle ]$ cd $ORACLE_HOME/OPatch/opatch lsinventory
&lt;/source&gt;
&lt;/small&gt;
: En base de données
&lt;small&gt;
&lt;source lang="bash"&gt;
set linesize 300
COLUMN action_time FORMAT A20
COLUMN action FORMAT A10
COLUMN bundle_series FORMAT A10
COLUMN comments FORMAT A30
COLUMN description FORMAT A40
COLUMN namespace FORMAT A20
COLUMN status FORMAT A10
COLUMN version FORMAT A10
SELECT TO_CHAR(action_time, 'DD-MON-YYYY HH24:MI:SS') AS action_time,
       action,
       namespace,
       version,
       id,
       comments,
       bundle_series
FROM   sys.registry$history
ORDER by action_time;
&lt;/source&gt;
&lt;/small&gt;

== Mettre à jour le drivers dans les applications efluid ==

un change dans l'archi pour les applications basées dessus : https://gerrit.efluid.uem.lan/c/archi/+/286459

un change dans efluidUtilsPom pour celle n'utilisant pas l'archi : https://gerrit.efluid.uem.lan/c/efluidUtilsPom/+/286458

= Liens internes =
* [[SQL]]
* [https://docs.oracle.com/database/121/LNPLS/triggers.htm#LNPLS99887 Documentation sur les triggers]
* [https://docs.oracle.com/database/121/SQLRF/functions199.htm#SQLRF06117 Documentation sur les variables de contexte SYS_CONTEXT ]
* [http://docs.oracle.com/cd/B19306_01/em.102/b16227/oui8_opatch.htm#CEGHIJGI Blocage lancement opatch ]</text>
      <sha1>ktmt19az054ek6x7opj2i2dt4kcqz7j</sha1>
    </revision>
  </page>
  <page>
    <title>Gerrit</title>
    <ns>0</ns>
    <id>1848</id>
    <revision>
      <id>4068231</id>
      <parentid>4066661</parentid>
      <timestamp>2023-01-30T10:40:16Z</timestamp>
      <contributor>
        <username>Carriers</username>
        <id>234</id>
      </contributor>
      <comment>/* Processus */</comment>
      <origin>4068231</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12772" sha1="mipe2p6dtuqkgbg03mxzytyid83smku" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = gerrit
 | logo              = logo_gerrit.png
 | siteInternet      = http://code.google.com/p/gerrit/
 | version           = {{outil.gerrit.version}}
 | supportTechnique  = {{usinelogicielle|subject=gerrit}}
 | guideInstallation = Gerrit_administration
 | guideUtilisation  = Gerrit_cas_utilisations
 | guideExploitation  = Gerrit_exploitation
 | guideMigrationDocker = Gerrit_migration_docker
 | faq               = [[FAQ:Gerrit|FAQ Gerrit]]
}}

Gerrit est une application web de revue de code pour le travail en équipe. C'est un logiciel gratuit développé chez Google par Shawn Pearce (†). Il est distribué sous la Licence Apache V2. Il permet à chaque utilisateur de lire, approuver ou rejeter les modifications du code source via un navigateur web. Celui-ci s'utilise avec le gestionnaire de version Git.

== Assistance / Formation ==

Si vous éprouvez des difficultés avec GIT/GERRIT, contactez :
* Sur Metz : [[Vincent Poutissou]]
* Sur Paris : [[David Bodin]]
* A défaut : {{usinelogicielle|subject=gerrit}}
Si les messins ne sont pas joignables, tentez avec les parisiens. Et inversement.

=== Supports de formation ===
Voici différents supports pour vous former à utiliser GIT/GERRIT :

{{Modèle:formation_gerrit}}
{{Modèle:formation_git}}

== Guides développeur ==
=== Prérequis d'utilisation de GERRIT ===
Configuration de GIT :
* Version de [[Git]] : [[Guide d'installation de Git|&gt; 2]]
* [[Guide de configuration du poste développeur pour Gerrit|Suivre le guide de configuration du poste développeur pour Gerrit]]
* Navigateur web différent de Internet Explorer
* [[Gestion des droits des référentiels Git|Avoir les droits sur le référentiel Git comme publicateur ou relecteur]]

=== Liens Utiles ===
* Liens vers l'application Gerrit Revue de code : http://gerrit.efluid.uem.lan
* Guide des cas d'utilisations de Gerrit : [[Gerrit_cas_utilisations|cas d'utilisations]]
* Les IP depuis CPL sont :
** gerritssh et gerritssh.efluid.uem.lan : 192.168.106.93
** gerrit et gerrit.efluid.uem.lan : 192.168.106.10
* [[Clone referentiel Gerrit]]
* [[Suivre les actualités Gerrit via un flux RSS]]

=== Personnalisation des menus ===
* Il est possible de personnaliser les menus en utilisant des requêtes.

* Pour ce faire, aller dans VotreUser (1) &gt; Settings(2) &gt; Préférences(3)

[[Fichier:GerritUserSettings.jpeg|default]]

* Ensuite aller au chapitre My Menu et entrer le nom de votre nouveau menu et dans l'url écrivez votre requête.

Par exemple une requête qui permet de voir mes changes qui ont été mergés dans Efluid branche develop : 

* Name : Changes merged efluid develop
* URL : #/q/owner:self status:merged branch:develop project:efluid

Une fois terminé appuyez sur le bouton + (1) puis Save changes (2) 

[[Fichier:exempleMyMenu.jpeg|default]]

* Une fois les manipulations précédentes terminées votre menu personnalisé apparaît.

[[Fichier:apparitionMenu.jpeg|default]] 
&lt;br /&gt;
* Exemple de requête  : [[Gerrit#Requêtes de recherche gerrit|Requêtes de recherche]].

=== Requêtes de recherche gerrit === 
Documentation synthaxique : [https://gerrit.efluid.uem.lan/Documentation/user-search.html Documentation gerrit]&lt;br /&gt;

{{alert|texte=Attention ! Si vous voulez mettre ses requêtes dans un menu (CF tuto : [[Gerrit#Personnalisation des menus|Personnalisation des menus]] ) il faut entrer l'url comme ceci '''#/q/VotreRequête'''}}

{| class="wikitable"
|-
! Requête !! Commentaire
|-
| owner:self is:open label:Code-Review=2 label:Verified=1 NOT label:Verified-1 NOT label:Code-Review-2 || Permet de connaitre vos changes qui sont prêts à être submit
|-
| owner:self is:open (label:Verified-1 OR label:Code-Review-2) || Permet de connaitre vos changes qui sont bloqués par un -1 ou -2
|-
| reviewerin:"Validateurs SQL Suite efluid et Enercom" status:open || Permet de connaitre les changes qui ont besoin d'une revue SQL
|-
|}

== Conventions de commit ==
* Les messages de commit doivent respecter la norme suivante
 &lt;REFERENCE_EVT_SUIVEFLUID&gt; : &lt;message du commit&gt;

(&lt;tt&gt;&lt;message du commit&gt;&lt;/tt&gt; : décrire la/les modification(s) effectuée(s) ; cette information servant à alimente le bon de livraison)
* Si l'on veut indiquer d'autres évènements (en plus de l'évènement principal) dans le commit il faut le faire de la manière suivante : 
 &lt;REFERENCE_EVT_SUIVEFLUID&gt; : #&lt;REFERENCE_AUTRE_EVT_SUIVEFLUID&gt; &lt;message du commit&gt;

'''Exemple de variante possible :'''
&lt;tt&gt;
  120572 : [dependencies] ecore-4.XX.100
    -  #123456 : correction XXX
&lt;/tt&gt;

==== "Tags" de commit ====

il est recommandé de précéder le commentaire de message d'un tag de la liste suivante :
* &lt;tt&gt;[fix]&lt;/tt&gt; évolution du code suite à une ano
* &lt;tt&gt;[feat]&lt;/tt&gt; déploiement de nouvelle fonction
* &lt;tt&gt;[tests]&lt;/tt&gt; mise à jour des TU/TI sans toucher au code métier

==== Editer un message de commit via gerrit ====

#Sur votre changeset, cliquez sur le bouton "Edit" (Entre les informations générales du changeset et la liste des fichiers modifiés/créés/supprimés). La liste des fichiers devient modifiable.
#Cliquer sur "Commit message" ; attention, vous ne devriez pas toucher aux autres fichiers du commit. En effet, gerrit ne conserve pas forcément l'encodage ni le formatage du projet.
#Modifiez le message du commit
#Cliquez sur le bouton "Done editing" (bouton qui a remplacé le bonton "Edit")
#Republiez le message de commit : bouton "publish" en haut de l'interface gerrit.
[[Fichier:Edit_message_gerrit_1.png]]
[[Fichier:Edit_message_gerrit_2.png]]

==== Pour aller plus loin ====

*Normes des messages gerrit du groupe FAC: [[Format_Msg_Commits_FAC|Format FAC]]
*Normes des messages gerrit du groupe Portail: [[Groupe_de_développement_portail|Règles Portail]]
*Un article intéressant à lire : https://chris.beams.io/posts/git-commit/

== Vocabulaire ==
* '''Change''' : correspond à un commit en attente de revue de code. Commit poussé sur la branche ''refs/for/*''
* '''PatchSet''' : correspond à une des versions d'un change. Chaque fois qu'un 'commit --amend' est effectué sur un change, Gerrit crée un nouveau pathchSet.
* '''Dépôt principal''' : contient l'ensemble des commits validés. Seuls les commits présents sur ce dépôt seront récupérés lors d’un pull. Le dépôt principal correspond à la référence ''refs/heads/*''
* '''Dépôt gerrit''' : contient l'ensemble des changes. Ce dépôt permet de stocker les commits en attente d’une revue de code. Ceux-ci ne pourront pas être récupérés lors d’un pull, tant qu’ils ne seront pas mergés sur le dépôt principal. Le dépôt gerrit correspond à la référence ''refs/for/*''
* '''Submit''' : Action qui autorise Gerrit à merger un change sur le dépôt principal.
* '''Abandon''' : Action pour archiver un change sans qu'il ne soit mergé sur le dépôt principal. Un change abandonné peut être restauré ultérieurement.
* '''Project''' : correspond à un dépôt Git. Il regroupe le dépôt principal et le dépôt Gerrit.
* '''Change-Id''' : Id commun à tous les patchSet d'un change.

=== Signification des labels ===
Les labels constituent les "notes" affectés à chaque ChangeSet Gerrit. Pour qu'un changeSet puisse être mergé il faut que tous les labels obligatoires soient valides, selon les règles suivantes : 
* CR : Code Review
** Note obligatoire, attribuée manuellement
** Attribution par des relecteurs / validateurs
** va de -2 à +2
** au moins un +2 est nécessaire pour qu'un changeSet soit "mergeable"
** aucun -2 ne doit être présent pour qu'un changeSet soit "mergeable"

* V : Verified
** Note obligatoire, attribuée automatiquement
** Attribution par l'usine logicielle
** va de -1 à +1
** un +1 est nécessaire pour qu'un changeSet soit "mergeable"
** un -1 rend le changeSet non "mergeable"

* MR : Maven Review
** Note optionelle, attribuée manuellement, uniquement si le changeSet contient des fichiers Maven (pom.xml, *.pom)
** Attribution par les membres du process de fabrication
** va de -1 à +1
** un +1 est nécessaire pour qu'un changeSet soit "mergeable"
** un -1 rend le changeSet non "mergeable"

* SR : SQL Review
** Note, attribuée manuellement, uniquement si le changeSet contient des modification SQL (fichiers présents dans /sql/database/*)
** Attribution par les validateurs SQL
** va de -1 à +1
** un +1 est nécessaire pour qu'un changeSet soit "mergeable"
** un -1 rend le changeSet non "mergeable"

=== Signification des notes des revues de codes (CR) ===
{| class="wikitable sortable"
|-
! Note
! Signification
! Catégorie disposant de la note
|-
| -2
|Ce changeSet ne doit pas être soumis car comporte des erreurs trop importantes. Le changeSet est bloqué par le relecteur/validateur.
|Relecteur ou Validateur
|-
| -1
|Ce changeSet comporte des erreurs qu'il serait intéressant de corriger tout de suite. Note non bloquante.
|Relecteur ou Validateur
|-
| 0
|Note utilisée pour des remarques d'ordre générales.
|Relecteur ou Validateur
|-
| +1
|Ce changeSet est OK du point de vue du relecteur mais nécessite une validation d'un validateur.
|Relecteur ou Validateur
|-
| +2
|Ce changeSet est OK du point de vue du validateur.
|Validateur
|}

[[Gerrit - Guide de Notation|Guide de Notation]]

== Processus ==
=== Demande de création d'un nouveau projet dans Gerrit ===
Créer un évènement dans suivefluid en suivant le modèle de l'événement 388461 et le transmettre par mail à usinelogicielle.

=== Workflow de publication dans gerrit ===

Processus à suivre pour tous développements qui passent par une revue de code :

* Le développeur soumet son code par les mécanismes habituels (git pub) à gerrit
* Le développeur indique un ou plusieurs relecteur de son changeSet Gerrit
* Le job de compilation auto ajoute +1 si la compilation est ok
* Le relecteur fait la revue de code et ajoute +1
* En cas de modification SQL ''(scripts DML, modifications DDL...)'', un relecteur SQL de l'équipe études et performances fait la revue et ajoute +1
* Un validateur du dépôt ajoute +2
* Le développeur submit son code

Les validateurs sont indiqués dans les descriptions des projets Gerrit.

==== Listes de diffusion ====
Validateurs xxx (autocomplété dans gerrit).

=== Workflow de soumission de code en cas de code-freeze ===
Le processus de soumission de code en cas de branche gelée est disponible ici : http://WPEROOM2.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_18703f (http://wperoom2.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_43ed8)
&lt;br /&gt;
&lt;br /&gt;
Le diagramme principal est repris ici, mais c'est le document précédent qui fait foi : 
[[Fichier:Processus soumissionDeCodeSurBrancheGelee - Macro.png]]

== Configuration des labels ==

=== Documentation gerrit ===
[https://gerrit-documentation.storage.googleapis.com/Documentation/2.13.2/config-labels.html Config label]

=== Désactiver un label pour un projet ===
Aller dans le project.config du projet puis ajouter function = NoOp

exemple pour mvn review : 

 [label "MVN-Review"]
   function = NoOp

=== CODE-REVIEW ===

[label "Code-Review"]
  function = MaxWithBlock
    copyMinScore = true
    value = -2 Do not submit
    value = -1 I would prefer that you didn't submit this
    value =  0 No score
    value = +1 Looks good to me, but someone else must approve
    value = +2 Looks good to me, approved
    defaultValue = 0
    copyAllScoresOnTrivialRebase = true
    copyAllScoresIfNoCodeChange = false

=== Verified ===
    [label "Verified"]
      branch = refs/heads/develop
      branch = ^refs/heads/maintenance_.*
      function = MaxWithBlock
      value = -1 Fails
      value =  0 No score
      value = +1 Verified
      defaultValue = 0
      copyAllScoresOnTrivialRebase = false
      copyAllScoresIfNoCodeChange = true 

=== SQL-REVIEW ===
  [label "SQL-Review"]
    function = MaxWithBlock
        value = -1 Not valid
        value =  0 No score
        value = +1 Verified
        defaultValue = 0
        copyAllScoresOnTrivialRebase = true
        copyAllScoresIfNoCodeChange = true

=== MVN-REVIEW ===
 [label "MVN-Review"]
    function = MaxWithBlock
        value = -1 Not valid
        value =  0 No score
        value = +1 Verified
        defaultValue = 0
        copyAllScoresOnTrivialRebase = true
        copyAllScoresIfNoCodeChange = true

Le MVN-REVIEW est désactivé pour les projets : OracleTools et Performance

== plugins ==
[[X-docs]]&lt;br /&gt;
[[gerrit-suivefluid]]

== Archives ==
* Guide sur la migration des projets : [[La migration sous gerrit pour les nuls]]

[[Category:Outil]]
[[Category:Gerrit]]

== Problème lié à Gerrit ==
Il est formellement interdit de modifier les fichiers dans Gerrit car cela modifie l'encodage de la classe</text>
      <sha1>mipe2p6dtuqkgbg03mxzytyid83smku</sha1>
    </revision>
  </page>
  <page>
    <title>JExplorer</title>
    <ns>0</ns>
    <id>1972</id>
    <revision>
      <id>834799</id>
      <parentid>834797</parentid>
      <timestamp>2015-06-02T06:16:33Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>834799</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1490" sha1="f9403jeiw8mg2xpk38xufeezpfnd3w7" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = JXplorer
 | version           = {{outil.jexplorer.version}}
 | siteInternet      = http://www.jxplorer.org
 | guideInstallation = 
}}
[[Category:outil]]
[[Category:JXplorer]]
Outil permettant de consulter facilement les données présente dans un annuaire LDAP.

==Lancement de JXplorer==

* Lancer JXplorer depuis l’icône.
[[image:IconeJXplorer.jpg]]&lt;br/&gt;&lt;br/&gt;
[[image:JXplorer.jpg|600px]]

==Connexion à l'annuaire==
{| class="wikitable"
|-
! Fenêtre !! Action
|-
| JXplorer || Se connecter à un annuaire LDAP « Fichier » -&gt; « Se connecter »
|-
| Ouverture d’une connexion LDAP/DSML || Choisir un template déjà défini.&lt;br/&gt;
Ou remplir la fenêtre avec les paramètres de connexion de votre base ldap
|}

[[image:ConnectionLdap-JXplorer.jpg]]

==Utilisation==

[[image:Utilisation-JXplorer.jpg|600px]]&lt;br/&gt;&lt;br/&gt;
* '''Partie gauche de la fenêtre :''' Navigation dans les branches de l’annuaire&lt;br/&gt;
* '''Partie droite de la fenêtre :''' Visualisation des données de l’entrée sélectionnée 

==Ajouter une entrée==

[[image:AjouterEntree-JXplorer.jpg]]&lt;br/&gt;&lt;br/&gt;
* Saisir la valeur cn de la nouvelle entrée et valider&lt;br/&gt;
[[image:CreationEntree-JXplorer.jpg]]&lt;br/&gt;&lt;br/&gt;
* Remplir les champs obligatoires (en gras) et optionnels, puis soumettre&lt;br/&gt;
[[image:SaisieEntree-JXplorer.jpg|600px]]&lt;br/&gt;&lt;br/&gt;
* La nouvelle entrée doit apparaitre dans la fenêtre de gauche.&lt;br/&gt;
[[image:ControleNouvelleEntree-JXplorer.jpg]]</text>
      <sha1>f9403jeiw8mg2xpk38xufeezpfnd3w7</sha1>
    </revision>
  </page>
  <page>
    <title>VisualVM</title>
    <ns>0</ns>
    <id>1987</id>
    <revision>
      <id>16916</id>
      <parentid>16914</parentid>
      <timestamp>2012-10-26T13:52:09Z</timestamp>
      <contributor>
        <username>Back</username>
        <id>82</id>
      </contributor>
      <origin>16916</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2858" sha1="0i4dgi31u6jfqp8ft55vlbr9k0ax1ah" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = VisualVM
 | siteInternet      = http://visualvm.java.net
 | version           = {{outil.VisualVM.version}}
 | guideInstallation = Guide d'installation de VisualVM
}}

Utilisé pour analyser les performances d'une application Java.

[[Category:outil]]

= Prérequis =

Il est nécessaire de paramétrer, avant le lancement de la JVM à monitorer, les différents éléments du connecteur JMX, tel que décrit ici : [[JVM]]

= Connexion =

== Serveur d'applications ==
* Récupérer la chaine de connexion JMX du serveur, dans le fichier de log Jonas par exemple : service:jmx:rmi://lrbddtec4/jndi/rmi://lrbddtec4:9198/jrmpconnector_jonas-1
* Ouvrir VisualVM
* Dans l'arbre de gauche, cliquer avec le bouton de droite sur "Remote". Selectionner "Add Remote Host"
[[Fichier:VisualVM_001.png]]
&lt;br /&gt;
&lt;br /&gt;

* Renseigner le nom ou l'IP du serveur sur lequel se trouve le serveur d'application.
* Cliquer avec le bouton de droite sur le serveur nouvellement créé, selectionner "Add JMX Connection"
[[Fichier:VisualVM_002.png]]
&lt;br /&gt;
&lt;br /&gt;

''Le serveur d'application doit etre lancé avant de dérouler les étapes ci-après :''
* Renseigner le service avec l'URL JMX récupéré dans l'étape 1.
* Double cliquer sur le connecteur JMX nouvellement créé.
[[Fichier:VisualVM_003.png]]

&lt;br /&gt;
&lt;br /&gt;


== Batchs ==

* Récupérer le numéro de port JMX configuré dans la chaine de lancement du batch (voir [[JVM]]) 
* Ouvrir VisualVM
* Dans l'arbre de gauche, cliquer avec le bouton de droite sur "Remote". Selectionner "Add Remote Host"
[[Fichier:VisualVM_001.png]]
&lt;br /&gt;
&lt;br /&gt;

* Renseigner le nom ou l'IP du serveur sur lequel s'execute le batch.

''Le batch doit etre lancé avant de dérouler les étapes ci-après :''

* Cliquer avec le bouton de droite sur le serveur nouvellement créé, selectionner "Add JMX Connection"
[[Fichier:VisualVM_004.png]]

* Renseigner le service en concaténant IP/NOM et PORT récupéré dans l'étape 1.
* Double cliquer sur le connecteur JMX nouvellement créé.
[[Fichier:VisualVM_005.png]]

= Utilisation =
== Paramétrage JVM ==
l'onglet "Overview" donne tous les paramétres JAVA chargés au lancement de la JVM, ainsi que les variables systèmes.

== Memoire, CPU et GC ==
L'onglet "Monitor" affiche les graphiques temps réel :
* de charge CPU du serveur
* de charge GC de la JVM
* d'utilisation de la Heap et la PermGen de la JVM
* du nombre de classes chargées
* du nombre de threads actifs
&lt;br /&gt;
&lt;br /&gt;

[[Fichier:VisualVM_006.png]]
&lt;br /&gt;

== Threads ==
L'onglet "Threads" affiche en temps réels l'état de tous les threads tournant dans la JVM.
&lt;br /&gt;
Cet onglet permet aussi de générer des threads-dump sous forme de fichier texte.
&lt;br /&gt;
&lt;br /&gt;

Le sous-onglet "Table" affiche les statistiques d'executions par Thread.

[[Fichier:VisualVM_007.png]]</text>
      <sha1>0i4dgi31u6jfqp8ft55vlbr9k0ax1ah</sha1>
    </revision>
  </page>
  <page>
    <title>M2e</title>
    <ns>0</ns>
    <id>907</id>
    <revision>
      <id>712871</id>
      <parentid>24984</parentid>
      <timestamp>2015-03-23T10:58:54Z</timestamp>
      <contributor>
        <username>Meyerj</username>
        <id>287</id>
      </contributor>
      <origin>712871</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="881" sha1="dnogj2xutpj4o7ejuqvcjhj157snym7" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = M2e
 | siteInternet      = http://www.eclipse.org/m2e/
 | logo              = Smallm2eclipse.png
 | version           = {{outil.m2e.version}}
}}

[[Category:plugin]]
[[Category:Construction Zip D'Eclipse]]
[[Category:maven]]

Plugin [[eclipse]] pour [[maven]]; aussi appelé [[m2eclipse]].
= Installation =
Dans [[eclipse]] '''Help &gt; Install New Software ...''' ajouter les plugins
* '''m2e - Maven Integration for Eclipse'''
* '''m2e - sl4j over logback logging (Optional)'''
via l'url http://download.eclipse.org/technology/m2e/releases

= Bug déclarés =
* Lors d'un time out sur la récupération d'un artifact la console écrit "Downloaded" alors qu'on devrait plutôt avoir "Downloading" [https://bugs.eclipse.org/bugs/show_bug.cgi?id=384224] =&gt; '''Statut : ouvert'''

= Liens utiles =
* Site officiel : http://eclipse.org/m2e/</text>
      <sha1>dnogj2xutpj4o7ejuqvcjhj157snym7</sha1>
    </revision>
  </page>
  <page>
    <title>Webby</title>
    <ns>0</ns>
    <id>875</id>
    <revision>
      <id>108542</id>
      <parentid>41872</parentid>
      <timestamp>2013-12-09T15:51:44Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Installation */</comment>
      <origin>108542</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4922" sha1="jgdla5lyzh72y14ngu35bu3pbwozaiw" xml:space="preserve">[[Category:plugin]]
[[Category:eclipse]]
[[Category:webby]]
[[Category:maven]]

{{Modèle:Infobox Outil
 | nom               = Webby
 | version           = {{outil.webby.version}}
}}

Plugin [[eclipse]] pour [[maven]].

Webby (web application runner) remplace WTP et a été développé par Jason Van Zyl le fondateur de Maven.

Une des grosse plus-value de webby est qu'il réutilise les classes compilées par éclipse et qu'il pointe directement sur les bibliothèques du repository maven, publish limité donc aux ressources.

*Intégration complète de Maven (war overlay, scope, etc.)
*Publish presque immédiat
*Le serveur d'application semble plus rapide
*Les chargements des classes à chaud se réalise avec succès hormis quelque fois pour les cas complexes (normal sinon il faut utiliser JRebel)
*Quelques fois le rechargement à chaud des properties ne se fait pas (voir la raison) 

= Installation =

{{alert|texte=Ce plugin est déjà installés par défaut dans le [[zip d'éclipse]]}}

Via [[eclipse]] '''Help &gt; Install New Software ...''' ajouter le plugin '''Web Application Runner''' via l'url : http://m2eclipse.sonatype.org/sites/m2e-webby 

(ou http://repository.tesla.io:8081/nexus/content/sites/m2e.extras/m2eclipse-webby/0.2.2/N/ pour les versions NB)
par exemple http://repository.tesla.io:8081/nexus/content/sites/m2e.extras/m2eclipse-webby/0.2.2/N/0.2.2.201211031759/

== Comment déployer une application avec webby ? ==
Pour exécuter une application sur un serveur Tomcat nous utilisons le lanceur Webby. &lt;br&gt;
*Faire clique-droit sur le projet, puis debug-as, puis debug configurations &lt;br&gt;
[[Fichier:WebbyCreationLanceur.PNG|500px]]

* Puis dans l'onglet Webby faire clique-droit, puis New. Et renseignez les champs comme suit &lt;br&gt;
[[Fichier:WebbyCreationLanceurParametrage.PNG|500px]]

* Puis faire apply, et ensuite Debug.

Si vous souhaitez déployer en même temps plusieurs applications sur [[tomcat]], attribuer au minimum un écart de 3 entre chaque numéro de port. (8080, 8083, 8086, ... le port n+1 est utilisé pour le port AJP et le n+2 pour le port RMI)

Le [[Tableau des applications utilisées par le développement]] détails les ports / utilisateur / url qu'il est conseillé d'utilisé sur les envirronements de développement

== Comment voir les applications déployées avec webby ? ==

Une vue permet de voir les applications déployées avec Webby. 
Pour l'ouvrir faire : 
Window / Show View / Others / Webby / WebApps

[[Image:Webby.PNG|none]]

== Paramétrage ==
* Si la gestion du cache des objets métier est activé, le paramétrage suivant doit être rajouté :
&lt;source lang="bash"&gt;
-Xms3000m -Xmx3000m -verbosegc -server -XX:+DisableExplicitGC -XX:+UseAdaptiveSizePolicy
-XX:+UseParallelGC -XX:+UseParallelOldGC -XX:ParallelGCThreads=8
&lt;/source&gt;
* En général &lt;tt&gt;-Xms1500m -Xmx1500m&lt;/tt&gt; c'est suffisant

= FAQ =
===== Erreur au lancement de webby après avoir lancer une commande maven pour créer une JAR ? =====
# On lance un goal "clean install" pour efluid avec le profils "efluid-jar"
# On lance webby et ça plante :-(!
# Il faut lancer une "clean" + "rebuild" afin de reconstruire le projet
===== Je n'arrive pas à lancer deux applications différents sur tomcat, j'ai l'erreur &lt;tt&gt;java.net.BindException: Address already in use: JVM_Bind&lt;/tt&gt; ? =====
Il faut installer la nouvelle version du [[Zip d'éclipse]] intégrant une nouvelle version de webby contenant un patch permettant d'utiliser 3 ports : Celui précisé sur l'interface (par exemple le 8080) ainsi que les deux suivants : 8081 (pour le port AJP) et 8082 (Pour le port RMI).

===== Timeout lors du lancement du webby efluidPub ou efluid avec cache activé ? =====

# On lance le webby efluidPub ou efluid
# le webby renvoie un message d'erreur : "Failed to start container"

[[Fichier:Erreur_webby.jpg‎]]

# Cette erreur arrive lorsque les objets mis dans le cache sont sérialisés, il suffit d'ignorer le message
# Tant que le repertoire du cache n'est pas vidé, ce message ne devrait pas réapparaitre.
# Pour obtenir une correction complète de ce problème il faut prendre le zip eclipse intégrant la gestion du timetout de webby sur [http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_7582a eroom]

[[Fichier:WebbyTimeout.png]]

===== Java Server Facets =====

Après avoir configuré la JRE avec la version 1.5 j'ai l'erreur : 

[[image:Projet-facets-version.JPG]]

Cette erreur n'empêche pas la compilation mais est ennuyante. Il faut modifier à la main le fichier .settings/org.eclipse.wst.common.project.facet.core.xml en changeant la ligne :

&lt;source lang="xml"&gt;
  &lt;installed facet="java" version="1.6"/&gt;
&lt;/source&gt;

pour

&lt;source lang="xml"&gt;
  &lt;installed facet="java" version="1.5"/&gt;
&lt;/source&gt;

== liens externes ==
* {{en}} https://github.com/sonatype/m2eclipse-webby
* {{en}} https://docs.sonatype.org/display/M2ECLIPSE/Integration+with+Maven+WAR+Plugin</text>
      <sha1>jgdla5lyzh72y14ngu35bu3pbwozaiw</sha1>
    </revision>
  </page>
  <page>
    <title>JMeter</title>
    <ns>0</ns>
    <id>2283</id>
    <revision>
      <id>1047843</id>
      <parentid>726695</parentid>
      <timestamp>2015-09-24T11:20:22Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <comment>/* liens */</comment>
      <origin>1047843</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1129" sha1="s9otsrvsc94bi8k5hnyge4jkri2phtk" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = JMeter
 | siteInternet      = jmeter.apache.org
 | version           = {{outil.JMeter.version}}
 | guideInstallation = Guide d'installation de JMeter
 | faq               = [[FAQ:JMeter|FAQ JMeter]]
}}
[[Category:outil]]
[[Category:JMeter]]
[[Category:Test]]

[[JMeter]] est un logiciel permettant de faire des tests de charge orientés performances ou orientés métiers sur différentes protocoles ou technologies. Il est développé par la Fondation Apache, en tant que sous projet Jakarta.
C’est une application entièrement Java avec une interface graphique utilisant l’API Swing, pouvant donc fonctionner sur tout environnement / poste de travail acceptant une machine virtuelle Java, par exemple : Windows, Linux, etc.

= liens = 
* [[Guide d'utilisation de JMeter]]
* [[JMeter utilisation du template d'enregistrement]]
* '''archives'''
** [http://wperoom2.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_149220 JMeter pour échanges efluid_énercom.doc]
** [http://wperoom2.uem.lan/eRoom/Production/AnalyseBatchsEfluid/0_57184 Configuration Files JMS JMeter.docx]</text>
      <sha1>s9otsrvsc94bi8k5hnyge4jkri2phtk</sha1>
    </revision>
  </page>
  <page>
    <title>Cavaj Java Decompiler</title>
    <ns>0</ns>
    <id>4309</id>
    <revision>
      <id>26981</id>
      <timestamp>2013-03-28T14:53:48Z</timestamp>
      <contributor>
        <username>Leoutre</username>
        <id>41</id>
      </contributor>
      <comment>Page créée avec « {{Modèle:Infobox Outil  | nom               = Cavaj Java Decompiler  | siteInternet      = http://cavaj-java-decompiler.softonic.fr/  | version           = Aucun versioni... »</comment>
      <origin>26981</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="382" sha1="1pz62zz1f06s02m1jwrelhh6qhnms80" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Cavaj Java Decompiler
 | siteInternet      = http://cavaj-java-decompiler.softonic.fr/
 | version           = Aucun versioning
 | guideInstallation = Guide d'installation de Cavaj Java Decompiler
}}

Utilisé pour reconstruire un fichier Java à partir d'un fichier d'extension .class

[[Category:outil]]

= Prérequis =

= Connexion =</text>
      <sha1>1pz62zz1f06s02m1jwrelhh6qhnms80</sha1>
    </revision>
  </page>
  <page>
    <title>LTFViewr</title>
    <ns>0</ns>
    <id>4311</id>
    <revision>
      <id>4061635</id>
      <parentid>1047840</parentid>
      <timestamp>2020-10-22T12:07:05Z</timestamp>
      <contributor>
        <username>Leoutre</username>
        <id>41</id>
      </contributor>
      <origin>4061635</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="759" sha1="dv70kmljo1mpdo8zz39ligm21jrzq5s" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = LTFViewr
 | siteInternet      = http://swiftgear.com/ltfviewer/features.html
 | version           = 5.2u
 | guideInstallation = Guide d'installation de LTFViewr
}}

[[Category:outil]]

Cet outil est utilisé pour visualiser des fichiers de très grande taille (&gt;1Go, par exemple). C'est l'outil idéal pour analyser des log trop gros pour être ouverts avec Notepad++ (ou des fichiers PUB générés avec une forte volumétrie d'échanges). Il offre les fonctionnalités suivantes :
*Faire des recherches de chaine de caractère
*Parcourir les occurences par ordre ascendant ou descendant
*Possibilité de sauter à un numéro de ligne.

A utiliser avec Notepad++ pour voir un bloc copié-collé depuis LTFViewr.</text>
      <sha1>dv70kmljo1mpdo8zz39ligm21jrzq5s</sha1>
    </revision>
  </page>
  <page>
    <title>GrepConsole</title>
    <ns>0</ns>
    <id>4828</id>
    <revision>
      <id>712869</id>
      <parentid>712868</parentid>
      <timestamp>2015-03-23T10:58:30Z</timestamp>
      <contributor>
        <username>Meyerj</username>
        <id>287</id>
      </contributor>
      <origin>712869</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4579" sha1="ci1w6p5rg7pmnrdfttkvkcbcby2yxg3" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = GrepConsole
 | siteInternet      = http://marian.schedenig.name/projects/grep-console/
 | logo              = GrepConsole_logo.png‎
 | version           = {{outil.GrepConsole.version}}
}}

GrepConsole est un plugin d'Eclipse permettant de modifier le style d'affichage de la console d'Eclipse en fonction de son contenu, de définir des actions spécifiques (hyperlien, lancement de script), et d'extraire du contenu de la console vers une autre vue d'Eclipse.
Les actions sont définies selon le contenu de chaque ligne, par le biais d'expressions régulières.
Ce plugin nécessite le jdk 1.6 pour fonctionner correctement.

== Configuration ==
Le plugin est contenu dans le fichier [[Zip d'éclipse]].
Le paramétrage par défaut est présent dans le master Workspace, et sur eRoom.


=== Paramètres du plugin ===
Dans Eclipse, ouvrir Window/Preferences/GrepConsole/Settings :
* '''Style match length''' : nombre maximal de caractères à utiliser par ligne pour faire la modification de style dans la console d'Eclipse. Permet des gains de performance si les expressions régulières sont longues à évaluer sur de longues lignes. Mettre 0 pour prendre toute la ligne.
* '''Filter match length''' : nombre maximal de caractères à utiliser par ligne pour faire extraire des données vers la GrepView. Permet des gains de performance si les expressions régulières sont longues à évaluer sur de longues lignes. Mettre 0 pour prendre toute la ligne.
* '''Foreground''' / '''Background''' : couleurs par défaut à appliquer sur la vue GrepView.
* '''Link modifier key''' : touche à utiliser pour pouvoir cliquer sur les liens hypertextes.

[[Fichier:GrepConsole_Settings.PNG]]

=== Paremètres de filtrage ===
Cette partie présente rapidement la façon de modifier le paramétrage des filtre de GrepConsole.
La fenêtre de paramétrage se situe dans Window/Preferences/GrepConsole ou sur l'icone (?) dans la console d'Eclipse ou la Grep View.

[[Fichier:GrepConsole_manage_expression.PNG]]

Les expressions sont présentés dans une arborescense groupes / expressions pour permettre d'activer / désactiver tout un groupe.
Depuis cet écran il est possible d'importer / exporter des expressions (boutons Load / Save selected / Save all).
La case à cocher [[Fichier:GrepConsole_checkbox.PNG]] indique si l'expression est activée dans la console d'Eclipse.
L'entonnoir [[Fichier:GrepConsole_filter.PNG]] indique si les expressions trouvées sont recopiée dans la vue GrepView.


Voici l'écran d'édition d'une expression :

[[Fichier:GrepConsole_edit_expression.PNG]]

Sur cet écran, on configure les champs suivants :
* '''Name''' : nom de l'expression
* '''Expression''' : expression régulière permettant de définir quelles lignes doivent être concernée par le filtre.
* '''Unless''' : expression régulière indiquant les lignes devant être ignorées, même si elles correspondent à l'expression régulière définie plus haut.
* '''Active''' by defaut : identique à la case à cocher.
* '''Filter''' by defaut : identique à l'entonnoir.
* '''Rewrite''' : expression à réécrire dans la GrepView (si Filter by default est activé). On peut réutiliser des groupes capturés par des parenthèses du champ expression : il suffit de mettre entre accolade le numéro du groupe.

* '''Group''' : numéro du groupe dont le stype est à modifier (cela peut être la ligne entière, un groupe du champ ''Expression'', la ligne réécrite en entier ou un groupe de la ligne ''Rewrite''
* '''Style''' : style à définir pour ce groupe.
* '''Link''' : indique si on permet une action particulière si on clique sur le groupe : lien hypertexte / ouverture d'un fichier / ouverture d'une classe java / commande / lancement d'un script.




== Utilisation ==
Ouvrir la '''GrepView''' dans Window/Show View/Other/Grep Console/GrepView
Il est possible de lier la GrepView à la console de son choix (Java Stack Trace, Maven, Webby...), si plusieurs consoles sont actives en même temps.

Lorsque du texte est ajouté dans la console, les modifications sont faites soit directement dans la console ou dans la vue GrepView

=== Spécialiser les filtres par lanceur (Batch) ===
Dans les lanceurs d'application, un onglet GrepConsole apparaît. Il possible définir les filtres à activer et désactiver par lanceur.
Cette fonction est intéressante pour désactiver les filtres inutiles pour les batchs.

[[Fichier:GrepConsole_Lanceur.PNG]]


[[Category:outil]]
[[Category:plugin]]
[[Category:Construction Zip D'Eclipse]]</text>
      <sha1>ci1w6p5rg7pmnrdfttkvkcbcby2yxg3</sha1>
    </revision>
  </page>
  <page>
    <title>Installeur efluid</title>
    <ns>0</ns>
    <id>4562</id>
    <revision>
      <id>4066385</id>
      <parentid>4065625</parentid>
      <timestamp>2021-11-22T13:05:30Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Liste des releases notes */</comment>
      <origin>4066385</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="43318" sha1="8ysvk5qhabsumkgtezqcwk9od3biaph" xml:space="preserve">[[Category:maven]]
[[Category:efluid]]
[[Category:installeur]]
[[Category:script installeur]]

{{Modèle:Infobox Outil
 | nom               = installeur efluid
 | version           = {{outil.installeurEfluid.version}}
 | supportTechnique  = {{usinelogicielle|subject=installeur}}
}}

L'installeur efluid (également appelé script installeur efluid) permet de mettre en place la suite efluid sur un environnement donné. Cela va de la récupération des livrables dans une version donnée, puis la montée de version du schéma de la base de données, puis le déploiement des applications (TP, batchs, Streamserve etc...) et enfin la vérification de la plateforme ainsi installée.

= Architecture =
== Vue globale ==
[[Fichier:ScriptInstalleur architecture.png]]

== Principes de déploiement efluid ==

[[image:scriptInstalleur.png|600px|]]

== Phases de l'installeur ==
=== Partie package ===
Voici les phases importantes de la partie package (donc sans profil Maven appelés) du script installeur
* process-test-classes =&gt; copie de la documentation de l'installeur  (attention cette phase est normalement reservée aux scripts pour la partie RUN avec profil, c'est un cas d'exception de mettre la copie de la documentation ici)
* test =&gt; copie des scripts de l'installeur, processing particulier de documentation dans les scripts installeurs des applications (Exemple dans efluid generate datamasking asciidoctor documentation)
* prepare-package =&gt; génération du site Maven, filtering des shell de l'installeur
* package =&gt; assembly final (création du zip de l'installeur applicatif)

= Documentation =
La documentation complète du script installeur [http://wikefluid/docInstalleur/efluid/develop/documentation/index.html se trouve ici].

Les opérations effectuées par les scripts de l'installeur sont décrites [http://wperoom2.uem.lan/eRoomReq/Files/Prod6/ProcessFabricationEfluid/0_2e20/phaseInstalleurEflud.xlsx  ici]

== Maintenance ==
La documentation complète du script installeur branche maintenance_12 d'efluid [http://wikefluid/docInstalleur/efluid/maintenance_12/documentation/index.html se trouve ici].

== Convention de rédaction ==
* Voici la convention de rédaction de la documentation de l'installeur :

=== Constitution des fichiers ===
* Les fichiers sont au format asciidoc, avec l'extension '''.ad'''
** Voici un guide rapide de la syntaxte asciidoctor : http://asciidoctor.org/docs/asciidoc-writers-guide/
* Les fichiers doivent encodés en UTF-8 (sans BOM)
* Les caractères de fin de ligne doivent être au format Windows avant archivage sous Git (CR LF)
* Chaque fichiers doit posséder l’entête suivant : 
&lt;source lang="html5"&gt;
:source-highlighter: coderay
:coderay-css: style
&lt;/source&gt;

=== Titres / Section ===
* Le titre de la page doit être du format suivant, cela constitue une section de niveau 1, il peut y avoir plusieurs sections de niveau 1 dans une page
 == Section Niveau 1

* Chaque sous section est du format suivant (et ainsi de suite)
 === Section Niveau 2
 ==== Section Niveau 3

=== Utilisation du gras et italique ===
* Le gars et l'italique s'utilisent avec modération dans les pages quand l'utilité s'en fait sentir
 *texte en gras*
 _texte en italique_

=== Listes ===
* Une liste non ordonnée se fait de la manière suivante : 
 * un élément
 * un autre élément
 ** un sous élément

* Une liste ordonnée se faite de la manière suivante : 
 . premier élément
 . second élément

=== Liens ===
* Un lien vers une page interne (avec une ancre) se faite de la manière suivante :
 link:./includes-files.html#initOpenLdap.sh["texte du lien"]

* L'ancre en question se fait de la manière suivante (ce texte n'est pas affiché) : 
&lt;source lang="dos"&gt;
[[initOpenLdap.sh]]
&lt;/source&gt;

* Une autre manière de procéder est d'ajouter une ancre sur du texte qui va être affiché : 
&lt;source lang="dos"&gt;
[desactiverRecuperationScriptDeployerStateless]
&lt;/source&gt;

=== Tableau ===
* Voici un exemple de tableau avec 2 colonne, dont chaque colonne à la même taille
&lt;source lang="dos"&gt;
[cols="1,1"]
|===
|Groupe/Entreprise| Valeur de CODE_CENTRE

|Bonneville|BON
|RSEIPC|RSEIPC

|===
&lt;/source&gt;

* Si l'on veut spécifier la taille des colonnes (en pourcentage l'une par rapport aux autres), alors on change la valeur de cols : 
&lt;source lang="dos"&gt;
[cols="1,2"]
|===
|Groupe/Entreprise| Valeur de CODE_CENTRE

|Bonneville|BON
|RSEIPC|RSEIPC

|===
&lt;/source&gt;

* Si l'on veut pouvoir mettre du code asciidoc dans une colonne alors il faut le spécifier dans cols avec un "a" :
&lt;source lang="dos"&gt;
[cols="1,2a"]
|===
|Groupe/Entreprise| Valeur de CODE_CENTRE

|Bonneville|*BON*
|RSEIPC|*RSEIPC*

|===
&lt;/source&gt;

* Attention il ne faut pas mettre de monospace dans les tableaux
=== Code source ===
* Pour afficher du code source en différents langages, il faut procéder de la manière suivante : 
&lt;source lang="xml"&gt;
[source,xml]
----
 &lt;localRepository&gt;/data/files/mavenRepository&lt;/localRepository&gt;
----
&lt;/source&gt;

* Pour afficher du texte avec un encart, mais sans coloration particulière il faut procéder de la manière suivante : 
&lt;source lang="dos"&gt;
----
# Utilisateur "deploy" : compte intermédiaire restreint, permettant de déployer les batchs sur le serveur
deploy@batchServeur:$ groups
batchuser deploy
----
&lt;/source&gt;

* Si l'on veut pouvoir mettre une syntaxte particulière dans l'encart alors il faut utiliser des macros, comme par exemple ici pour mettre du texte en gras : 
&lt;source lang="dos"&gt;
[subs="verbatim,macros"]
----
pass:quotes[*Exemple pour le serveur cible batchServeur (cas n°2):*]
# Utilisateur "deploy" : compte intermédiaire restreint, permettant de déployer les batchs sur le serveur
deploy@batchServeur:$ groups
pass:quotes[*batchuser*] deploy
----
&lt;/source&gt;

=== Affichage de paramètres technique / fichiers ===
* L'affichage d'un paramètre technique efluid doit se faire toujours de la meme façon c'est à dire avec un lien vers la page du paramètre et en italique :
 link:./suite_efluid.html#batch.min.connections.pool[_batch.min.connections.pool_]
* Attention si ce paramètre se trouve dans le tableau global des paramètres (fichier description.txt), alors la syntaxe est différente car c'est du html :
&lt;source lang="html5"&gt;
 &lt;a href="#batch.min.connections.pool"&gt;&lt;i&gt;batch.min.connections.pool&lt;/i&gt;&lt;/a&gt;
&lt;/source&gt;
* L'affichage d'un nom de fichiers, ou de dossier se fait en monospace : 
 `/data/FLD_UR/testbatch/properties2`
* L'affichage de portion de configuration, ou de paramètres hors efluid se fait également en monospace : 
 `MEM_ARGS=-Xms4g –Xmx4g`

== Répertoires de l'installeur ==
Les répertoires listés ci-dessous sont à renseigner dans l'installeur. Les contraintes/pré-requis existant pour ces répertoires sont listés ci-dessous (à reporter dans la documentation de l'installeur une fois stable):
=== UPLOAD ===
*'''upload.temp.dir''': Répertoire temporaire du serveur d'application pour uploader ses fichiers
** Création par installeur: oui
** Brique fonctionnelle owner du répertoire: TP
** Partage: Non
** Droits attendus: 750.

=== REPERTOIRES ===
* '''repertoire.reception''': répertoire de dépot des fichiers dans le cadre de la fonctionnalité "demande multiple" &lt;br /&gt;
** Création par installeur:  oui
** Brique fonctionnelle: TP
** Droits par défaut : 750
** Partage: non, seulement utilisé par le TP

* '''repertoire.partage.batch''': référence le répertoire files des batchs qui doit exister au préalable ou le sera une fois le deployerBatch.sh exécuté. 
** Création par installeur: non
** Brique fonctionnelle owner du répertoire: batchs (par unzip des batchs)
** Droits attendus: accès lecture/écriture (770) pour permettre la lecture et la dépose de fichiers pour les batchs par TP.

* '''repertoire.resultat.exec.diff''': référence le répertoire de stockage des résultats des exécutions différées 
** Création par installeur: non
** Brique fonctionnelle owner du répertoire: batchs
** Partage: oui
** Droits attendus: accès lecture (750) pour TP.

* '''cache.serialize.dir''': répertoire dans lequel sont stockés les fichiers résultats de la sérialisation d’un objet maitre. 
** Création par installeur: oui
** Brique fonctionnelle owner du répertoire: TP
** Partage: Non
** Droits attendus: 750.

*'''log.exception.dir''': 
** Création par installeur: oui
** Brique fonctionnelle owner du répertoire: TP
** Partage: Non
** Droits attendus: 750.

=== EDITIQUE ===
*'''repertoire.streamserve.in''':
** Création par installeur: oui
** Brique fonctionnelle owner du répertoire: TP
** Partage: Oui, streamserve en lecture
** Droits attendus: 750

repertoire.racine.archivage.streamserve: non créé par l'installeur
    - brique fonctionnelle qui crée ?
    - droits requis (lecture/écriture), propriétaire et groupe ?
    - partagé? avec qui ?

repertoire.prefixe.archivage.streamserve: non créé par l'installeur
    - brique fonctionnelle qui crée ?
    - droits requis (lecture/écriture), propriétaire et groupe ?
    - partagé? avec qui ?

*'''edition.sauvegarde.flux.repertoire''': répertoire (chemin absolu) de sauvegarde des flux d'édition. Les traces des flux ne sont sauvegardées que si le répertoire existe (mode debug). Pas de valeur par défaut (paramètre vide) afin d'éviter de générer des traces..
** Création par installeur: oui si valorisé
** Brique fonctionnelle owner du répertoire: TP
** Partage: Non
** Droits attendus: 750

streamserve.application.dir: non créé par l'installeur, répertoire interne à Streamserve où sont les datas StreamServe (les services streamserves)
streamserve.home: non créé par l'installeur, répertoire interne à Streamserve où se trouve le moteur.

=== BATCH ===

*'''batchs.log.home''': 
** Création par installeur: oui (extract zip batchs)
** Brique fonctionnelle owner du répertoire: batchs
** Partage: oui, avec TP
** Droits attendus: 750.


batch.home:
    - brique fonctionnelle qui crée ? installeur batch
    - droits requis (lecture/écriture), propriétaire et groupe ? 750
    - partagé? avec qui ? TP, pour accéder aux répertoires de la sous-arborescence

*'''batch.repertoire.resultat.exec.diff''':
** Création par installeur: oui si renseigné
** Brique fonctionnelle owner du répertoire: batchs
** Partage: oui, lecture pour TP
** Droits attendus: 750.

*'''batch.edition.output''': 
** Création par installeur: oui si renseigné
** Brique fonctionnelle owner du répertoire: batchs
** Partage: oui, lecture pour StreamServe
** Droits attendus: 750.

*'''batch.edition.output.tmp''':
** Création par installeur: oui si renseigné
** Brique fonctionnelle owner du répertoire: batchs
** Partage: Non
** Droits attendus: 750.


*'''batch.ordo.repertoire.traitement.tmp''': N'existe plus. A nettoyer dans les properties.

=== BASE PARAM ===

ear.statefull.server.container.root.directory: non créé par l'installeur, requis pour le deploiement du TP
    - brique fonctionnelle qui crée ? 
    - droits requis (lecture/écriture), propriétaire et groupe ?
    - partagé? avec qui ?

ear.stateless.server.container.root.directory: non créé par l'installeur, requis pour le deploiement du TP
    - brique fonctionnelle qui crée ?
    - droits requis (lecture/écriture), propriétaire et groupe ?
    - partagé? avec qui ?

== Conception technique ==
=== Phases des scripts de l'installeur ===
Le xls de travail se trouve sous http://wperoom2.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_1d75 (phaseInstalleurEflud.xlsx)

=== Lancement des scripts WLST ===
[[Fichier:ScriptInstalleur LancementWLST.png]]
&lt;br&gt; Visio : [http://wperoom2.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_1db3]

=== Vérification des paramètres obligatoires ===
[[Fichier:ScriptInstalleur verificationParametresObligatoires.png]]
&lt;br&gt; Visio : [http://wperoom2.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_1db3]

=== Embedded Docker via le script installEmbedded.sh ===
[[Fichier:Conception shell installEmbedded mode docker.png]]
&lt;br&gt; Visio : [http://wperoom2.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_1db3] : ScriptInstalleur_shell_installEmbedded_mode_docker.vsd

=== Installation de plugin ===
==== Mode automatique : partie TP ====
[[Fichier:ScriptInstalleur shell upgradePlugin mode automatic.png]]
&lt;br&gt; Visio : [http://wperoom2.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_1db3] : ScriptInstalleur_shell_upgradePlugin_mode_automatic.vsd

==== Mode automatique : partie batchs ====
[[Fichier:ScriptInstalleur shell upgradePlugin partieBatch mode automatic.png]]
&lt;br&gt; Visio : [http://wperoom2.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_1db3] : ScriptInstalleur_shell_upgradePlugin_partieBatch_mode_automatic.vsd

==== Mode à la demande ====
[[Fichier:ScriptInstalleur shell upgradePlugin mode a la demande.png]]
&lt;br&gt; Visio : [http://wperoom2.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_1db3] : ScriptInstalleur_shell_upgradePlugin_mode_a_la_demande.vsd

== Spécificités dans les projets ==
=== efluid-migration ===
* Zip des batchs
[[Fichier:Schema batchs efluid migration.png]]
&lt;br&gt;Visio : [http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_107a60]

= Release notes =
== Génération automatiques ==
* Les releases notes se générent de manière automatique grâce aux messages de commits. Ceux-ci doivent respecter la forme suivante : 
 &lt;N° Evènement&gt; : [&lt;APPLICATIONS&gt;][info|verif|action][catégorie] description
 Exemple
 135000 : [SUITEEFLUID][info][Embedded] l'exemple special XXX

* info|verif|action : détermine si le message sera rangé dans une catégorie "Pour information", "Pour action", "Pour vérification"

* Catégorie, message libre qui détermine la catégorie ou l'on rangera le message de commit. Par exemple "Embedded", "batchs"...

* Application détermine la liste des applications pour lesquels cette release note sera appliquée (sachant que coté installeur il y a toujours une release note globale en plus) : 
** appli1 : release note sera appliquée uniquement à appli1
** appli1,appli2 : release note sera appliquée à appli1 et à appli2
*** La liste complète des applications disponible est : efluid, efluidpub, efluidnet, ael, portailpartenaire, portailrecrutement, efluidproxy, edoc, enercom, ethaque, suivefluid, suiveclient, eldap, efluidmigration
** all : sera appliqué à toutes les applications
** none : ne sera appliqué à aucune application
** suiteEfluid (ou se) : sera appliqué à toutes les applications de la suite efluid
*** La liste des applications de la suite efluid est : efluid, efluidpub, efluidnet, ael, portailpartenaire, portailrecrutement, efluidproxy, efluidmigration
** &lt;vide&gt; : idem à none

* Ces informations permettront de générer une release note de la forme : 
&lt;source lang="dos"&gt;
Nouveautés

    Ajout de paramètres link:./suite_efluid.html#migration.racine.repertoire.injection[migration.racine.repertoire.injection] (132060)
&lt;/source&gt;

* Format de la description du commit
** Le texte peut se trouver sur plusieurs lignes ce n'est pas un problème
** Faire reference à une ancre de la documentation (lien), en utilisant la syntaxe
 &lt;&lt;lien|texte du lien&gt;&gt;
 Exemple : &lt;&lt;link:./suite_efluid.html#cache.mode.chargement|cache.mode.chargement&gt;&gt;
** Pour mettre en gras/italique une partie il faut utiliser la syntaxe asciidoctor
 *texte en gras*
 _texte en italique_

== Liste des releases notes ==

La release notes du script installeur efluid [https://wikefluid.efluid.uem.lan/docInstalleur/efluid/develop/documentation/release-notes.html se trouve ici]

La documentation de l'ensemble des paramètres [https://wikefluid.efluid.uem.lan/docInstalleur/efluid/develop/documentation/full.html se trouve ici]

La documentation du script installeur efluid [https://wikefluid.efluid.uem.lan/docInstalleur/efluid/develop/documentation/news.html se trouve ici]

La documentation du script installeur migefluid [https://wikefluid.efluid.uem.lan/docInstalleur/efluid/develop/documentation/migefluid.html se trouve ici]

La documentation du script installeur efluidnet [https://wikefluid.efluid.uem.lan/docInstalleur/efluidnet/develop/documentation/news.html se trouve ici]

La documentation du script installeur ael [https://wikefluid.efluid.uem.lan/docInstalleur/ael/develop/documentation/news.html se trouve ici]

La documentation du script installeur aelgrd [https://wikefluid.efluid.uem.lan/docInstalleur/aelgrd/develop/documentation/news.html se trouve ici]

La documentation du script installeur portail-partenaire [https://wikefluid.efluid.uem.lan/docInstalleur/portail-partenaire/develop/documentation/news.html se trouve ici]

La documentation du script installeur eldap [https://wikefluid.efluid.uem.lan/docInstalleur/eldap/develop/documentation/news.html se trouve ici]

La documentation du script installeur edoc [https://wikefluid.efluid.uem.lan/docInstalleur/edoc/develop/documentation/news.html se trouve ici]

La documentation du script installeur suivefluid [https://wikefluid.efluid.uem.lan/docInstalleur/suivefluid/develop/documentation/ se trouve ici]

La documentation du script installeur suiveclient [https://wikefluid.efluid.uem.lan/docInstalleur/suiveclient/develop/documentation/ se trouve ici]

La documentation du script installeur ethaque [https://wikefluid.efluid.uem.lan/docInstalleur/ethaque/develop/documentation/ se trouve ici]

La documentation du script installeur enercom [https://wikefluid.efluid.uem.lan/docInstalleur/enercom/develop/documentation/ se trouve ici]

La documentation de signefluid [https://wikefluid.efluid.uem.lan/docInstalleur/signefluid/develop/documentation/ se trouve ici]

La documentation du scriptSqlLauncher [https://wikefluid.efluid.uem.lan/docInstalleur/efluid/utils/efluid-scriptsqllauncher/documentation/ se trouve ici]

= Artifactory frontal =
[[Guide_d%27installation_de_maven#Configuration_de_l.27installation_client|Configuration maven coté client]]

= Validation de l'installeur =
== Validation sur CJP ==
=== Description des tests unitaire ===
==== Tests unitaires sur les enforcer ====

En début de job: http://usinevalidation.uem.lan/job/Fvalidation-gerrit/job/Ftools/job/Finstalleur/job/script-installeur-V2/

Les fichiers de configurations dédiés aux tests sont à mettre dans le repo git scriptInstalleur, groupés par type de serveur d'appli:
 installeur-parent/src/test
 installeur-parent/src/test/weblogic
 installeur-parent/src/test/embedded
 installeur-parent/src/test/embedded-docker

Les noms de fichiers de properties pour les tests doivent être nommés: given-configuration.properties-&lt;nom-du-test&gt;

Exemple pour les enforcer de l'embedded : scriptInstalleur/installeur-parent/src/test/embedded
 installeur-parent/src/test/embedded/given-configuration.properties-https-not-activate-with-prop-not-set
 installeur-parent/src/test/embedded/given-configuration.properties-https-activate-with-prop-set
 installeur-parent/src/test/embedded/given-configuration.properties-https-activate-with-prop-not-set

Conventions prises: 
* les properties mandatory sont valorisées, avec le mot clé "mandatory" si pas de valeur spécifique imposée
* les properties sous test sont biensur valorisées pour atteindre les objectifs du test.
* les properties optionnelles hors tests restent vides pour ne pas surcharger le fichier.

Les résultats attendus sont sous installeur-parent/src/test/expected: 
* 1 fichier pour tous les tests en succès: 
 installeur-parent/src/test/expected/expected-result-success.dta
* 1 fichier par test en erreur: 
 installeur-parent/src/test/expected/expected-result-for-&lt;nom-du-test&gt;

Exemple de contenu de résultat attendu:
 [INFO] --- maven-enforcer-plugin:1.2:enforce (check-properties-secured-embedded-exists) @ scriptInstalleur-parent ---
 [WARNING] Rule 0: org.apache.maven.plugins.enforcer.RequireProperty failed with message:
 The parameter install.embedded.https.port or .install.embedded.https.port can not be empty and is a numeric type ([0-9]+)
 [WARNING] Rule 1: org.apache.maven.plugins.enforcer.RequireProperty failed with message:
 Property "install.embedded.https.server.privkey" evaluates to "".  This does not match the regular expression "..*"
 [WARNING] Rule 2: org.apache.maven.plugins.enforcer.RequireProperty failed with message:
 Property "install.embedded.https.server.pubcert" evaluates to "".  This does not match the regular expression "..*"
 [INFO] BUILD FAILURE
 [ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.2:enforce (check-properties-secured-embedded-exists) on project scriptInstalleur-parent: Some Enforcer rules have failed
 . Look above for specific messages explaining why the rule failed. -&gt; [Help 1]

Un même test &lt;nom-du-test&gt; peut être exécuté pour chaque type de serveur d'application: embedded, embedded-docker, weblogic

3 méthodes (à ne pas modifier) sont disponibles pour lancer les tests et vérifier le résultat:
* executeTest : s'occupe de lancer la commande mvn requise avec les différents paramètres attendus: 
** le nom du test &lt;nom-du-test&gt;
** le type de serveur d'application permettant de prendre les bons fichiers de conf en entrée
** la phase sur lequel l'enforcer à tester se déclenche
** l'id dans le pom.xml contenant l'enforcer à tester
** la property testée

* assertFailureTestResult: gère la vérification par rapport à un résultat d'erreur attendu contenu dans un fichier du répertoire expected
* assertSuccessTestResult: gère la vérification par rapport à un résultat SUCCESS attendu (contenu dans le fichier expected-result-success.dta du répertoire expected)

Les tests sont faits sous la forme suivante:

 # TU: check enforcer for embedded en fonction des tests existants (fichiers given-XXX)
 if [ -f src/test/embedded/given-configuration.properties-session-tracking-nimp-set ]; then
   # Given global 
   testedEnforcerId=&lt;nom de l'id d'exec de l'enforcer dans le pom.xml&gt;
   testedProperty=&lt;nom de la property&gt;
   phaseRequired=&lt;phase maven de déclenchement&gt;

   ########## EMBEDDED | EMBEDDED-DOCKER | WEBLOGIC
   # Test &lt;nom de la property&gt; in (embedded | embedded-docker | weblogic)
   targetApplicationServer=&lt;serveur d'application&gt;
   
   
   ## Test XXX value set =&gt; KO
   ### Given
   testName=&lt;nom-du-test-KO&gt;
   ### When
   executeTest ${testName} ${targetApplicationServer} ${phaseRequired} ${testedEnforcerId} ${testedProperty}
   ### Then
   assertFailureTestResult ${testName} ${targetApplicationServer} ${testedEnforcerId} ${testedProperty}
    

   ## Test XXX value set =&gt; OK
   ### Given
   testName=&lt;nom-du-test-OK&gt;
   ### When
   executeTest ${testName} ${targetApplicationServer} ${phaseRequired} ${testedEnforcerId} ${testedProperty}
   ### Then
   assertSuccessTestResult ${testName} ${targetApplicationServer} ${testedEnforcerId} ${testedProperty}

 fi

Properties testées:
* Evt 213983: nouveaux paramètres pour HTTPS
* Evt 207381: session.tracking.mode 
* Evt 212957: paramètres supplémentaires du datasource embedded

==== Configuration des serveurs pour tests intégration ====

Les serveurs ldsanbld5 et ldsanbld6 sont utilisés pour les tests d'intégration de sshexec_maven-plugin et copy-maven-plugin. Les points de configuration suivants ont été apportés sur les serveurs:
===== Configuration des accès ssh par clés =====
* Les clés publiques du compte ulouser de lpsrvulo6 et lpsrvulo3 (~ulouser/.ssh/id_rsa.pub et ~ulouser/.ssh/id_rsa_passphrase.pub) ont été recopiées dans le fichier $HOME/.ssh/authorized_keys du compte weblogic sur les serveurs ldsanbld5 et ldsanbld6.
Ceci permet de faire des tests de connexion ssh avec clé publique sans passphrase, et avec clé publique avec passphrase (azerty).

===== Configuration et lancement d'un démon sshd sur le port 2222 (root)=====
* Dupliquer la config ssh pour disposer d'une config où sera modifiée les port d'écoute et le fichier de flag pid
      - cp /etc/ssh/sshd_config /etc/ssh/sshd_config_newport
      Edition du fichier /etc/ssh/sshd_config_newport et modification de:
      Port 2222
      PidFile /var/run/sshd_newport.pid
* Dupliquer le script de lancement dans /etc/init.d pour le customiser:
      cp /etc/init.d/sshd /etc/init.d/sshd_newport
      Editer le fichier, et remplacer la chaine "sshd" par "sshd_newport" et "sshd_config" par "sshd_config_newport" sauf pour la variable SSHD, qui vaut toujours sshd (le démon est le même, seule la configuration de démarrage diffère)
      # config: /etc/ssh/sshd_config_newport
      # pidfile: /var/run/sshd_newport.pid
      [ -f /etc/sysconfig/sshd_newport ] &amp;&amp; . /etc/sysconfig/sshd_newport
      prog="sshd_newport"
      PID_FILE=/var/run/sshd_newport.pid
* Dupliquer le fichier système /etc/sysconfig/sshd pour le customiser avec le nom du fichier de configuration sshd à utilisaer au lancement:
      - cp /etc/sysconfig/sshd /etc/sysconfig/sshd_newport
      Editer le fichier et configurer:
      - OPTIONS="-f /etc/ssh/sshd_config_newport"
* Préparer la configuration PAM pour l'authentification :
      - ln -s /etc/pam.d/sshd /etc/pam.d/sshd_newport
* Démarrer le service :
      - service sshd_newport start
      - service sshd_newport status
* Mettre à jour la configuration pour l'utilitaire de gestion des services chkconfig :
      - chkconfig --add sshd_newport
      - chkconfig sshd_newport on
* Vérification d'écoute sur le port 2222:
      - lsof -i TCP:2222
      - ps -ef | grep &lt;pidDuProcEnEcouteSur2222&gt;

==== sshexec-maven-plugin ====
Test de lancement de commandes sur une liste de serveurs définie dans le paramètre &lt;testServerScpLocation&gt;
Le format du paramètre est: serveurLocation[,serveurLocation]
* avec &lt;serveurLocation&gt; de la forme scp://&lt;user&gt;:&lt;passwd&gt;@&lt;hostname&gt;${sshTestPort}
Le test est fait pour 2 serveurs: scp://installeurtst:&lt;motDePasse&gt;@lpdocedt2${sshTestPort},scp://installeurtst:&lt;motDePasse&gt;@lpdocedt3${sshTestPort}
* 1 test est fait avec le port par défaut vide =&gt; port 22 utilisé.

Note: un compte installeurtst spécifique a été créé sur les serveurs lpdocedt2 et lpdocedt3 pour permettre ces tests. Le fichier $HOME/.ssh/authorized_keys de installeurtst a été configuré pour contenir la clé publique sans passphrase et la clé publique avec passphrase du compte ulouser des usines (même clés/publiques/privées déployées sur les différents slaves) =&gt; Si ajout d'un nouveau slave, penser à configurer le répertoire .ssh pour disposer des clés à présenter.


Test de création/suppression de répertoire (sur ldsanbld5 uniquement) selon les 3 modes d'authentification possibles: 
* par mot de passe
* par clé publique sans passphrase
* par clé publique avec passphrase

En cas de besoin de test d'une nouvelle version de plugin sshexec-maven-plugin: -DsshExecMavenPluginVersion=&lt;nouvelleVersion&gt;.
    - exemple: mvn test -f scriptInstalleur-parent.pom -Ptest-unitaire-script-installeur -DsshTestPort=:2222 -DDsshExecMavenPluginVersion=0.3-beta-1-efluid1

Jobs de release du plugin: http://usinelogicielle/view/release/job/sshexec-maven-plugin/

==== Création répertoire codeCentre pour streamserve (220202) ====
Test de création d'un répertoire puis suppression si la property streamserve.application.codecentre.enterprise.parameter est non vide et non nulle
Test de skip de la création du répertoire si la property vide

==== maven-common ====
Librairie jar utilitaire pour les plugin sshexec-maven-plugin et copy-maven-plugin. Cette librairie a été fixée afin de permettre la surcharge du port d'écoute ssh pour les plugin sshexec et copy.

Job de release: http://usinelogicielle/view/release/job/maven-common-plugin-release/

==== copy-maven-plugin ====
Test de recopie d'un fichier (pom.xml) vers ldsanbld5 selon les 3 modes d'authentification possibles: 
* par mot de passe
* par clé publique sans passphrase
* par clé publique avec passphrase

==== groovy-maven-plugin ====
* Avec le fichier settings.xml par défaut (aucun client défini), on vérifie que le client renvoyé est : '''efluid'''
* On ajoute dans le fichier settings.xml la section suivante :
&lt;source lang="xml"&gt;
&lt;servers&gt;
   &lt;server&gt;
      &lt;id&gt;efluidMavenRepositoryFrontal&lt;/id&gt;
      &lt;username&gt;BIDULE&lt;/username&gt;
      &lt;password&gt;password&lt;/password&gt;
   &lt;/server&gt;
&lt;/servers&gt;
&lt;/source&gt;
* On vérifie que le client renvoyé est : '''BIDULE'''

==== build-helper-maven-plugin ====
* On vérifie que la variable parsedVersion.majorVersion est égale à 1

* On vérifie la bonne création de la variable test.current.time via le goal timestamp-property, pour créer une variable contenant un timestamp pour la création d'un répertoire temporaire unique. Correspond au test unitaire du profil deploy-gen appelé par les deployeurs.

==== test des options de récupération de script ====
* On veut ici tester toutes les options de récupérations des scripts, et vérifier que pour chacune on obtient bien le script adéquat
** Par défaut sans aucune option : récupère initOffline.sh, installeur.sh, deployerJonas.sh, deployerWeblogic.sh, README, application-configuration.properties
** desactiverRecuperationScriptCryptageProperties : gère la récupération des scripts crypterProperties.sh et generateCryptoKey.sh
** desactiverRecuperationScriptLancerLdif : gère la récupération du script lancerScriptsLdif.sh
** desactiverRecuperationScriptLancerSql : gère la récupération du script lancerScriptsSql.sh
** desactiverRecuperationDeployerStreamserve : gère la récupération du script deployerStreamserve.sh
** desactiverRecuperationDeployerBatch : gère la récupération du script deployerBatchs.sh
** desactiverRecuperationScriptDeployerStateless : gère la récupération des scripts deployerJonas-stateless.sh et deployerWeblogic-stateless.sh

==== test des droits de coopération au déploiement des batchs entre 2 users ====

Le but du test est de valider qu'on peut faire des modifications de droits sur le répertoire des batchs en se basant sur le contenu de l'archive zip des batchs (unzip -Zl), sans impact sur les fichiers/répertoires présents dans la sous-arborescence, qui pourrait appartenir à un autre user (user tp).

Objectif: valider la commande présente dans deployerBatchs.sh :

* sh -c  "unzip -Z1 ${applicationName}-batchs-${project.version}.zip | awk -v  installDir=${batchsInstallFolder} '{ print installDir \"/\"\$1}' | xargs chmod ${dossierDroitParDefaut} "

Note: un compte installeurtstbatch spécifique a été créé sur le serveur lpdocedt3 pour permettre ce test =&gt; Si ajout d'un nouveau slave, penser à configurer le répertoire .ssh pour disposer des clés à présenter.

=== Description des tests d'intégration Docker V13 ===
On récupère tout d'abord un script installeur dans la version du paramètre du job (qui vient donc d'être packagé à partir du projet efluid).

Les tests sont lancés avec une version de Maven 3.3.9
==== test installeur.sh ====
* On récupère un properties com.efluid.properties:efluid-configuration.dockerBatchNonReg:HEAD-SNAPSHOT:properties, puis on lance : 
 ./installeur.sh

==== test generatePropertiesJar.sh ====
* On part d'un properties vierge, et on tente de lancer le script en désactivant globalement les enforcer afin de vérifier que la commande ne plante pas (c'est ce qui est fait dans le dockerfile application-tomcat-embedded pour générer un repo maven minimal) : 
 ./generatePropertiesJar.sh -DskipEnforcerGeneralUlOnly=true
* Ensuite on récupère un properties com.efluid.properties:efluid-configuration.dockerBatchNonReg:HEAD-SNAPSHOT:properties, puis on lance : 
 ./generatePropertiesJar.sh
* On vérifie que le jar de properties client est bien généré

==== test de déploiement de batch ====
* A la suite de la commande précédente on lance un déploiement de batch sur un conteneur Docker batch
 ./deployerBatchs.sh -Dbatchs.server.sshport=:22001

==== test de déploiement embedded en mode classique avec plugins actifs (à faire quand on aura le remove instance) ====
* A la suite de la commande précédente on lance un déploiement d'efluid embedded en mode classique en utilisant le properties suivant com.efluid.properties:efluid-configuration.embeddedClassiqueAvecPluginsNonReg:HEAD-SNAPSHOT:properties
 ./installEmbedded.sh

* On vérifie à ce moment la que les plugins sont bien déployés, via verifInstall
* On supprime l'instance embedded via remove instance

==== test de déploiement embedded en mode docker avec plugins actifs ====
* A la suite de la commande précédente on lance un déploiement d'efluid embedded sur un conteneur Docker en utilisant le properties suivant com.efluid.properties:efluid-configuration.dockerEmbeddedAvecPluginsNonReg:HEAD-SNAPSHOT:properties
 ./installEmbedded.sh

* On vérifie à ce moment la que les plugins sont bien déployés, via verifInstall
* Vérifier que la BDD est bien montée pour le plugin travaux dans la version cible

==== test de déploiement batchs en mode docker avec plugins actifs ====
* A la suite de la commande précédente on lance un déploiement des batchs sur noobaleine en utilisant le properties suivant com.efluid.properties:efluid-configuration.dockerBatchsAvecPluginsNonReg:HEAD-SNAPSHOT:properties
 ./deployerBatchs.sh

* On vérifie à ce moment la que les plugins sont bien déployés, via un cat du fichier /tmp/batchs/efluid/files/plugins/travaux/classes/META-INF/MANIFEST.MF

==== test de déploiement embedded en mode docker ====
* A la suite de la commande précédente on lance un déploiement d'efluid embedded sur un conteneur Docker en utilisant le properties suivant com.efluid.properties:efluid-configuration.dockerEmbeddedNonReg:HEAD-SNAPSHOT:properties
 ./installEmbedded.sh

* On vérifie à ce moment la que les plugins ne sont pas déployés.

==== test de déploiement d'un plugin en standalone (= mode manuel) ====
* On récupère la version courante de l'application et on la stock dans currentVersion
* On lance la commande suivante en conservant le même properties com.efluid.properties:efluid-configuration.dockerEmbeddedAvecPluginsNonReg:HEAD-SNAPSHOT:properties
 ./upgradePlugin.sh --name=travaux --version=$currentVersion

* On vérifie à ce moment la que le plugin travaux est bien actif désormais et en version $currentVersion
* Vérifier que la BDD est bien montée pour le plugin travaux dans la version $currentVersion   (pas forcément nécessaire comme test car la BDD sera deja dans la bonne version par les tests précédents)

==== test de la relocalisation installation et livrables en mode embedded et récupération de l'installeur joramMQ ====

===== Objectifs du test =====
Les objectifs de ce test sont de tester une installation:
* avec les livrables de l'installeur relocalisés (non récupérés dans livrables mais dans livraison.outputDirectory surchargé en ligne de commande via -D)
* avec un install.embedded.server.dir surchargé (et non /opt par défaut) pour relocaliser l'installation
* avec contrôle après installeur.sh que l'installeur de pivot JMS joramMQ est bien récupéré et dézippé sous ./utils : test -f utils/efluid-jorammqpivot/installeur.sh
Pas de démarrage du serveur d'application en fin d'installation car ne fait pas partie des objectifs de test

Ce test fait l'exécution du script installeur, type embedded (et non weblogic) en mode non docker (mode classique) avec relocalisation des livrables
L'installation est faite dans un conteneur Docker démarré au début du job. Le déploiement se fera en utilisant le serveur ssh démarré dans le conteneur.

===== Problèmes contournés dans ce test =====
Avec install.docker.enable=false =&gt; installEmbedded aura le comportement suivant:
* utilisation de yum et non rpm
* démarrage du serveur d'appli en fin d'install

=&gt; Pour changer ces 2 comportements (utilisation de rpm préférée car yum non dispo dans Docker et pas de démarrage), on force dans le script la variable isInsideContainer=0 
    sed -i "s/isInsideContainer=.*/isInsideContainer=0/" ./installEmbedded.sh

==== test de déploiement weblogic ====
* A la suite de la commande précédente on lance un déploiement d'efluid statefull sur un conteneur Docker weblogic (Admin + un noeud managé efluid statefull)
 ./deployerWeblogic.sh -DdesactiverRecuperationScriptDeployerStateless=true -DdesactiverCreationDatasourceStatefull=false -DdesactiverCreationJms=false

==== test de déploiement en mode offline ====
* On récupère le properties com.efluid.properties:efluid-configuration.dockerBatchNonReg:HEAD-SNAPSHOT:properties, puis on lance un déploiement batch en mode offline : 
 ./initOffline.sh -Dmaven.repo.local=${WORKSPACE}/tempMavenRepository
 ./installeur.sh -o -Dmaven.repo.local=${WORKSPACE}/tempMavenRepository
 ./deployerBatchs.sh -o -Dmaven.repo.local=${WORKSPACE}/tempMavenRepository -Dbatchs.server.sshport=:22001

==== test de déploiement de soapui ====
* On récupère le properties com.efluid.properties:efluid-configuration.dockerBatchNonReg:HEAD-SNAPSHOT:properties puis on lance le déploiement de soapui
  ./utils/soapui/deployerSoapui.sh -Dsoapui.server.sshport=:22001

* On récupère ensuite le properties com.efluid.properties:efluid-configuration.dockerBatchSoapUiNonReg:HEAD-SNAPSHOT:properties puis on lance le déploiement de soapui
 ./utils/soapui/deployerSoapui.sh -Dsoapui.server.sshport=:22001

==== test d'initialisation socle technique openldap ====
* On récupère le properties com.efluid.properties:efluid-configuration.dockerOpenLdapNonReg:HEAD-SNAPSHOT:properties, puis on lance l'initialisation openldap
 ./socleTechnique/initOpenLdap.sh
* On récupère ensuite un fichier ldif de test com.efluid.utils:prod-uem-light-ldif:1.0.0:ldif, que l'on va injecter sur notre nouvel annuaire openldap via le script adéquat
 ./lancerScriptsLdif.sh
* On refait ensuite une initialisation sur le properties com.efluid.properties:efluid-configuration.dockerOpenLdapNonReg2:HEAD-SNAPSHOT:properties
 ./socleTechnique/initOpenLdap.sh
* Puis on injecte le fichier com.efluid.utils:prod-uem-light-ldif:1.0.0:ldif  en passant des paramètre dans la ligne de commande
 ./lancerScriptsLdif.sh -Dldap.load.ldif.filename=prod_uem_light.ldif -Dldap.load.user=cn=admin,dc=efluid,dc=fr -Dldap.load.password=passwd

==== test LDIF ====
* On vérifie que dans le dossier livrables il y ait bien un sous dossier "LDIF" contenant les scripts à jouer
* On vérifie que les scripts ont bien été valorisés
* On exécute les scripts via lancerScriptsLdif.sh en sachant qu'ici les objets n'existent pas encore donc pas besoin de l'option -DforceExecLdapPlugin=true
* Puis on re-exécuter le même script pour vérifier l'idempotence de celui-ci si on utilise l'option -DforceExecLdapPlugin=true qui permet de ne pas planter si le DN existe deja (ce qui est le cas ici vu qu'on a lancé le script juste avant)

==== test du script lancerSqlMigrator ==== 
* On fait une copie de base EFLUID_TI_INSTALLEUR sur un schéma temportaire EFLUID_BUILD_{numéro_build}
* On configure le fichier efluid-configuration.properties concernant les properties jdbc
&lt;source lang="properties"&gt;
jdbc.connect.string=jdbc:oracle:thin:@LPBDDEDT3:2483:PTECEDT1
jdbc.password=devdev
jdbc.user=EFLUID_BUILD_${BUILD_NUMBER}
bdd.tablespace.data=EFLUID_BUILD_DATA
bdd.tablespace.index=EFLUID_BUILD_INDEX
bdd.tablespace.param=EFLUID_BUILD_PARAM
bdd.tablespace.bloc=EFLUID_BUILD_BLOB
&lt;/source&gt;
* On teste la livraison d'un livrable correctif, on utilise un zip sql allegé (contenant un script efluid de création d'une table de non reg) qui va jouer l'upgrade-correctif puis l'upgrade standard : com/efluid/efluid-sql-database-correctif/13.2.100-NonReg-SNAPSHOT/efluid-sql-database-correctif-13.2.100-NonReg-SNAPSHOT.zip
* On teste l'insertion d'une ligne dans la table de non régression ajouté.

* On teste l'upgrade standard, on utilise un zip sql allegé com/efluid/efluid-sql-database/13.2.100-NonReg-SNAPSHOT/efluid-sql-database-13.2.100-NonReg-SNAPSHOT.zip

* On teste l'upgrade avec l'option de remplacement, on utilise un zip sql allegé com/efluid/efluid-sql-database/13.2.100-NonReg-1-SNAPSHOT/efluid-sql-database-13.2.100-NonReg-1-SNAPSHOT.zip

==== test du script genererDocumentationSqlMigrator ==== 
* On lance la generation de la documentation sqlMigrator en skippant les modules edk, ecore, reversement et parametrage car ils ne sont pas présent dans le zip SQL que l'on utilise (com.efluid:efluid-sql-database:13.2.100_NonReg-SNAPSHOT:zip)
* On déploie cette documentation à l'emplacement suivant : http://wikefluid/docInstalleur/documentationSqlMigrator/index.html

==== test du script executeScriptSqlLauncher ====
* On lance le script executeScriptSqlLauncher.sh sur un evènement particulier 176671

=== Tests installeur par application ===

Cf http://cje.efluid.uem.lan/usinevalidationapplications/Fvalidation-gerrit/FsuiteEfluid/Fefluid/efluid.validation-installeur-gerrit

=== Description des tests d'intégration Docker v12 ===
Cette section comprend ce qui a été supprimé à partir de la v13.
Les tests sont lancés avec une version de Maven 3.0.4

==== test du script lancerScriptIndex.sh (remplacé par lancerSqlMigrator.sh) ====
* On utilise un zip d'index efluid allégé (2 index) : com/efluid/efluid-sql-index/12.11.100-nonReg-SNAPSHOT/efluid-sql-index-12.11.100-nonReg-SNAPSHOT.zip
* On lance le script des index sur une petite base dont voici les coordonnées :
&lt;source lang="properties"&gt;
jdbc.connect.string=jdbc:oracle:thin:@LDBDDEDT1:2483:DFLDEDT
jdbc.password=devdev
jdbc.user=DEV_MAQ_FLD
bdd.tablespace.index=DEV_MAQ_FLD_INDEX
&lt;/source&gt;
* On vérifie dans la logs que le script d'index a bien été joué, et qu'il a bien tracé les index qui nous interesse
* On relance ensuite le même script avec la ligne suivante en plus dans le ficheir de configuration et vérifie que le script ne renvoi aucune erreur
&lt;source lang="properties"&gt;
deployeur.ear.stateless.admin.server.password=toto
&lt;/source&gt;

=== gestion des droits sur les répertoires créés par le script installeur (à partir de la version 1.14.0) ===
Afin de pouvoir surcharger facilement les droits d'accès aux répertoires, créés par le script installeur, deux variables ont été mises en place, dans le pom scriptInstalleur-parent:
* dossierDroitParDefaut : droit par défaut, affecté à l'ensemble des répertoires créés
* dossierDroitEtendu : droit moins strict, affecté aux répertoires nécessitant d'être modifié par d’autre utilisateur que le owner. Droit mis en place pour erdf, sur les répertoires suivants :
** batch.log.filename
** batch.repertoire.archivage
** batch.repertoire.certificats
** batch.repertoire.reception
** batch.repertoire.travail
** batch.repertoire.sauvegarde.echanges

== Validation de l'installeur sur CJE ==

= Diagramme des properties de surcharge =

[[Fichier:Diag-properties-efluid.png|800px|sans_cadre|gauche|efluid]]
[[Fichier:Diag-properties-efluidpub.png|700px|sans_cadre|gauche|efluidpub]]
[[Fichier:Diag-proeprties efluidnet.png|700px|sans_cadre|gauche|efluid.net]]
[[Fichier:Diag-properties-ael.png|600px|sans_cadre|gauche|ael]]

[[Fichier:Diag-properties-eldap.png|600px|sans_cadre|gauche|eldap]]

[[Fichier:Diag-properties-enercom.png|600px|sans_cadre|gauche|enercom]]

[[Fichier:Diag-properties-ethaque.png|600px|sans_cadre|gauche|ethaque]]

[[Fichier:Diag-properties-suivefluid.png|600px|sans_cadre|gauche|suivefluid]]</text>
      <sha1>8ysvk5qhabsumkgtezqcwk9od3biaph</sha1>
    </revision>
  </page>
  <page>
    <title>YourKit</title>
    <ns>0</ns>
    <id>5863</id>
    <revision>
      <id>4067045</id>
      <parentid>4067044</parentid>
      <timestamp>2022-03-28T12:20:22Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Serveur de licence */</comment>
      <origin>4067045</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1931" sha1="4lab3234ro6o3nx5mbndm9y8669gdpa" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = YourKit
 | siteInternet      = http://www.yourkit.com/
 | version           = {{outil.yourkit.version}}
 | supportTechnique  = [[Alexis DMYTRYK]]		
 | faq               = [[FAQ:YourKit|FAQ YourKit]]
}}
[[Category:YourKit]]

efluid SAS dispose de 5 licences flottantes pour utiliser l'outil [[YourKit]] qui permet d'analyser les problèmes de performances de l'application. (http://www.yourkit.com/features/index.jsp)

= Yourkit 2021 =
== Installation de la licence '''YourKit 2021''' sur le serveur ==

disponible [https://www.yourkit.com/m/server| ici ]

* Se connecter en ssh à &lt;tt&gt;{{outil.yourkit.2019.serveurLicence}}&lt;/tt&gt;
* créer un fichier &lt;tt&gt;/opt/yourkit-license-server/licenses/key2.txt&lt;/tt&gt;
* Coller la clef de licence serveur dans le fichier &lt;tt&gt;key2.txt&lt;/tt&gt; (la clef est dans le keepass performance, chercher "yourkit")
&lt;br&gt;
Le serveur de licence yourkit s'administre via systemd.&lt;br&gt;
Le service s'appelle yourkit-server. Il est activé pour redémarrage au boot.
&lt;br&gt;
Pilotage du service depuis le compte root. 
* arrêt  : systemctl stop yourkit-server
* Démarrage : systemctl start yourkit-server
* status depuis root : systemctl status yourkit-server
&lt;br&gt;
Pour visualiser les licences consommées : http://{{outil.yourkit.2019.serveurLicence}}:10112/status

== Installation de la licence '''YourKit 2019 / 2021''' sur le client ==
* Récupérer la dernière version du logiciel sur eRoom : &lt;tt&gt;[[F_INSTALL]]\YourKit&lt;/tt&gt;
* Ouvrir le client YourKit 2019 / 2021
* Un prompt demandant la clef apparaît
* Renseigner &lt;tt&gt;*:{{outil.yourkit.2019.serveurLicence}}&lt;/tt&gt;
* Accepter

Les fois suivantes le prompt ne doit plus apparaître

== Serveur de licence ==
* Host : &lt;tt&gt;{{outil.yourkit.2019.serveurLicence}}&lt;/tt&gt; (IP : &lt;tt&gt;192.168.106.27&lt;/tt&gt;)
* Port : &lt;tt&gt;10112&lt;/tt&gt; (Par défaut)

= liens =
* {{en}} http://code.google.com/p/maven-yourkit-plugin/wiki/GettingStarted</text>
      <sha1>4lab3234ro6o3nx5mbndm9y8669gdpa</sha1>
    </revision>
  </page>
  <page>
    <title>Vega</title>
    <ns>0</ns>
    <id>4042</id>
    <revision>
      <id>864326</id>
      <parentid>864325</parentid>
      <timestamp>2015-06-17T15:04:24Z</timestamp>
      <contributor>
        <username>Back</username>
        <id>82</id>
      </contributor>
      <origin>864326</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="265" sha1="fmhqnvhrfyxb8j3zamtkkaaed1kfv4x" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = vega
}}
Ordonnanceur utilisé par les équipes d'exploitation des clients : [[uem]], [[smeg]], [[seolis]], [[vialis]], [[gedia]], [[rseipc]] pour ordonnancer l’exécution des batchs.

Caractères interdits :
 " , [ |</text>
      <sha1>fmhqnvhrfyxb8j3zamtkkaaed1kfv4x</sha1>
    </revision>
  </page>
  <page>
    <title>Jenkins</title>
    <ns>0</ns>
    <id>12178</id>
    <revision>
      <id>4066977</id>
      <parentid>4066976</parentid>
      <timestamp>2022-03-15T09:10:51Z</timestamp>
      <contributor>
        <username>Carriers</username>
        <id>234</id>
      </contributor>
      <comment>/* Etat CJP */</comment>
      <origin>4066977</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14714" sha1="oy6eervuhz4nfmwpjyuis9gznnoeyzp" xml:space="preserve">{{Modèle:Infobox Outil
 | nom              = jenkins
 | logo             = Jenkins1_300_224.png
 | siteInternet     = http://jenkins-ci.org/
 | version          = {{outil.jenkins.version}}
 | supportTechnique  = {{usinelogicielle|subject=jenkins}}
 | guideInstallation = Guide d'installation de jenkins
 | faq               = [[FAQ:Jenkins|FAQ Jenkins]]
}}

[[Category:jenkins]]
[[Category:outil]]

Jenkins est un outil d'intégration continue, il permet :
* de compiler de manière régulière le code des différents applications
* de déployer automatique les envirronements [[nightly-build]] 
* de lancer de manière régulière les tests unitaires

= Surveillance activité de lancement des Jobs =

Des problèmes ont été détectés sur le lancement des Jobs planifiés dans Jenkins: règulièrement, après le week-end, les Jobs planifiés ne sont plus démarrés par Jenkins.

Pour permettre le monitoring de l'activité Jenkins et détecter au plus tôt quand les jobs ne sont plus déclenchés, le mécanisme suivant a été mis en place, en attente de la qualification/correction du problème:

* Création d'un job dans l'onglet interne: flagCronTrigger. Ce job, planifié toutes les heures, est simplement chargé de poser un fichier indicateur (chedulerIsAlive)d'activité dans /data/EDT/jenkins/tmp. Ce job est lancé sur le master (lpsrvulo10).
* Planification dans la crontab de Jenkins (toutes les heures, 45 mn après chaque heure) d'un script chargé de vérifier l'existence du fichier indicateur, et le supprimer s'il existe. S'il n'existe pas, un mail d'alerte est transmis à UsineLogicielle.

= Mise en œuvre Cloudbees Jenkins Enterprise &amp; Jenkins Operations Center =
== Liste des nœuds Jenkins ==
Le Jenkins Operations Center (JOC): 
* http://lpsrvulo12:8888/

{| class="wikitable alternance centre"
|+ Versions du core Jenkins Operations Center
|-
 |
 ! scope="col" | lpsrvulo12 (CJOC principal)
 ! scope="col" | ??? (CJOC secondaire)
 |-
 ! scope="row" | Jenkins ver. 1.609 (CloudBees Jenkins Operations Center 1.6)
 |  
 |  
 |-
 ! scope="row" | Jenkins ver. 1.625.3.1 (CloudBees Jenkins Operations Center 1.8)
 | X
 | N/A
|}

Les Jenkins Enterprise Client Master:
* UsineLogicielle: http://usinelogicielle.uem.lan (http://lpsrvedt1:8080)
* UsineValidation: http://usinevalidation.uem.lan (http://lpsrvedt1:8180)
* UsineDeploiement: http://usinedeploiement.uem.lan (http://lpsrvedt1:8280)
* UsineRecette: http://lpsrvedt1:8380
* UsineAdministration: http://lpsrvedt1:8480

{| class="wikitable alternance centre"
|+ Versions du core Jenkins client Master
|-
 |
 ! scope="col" | usineLogicielle
 ! scope="col" | usineValidation
 ! scope="col" | usineDeploiement
 ! scope="col" | usineAdministration
 ! scope="col" | usineRecette
 |-
 ! scope="row" | Jenkins ver 1.609.1.1 (CloudBees Jenkins Enterprise: 15.05)
 |  
 |  
 |  
 | 
 | 
 |-
 ! scope="row" | Jenkins ver 1.625.3.1 (CloudBees Jenkins Enterprise: 15.11)
 | X
 | X
 | X
 | X
 | X
|}

== Redémarrage des Master de lpsrvedt1  ==

Un job est disponible sur l'UsineAdministration: http://lpsrvedt1.uem.lan:8480/view/jenkins/job/jenkins.restart-master/

L'UsineAdministration ne peut pas être redémarrée via son propre job !

=&gt; Un script de redémarrage est disponible sur lpsrvedt1, à lancer en tant que root: 
   $ cd /data/EDT/interneUL/scripts/
   $ restart-master.sh &lt;action&gt; &lt;master&gt;
     * action = start | stop | restart
     * master = jenkinsUR | jenkinsUV | jenkinsUD | jenkinsUA | jenkinsUL

== Procédure de migration des Client Master  ==

Pour redémarrer après migration 1.625.x -&gt; 2.19.4.2 : https://stackoverflow.com/questions/38157686/migrating-to-jenkins-2-1-ajp-support-is-removed-in-winstone-3-0-due-to-jetty-9

=== UL/UV/UD/UR  ===

Afin de migrer le core des Jenkins Enterprise Client Master (UL, UV, UD, UR), la procédure suivante est à suivre:
* Télécharger le WAR du CJE (CloudBees Jenkins Enterprise) à installer depuis http://download.infradna.com/cje/ et le déposer dans /data/install/jenkins/${JenkinsVersion}
* Lancer le job de migration: http://lpsrvedt1.uem.lan:8480/view/jenkins/job/jenkins.upgrade-version
* Redémarrer l'usine migrée en utilisant le job: http://lpsrvedt1.uem.lan:8480/view/jenkins/job/jenkins.restart-master/
* Suivre la précédure de mise à jour des plugins qui suit.


NOTE: en cas de problème rencontré, il est possible de restaurer le master migré pour le remettre dans son état pré-migration: http://lpsrvedt1.uem.lan:8480/view/jenkins/job/jenkins.restore-version/

=== UA  ===

* Le WAR est forcément déjà présent sur le serveur (migration UR en amont)
* Se connecter ulouser sur lpsrvedt1
* Se placer dans le répertoire /data/EDT/interneUL/scripts
* Exécuter le script jenkins-upgrade-version.sh
* Redémarrer l'usine jenkinsUA: sudo /etc/init.d/jenkinsUA start
* Vérifier via 'ps -ef | grep jenkinsUA' que le master est bien démarré en "daemonized". 
* Si ce n'est pas la cas, refaire "sudo /etc/init.d/jenkinsUA restart" jusqu'à obtenir "-Dcom.sun.akuma.Daemon=daemonized" sur la ligne du 'ps -ef | grep jenkinsUA'

Suivre la précédure de mise à jour des plugins qui suit.

NOTE: en cas de problème rencontré, il est possible de restaurer le master migré pour le remettre dans son état pré-migration: se connecter ulouser sur lpsrvedt1, se placer dans le répertoire /data/EDT/interneUL/scripts et lancer jenkins-restore-version.sh (voir les paramètres attendus en lancant l'outil sans paramètre).

== Mise à jour des plugins via UpdateCenter ==
* Se connecter sur le client Master à mettre à jour et aller dans la page de gestion des plugins: http://&lt;usineXXX&gt;.uem.lan/pluginManager/
* Se rendre dans l'onglet "Disponibles" (http://usinevalidation.uem.lan/pluginManager/available) et sélectionner tous les plugins que l'on souhaite activer sur l'usine. ATTENTION: ne jamais sélectionner un plugin "Operations Center Server ....", dédié au JOC.
* Cliquer sur "Installer sans redémarrer", et cliquer sur redémarrer une fois les installations attendues OK.
* Une fois l'usine le client Master redémarré, se rendre dans l'onglet "Mises à jour" (http://usinevalidation.uem.lan/pluginManager/) et sélectionner tous les plugins que l'on souhaite mettre à jour (tous, normalement).
* Redémarrer le client Master une fois les mises à jour OK.

== Redémarrage des Master ==

Les anomalies suivantes ont été observées sur Usine logicielle et usine validation, en fin d'execution, après le SUCCESS de la compilation:

&lt;source lang="C"&gt;
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 7:08.997s (Wall Clock)
[INFO] Finished at: Fri Jan 08 10:57:21 CET 2016
[INFO] Final Memory: 60M/1026M
[INFO] ------------------------------------------------------------------------
[JENKINS] Archiving disabled
En attente que Jenkins finisse de récupérer les données
Triggering projects: Fgestion-interne » bdd.free-resources-token
channel stopped
ERROR: Echec à la lecture des POMs
java.io.IOException: Can't read POM: /data/EDT/jenkinsSlave_4all_1/4edcd6d0/workspace/Fvalidation-gerrit/ecore.JDK8/pom.xml
	at jenkins.plugins.maveninfo.extractor.properties.PomPropertiesFinder.findProperties(PomPropertiesFinder.java:54)
	at jenkins.plugins.maveninfo.extractor.MavenInfoExtractor.extract(MavenInfoExtractor.java:58)
	at jenkins.plugins.maveninfo.extractor.MavenInfoEnvironment.tearDown(MavenInfoEnvironment.java:42)
	at hudson.maven.MavenModuleSetBuild$MavenModuleSetBuildExecution.doRun(MavenModuleSetBuild.java:882)
	at hudson.model.AbstractBuild$AbstractBuildExecution.run(AbstractBuild.java:536)
	at hudson.model.Run.execute(Run.java:1741)
	at hudson.maven.MavenModuleSetBuild.run(MavenModuleSetBuild.java:531)
	at hudson.model.ResourceController.execute(ResourceController.java:98)
	at hudson.model.Executor.run(Executor.java:374)
Notifying upstream projects of job completion
Finished: FAILURE
&lt;/source&gt;
Un redémarrage des usines a permis de résoudre le problème. 
Pour éviter ce type d'erreur, les usines (sauf UA) sont donc redémarrées tous les dimanches à 11h00 via le job http://lpsrvedt1.uem.lan:8480/view/jenkins/job/jenkins.orchestrate-restart-all-masters/
* Cela ne règle pas le vrai problème de fond qui est un problème d'encodage Cp1252 non supporté dans le pom.xml. Pour corriger cela il faut utiliser le job suivant : http://lpsrvedt1.uem.lan:8480/job/pom.change-cp1252-with-windows1252/

= Configuration spécifique des MASTER Jenkins =

Le  fichier /etc/sysconfig/jenkinsUx est modifié sur les master (variable JENKINS_JAVA_OPTIONS):

* Pour permettre les échanges de fichiers sans problèmes de droits entre ulouser (slaves) et jenkins (master) sur lpsrvedt1, un fichier a été ajouté: /var/lib/jenkins/.bashrc contenant la commande "umask 002". Comme le compte jenkins ne dispose pas de login (/bin/false dans /etc/passwd), la ligne suivante a été ajoutée à la fin de chaque fichier /etc/sysconfig/jenkinsU*: "source /var/lib/jenkins/.bashrc".
Pour l'utilisateur ulouser de lpsrvedt1, la commande "umask 002" a aussi été ajoutée en fin de fichier $HOME/.bashrc

* Pour changer la stratégie d'allocation/réservation des slaves lors des demandes faites par les différents job: 
   -Dcom.cloudbees.opscenter.client.cloud.CloudImpl.retentionStrategyShotCount=-1


* Pour augmenter la taille du contenu d'un job. Notamment pour les scripts groovy: -Dorg.eclipse.jetty.server.Request.maxFormContentSize=500000

= Etat CJP =

CJOC : lpsrvulo12
Masters : lpsrvedt1
* jenkinsUV : stoppé
* jenkinsUA
* jenkinsUL
* jenkinsUD: désactivé

Pour arrêter ou redémarrer un master, aller sur lpsrvedt1. Se connecter jenkins user.
 cd /data/EDT/interneUL/scripts
 ./restart-master.sh stop jenkinsUV

Usage: $(basename $0) &lt;stop | start | restart&gt; &lt;jenkinsUA | jenkinsUR | jenkinsUL | jenkinsUV | jenkinsUD&gt;

= RAF migration CJP vers CBC =


* https://usinelogicielle.uem.lan/job/FefluidTools/job/FdbTools/ =&gt; à conserver jusqu'à extinction V13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FefluidTools/job/Fetools/dockerfile.release =&gt; à conserver jusqu'à extinction V13 prévue pour février 2022 (mais ne sert plus car les fichiers ont été remis dans l'installeur directement)
* https://usinelogicielle.uem.lan/job/FefluidTools/job/Finstalleur =&gt; à conserver jusqu'à extinction V13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FefluidTools/job/FjmsTools/  =&gt; à conserver jusqu'à extinction V13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FefluidTools/job/FmavenPlugins/job/sql-maven-plugin.release/ =&gt; à conserver jusqu'à extinction V13 prévue pour février 2022 
* https://usinelogicielle.uem.lan/job/FefluidTools/job/FscriptSqlLauncher/job/scriptsqllauncher.release/ --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/Feldap/job/eldap.release-socle-13/  --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FjobsCommuns/job/application.deploy-v13/   --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FjobsCommuns/job/efluidDemat.deploy-v13/   --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FjobsCommuns/job/release.call-suivefluid-gestion-version-pour-creer-branche-maintenance/  --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FjobsCommuns/job/release.call-suivefluid-gestion-version-pour-construire-version/  --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FjobsCommuns/job/weblogic.create-realm-for-erdf-environnement-v13/ -&gt;  --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FsuiteEfluid/job/suite-efluid.orchestrate-new-release-COPIE/ --&gt; --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FsuiteEfluid/job/suite-efluid.orchestrate-new-release-socle-14-afterMigration/ --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinelogicielle.uem.lan/job/FsuiteEfluid/job/suite-efluid.orchestrate-nightly-build-workflow-maintenance_13-UEM-NB-CLASSIQUE/  --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022, on voulait garder une NB pour EDFSEI en v13

* https://usinelogicielle.uem.lan/job/FjobsUtilitaires/job/etools.deploy-properties-to-artifactory/ -&gt; à migrer 
* https://usinevalidation.uem.lan/job/Fvalidation-gerrit/job/performances/--&gt; migrer et ajouter le shellCheck
* https://usinevalidation.uem.lan/job/Fvalidation-gerrit/job/Ftools/job/Fetools/job/etools.validation-shell/ --&gt; à migrer
UD
   - NA
UV
 
* https://usinevalidation.uem.lan/job/Ftests/job/scriptInstalleur.test-installation-docker/ --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinevalidation.uem.lan/job/Fusinelogicielle/job/FjobsCommuns/ --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinevalidation.uem.lan/job/Fvalidation-gerrit/job/Ftools/job/FdbTools/job/efluidDbTools-script-sql-launcher/ --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022 
* https://usinevalidation.uem.lan/job/Fvalidation-gerrit/job/Ftools/job/Finstalleur/job/script-installeur-V2/ --&gt; à conserver jusqu'à extinction v13 prévue pour février 2022
* https://usinevalidation.uem.lan/job/Fvalidation-gerrit/job/Ftools/job/FjenkinsConfigurations/ =&gt; on garde maintenance_legacy_v13

UA

* http://lpsrvedt1.uem.lan:8480/job/batchs.start-docker-environnement/ --&gt; on garde NB ELDAP v12 (weblo jusque fin edfsei)
* http://lpsrvedt1.uem.lan:8480/job/gerrit.freeze-unfreeze-branche/ --&gt; on garde pour le job de release
* http://lpsrvedt1.uem.lan:8480/job/weblogic.start-docker-environnement-pre-deploiement-application/ --&gt; on garde NB ELDAP V12 (weblo jusque fin edfsei)

= Interaction avec Jenkins =

Pour interagir avec Jenkins il faut utiliser les services REST mis à disposition.

La documentation suivante explique comment s'en servir : https://www.jenkins.io/doc/book/using/remote-access-api/

Pour faire des tests, il faut utiliser l'utilisateur : '''jenkinsdev'''  (mot de passe à demander à l'UL)

Et il faut utiliser le master suivant : https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinerecette/

= liens =
== externes ==
* {{en}} http://jenkins-ci.org
== internes ==
* http://wikefluid/docInstalleur/jenkinsConfigurations/</text>
      <sha1>oy6eervuhz4nfmwpjyuis9gznnoeyzp</sha1>
    </revision>
  </page>
  <page>
    <title>Bouchons</title>
    <ns>0</ns>
    <id>25480</id>
    <revision>
      <id>233775</id>
      <parentid>233774</parentid>
      <timestamp>2014-05-26T07:11:24Z</timestamp>
      <contributor>
        <username>Tambori</username>
        <id>73</id>
      </contributor>
      <origin>233775</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2636" sha1="c2ndt4lmuptqjoxww4a2qyenv6imz22" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Bouchons &amp; Lanceurs
 | logo              = Logo HP ALM.jpg
 | supportTechnique  = [[JTA]]
 | faq               = [[FAQ:OutilsHP|FAQ Outils HP]]
}}

[[Category:outil]]
[[Category:hp]]

= Informations générales =
== Documents de conception ==
Comment réagit le bouchon en fonction de mon contexte ? Comment a-t-il été pensé ? Toutes ces réponses se trouvent dans les documents de conceptions sur eRoom : 

Mes eRooms &gt; efluid - Qualification Logicielle &gt; 03_ICF_ARGOS &gt; 35-Chantier Automates et Simulateurs &gt; [http://wperoom1/eRoom/Production/QualificationLogicielle/0_10b7c8 10-Conception]

== Tutoriels Service Virtualisation et UFT ==
Tous les tutos sont disponibles sur eRoom : 

Mes eRooms &gt; efluid - Qualification Logicielle &gt; 03_ICF_ARGOS &gt; 35-Chantier Automates et Simulateurs &gt; [http://wperoom1/eRoom/Production/QualificationLogicielle/0_100bed 00-Stratégie et guides]

== Problèmes rencontrés avec l'outillage HP ==
Pour recenser les différents bugs/problèmes rencontrés avec l'outillage HP, ou si vous avez simplement des questions, il y a un fichier sur eRoom servant à communiquer avec l'équipe HP. Vous pouvez l'alimenter sans problèmes : 

Mes eRooms &gt; efluid - Qualification Logicielle &gt; 03_ICF_ARGOS &gt; 20-Outillage &gt; 30-Fichier échanges HP &gt; [http://wperoom1/eRoomReq/Files/Production/QualificationLogicielle/0_11a680/IF%20argos%20-%20FichierEchange%20OutilsHP.xlsx IF argos - FichierEchange OutilsHP.xlsx]

== ALM ==
Vous pouvez découvrir l'ensemble des ressources déployées sur HP ALM Explorer.
Adresse ALM : http://wrqcedt1:8080/qcbin/
[[Fichier:AuthALM.png]]

= Bouchons déployés =
== Toutes versions 12.x ==
L'ensemble des bouchons HP disponibles (avec leurs URL de déploiement) est disponible sur eRoom.

Mes eRooms &gt; efluid - Projets ERDF &gt; ERDF &gt; 140 - Mutualisation &gt; Suivi &gt; [http://wperoom1/eRoomReq/Files/Prod4/ProjetsERDFEfluid/0_3570/Mutualisation_suivi_simulateurs.xlsx Mutualisation_suivi_simulateurs.xlsx]

== 12.5 ==
=== XSD et WSDL de références ===
Les XSD et WSDL de référence utilisés pour le développement des simulateurs est disponible sur eRoom : 

Mes eRooms &gt; efluid - Qualification Logicielle &gt; 03_ICF_ARGOS &gt; 35-Chantier Automates et Simulateurs &gt; 20-Composants &gt; [http://wperoom1/eRoomReq/Files/Production/QualificationLogicielle/0_1234cd/argos%20-%20Simulateurs%20V12.5%20-%20R%E9f%E9rentiel%20des%20WSDL%20et%20XSD%20-%20v1.docx argos - Simulateurs V12.5 - Référentiel des WSDL et XSD - v1.docx]

= Liens externes =
* {{fr}} http://www8.hp.com/fr/fr/software-solutions/software.html?compURI=1174233#.Uyhcj_l5O0c</text>
      <sha1>c2ndt4lmuptqjoxww4a2qyenv6imz22</sha1>
    </revision>
  </page>
  <page>
    <title>Exstream Opentext</title>
    <ns>0</ns>
    <id>37106</id>
    <revision>
      <id>4069109</id>
      <parentid>4069108</parentid>
      <timestamp>2023-04-21T09:06:23Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <origin>4069109</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4713" sha1="t7oni2qrbmrayxiydx2u3znraue9j54" xml:space="preserve">[[Category:outil]]
[[Category:éditique]]
{{Modèle:Infobox Outil
 | nom               = Exstream OpenText
 | siteInternet      = http://www.opentext.com/
 | version           = {{outil.streamserve.version}}
 | supportTechnique  = [[Thomas MANGIN]]
}}

= Généralités =

Exstream Opentext est un outil de composition de documents tels que les factures, les courriers, les états comptables, etc... dans différents formats (PDF, RTF, CSV, PCL).

= Fonctionnement = 
Exstream peut être considéré comme une interface notamment dans le projet efluid. Les applications telles que efluid générèrent des fichiers XML. Ces fichiers seront interprétés par le code applicatif Exstream afin de composer un document en sortie.


[[Fichier:FonctionnementStreamServeHTTP.jpg|cadre|centré|Fonctionnement TP]] [[Fichier:FonctionnementStreamServeBatch.jpg|cadre|centré|Fonctionnement Batch]]

= Architecture générale = 

[[Fichier:ArchitectureGeneraleStreamServe.jpg|cadre|centré|Architecture générale]]

= FAQ = 

En cas de saturation des Tablespaces, déterminer la table concernée

 SELECT
    owner,
    table_name,
    TRUNC(sum(bytes)/1024/1024) Meg,
    ROUND(ratio_to_report( sum(bytes) ) over () * 100) Percent
 FROM
 (
    SELECT segment_name table_name, owner, bytes
    FROM dba_segments
    WHERE segment_type IN ('TABLE', 'TABLE PARTITION', 'TABLE SUBPARTITION')
    
    UNION ALL
 
    SELECT i.table_name, i.owner, s.bytes
    FROM dba_indexes i, dba_segments s
    WHERE s.segment_name = i.index_name
    AND s.owner = i.owner
    AND s.segment_type IN ('INDEX', 'INDEX PARTITION', 'INDEX SUBPARTITION')
    
    UNION ALL
     
    SELECT l.table_name, l.owner, s.bytes
    FROM dba_lobs l, dba_segments s
    WHERE s.segment_name = l.segment_name
    AND s.owner = l.owner
    AND s.segment_type IN ('LOBSEGMENT', 'LOB PARTITION')
 
    UNION ALL
 
    SELECT l.table_name, l.owner, s.bytes
    FROM dba_lobs l, dba_segments s
    WHERE s.segment_name = l.index_name
    AND s.owner = l.owner
    AND s.segment_type = 'LOBINDEX'
 )
 
 WHERE owner in UPPER('&amp;owner') -- nécessaire d'indiquer le OWNER à regarder
 GROUP BY table_name, owner
 HAVING SUM(bytes)/1024/1024 &gt; 10 /* Ignore really small tables */
 ORDER BY SUM(bytes) desc ;


Si la table est DATA_CXIN_00000035, la supprimé serveur arrêter et la recréer par exemple :

      CREATE TABLE "TENANT_LDSRVEDT2"."DATA_CXIN_00000035" 
       (	"DOCUMENTABSTRACTIONID" RAW(16) NOT NULL ENABLE, 
        "CHUNKINDEX" NUMBER(*,0) NOT NULL ENABLE, 
        "DATA" BLOB, 
         CONSTRAINT "PK_DATA_CXIN_00000035" PRIMARY KEY ("DOCUMENTABSTRACTIONID", "CHUNKINDEX")
      USING INDEX PCTFREE 10 INITRANS 2 MAXTRANS 255 COMPUTE STATISTICS 
      STORAGE(INITIAL 65536 NEXT 1048576 MINEXTENTS 1 MAXEXTENTS 2147483645
      PCTINCREASE 0 FREELISTS 1 FREELIST GROUPS 1
      BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)
      TABLESPACE "USERS"  ENABLE, 
         CONSTRAINT "FK_DATA_CXIN_00000035_01" FOREIGN KEY ("DOCUMENTABSTRACTIONID")
          REFERENCES "TENANT_LDSRVEDT2"."CXIN_00000035" ("ID") ON DELETE CASCADE ENABLE
       ) SEGMENT CREATION IMMEDIATE 
      PCTFREE 10 PCTUSED 40 INITRANS 1 MAXTRANS 255 
     NOCOMPRESS LOGGING
      STORAGE(INITIAL 65536 NEXT 1048576 MINEXTENTS 1 MAXEXTENTS 2147483645
      PCTINCREASE 0 FREELISTS 1 FREELIST GROUPS 1
      BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)
      TABLESPACE "USERS" 
     LOB ("DATA") STORE AS SECUREFILE (
      TABLESPACE "USERS" ENABLE STORAGE IN ROW CHUNK 8192
      NOCACHE LOGGING  NOCOMPRESS  KEEP_DUPLICATES 
      STORAGE(INITIAL 106496 NEXT 1048576 MINEXTENTS 1 MAXEXTENTS 2147483645
      PCTINCREASE 0
      BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)) ;

la même opération est possible sur DATA_CXOUT_00000036


Il est possible que le contenu de la table stockant les logs d’ExStream ne soit jamais supprimé.
Dans ce cas il est nécessaire de purger manuellement cette table.

La procédure est la suivante :

1.	Arrêt de ExStream

2.	Création d’un index sur le logtime : 
 CREATE INDEX IDX_LOG_TIME ON CXLOG_00000039 (logtime);
3.	Enregistrement de toutes les lignes qu’on souhaite conserver dans une nouvelle table (ici tout ce qui a moins de 10 jours) :
 create table TMP_CXLOG_00000039 as
 select /*+ FULL */ *
 from CXLOG_00000039
 where logtime &gt;= to_timestamp(sysdate-10)
 ;
4.	Vidage de la table des logs
 truncate table CXLOG_00000039;
5.	Insertion des lignes sauvegardées
 insert into CXLOG_00000039
     select /*+ FULL */ *
     from TMP_CXLOG_00000039
 ;
6.	Suppression de la table temporaire créé
 drop table TMP_CXLOG_00000039;
7.	Redémarrage de ExStream</text>
      <sha1>t7oni2qrbmrayxiydx2u3znraue9j54</sha1>
    </revision>
  </page>
  <page>
    <title>Screen</title>
    <ns>0</ns>
    <id>62180</id>
    <revision>
      <id>221685</id>
      <timestamp>2014-05-16T13:26:04Z</timestamp>
      <contributor>
        <username>Rueff</username>
        <id>157</id>
      </contributor>
      <comment>Page créée avec « [[Category:outil]]  {{Modèle:Infobox Outil  | nom               = screen  | siteInternet      = http://www.gnu.org/software/screen/ }}  = Présentation =  Screen est un '... »</comment>
      <origin>221685</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5600" sha1="okpf35rt9z5c9cb9ltc34e7dm3zj1vd" xml:space="preserve">[[Category:outil]]

{{Modèle:Infobox Outil
 | nom               = screen
 | siteInternet      = http://www.gnu.org/software/screen/
}}

= Présentation =

Screen est un ''multiplexeur de terminaux'', capable d'ouvrir un ou plusieurs terminaux dans une même console, de passer de l'un à l'autre, de s'en déconnecter pour les laisser tourner en tâche de fond et de les récupérer plus tard.

Il offre d'autres services utiles comme :
* La possibilité d'attacher et de détacher une session, pratique par exemple pour lancer un traitement batch, de déconnecter et récupérer le résultat plus tard,
* La possibilité de partager un terminal avec un autre utilisateur, idéal pour aider un utilisateur distant,
* La possibilité d'ouvrir plusieurs ligne de commande sur un serveur sans avoir à se reconnecter à chaque fois.

Cette page se veut être un tutoriel très simple de l'outil. La documentation complèt est disponible ici : http://www.gnu.org/software/screen/manual/screen.html

= Principe de fonctionnement =
Bien évidement, l'outil doit être installé sur le serveur au préalable. Voir avec le sysadmin en charge.

Il se lance très simplement, en entrant la commande &lt;code&gt;screen&lt;/code&gt;:
  [git@lpsrvgit1 ~]$ screen -S &lt;un nom explicite&gt;

Selon la configuration du serveur, un écran d'accueil peut s'afficher. Ou pas. Quoi qu'il en soit, il est simple de confirmer qu'on se retrouve à l'intérieur d'une session screen, en entrant le raccourci '''&lt;ctrl&gt;&lt;a&gt; suivi de "''' (touche 3 du clavier).

L'argument &lt;un nom explicite&gt; permet de retrouver des sessions plus tard, voir plus bas "Gestion des sessions". Dans mon cas j'ai choisi mon nom de famille.

{{info|texte=L'utilisation des raccourcis est systématiquement la même, vous commencez par faire le raccourci &lt;ctrl&gt;&lt;a&gt; suivi d'un lettre.}}

Ce raccourci affiche le sélecteur de fenêtre screen actives, dans notre cas :
  Num Name                  Flags
    0 bash                  $
On y navigue à l'aide des flèches du clavier, on active la fenêtre sélectionnée en appuyant sur &lt;entrer&gt;.

= Gestion des fenêtres =
Pour s'y retrouver, on peut libeller la fenêtre active. Le raccourci est '''&lt;ctrl&gt;&lt;a&gt; A''' :
  [git@lpsrvgit1 ~]$
  Set window's title to: Mon premier exemple

On vérifie en consultant la liste des fenêtres ('''&lt;ctrl&gt;&lt;a&gt; "''') :
  Num Name                  Flags
    0 Mon premier exemple   $

Pouvoir lister les fenêtres signifie qu'on peut en créer plusieurs. Le raccourci est '''&lt;ctrl&gt;&lt;a&gt; c'''. Si je crée une nouvelle fenêtre ('''&lt;ctrl&gt;&lt;a&gt; c'''), que je la labellise "Mon deuxième exemple" ('''&lt;ctrl&gt;&lt;a&gt; A''') en enfin que le liste les fenêtres disponibles ('''&lt;ctrl&gt;&lt;a&gt; "'''):
  Num Name                  Flags
    0 Mon premier exemple   $
    1 Mon deuxième exemple  $

Grâce au sélecteur, je peux changer de fenêtre. Je peux également naviguer d'une fenêtre avec les raccourcis '''&lt;ctrl&gt;&lt;a&gt; n''' (avancer) et '''&lt;ctrl&gt;&lt;a&gt; p''' (reculer). Un peu comme &lt;alt&gt;&lt;tab&gt; sous windows.

Une fenêtre se détruit en quittant le shell lancé. Avec la commande &lt;code&gt;exit&lt;/code&gt; par exemple:
 [git@lpsrvgit1 ~]$ exit
On peut également tuer une fenêtre avec le raccourci '''&lt;ctrl&gt;&lt;a&gt; K'''.

= Gestion des sessions =

screen permet non seulement de multiplexer des terminaux, mais également de se déconnecter en les laissant tourner en tâche de fond. Reprenons notre exemple. Voici un commande affichant la date chaque seconde: &lt;code&gt;while true; do date; sleep 1; done&lt;/code&gt;. Je l'entre en ligne de commande :
  [git@lpsrvgit1 ~]$ while true; do date; sleep 1; done
  ven mai 16 14:59:20 CEST 2014
  ven mai 16 14:59:21 CEST 2014
  ven mai 16 14:59:22 CEST 2014
  ven mai 16 14:59:23 CEST 2014
  ven mai 16 14:59:24 CEST 2014

Je vais me détache de ma session avec le raccourci '''&lt;ctrl&gt;&lt;a&gt; d''' :
  [git@lpsrvgit1 ~]$ screen -S rueff
  [detached]
  [git@lpsrvgit1 ~]$
Je peux m'y rattacher à l'aide de la commande &lt;code&gt;screen -r &lt;mon identifiant de session&gt;&lt;/code&gt; (dans mon cas screen -r rueff). Je retrouve ma fenêtre, dont le contenu a entre temps progressé :
  ven mai 16 15:00:07 CEST 2014
  ven mai 16 15:00:08 CEST 2014
  ven mai 16 15:00:09 CEST 2014
  ven mai 16 15:00:10 CEST 2014
  ven mai 16 15:00:11 CEST 2014
  ven mai 16 15:00:12 CEST 2014
  ven mai 16 15:00:13 CEST 2014

Il peut avoir tellement progressé qu'on ne voit plus le début. Il est possible de "remonter" dans l'affichage en passant en mode 'scrollback'' avec le raccourci '''&lt;ctrl&gt;&lt;a&gt; &lt;echap&gt;'''. On s'y promène à l'aide ds touches fléchés, et on en sort à nouveau via &lt;echap&gt;. On peut également logguer le contenu de l'écran dans un fichier : '''&lt;ctrl&gt;&lt;a&gt; H'''.

= Session partagée =
Pour que plusieurs utilisateurs puisse se conencter simultanément, le prmier crée une session screen avec un nom déterminé, les autres s'y attache via &lt;code&gt;screen -x &lt;nom de la session&gt;&lt;/code&gt;.

= Résumé des commandes raccourcis =
En premier lieu : '''&lt;ctrl&gt;&lt;a&gt; ? affiche l'aide'''.

* &lt;code&gt;screen -S toto&lt;/code&gt; : créer une session
* &lt;code&gt;screen -r toto&lt;/code&gt; : s'attacher à une session en mode exclusif
* &lt;code&gt;screen -x toto&lt;/code&gt; : s'attacher à une session en mode prtagé

* &lt;ctrl&gt;&lt;a&gt; A : nommer la fenêtre
* &lt;ctrl&gt;&lt;a&gt; c : créer une fenêtre
* &lt;ctrl&gt;&lt;a&gt; d : se détacher de la session
* &lt;ctrl&gt;&lt;a&gt; H : logguer le contenu de l'écran
* &lt;ctrl&gt;&lt;a&gt; K : tuer une fenêtre
* &lt;ctrl&gt;&lt;a&gt; n : aller à la fenêtre suivante
* &lt;ctrl&gt;&lt;a&gt; p : aller à la fenêtre précédent
* &lt;ctrl&gt;&lt;a&gt; " : lister les fenêtres
* &lt;ctrl&gt;&lt;a&gt; &lt;echap&gt; : passer en mode scrollback, dont on sort en appuyant sur &lt;echap&gt;</text>
      <sha1>okpf35rt9z5c9cb9ltc34e7dm3zj1vd</sha1>
    </revision>
  </page>
  <page>
    <title>Docker</title>
    <ns>0</ns>
    <id>85288</id>
    <revision>
      <id>2539240</id>
      <parentid>2539166</parentid>
      <timestamp>2017-02-08T10:02:31Z</timestamp>
      <contributor>
        <username>Wozniak</username>
        <id>307</id>
      </contributor>
      <comment>/* Bugs */</comment>
      <origin>2539240</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5634" sha1="5pxy8e004qbs4qf7sgl4764i3sgoa0g" xml:space="preserve">[[Category:outil]]
[[Category:docker]]
{{Modèle:Infobox Outil
 | nom               = Docker
 | logo              = Docker.png
 | siteInternet      = http://www.docker.com/
 | version           = {{outil.docker.version}}
 | supportTechnique  = [[Vincent CARRIER]]
 | guideInstallation = Guide d'installation de docker
 | faq               = [[FAQ:Docker|FAQ Docker]]
}}

= Conteneurs disponibles =
== MongoDB ==
* Un conteneur mongoDB est disponible sur LDSRVULO1.
* Instanciation du conteneur
 docker run -d --restart=always -p 27017:27017 --name mongoDBName mongo

== Wildfly ==
* Un conteneur avec Wildfly 8.1.0.Final est disponible sur LDSRVULO1
* Image de base disponible ici : [https://registry.hub.docker.com/u/jboss/wildfly/ https://registry.hub.docker.com/u/jboss/wildfly/]
* Image jdk 8 sur etools/docker/images/wildfly-admin-jdk8
* Instanciation du conteneur
 docker run -it --restart=always -p 8080:8080 -p 9990:9990 --name wildflyName jboss/wildfly-admin-jdk8
* Les login/mdp d'accès à la console sont : admin/Admin#70365

* Sur lpdocedt1, le Dockerfile se trouve sous /data/scripts/wildfly-admin-jdk8

== Oracle 11G expres ==
* Conteneur disponible sur LDSRVULO1
* Image [https://registry.hub.docker.com/u/wnameless/oracle-xe-11g/ https://registry.hub.docker.com/u/wnameless/oracle-xe-11g/]
* Instanciation du conteneur
 docker run -d -p 49160:22 -p 49161:1521 wnameless/oracle-xe-11g

== TODO efluid embedded ==
* Instanciation du conteneur
   docker run -d -p 8090:8080 -v /root/lib:/opt/apache-tomcat-8.5.4.5-SNAPSHOT/webapps/efluid-13.3.100-PROTO-EMBEDDED-SNAPSHOT/WEB-INF/classes --name efluidEmbedded partifactorydocker.uem.lan/application-tomcat-embedded:efluid-13.3.100-PROTO-EMBEDDED-SNAPSHOT

== Wekan ==
* Instanciation des conteneur
    docker run -d --name wekan-db mongo
    docker run -d --link "wekan-db:db" -e "MONGO_URL=mongodb://db" -e "ROOT_URL=http://lddocedt1:8091" -p 8091:80 mquandalle/wekan

= Images via Dockerfile =
* https://docs.docker.com/reference/builder/
* Les packages utilisés dans les Dockerfiles sont récupérés via la commande wget (--user=usinelogicielle). Les packages sont stockés dans l'artifactory sous http://eartifact/artifactory/libs-release-local/com/efluid/dockerfiles/...
* Les Dockerfile doivent être placés dans etools : ''etools\docker\images\dockerfile''

== Création d'un Dockerfile ==
* Il faut créer un fichier ''Dockerfile'' dans un répertoire donné
* Pour builder l'image il faut lancer la commande suivante
 docker build --tag=nomDuTag &lt;RepertoireDuDockerFile&gt;
* Pour se placer dans l'image et faire des modifications
 docker run -i -t --name essaiTartempion imageRepository:imageTag /bin/bash
* Pour commiter les modifications
 docker commit idContainer ImageRepository:ImageTag

== Utilisation du proxy UEM ==
* Il faut déclarer les variables d'environnements suivantes pour pouvoir se connecter à Internet directement (via wget ou curl par exemple)
 ENV http_proxy http://USER:PASSWORD@lpsrvpxy:8080
 ENV no_proxy localhost,127.0.0.1,wikefluid,eartifact,usinelogicielle
* Pour faire du yum il est nécessaire de déclarer le proxy dans la configuration de yum
 RUN echo "proxy=http://lpsrvpxy:8080/" &gt;&gt; /etc/yum.conf
 RUN echo "proxy_username=D_NT_UEM\USER" &gt;&gt; /etc/yum.conf
 RUN echo "proxy_password=PASSWORD" &gt;&gt; /etc/yum.conf

== Le context du build ==
* Tous les fichiers présents "à coté" du Dockerfile seront présents dans le context du build
** Exemple : on a l'arborescence suivante
&lt;source lang="dos"&gt;
 /data/file/
             - Dockerfile
             - toto.jar
             - titi.txt
&lt;/source&gt;
* Les fichiers toto.jar et titi.txt seront accessible via les commandes du Dockerfile
** On pourra donc faire par exemple
 ADD toto.jar /opt/toto.jar

== Faire un mapping de répertoire local pour le rendre disponible dans un conteneur ==
* Il faut déclarer le volume dans le Dockerfile
 VOLUME ["/data/install"]
* Puis au moment du lancement du conteneur, faire le mapping
 docker run -v [host directory]:[container directory]

= Commandes utiles =
* https://www.docker.com/sites/default/files/Docker_CheatSheet_08.09.2016_0.pdf

== Conteneurs ==
* Connaitre la liste des conteneurs démarré
 docker ps
* Connaitre la liste de tous les conteneurs
 docker ps -a
* Supprimer un conteneur
 docker rm -v ''containeurId''
* Démarrer un conteneur
 docker start ''containeurId''
* Arreter un conteneur
 docker stop ''containeurId''
* Redemarrer un conteneur
 docker restart ''containeurId''
* Voir les logs du conteneur
 docker logs ''containeurId''

== Images ==
* Les backup d'images peuvent aussi être placés dans etools : ''etools\docker\images\backup''

* Lister les images
 docker images
* Supprimer une image
 docker rmi ''ImageId''
* Backuper une image
 docker save ''ImageName'' | gzip -c &gt; ''PathToTarGzippedFile''
 exemple : docker save rhel6-base | gzip -c &gt; /data/rhel6-base.tgz
* Charger une image
 gunzip -c ''PathToTarGzippedFile'' | docker load
 exemple : gunzip -c rhel6-base.tgz | docker load

= Articles intéressants =
== Extraits de Linux Magazine 174 ==
[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_130117 Chapitre 1 - Vos applications intermodales]&lt;br /&gt;

[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_130118 Chapitre 2 - L'utilisation des conteneurs sous Docker]&lt;br /&gt;

[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_13011b Chapitre 3 - Outils et écosystème de Docker]&lt;br /&gt;

= Liens internes =
== Bugs ==
Bug utilisation module docker_container en 2.2 : http://wikefluid/index.php/Guide_d%27utilisation_de_Ansible#Bug_module_ansible_docker_container_18461</text>
      <sha1>5pxy8e004qbs4qf7sgl4764i3sgoa0g</sha1>
    </revision>
  </page>
  <page>
    <title>Xming</title>
    <ns>0</ns>
    <id>252742</id>
    <revision>
      <id>499238</id>
      <timestamp>2014-11-25T13:21:44Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>Page créée avec « {{Modèle:Infobox Outil  | nom               = Xming  | siteInternet      = http://sourceforge.net/projects/xming/  | version           = {{outil.xming.version}}  | faq   ... »</comment>
      <origin>499238</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="284" sha1="h2rzm6axyvtiwr6a5datzelfbbqx0ii" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Xming
 | siteInternet      = http://sourceforge.net/projects/xming/
 | version           = {{outil.xming.version}}
 | faq               = [[FAQ:XMing| FAQ Xming]]
 | guideInstallation = Guide d'installation de Xming
}}
[[Category:Xming]]</text>
      <sha1>h2rzm6axyvtiwr6a5datzelfbbqx0ii</sha1>
    </revision>
  </page>
  <page>
    <title>Assemblage des applications / composants</title>
    <ns>0</ns>
    <id>127617</id>
    <revision>
      <id>4055486</id>
      <parentid>4055485</parentid>
      <timestamp>2019-11-05T09:54:33Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Assemblage d'une application */</comment>
      <origin>4055486</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6573" sha1="7z0wflmgab0dgpf4q6ymezaioy5rxo0" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Assemblage des applications / composants
 | logo              = Integration_continue.jpeg
 | supportTechnique  = {{usinelogicielle|subject=Assemblage}}
 | siteInternet      = http://en.wikipedia.org/wiki/Continuous_integration
}}

[[Category:Outil]]
[[Category:Intégration Continue]]
[[Category:Jenkins]]

NOUVELLE DOCUMENTATION : http://wikefluid/docInstalleur/jenkinsConfigurations/
= Cas d'école d'assemblage =

== Créer une branche de maintenance sans job / Oubli de cocher la case "création d'une branche de maintenance" ==


Prenons le cas de suivefluid. Il nous a été demandé d'assembler une version '''4.5.100.RC1''' sachant que la prochaine sera une version '''5.1.100-SNAPSHOT''', celà implique la création de deux branches de maintenances :
* La branche de '''maintenance_4.5''' où l'on va assembler les prochaines '''4.5.200''', '''4.5.300''', etc...
* La branche de '''maintenance_4''' où l'on va assembler les prochaines '''4.6.100''', '''4.7.100''', '''4.8.100''', etc...


Lorsque l'on lance le job d'assemblage, celui-ci ne va pouvoir créer qu'une seule branche de maintenance : la '''maintenance_4.5'''


A notre charge de créer la branche de '''maintenance_4'''.


La première chose à faire est de créer le nouveau pom parent pour la prochaine version qui sera assemblée sur la maintenance_4 à savoir la version '''4.6.100-SNAPSHOT'''

On part toujours d'un pom de release, aussi commençons par télécharger le pom 4.5.100.RC1 : http://eartifact.uem.lan/artifactory/libs-release-local/com/efluid/suivefluid-parent/4.5.100.RC1/suivefluid-parent-4.5.100.RC1.pom

Il faut maintenant changer la version du pom suivefluid-parent :
http://usinelogicielle.uem.lan/job/FjobsUtilitaires/job/pom.update-properties-multi-versions-in-git/ 

&lt;source lang="xml"&gt;
&lt;version&gt;4.5.100.RC1&lt;/version&gt; 
             en
&lt;version&gt;4.6.100.RC2-SNAPSHOT&lt;/version&gt;
&lt;/source&gt;

et sauvegarder le fichier avec un nom de la forme '''''&lt;application&gt;-parent-&lt;nouvelleVersion&gt;-SNAPSHOT.pom'''''

Pour le cas courant cela nous donnerait '''suivefluid-parent-4.6.100.RC2-SNAPSHOT'''.
Pour finir, il faut déployer le nouveau pom dans eartifact.

La deuxième étape consiste à créer la nouvelle branche de maintenance_4 et de mettre à jour les poms pour qu'ils portent la bonne version et que parent de cette version corresponde au nouveau que l'on vient de déployer. Lorsque l'on créer une nouvelle branche, on la créer à partir du tag de la dernière RC (la RC1 dans tout les cas)

&lt;source lang="bash"&gt;
meyerj@PC2060 MINGW64 /d/java/workspaces/developpement_dev/suivefluid (develop u=) 
$ git branch maintenance_4 4.5.100.RC1
$ git push origin maintenance_4
$ git checkout maintenance_4
&lt;/source&gt;

Mettons à jour la version des poms de tout les modules et du parent. On lance également une compilation pour être sûr que tout fonctionne encore :
&lt;source lang="bash"&gt;
meyerj@PC2060 MINGW64 /d/java/workspaces/developpement_dev/suivefluid (develop u=) 
$ mvn org.codehaus.mojo:versions-maven-plugin:1.2.2-hermes:set versions:commit -DnewVersion=4.6.100.RC2-SNAPSHOT -DparentVersion=4.6.100.RC2-SNAPSHOT -DforceChangeAllModules=true
$ mvn versions:update-parent -N -DforceChangement=true -DparentVersion=4.6.100.RC2-SNAPSHOT
$ mvn clean install -DskipTests
&lt;/source&gt;

On ajoute, on commit et on push les modifications :
&lt;source lang="bash"&gt;
meyerj@PC2060 MINGW64 /d/java/workspaces/developpement_dev/suivefluid (develop u=) 
$ git add . -A
$ git commit -m '120682 : [fix] Création de la branche de maintenance_4'
$ git push --set-upstream origin maintenance_4
&lt;/source&gt;

Dans le cas où la gestion des scripts ne s'effectuerait pas encore avec SQLMigrator (enercom par exemple), il ne faut pas oublier de créer les branches de maintenances et les environnements sur ebuild. La démarche est expliquée ici : http://wikefluid/index.php/Assemblage_des_applications_/_composants#Op.C3.A9rations_.C3.A0_effectuer_sur_ebuild_.28hors_suite_efluid.29

Pour finir cette section, il faut lancer l'API suivefluid de création d'une branche de maintenance : 
http://usinelogicielle.uem.lan/job/FjobsCommuns/job/release.call-suivefluid-gestion-version-pour-creer-branche-maintenance/

{{avertissement}} Pour le cas de suivefluid, il faut penser à effectuer les mêmes opérations Git sur le repository suivefluidStrs qui stocke le contenu Streamserve de suivefluid.


= TODO =
== Liste de check ==
assemblage

* commun

** (POST) Vérifier que la version est à jour dans Suivefluid et que la prochaine est bien créée

* briques

** Archi/EDK/ecore

*** commun

**** (PRE) Vérifier qu'il y a des modifications, et si non vérifier que la brique parente n'a pas été releasée pour la même application cible
**** (PRE) Regarder s'il existe des commits en attente dans Gerrit

*** 3.X

**** (PRE) Vérifier les TI via chaque job dédié qui doit avoir été lancé juste avant la release
**** (POST) Mettre à jour le pom parent de chaque application dont on veut faire l'intégration, via le job XXX pour efluid, et manuellement pour les autres applications

*** develop

**** (POST) Controler que toutes les intégrations sont faites et si ce n'est pas une erreur technique sinon contacter le responsable du composant pour qu'il corrige. Puis mettre le MVN Review et submiter.

* applications

== Tutos ==
* Cas de reprise sur erreur

** Etape : mise à jour Suivefluid
*** TODO

=== Création des RPM dans une application ===
 mvn deploy -P create-rpm-packages -pl : ${ applicationName}-server-embedded-tomcat  

=== Génération d’une image docker pour l’application (ex: lddocedt1, ulouser) ===
Depuis un serveur linux avec existance de /opt/conf-maven-docker :
 mkdir DOCKER8080
 cd DOCKER8080
 mvn org.apache.maven.plugins:maven-dependency-plugin:2.6:get -Dartifact=com.efluid.utils.dockerfile:application-tomcat-embedded:1.30.1:zip -Ddest=application-tomcat-embedded.zip
 unzip application-tomcat-embedded.zip
 cp -R /opt/conf-maven-docker .
 - 
 docker build --build-arg APPLICATION_NAME=${applicationName} --build-arg APPLICATION_VERSION=${version} -t partifactorydocker.uem.lan/application-tomcat-embedded:${applicationName} -${version} --no-cache=true --pull=true .

Pour tagguer l’image:
 docker tag partifactorydocker.uem.lan/application-tomcat-embedded:${applicationName} -${version} partifactorydocker.uem.lan/application-tomcat-embedded:${applicationName}-${version}

Pour publier dans Artifactory : 
 docker push partifactorydocker.uem.lan/application-tomcat-embedded:${applicationName}-${version}</text>
      <sha1>7z0wflmgab0dgpf4q6ymezaioy5rxo0</sha1>
    </revision>
  </page>
  <page>
    <title>Usine déploiement</title>
    <ns>0</ns>
    <id>346280</id>
    <revision>
      <id>639391</id>
      <parentid>639390</parentid>
      <timestamp>2015-02-11T09:41:03Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <origin>639391</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="326" sha1="s2dadj4xmhfe22tthib7w65g5ju3zh0" xml:space="preserve">[[Category:outil]]

[http://usinedeploiement.uem.lan L'usine de déploiement] permet le pilotage des opérations sur les environnement de recette éditeur des applications :

* [[Enercom]]
* [[Ethaque]]
* [[Suivefluid]]


[[D%C3%A9ploiement_des_applications_en_recette_%C3%A9diteur|la procèdure compléte est disponible ici]]</text>
      <sha1>s2dadj4xmhfe22tthib7w65g5ju3zh0</sha1>
    </revision>
  </page>
  <page>
    <title>Sublime Text</title>
    <ns>0</ns>
    <id>13444</id>
    <revision>
      <id>1628141</id>
      <parentid>1628137</parentid>
      <timestamp>2016-05-25T11:08:39Z</timestamp>
      <contributor>
        <username>Bouthino</username>
        <id>7</id>
      </contributor>
      <comment>/* Fonctions de base */</comment>
      <origin>1628141</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2691" sha1="he9ya2imnej8b1ukaerommemo9qyx14" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Sublime Text
 | siteInternet      = http://www.sublimetext.com
 | guideInstallation = Guide d'installation de Sublime Text
 | version           = {{outil.sublimetext.version}}
}}
[[Category:sublime text]]
C'est un éditeur de texte avancé pour les développeurs.
= Fonctions de base =
* &lt;tt&gt;Ctrl+P&lt;/tt&gt; = Recherche de fichier (très performant)
** et "@" = nom de méthode
** et "#" = recherche de caractères dans le fichier
** et ":" = numéro de ligne
* &lt;tt&gt;Ctrl+shift+P&lt;/tt&gt; = Commandes (syntaxe, git)
* &lt;tt&gt;Ctrl+Shift+L&lt;/tt&gt; = Sélection multiple et édition multiple
* &lt;tt&gt;Ctrl+D&lt;/tt&gt; = sélectionner nouvelle occurrence + modification en masse
* &lt;tt&gt;Ctrl+shift+K&lt;/tt&gt; = supprimer une ligne
* &lt;tt&gt;Shift+"Bouton droit de la souris"&lt;/tt&gt; ou  &lt;tt&gt;"Bouton milieu de la souris"&lt;/tt&gt; =  sélection en bloc

= Configuration de Sublime Text =
== Encodage des fichiers ==

Comme pour n'importe quel autre éditeur de texte, il est très important pour nous de mettre en place le même encodage sur tout nos fichiers. L'encodage actuel est le Cp1252. Pour convertir un fichier dans l'encodage voulu, il suffit d'aller dans File &gt; ReOpen with encoding et choisir Western (Windows 1252 = Cp1252).

Il est également possible d'écrire un fichier et de le sauvegarder directement avec l'encodage désiré en allant dans File &gt; Save with encoding et choisir Western (Windows 1252 = Cp1252)

[[image: SaveSublimeEncoding2.png | 1000x700px]]

= Plugin complémentaires (non inclus dans l'installation standard) =
== Installation ==
* Il faut installer en 1er lieu "package control" pour installer les autres packages comme git

=== Package control ===
https://sublime.wbond.net/installation&lt;br&gt;

# Click the Preferences &gt; Browse Packages… menu 
# Browse up a folder and then into the Installed Packages/ folder 
# Download Package [https://sublime.wbond.net/Package%20Control.sublime-package Control.sublime-package] and copy it into the "Installed Packages/" directory 
# Restart Sublime Text 

==== Package git ====
https://github.com/kemayo/sublime-text-git/wiki&lt;br&gt;

===== Configuration options internet =====
* décocher la case ci-dessous :
[[Image:Verification internet.jpg]]

===== Configuration proxy =====
* Modifier le fichier de configuration package control : Package Control.sublime-settings
** "http_proxy": "192.168.102.103:8080",
** "https_proxy": "192.168.102.103:8080",
** "proxy_username": "bouthino",
** "proxy_password": "********",
[[Image:Proxy package control 2.jpg]]

===== Configuration git =====
* Modifier le chemin vers l'exécutable GIT
** "git_command": "D:/Programs/git/bin/git.exe"
[[Image:Proxy package control.jpg]]</text>
      <sha1>he9ya2imnej8b1ukaerommemo9qyx14</sha1>
    </revision>
  </page>
  <page>
    <title>OPCOM</title>
    <ns>0</ns>
    <id>470000</id>
    <revision>
      <id>864327</id>
      <timestamp>2015-06-17T15:06:43Z</timestamp>
      <contributor>
        <username>Back</username>
        <id>82</id>
      </contributor>
      <comment>Page créée avec « {{Modèle:Infobox Outil  | nom               = OPCOM }} Ordonnanceur utilisé par les équipes d'exploitation des clients : [[ES]], [[EDF-SEI]] pour ordonnancer l’exécu... »</comment>
      <origin>864327</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="219" sha1="6jrtdyeevbh00iv2y2qb16c8giy9o7a" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = OPCOM
}}
Ordonnanceur utilisé par les équipes d'exploitation des clients : [[ES]], [[EDF-SEI]] pour ordonnancer l’exécution des batchs.

Caractères interdits :
 [ ( %</text>
      <sha1>6jrtdyeevbh00iv2y2qb16c8giy9o7a</sha1>
    </revision>
  </page>
  <page>
    <title>Openldap</title>
    <ns>0</ns>
    <id>471907</id>
    <revision>
      <id>4051614</id>
      <parentid>4051613</parentid>
      <timestamp>2019-04-04T11:50:16Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Méthode avec Docker */</comment>
      <origin>4051614</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5826" sha1="izzeo4ozuvlesbdy1qzq4nozqp11ag7" xml:space="preserve">[[Category:outil]]
[[Category:openldap]]
{{Modèle:Infobox Outil
 | nom               = OpenLDAP
 | logo              = LDAPworm.png
 | siteInternet      = http://www.openldap.org/
 | version           = {{outil.openldap.version}}
 | supportTechnique  = [[Vincent CARRIER]]
 | guideInstallation = Guide d'installation d'OpenLDAP
 | faq               = [[FAQ:OpenLDAP|FAQ OpenLDAP]]
}}

= Pour configurer un serveur LDAP conforme aux préconisations éditeur =

== Méthode avec installation sur un serveur Linux ==

=== Pré-requis ===

En pré-requis, les RPMS suivants doivent être installés sur le serveur (ex: ici pour un redhat 6.5)
* openldap-servers-2.4.23-32.el6_4.1.x86_64
* openldap-2.4.23-32.el6_4.1.x86_64
* openldap-clients-2.4.23-32.el6_4.1.x86_64

=== Configuration cn=config ===

Le service ldap doit être stoppé
 service slapd status

Sinon le stopper
 service slapd stop

Déplacer l'ancienne base LDAP
 mv /etc/openldap/slapd.d /etc/openldap/slapd.d.svg
 
Contenu du fichier /etc/openldap/slapd.conf (qui doit appartenir à ldap:ldap). Le mot de passe est à modifier, au choix de la personne qui installe.
 include         /etc/openldap/schema/core.schema
 include         /etc/openldap/schema/cosine.schema
 include         /etc/openldap/schema/nis.schema
 include         /etc/openldap/schema/inetorgperson.schema
 pidfile         /var/run/openldap/slapd.pid
 argsfile        /var/run/openldap/slapd.args
 idletimeout     900
 allow bind_v2
 database        config
 rootdn          "cn=config"
 rootpw          passwd

 
Contenu du fichier config.ldif pour le respect des préconisations éditeur pour LDAP  (olcAllows, olcIdleTimeout, olcConnMaxPending, olcConnMaxPendingAuth). Les préconisations éditeurs LDAP se trouvent [http://wikefluid/docInstalleur/efluid/documentation/preconisations_techniques.html#PRECONISATIONS_LDAP là].
 dn: cn=config
 changetype: modify
 replace: olcAllows
 olcAllows: bind_v2
 dn: cn=config
 changetype: modify
 replace: olcIdleTimeout
 olcIdleTimeout: 900
 dn: cn=config
 changetype: modify
 replace: olcConnMaxPending
 olcConnMaxPending: 5
 dn: cn=config
 changetype: modify
 replace: olcConnMaxPendingAuth
 olcConnMaxPendingAuth: 10

Conversion de la configuration stockée dans slapd.conf au format OLC (on-line configuration cn=config) dans la base LDAP
 mkdir -p /etc/openldap/slapd.d
 slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d
 chown -R ldap:ldap /etc/openldap/slapd.d

Démarrage du service 
 service slapd start

=== Configuration de la base LDAP pour efluid ===

Ajout de la configuration pour les préconisations éditeurs. Si le port n'a pas été changé, le port par défaut est le port 389. Sinon l'adapter à la valeur configurée dans la commande ci-dessous. Le mot de passe (option -w) est aussi à remplacer.
 /usr/bin/ldapmodify -w passwd -D "cn=config" -H ldap://localhost:389 -f /root/config.ldif; 


Création du répertoire qui va acceuillir la base LDAP pour efluid. Ici on choisit /data/EDT/openldap. Ce chemin est libre de choix. Reporter son choix dans la suite de la procédure décrite ici.
 mkdir -p /data/EDT/openldap
 chown ldap:ldap /data/EDT/openldap

Contenu du fichier base.ldif pour la création de la BASE LDAP pour efluid (respecte aussi les préconisations éditeurs sur olcSizeLimit, olcTimeLimit, olcDbCachesize, olcDbCheckpoint)
 dn: olcDatabase=bdb,cn=config
 objectClass: olcDatabaseConfig
 objectClass: olcBdbConfig
 olcDatabase: bdb
 olcSuffix: dc=erdf,c=fr
 olcReadOnly: FALSE
 olcRootDN: cn=admin,dc=erdf,c=fr
 olcRootPW: password
 olcSizeLimit: 2000
 olcTimeLimit: 600
 olcDbCachesize: 10000
 olcDbCheckpoint: 128 5
 olcDbDirectory: /data/EDT/openldap

Création de la base LDAP pour efluid. Si le port n'a pas été changé, le port par défaut est le port 389. Sinon l'adapter à la valeur configurée dans la commande ci-dessous. Le mot de passe (option -w) est aussi à remplacer.
 /usr/bin/ldapadd -w passwd -D "cn=config" -H ldap://localhost:389 -f /root/base.ldif;


== Méthode avec Docker ==

Un containeur docker intégrant un serveur openLDAP a été mis au point. La configuration du serveur openLDAP respecte les préconisations éditeurs.
Ce type de container est utilisé pour tester l'outil initOpenLdap de l'installer, qui permet d'initialiser l'annuaire LDAP efluid.

Son dockerfile et fichiers joints se trouvent dans le dépôt GIT etools sous docker/images/dockerfile/openldap-nonregression.

Pour construire l'image correspondante, il faut se connecter sous un serveur disposant déjà de docker.
Voir page wiki sur le sujet [http://wikefluid/index.php/Guide_d%27installation_de_docker ici].

Construire l'image en lançant la commande depuis le répertoire contenant le DockerFile et les fichiers joints. Le nom du containeur est libre de choix.
 docker build -t test-openldap-nonregression:v12 $PWD

Pour lancer un containeur. L'alias du containeur est libre de choix.
 docker run --name monContaineur -d -p 2389:389 -p 2222:22 test-openldap-nonregression:v12

Avec un volume pour la persistance des données.
 docker run --name monContaineur -d -p 2389:389 -p 2222:22 -v /data/EDT/files/ENEDISLDAPV13/openldappersist:/data/EDT/openldap partifactorydocker.uem.lan/openldap-v13

et modifier la racine de la structure par défaut ''dc=efluid,c=fr''

 docker run --name monContaineur -d -p 2389:389 -p 2222:22 -v /data/EDT/files/ENEDISLDAPV13/openldappersist:/data/EDT/openldap -e LDAP_ENV_DC=dc=erdf,c=fr partifactorydocker.uem.lan/openldap-v13

Ici on mappe le port 389 (LDAP) du containeur sur le port 2389 du serveur hôte. Depuis l'extérieur, le serveur LDAP est donc accessible sur le serveur 2389.

On mappe le port 22 (SSH) du containeur sur le port 2222 du serveur hôte. Depuis l'extérieur, le containeur est accessible en SSH sur le port 2222 du serveur hôte.</text>
      <sha1>izzeo4ozuvlesbdy1qzq4nozqp11ag7</sha1>
    </revision>
  </page>
  <page>
    <title>IntelliJ</title>
    <ns>0</ns>
    <id>523099</id>
    <revision>
      <id>4069622</id>
      <parentid>4069621</parentid>
      <timestamp>2023-07-17T12:22:54Z</timestamp>
      <contributor>
        <username>Grzejsz</username>
        <id>69</id>
      </contributor>
      <comment>/* changer le formattage par défaut de l'éditeur */</comment>
      <origin>4069622</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6584" sha1="l7v6sv8iq9q0a9ftqcu2lvxot2z9xr0" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = IntelliJ
 | logo              = Intellij2017ico.PNG
 | siteInternet      = https://www.jetbrains.com/idea/
 | version           = {{outil.intellij.version}}
 | guideInstallation = Guide d'installation d'intelliJ
 | supportTechnique  = http://eforum.uem.lan/viewforum.php?f=16
 | Tips &amp; Tricks     = https://www.youtube.com/user/intellijideavideo
 | faq               = [[FAQ:IntelliJ|FAQ IntelliJ]]
}}

[[Category:outil]]
[[Category:intelliJ]]

== Installation IntelliJ ==

Voir le [[Guide d'installation d'intelliJ]].

== lancement IntelliJ ==

Pour lancer IntelliJ, il faut aller dans '''''D:\Programs\intellij\bin''''' puis cliquer sur idea64
[[Fichier:Cheminversintellij64.PNG]]

La première fois, une fenêtre "complete Installation" s'ouvrira. Cocher '''Custom location. Config folder or installation home of the previoues version:''' aller chercher la configuration dans '''''D:\Programs\intellij\.IdeaIC2017.2'''''

[[Fichier:Configenvironnement.PNG]]

== configurer Maven ==

Sur la page de démarrage cliquer sur Configure puis Settings &lt;br /&gt;

[[Fichier:IntelliJsettings.png]]

aller dans Build,Execution,Deployement &gt; BuildTools &gt; Maven

* Maven home directory choisissez : '''''D:/Programs/maven'''''
Normalement le local repository sera automatiquement configuré par contre le User settings file il faut cocher Override
* User settings file  : '''''D:\Programs\maven\conf\settings.xml'''''
* Local repository : '''''D:\java\mavenRepository'''''

[[Fichier:SettingsMaven.PNG]]

== configuration générale ==
=== changer le formattage par défaut de l'éditeur ===

==== via plugin SettingsRepository ====
A installer suivant les instructions de la page dédiée au plugin [[SettingsRepository]]

==== via fichier xml (Eclipse) ====
Par défaut, intellij (sous windows) utilise le formattage par défaut de l'IDE. 
Il faut récupérer le fichier de configuration efluid-formatter.xml qui se trouve à la racine de votre installation eclipse et le copier à la racine de votre installation IntelliJ.
Il faut ensuite importer la configuration dans IntelliJ.
* Pour cela il vous suffit de vous rendre dans File &gt; Settings &gt; 
[[Fichier:file_settings.jpg]]
* Dans Editor &gt; Code Style &gt; Java sélectionner la fonction Import Scheme &gt; Eclipse XML Profile
[[Fichier:Editor.jpg]]

=== changer le terminal de windows command line vers git bash ===

Par défaut, intellij (sous windows) a comme terminal de commande : windows command line. Pour le changer par exemple par le git bash il vous suffit de vous rendre dans File &gt; Settings &gt; Terminal 
* Dans shell path mettre : D:\Programs\Git\bash.exe
[[Fichier:SettingsTerminalGitBash.PNG]]

Résultat : 
[[Fichier:TerminalSousGitBash.PNG|1300px]]

== configurer serveur d'application ==
* [[intellij_efluid|Lancer l'application]] - Version V14+ (suite à la re-modularisation)
* [[Intellij webapp|Lancer l'application]] - Versions jusqu'à V13.x

== plugins ==
=== plugin mise à disposition ===

{| class="wikitable"
|-
! Nom !! version !! description 
|-
| Asciidoc || 0.19.2 || AsciiDoc language support for IntelliJ platform.
|-
| String manipulation || 5.7.143.000.0 || / 
|-
| Java Stream Debugger || 0.1.5 || 
|-
| Bazel || 2017.11.06.0.5 || / 
|-
| Cucumber for Groovy || 172.4343 || / 
|-
| Cucumber for Java || 172.4343 || /
|}

=== plugins intéressants ===
* https://plugins.jetbrains.com/plugin/10345-assertions2assertj
* https://wikefluid.efluid.uem.lan/index.php/SettingsRepository

= Optimisations =
* déplacer le répertoire de travail vers un emplacement non scanné par l'antivirus
** Créer un nouveau répertoire &lt;tt&gt;D:/java/intellij-home&lt;tt/&gt;
** Déplacer le contenu de &lt;tt&gt;${user.home}/.IntelliJIdea/config&lt;/tt&gt; vers &lt;tt&gt;D:/java/intellij-home&lt;/tt&gt;
** Editer le fichier &lt;tt&gt;D:\Programs\&lt;RepertoireInstallation&gt;\bin\idea.properties&lt;/tt&gt; et modifier les 2 propriétés suivantes :
*** &lt;tt&gt;idea.config.path=D:/java/intellij-home/config&lt;/tt&gt;
*** &lt;tt&gt;idea.system.path=D:/java/intellij-home/system&lt;/tt&gt;

= Licences =
* [[Gestion du serveur de licence intelliJ efluidSAS]]

== Utilisation d'une licence efluidSAS depuis intelliJ ==
=== Via le serveur de licence ===
* permet 48h offline tant que IJ n'a pas été redémarré depuis qu'il a récupérer un ticket en étant connecté au serveur de licence
* Si les licences sont toutes utilisées, faire une demande via Footprints.
[[Fichier:IJLicense01.PNG]]

=== Via une licence nominative ===
Un email doit vous avoir été envoyé, de ce format : 

 Dear Thomas, 
 A JetBrains IntelliJ IDEA Ultimate license has been connected to your t-collignon@efluid.fr JetBrains Account. 
 Please use these JetBrains Account credentials in the product to activate your license. 
 If for some reason it is impossible for you to use your JetBrains Account, please ask the owner of the license to generate license key for you.

* Si on a un compte JetBrains (cas à privilégier dans le cas d'une licence nominative car nécessite moins de gestion d'administration), on utilise l'option get license from JB account, puis on saisit les informations et activate :
[[Fichier:IJLicense02.PNG]]

* Sinon il faut demander à l'administrateur du serveur de licence (Actuellement TCO) de donner une clé de licence :
[[Fichier:IJLicense03.PNG]]

= Raccourcis =
* https://resources.jetbrains.com/storage/products/intellij-idea/docs/IntelliJIDEA_ReferenceCard.pdf
* http://blog.soat.fr/2014/04/shortcuts-mapping-eclipse-intellij-idea/
* http://javamind-fr.blogspot.fr/2013/01/intellij-et-les-raccourcis.html
* http://www.jetbrains.com/help/idea/mastering-keyboard-shortcuts.html
* Mettre en commentaire Ctrl + / (celui du numpad)
* Toutes actions CTRL + Maj + A 
* Recherche Double shift
* Précédent / Suivant = Ctrl + Alt + gauche|droite (désactiver dans icone intel, touches d’accès rapide)

= liens =
* https://www.jetbrains.com/help/idea/symbols-reference.html
* http://eforum.uem.lan/viewtopic.php?f=16&amp;t=3309

== Plugins ==

=== installation bazel ===
* récupérer bazel pour Windows et l'unzip dans D:\Programs\bazel : https://github.com/bazelbuild/bazel/releases/download/0.25.3/bazel-0.25.3-windows-x86_64.zip
* ajouter bazel dans les variables d'environnement utilisateur:
** BAZEL_HOME: D:\Programs\bazel
** Path: …;%BAZEL_HOME%
* récupérer le plugin bazel pour intellij : https://plugins.jetbrains.com/plugin/8609-bazel/versions
* installer le plugin : File &gt; Settings &gt; Plugins &gt; options &gt; Install Plugin from Disk … &gt; (sélectionner le zip contenant le plugin bazel)
[[Fichier:Install-plugin-intellij.png|default]]</text>
      <sha1>l7v6sv8iq9q0a9ftqcu2lvxot2z9xr0</sha1>
    </revision>
  </page>
  <page>
    <title>SqlMigrator</title>
    <ns>0</ns>
    <id>411773</id>
    <revision>
      <id>4067114</id>
      <parentid>4065692</parentid>
      <timestamp>2022-04-06T06:04:03Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Documentation */</comment>
      <origin>4067114</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="17665" sha1="8dpukidgkbny2fby7gvvn7zrp61xfde" xml:space="preserve">[[Category:outil]]

{{Modèle:Infobox Outil
 | nom               = sqlMigrator
 | version           = {{outil.sqlMigrator.version}}
 | supportTechnique  = {{usinelogicielle|subject=sqlMigrator}}
}}

= Documentation =

https://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/

= Présentation globale =
La présentation initiale du projet se trouve ici : http://wperoom2.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_15dffe

SQLMigrator comprend deux modes de fonctionnement.
* Le mode upgrade (utilisé par les devs et le scriptInstalleur). Ce mode est destiné à la pure montée de version 12.15.1200 -&gt; 13.4.100 par exemple.
** Le mode upgrade ne joue que ce qui se trouve dans le dossier {application}/sql/database/{application}/ddl|dml/upgrade 
** Le mode upgrade ne peut être joué sur une base vide
** Le mode upgrade peut prendre ces paramètres : 
*** '''sqlmigratorOffline''' : permet de simuler l'exécution de sqlMigrator. Génère les fichiers sql dans target qui auraient été joués sur la base
*** '''context''' : permet de setter un context
*** '''label''' : permet de setter un label
*** '''skipIndex''' : permet de skipper l'exécution des indexs. Par défaut à false
*** '''skipFinish''' : permet de skipper l'étape finish qui contient les scripts de perf et la maj de TAPPLICATIONINFO. Par défaut à false.
*** '''skipParametrage''' : permet de skipper les scripts de paramétrage se trouvant dans le dossier paramétrage. Par défaut à true en mode dev et à false en mode scriptInstalleur.
* Le mode UL-destruction (utilisé uniquement côté dev, à implémenter dans le sriptInstalleur quand le besoin sera nécessaire)
** Ce mode permet de construire une BDD from scratch en utilisant tout ce qu'il se trouve dans les dossiers drop, create, init
** Par défaut, il faut ajouter en paramètre un fichier de properties permettant de cible la BDD voulue.
** Ce mode n'est utilisé que par l'UL

= FAQ =
== Taille maximal d'un nom de module ==
* Les noms des modules ne doivent pas dépasser 12 caractères. La limitation lors de la création de la table de changelog étant de 30.

== Fonctionnement job de validation ==

3 étapes dans les jobs de validation des projets : 
* Création d'une base de données 
**  lien jdbc LPBDDEDT4:2483/PTECEDT2
**  schemaUser : {APPLICATION}_BUILD_{BUILD_NUMBER}
**  mot de passe Its4bdd_{schémUser}

* Lancement du mode upgrade
* Lancement du mode UL-destruction afin de vérifier que les dev ont livrés la même chose dans les deux dossiers.

== Conventions TBS Oracle12 ==

Les tablespaces sont nommés différemment en oracle12 par l'équipe perf.
*DATA devient DTA
*INDEX devient IDX
*PARAM devient PRM
*BLOB devient BLB
*BATCH_INDEX devient B_IDX
*BATCH_DATA devient B_DTA

Il faut faire attention de prendre en compte ces nouveaux nommages dans les fichiers de configurations

== Génération du script des index à partir du CSV ==
* Lancer la commande suivante : 
 mvn validate -P generer-script-index -N
* Le script '''index.sql''' sera généré à la racine du projet.

== Génération du SQL sans passage en base ==

Pré-requis : avoir un fichier framework2.properties qui pointe vers une BDD valide

 scripts/sql-upgrade.sh -DsqlmigratorOffline=true

== Conventions SQLMigrator ==

Les conventions concernant les scripts sqlMigrator se trouvent ici : [[Conventions SQLMigrator]]

== Procédure de livraison d'un script de montée de version ==
Procédure de livraison d'un script de montée de version : 

http://wikefluid/index.php/Livraison_de_script_de_mont%C3%A9e_de_version_dans_ebuild_pour_sqlMigrator

== Context pour le paramétrage ==

Aucun script de paramétrage ne doit être inclut dans les scripts de montée de version via SqlMigrator sauf pour la dernière RC.&lt;br /&gt;

Pour ne pas jouer ces scripts il faut ajouter l'option au lancement -DskipParametrage=true

Cette option prend en compte le fait de jouer ou non le dossier paramétrage qui est désormais définit comme un module.

== Exécution manuelle des scripts de paramétrage (PARAM_ERDF) ==

Procédure d'exécution manuelle des scripts de guichet de paramétrage :

http://wikefluid/index.php/Guichet_de_param%C3%A9trage

== Livraison d'un livrable de remplacement ==


Il peut arriver qu'un script soit en erreur dans une RC (ou après release) et qu'on s'en rende compte après coup. Il est possible de ne relivrer, pour débloquer, qu'un livrable sql dit de remplacement. 
Cette exécution jouera uniquement ce livrable de remplacement et passera outre le livrable d'origine livré avec la version et n'est '''actuellement disponible que pour efluid'''.

Ce livrable est à mettre dans artifactory avec le nom suivant : efluid-sql-database-{numeroVersion}_{numeroRemplacement}
Par exemple pour la 13.4.100.RC8, nous avons du livrer un livrable de remplacement que nous avons nommé '''efluid-sql-database-13.4.100.RC8_2.zip'''

La ligne de commande à lancée pour exécuter ce livrable est :

'''./lancerSqlMigrator.sh -DskipUtilisationZipSqlDatabaseRemplacement=false -DversionLivrableSqlDatabaseDeRemplacement=13.4.100.RC8_2'''

Un enforcer est présent afin de contrôler le nom du livrable. Ce nom doit comprendre le numéro de version en cours de déploiement. Cette validation peut être skippée (à destination uniquement de l'UL) avec l'ajout du paramètre : '''-DskipCheckVersionLivrableSqlDatabaseDeRemplacementWithProjectVersion=true'''

Attention, penser à ajouter le -DclientName si jamais on passe ce livrable sur une base ERDF.


== Comment exécuter un script de manière isolé avec SQLMigrator ==

Il peut être pratique d'exécuter un script de manière isolée, sans exécuter la montée de version intégralement.
Pour cela, on peut utiliser les labels, qui permettent de filtrer les scripts jouées pour la montée de version.

Par exemple, si l'étiquette '''suivefluid-183542-ddl-1''' n'est utilisée que pour un seul changeset :

 &lt;changeSet author="charroy" id="suivefluid-183542-ddl-1" labels="'''suivefluid-183542-ddl-1''', v5, ddl"&gt;
 	&lt;preConditions onFail="MARK_RAN"&gt;
 		&lt;columnExists tableName="tevenement" columnName="OLD_TYPEERREUR"/&gt;
 	&lt;/preConditions&gt;
 	&lt;sql&gt;
 		call ModificationStructure.rebuildIndexesBeforeDrop('tevenement','OLD_TYPEERREUR')
 	&lt;/sql&gt;
 	&lt;dropColumn tableName="tevenement"&gt;
 		&lt;column name="OLD_TYPEERREUR"/&gt;
 	&lt;/dropColumn&gt;
 &lt;/changeSet&gt;

On peut n'exécuter que ce changeset de la manière suivante :

 ./sql-upgrade-light.sh '''-D label=suivefluid-183542-ddl-1'''

'''Attention : Cette pratique n'est pas le cas d'usage nominal, elle ne garantie pas que la BDD soit à jour avec le code Java'''


== Comment valoriser une valeur variabilisée dans un script ? ==

On peut définir des variables dans le code SQL d'un changeset LiquiBase/ SQLMigrator avec la syntaxe suivante "${maVariable}".
Par exemple : 

 grant select, insert, delete, update on TVALEURINTERVALLEQUANTITE to '''${USER_GRANT}''';
 grant select, insert, delete, update on TSTAT to '''${USER_GRANT}''';
 grant select, insert, delete, update on TLIGNESTATISTIQUE to '''${USER_GRANT}''';
 commit;


'''Attention : Il faut utiliser cette syntaxe que la variable utilisée est gérée dans le déploiement de l'application.'''

Si cette syntaxe est utilisée, pour tester un script sur le poste de développement, on peut valoriser une telle variable de la manière suivante :

 ./sql-upgrade-light.sh '''-D maVariable=maValeur'''

Pour l'exemple ci-dessus :

 ./sql-upgrade-light.sh '''-D USER_GRANT=SEF_CLIENT'''

= FAQ des cas d'erreurs =

 ddl/upgrade/4/changelog/arc/functionalunit/changeLog.xml::suivefluid-172926-ddl::lagarde '''is now: 7:83c897ab2167fb89628d7c1a193a432e'''

* Le checksum du script a été modifié. Ce qui veut dire que la signature du script (décrite par id, author, filepath et contenu du fichier) a été modifié. En général, se passe sur les bases de DEV car les développeurs ont joués le script avec sql-upgrade sur la base puis l'on mit sur gerrit, l'ont modifié puis mergé. Donc le checksum est encore l'ancien. Il faut demander au développeur de corriger.

 [ERROR] Failed to execute goal com.efluid.utils.sql:sqlmigrator-maven-plugin:2.96.1:upgrade (upgrade) on project efluidnet-parent: Failed to execute SQLMigrator:   
 liquibase.exception.MigrationFailedException: Migration failed for change set ddl/upgrade/4/changelog/arc/modeleObjetMetier/changeLog.xml::suivefluid-194687-ddl-2 ::thibaut:
 [ERROR] Reason: liquibase.exception.DatabaseException: ORA-01430: la colonne ajoutée existe déjà dans la table
 [ERROR] [Failed SQL: ALTER TABLE DEV_FLDNET.TVALEURATTRIBUTPIECEJOINTE ADD REFERENCE VARCHAR2(250)]

* "La colonne ajoutée existe déjà dans la table" ou "La table ajoutée existe déjà" ou "ce nom d'objet existe déjà" veut dire que l'objet existe déjà sur la base. Peut se produire car : 
** Le développeur a ajouté manuellement son objet sur la bdd. Dans ce cas, il faut lui demander de corriger
** Le développeur a oublié de livrer un drop de son objet, il faut donc qu'il livre dans le dossier correspondant.
** Cet objet existe déjà et est créé en amont. Soit dans une brique soit dans le même projet mais le développeur ne l'a pas vu.
** Il est possible que l'exécution des drop se soit mal passé. Il faut donc regarder s'il n'y a pas eu un no wait ou une indispo de la base lors de l'exécution du drop de cette table

 ERROR] Failed to execute goal com.efluid.utils.sql:sqlmigrator-maven-plugin:2.96.1:upgrade (upgrade) on project ecore-racine: Failed to execute SQLMigrator:  
 liquibase.exception.MigrationFailedException: Migration failed for change set ddl/upgrade/4/changelog/arc/modeleObjetMetier/changeLog.xml::suivefluid-188055-ddl::thibaut:
 [ERROR] Reason: liquibase.exception.DatabaseException: ORA-00908: mot-cl� NULL absent
 [ERROR] [Failed SQL: create table TCONTRAINTEATTRIBUT
 [ERROR] (
 [ERROR] ID VARCHAR2(25) ,
 [ERROR] ROLE VARCHAR2(80) ,
 [ERROR] ETATOBJET NUMBER(1) ,
 [ERROR] ATTRIBUT_ID VARCHAR2(25) ,
 [ERROR] ATTRIBUT_ROLE VARCHAR2(80) ,
 [ERROR] LIBELLE VARCHAR2(80) ,
 [ERROR] COMPLEMENTJSON CLOB ,
 [ERROR] DATEMODIFICATION TIMESTAMP(6) ,
 [ERROR] ACTEURMODIFICATION VARCHAR2(50) ,
 [ERROR] DATECREATION TIMESTAMP(6) ,
 [ERROR] ACTEURCREATION VARCHAR2(50) ,
 [ERROR] DATESUPPRESSION TIMESTAMP(6) ,
 [ERROR] ACTEURSUPPRESSION VARCHAR2(50) ,
 [ERROR] constraint PK_TCONTRAINTEATTRIBUT PRIMARY KEY (ID) using index tablespace DEV_ECORE_INDEX
 [ERROR] , constraint COMPLEMENTJSON_JSON_CHECK check (COMPLEMENTJSON IS JSON)
 [ERROR] ) tablespace DEV_ECORE_DATA]
 [ERROR] -&gt; [Help 1]
 [ERROR] 

*'''constraint COMPLEMENTJSON_JSON_CHECK check (COMPLEMENTJSON IS JSON)''' utilise une fonction oracle12. Si une erreur intervient sur cette table, cela signifie que nous ne sommes pas sur une base oracle12

 [ERROR] Reason: liquibase.exception.DatabaseException: ORA-02289: la s�quence n'existe pas
 [ERROR] ORA-06512: � "TST_INT_MIG_ERDF.GESTIONIDENTIFIANT", ligne 139


* Cette erreur se produit sur les tests de non régression en général. Se produit quand l'import s'est mal passé. Il faut donc remonter sur le job d'import et voir ou se trouve l'erreur.

= PostgreSQL =

== Modifications code SqlMigrator ==
Des modifications de code sont nécessaire pour faire fonctionner sqlMigrator avec d'autres datasource.

Les adaptations de code côté sqlMigrator : https://gerrit.efluid.uem.lan/c/sqlMigrator/+/157998

Ajout d'un Dialect permettant de spécifier côté oracle ou postgre si des différences sont à prendre en compte.

Les scripts de preparation (CreatePackageGestionIdentifiants …) ont été splittés dans deux dossiers. Un dossier oracle et un postgre.

[[Fichier:RessourceSqlMigrator.PNG|sans_cadre|default]]

== Architecture d'un projet pour sql/database (exemple Archi) ==

Avant l'architecture était :

 ddl/
   drop/
   create/
         table/
         sequence/
         package/
   index/
        DescriptionIndex.csv
   upgrade/
        4/
        5/

On considère que les actions drop sont les mêmes peu importe la datasource actuellement. 
Seules les actions create et upgrade peuvent différer. Notamment à cause des différences remontées dans ce document (comme les type de colonne non supportés d'un SGBD à un autre) : http://wperoom4.uem.lan/eRoom/Production/GestionProjetEfluid/0_27ea13 

On va donc splitté le dossier create en deux sous dossiers qui sont nécessaires car le traitement est fait par simple fichier sql :
 ddl/
   drop/ 
   create/
         oracle/
               table/
               sequence/
               package/
         PostgreSQL/
               table/
               sequence/
   index/
   upgrade/ 
   
Côté upgrade, il y a moins d'obligations à splitté, différentes façons de faire peuvent être envisager. Donc on resterait sur un même dossier upgrade pour tous.

Côté projet archi, modification de la structure des ddl/dml : https://gerrit.efluid.uem.lan/c/archi/+/158912

== Comment traiter la partie upgrade pour ne pas dupliquer ? ==

L'idée et de rendre la vie plus facile pour les devs et qu'ils aient à dupliquer ou à penser à la datasource le moins possibles. 
Plusieurs possibilités, mais l'idée serait par ordre de priorité de traiter les cas comme suit :

1-  Utiliser un maximum les balises liquibase : https://docs.liquibase.com/change-types/community/home.html 

Les balises liquibase pour la majorité peuvent être utilisées sur plusieurs datasource sans préciser quelque chose de particulier.

2-  Rendre les scripts communs pour les deux SGBD grâce aux properties 

Les properties sont des propriétés paramétrable dans les changeLog.xml qui peuvent être utilisées via des varibles dans les balises liquibase.
Par exemple, si je sais que je vais créer une table mais que je dois utiliser des BLOB. Pour Oracle ça fonctionne, mais pour PG, le BLOB n'existe pas, on utilisera BYTEA. 
On pourrait donc avoir :

   &lt;property name="blob_type" value="bytea" dbms="postgresql"/&gt;
   &lt;property name="blob_type" value="blob" dbms="oracle"/&gt;
   
   &lt;changeSet author="costem_ALL" id="costem_ALL"&gt;
        &lt;createTable tableName="MCO_TEST_BOTH"&gt;
            &lt;column name="id" type="integer"/&gt; 
            &lt;column name="test_blob" type="${blob_type}"/&gt;
         &lt;/createTable&gt;
   &lt;/changeSet&gt;
   
Les properties sont valables pour tout un fichier changeLog.xml (à vérifier si on peut également tirer ça d'un changeLog parent). On pourrait alors définir nos spécificités avec ça et continuer d'utiliser les balises liquibase.

3-  Avoir un changeLog particulier pour un SGBD grâce à l'attribut dbms de liquibase

Dans certains cas, les commandes sql sont trop complexes pour pouvoir être utiliser via des balises liquibase. Notamment les scripts de haute volumétrie.
Dans ce cas de figure, on peut tout simplement utiliser l'attribut dbms sur un changeset en spécifiant la datasource voulue :

Cas Oracle : 
 &lt;changeSet author="costem_ORACLE" id="costem_ORACLE" dbms="oracle"&gt;
        &lt;createTable tableName="MCO_TEST_ORACLE"&gt;
            &lt;column name="id" type="integer"/&gt; 
            &lt;column name="test_blob" type="blob"/&gt;
            &lt;column name="test_varchar" type="varchar2(255)"/&gt;
         &lt;/createTable&gt;
   &lt;/changeSet&gt;

Cas PostgreSQL : 
 &lt;changeSet author="costem_POSTGRE" id="costem_POSTGRE" dbms="postgresql"&gt;
        &lt;createTable tableName="MCO_TEST_POSTGRE" &gt;
            &lt;column name="id" type="integer"/&gt; 
            &lt;column name="test_blob" type="bytea"/&gt;
            &lt;column name="test_varchar" type="varchar(255)"/&gt;
         &lt;/createTable&gt;
   &lt;/changeSet&gt;

On peut également penser à traiter ces changes particuliers en les incluants dans un fichier changelog nommé spécifiquement changeLog_Oracle.xml par exemple.

== Temps observés ==

Concernant la création de schéma from scratch pour archi :

Oracle : Ran in 0:01:32.892

PostgreSQL : Ran in 0:01:08.356


A voir par la suite sur les upgrades et sur la création from scratch d'efluid si différence

== Questions et travail restant ==

* Est ce qu'il y a une limite sur la taille des colonnes comme ce qu'on a connu sur Oracle ?
--&gt; pas de limite à 30 comme Oracle pour la v13. On est à plus de 100 donc on devrait être bon.

* Dans les tables CHANGELOG, on avait en oracle l'insertion de CLIENT_ID et IP_ADRESS 
  CLIENT_ID     VARCHAR2(64 BYTE) DEFAULT SYS_CONTEXT('USERENV', 'CLIENT_IDENTIFIER'),
  IP_ADDRESS    VARCHAR2(15) DEFAULT SYS_CONTEXT('USERENV', 'IP_ADDRESS')
Quel est l'équivalent PG ?
A--&gt; voir côté doc et variable SYSTEM, il y a un équivalent 

* TBS : Est ce qu'il y a encore un intêret à devoir les spécifier lors des créations de table ? La majorité partent sur le TBS par défaut. Cela ne suffit pas ?
--&gt; A rediscuter mais on garder les variables TBS. 

* Equivalent paramètre PARALLEL en PG ? Comment va être gérer la haute volumétrie ?
--&gt; A analyser

* Il faut ré ecrire GestionIDentifiant et ModificationStructure
--&gt; A analyser et rediscuter (354833 et 354694)

* Il faut revoir la moulinette de gestion des indexs 
--&gt; A analyser (354694)

* Est ce que les scripts finish sont encore tous nécessaires ?
--&gt; A analyser (360910)
* Comment sont gérées les colonnes JSON en PG ? Actuellement en oracle on doit définir un store as, en PG une simple création de colonne en spécifiant json suffit-elle ?
--&gt; Potentiellement rien de plus à faire. Juste à définir si on garde les colonnes de type json ou jsonb pour PG.

* Voir pour ajouter plus de tests dans sqlMigrator pour la partie PG -&gt; nécessite de travailler sur les jobs de validation Jenkins et d'avoir ce qu'il faut pour créer des schémas BDD PG</text>
      <sha1>8dpukidgkbny2fby7gvvn7zrp61xfde</sha1>
    </revision>
  </page>
  <page>
    <title>SonarQube</title>
    <ns>0</ns>
    <id>550362</id>
    <revision>
      <id>1084440</id>
      <parentid>1084434</parentid>
      <timestamp>2015-10-12T14:25:13Z</timestamp>
      <contributor>
        <username>Laas</username>
        <id>168</id>
      </contributor>
      <origin>1084440</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6157" sha1="leads76m9ailzhho6n0h23kyz65yvk6" xml:space="preserve">{{Modèle:Infobox Outil
 | nom              = SonarQube
 | logo             = Sonarqube.png
 | siteInternet     = http://www.sonarqube.org/
 | version          = 4.5.5
}}
==Description==
SonarQube est le nouveau nom de Sonar.
C'est un outil gratuit et open-source de mesure de la qualité du code.&lt;br/&gt;
Lien : [http://especteur/ especteur] &lt;br/&gt;
&lt;br/&gt;
Il permet, entre autres, de :
* localiser les endroits où les tests sont trop superficiels, voire inexistants;
* détecter des incompréhensions ou des étourderies, puis de nous orienter dans la bonne direction pour corriger (que ça soit de l'ordre de la gestion de la mémoire jusqu'à l'élégance du code);
* vérifier que le projet est bien délimité, en contrôlant les dépendances entre les différents packages, et que les conventions internes sont bien respectées (ex: pas d'appel à la couche "process" dans la couche "présentation");
* générer plein de chiffres et de graphes pour montrer au chef que la qualité du projet augmente.
&lt;br/&gt;
SonarQube se base sur 7 axes pour mesurer la qualité du code :
* Bugs potentiels : anomalies remontées provoquant un bug;
* Règles de codage : anomalies remontées affectant la lisibilité/maintenabilité du code;
* Tests : la couverture des tests et leur succès (plus y'en a, mieux c'est);
* Duplications : les copier-coller (moins y'en a, mieux c'est);
* Commentaires : les API publiques doivent être documentées et les commentaires "non-javadoc" sont à bannir;
* Architecture et design : les problèmes de dépendances entre packages;
* Complexité : le nombre de méthode par classe (moins y'en a mieux c'est), le nombre de ligne par méthode (le nombre parfait est ici 1);
&lt;br/&gt;
Tous ces axes sont mesurés au travers de "widgets" paramétrables sur le "dashboard" de SonarQube et par projet (efluid, ecore, suivefluid, etc.).

==Utilisation de base==
===Page d'accueil===
Sur la page d'accueil de SonarQube, on peut voir chaque projet avec un résumé en quelques chiffres.&lt;br/&gt;
Les colonnes particulièrement importantes sont celles nommées "ISSUES" (problèmes) et "UTS SUCCESS" (réussite des tests unitaires). Les colonnes "ISSUSES" permettent de suivre le nombre d'anomalies détectées et leurs tendances.&lt;br/&gt;
&lt;br/&gt;

[[Fichier:Sonar_main.PNG]]

===Consultation d'un projet===
Lors du clic sur le nom d'un projet, par exemple "efluid", on peut consulter plus en détail les métriques.&lt;br/&gt;
Sur la capture suivante, on a:
&lt;ul&gt;
&lt;li&gt;A: le "chemin de fer" ("breadcrumb" dans la doc) du projet en cours de consultation (par exemple: "efluid&gt;crm-contrat");
&lt;li&gt;B: le détail des anomalies remontées en fonction de leur "poids";
&lt;li&gt;C: "Components" permet d'accéder aux différents composants (modules, packages, classes) du projet en cours de consultation.
&lt;/ul&gt;
Le reste de la page est composé de "widgets" que l'on peut paramétrer, ajouter, déplacer...&lt;br/&gt;
&lt;br/&gt;
[[Fichier:Sonar_projet.png]]

===Anomalies===
Depuis un projet, en cliquant sur un groupe d'anomalies ou sur "Issues Drilldown" dans le menu "TOOLS" à gauche, on peut consulter les anomalies détectées dans ce projet.&lt;br/&gt;
Il est possible de les filtrer par sévérité, ou par delta de temps ("Time changes...").&lt;br/&gt;
&lt;br/&gt;
[[Fichier:Sonar_issuesdrilldown.PNG]]&lt;br/&gt;
&lt;br/&gt;

==Exemples==
Pour exemple, recherchons une anomalie bloquante dans le projet efluid:&lt;br/&gt;
&lt;ol&gt;
&lt;li&gt;Depuis le "Dashboard" (c'est la page d'accueil);
&lt;li&gt;Cliquer sur le projet "efluid"
&lt;li&gt;Sur l'écran de consultation du projet, cliquer sur "Blocker" pour les événements bloquants;&lt;br/&gt;
Ou sur "Issues Drilldown" à gauche pour consulter toutes les anomalies du projet "efluid";
&lt;li&gt;Cliquer sur le ou les fichier qui nous intéresse;
&lt;li&gt;La belle erreur avec une belle description qui nous explique pourquoi c'est pas bien;
&lt;li&gt;Corriger !
&lt;/ol&gt;
[[Fichier:Sonar_examples_1_2.PNG]]
[[Fichier:Sonar_examples_3_4.PNG]] &lt;br/&gt;
&lt;br/&gt;
En cliquant sur "Issues Drilldown" depuis le projet efluid, on aurait la totalité des anomalies, triées par jour d'apparition, sévérité, anomalie, package et fichier:&lt;br/&gt;
&lt;br/&gt;
[[Fichier:Sonar_issues_detail.png]]&lt;br/&gt;

==Anomalies==

===Sévérité===
Il y a 5 types d'anomalies différentes:&lt;br/&gt;
&lt;ul&gt;
&lt;li&gt;Blocker: pas de doute, c'est un bug;
&lt;li&gt;Critical: c'est sûrement un bug, ou alors ça ne va pas tarder;
&lt;li&gt;Major: c'est mal codé, inefficace;
&lt;li&gt;Minor: c'est inefficace, ou le code ne respecte pas les conventions;
&lt;li&gt;Info: le code ne respecte pas les conventions.
&lt;/ul&gt;
[[Fichier:Sonar_issues.PNG]]&lt;br/&gt;
&lt;br/&gt;
Sur n'importe quelle page de SonarQube, on a toujours accès au menu avec notamment les liens "Issues", "Rules" et "Quality Profiles".&lt;br/&gt;

[[Fichier:Sonar_menu.PNG]]&lt;br/&gt;
&lt;br/&gt;
===Issues===
La page "Issues" liste tous les problèmes remontés par SonarQube.&lt;br/&gt;
On peut, rechercher les anomalies suivant plusieurs filtres, et les consulter en dessous.&lt;br/&gt;
A la différence de l'approche par projet, package, etc., ici tout est en vrac. Vue la répartition en groupe de dev, cette section ne devrait pas être très utile.&lt;br/&gt;
&lt;br/&gt;
[[Fichier:Sonar_rules.png]]&lt;br/&gt;
&lt;br/&gt;
===Rules===
De la même manière, la page "Rules" liste, en vrac, toutes les anomalies actuellement détectable par SonarQube.&lt;br/&gt;
Elles ne sont pas toutes actives, heureusement, il y en a environ 3000 par défaut ! Seules celles dans les Quality Profiles "efluid" et "commun efluid" sont activées.&lt;br/&gt;
Il est possible d'en ajouter de nouvelles, personnalisées, ex: interdire l'appel de la couche "process" dans la couche "web".&lt;br/&gt;
&lt;br/&gt;
[[Fichier:Sonar_rules2.png]]&lt;br/&gt;
&lt;br/&gt;

===Quality Profiles===
Les "Quality Profiles", sont les anomalies paramétrées pour être remontées par SonarQube. Il y en a une 30aine actuellement (sur 3000 possibles donc...)&lt;br/&gt;
On peut paramétrer leur pertinence, leur sévérité, leur analyse dans tel ou tel projet.&lt;br/&gt;
Si vous voulez, par exemple, savoir quels sont les anomalies bloquantes, vous pouvez le voir ici. En cliquant sur "Blocker" vous serez redirigés vers la page "Rules" en filtrant sur la sévérité voulue.&lt;br/&gt;
&lt;br/&gt;
[[Fichier:Sonar_qualityprofiles.PNG]]&lt;br/&gt;
&lt;br/&gt;

[[Category:outil]]</text>
      <sha1>leads76m9ailzhho6n0h23kyz65yvk6</sha1>
    </revision>
  </page>
  <page>
    <title>Guide d'installation du JDK</title>
    <ns>0</ns>
    <id>865</id>
    <revision>
      <id>4069757</id>
      <parentid>4069714</parentid>
      <timestamp>2023-08-14T14:15:17Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Intégrer une nouvelle version du Jdk */</comment>
      <origin>4069757</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9238" sha1="oaqziwk9roc4f3idjscd3qbxghzwvvb" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Java Development Kit
 | logo              = javajdk.png
 | siteInternet      = http://www.oracle.com/
 | version           = {{outil.jdk.version}}
 | supportTechnique  = {{usinelogicielle|subject=eclipse}}
 | faq               = [[FAQ:JDK|FAQ JDK]]
}}

= Procédure d'installation des JDKs =

Il faut installer tous les JDK mentionnés ci-dessous pour que votre poste de développeur soit valide.

== Installation du JDK {{outil.jdk.version}} ==

Récuperez la version du jdk{{outil.jdk.version}} dans https://eartifact.efluid.uem.lan/artifactory/ext-release-local/org/openjdk/jdk/{{outil.jdk.version}}/jdk{{outil.jdk.version}}.zip (il s'agit d'un zip) puis dézippez l'archive dans le répertoire d'installation classique des jdks :
* D:\Programs\jdk\jdk{{outil.jdk.version}}

[[Fichier:DezipJDK8_01.jpg]]

N'oubliez pas de mettre vos variables d'environnements à jour en suivant la procédure [[Guide_d%27installation_du_JDK#Mise_.C3.A0_jour_de_la_variable_d.27environnement_JAVA_HOME|ici]]]

== Installation du JDK 11.0.8 ==
Récuperez la version du jdk11.0.8 dans {{F_INSTALL|path=\jdk\}}  (il s'agit d'un zip) puis dézippez l'archive dans le répertoire d'installation classique des jdks :
* D:\Programs\jdk\jdk11.0.8

== Installation du JDK {{outil.jdk.oldversion}} == 

Récuperez la version du jdk désirée dans {{F_INSTALL|path=\jdk\}} puis lancez l'installation windows classique, en spécifiant le répertoire d'installation du JDK :
* &lt;tt&gt;D:\Programs\jdk\jdk{{outil.jdk.oldversion}}&lt;/tt&gt;


[[Fichier:DezipJDK8_01.jpg]]


Il faut ensuite ajouter quelques fichiers dans votre installation du JDK :
* Copier le fichier {{F_INSTALL|path=\jdk\java.policy}}, dans le sous-répertoire de la jre : &lt;tt&gt;D:\programs\jdk\jdk{{outil.jdk.oldversion}}\jre\lib\security&lt;/tt&gt;
* Dézipper l'archive {{F_INSTALL|path=\jdk\UnlimitedJCEPolicyJDK7.zip}} dans le sous-répertoire de la jre : &lt;tt&gt;D:\programs\jdk\jdk{{outil.jdk.oldversion}}\jre\lib\security&lt;/tt&gt; remplacez les deux jars '''''local_policy.jar''''' et '''''US_export_policy.jar'''''

== Mise à jour de la variable d'environnement JAVA_HOME ==

Il faut vérifier que l'on a bien une variable d'environnement JAVA_HOME existante et que celle-ci soit présente dans le PATH. 
* Panneau de configuration &gt; Système et sécurité &gt; Système &gt; Paramètres système avancés &gt; Variables d'environnement


La variable JAVA_HOME doit être valorisée à JAVA_HOME = "D:\programs\jdk\jdk{{outil.jdk.version}}"


[[Fichier:VEnv_01.jpg]]


Dans la variable PATH, il vaut vérifier qu'on retrouve bien la chaîne '''''%JAVA_HOME%\bin''''' en tête de PATH


[[Fichier:VEnv_02.jpg]]

En mode console : 
Utilisez la commande : echo %JAVA_HOME%


[[Fichier:JAVA HOME CMD.jpeg]]

== Mise à jour de la version du JDK dans eclipse ==

* [[Mettre à jour le JDK dans eclipse]]

= Constitution du zip de JDK =

Pour constituer les zip JDK Windows et Linux il faut utiliser le job jenkins dédié : https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinelogiciellerelease/job/Ftools/job/Fjdk/job/jdk.create-new-version-zip/

Une fois un zip Linux constitué il faut mettre à jour l'image Docker socle jenkins java et mettre à jour le RPM java embedded (tout est dans etools)

Le changement de version nécessite deux changes par exemple : https://gerrit.efluid.uem.lan/q/OpenJDK%252B17

Les étapes de constitutions sont listées ci-dessous

== 11 ==
=== Windows ===
* Télécharger le JDK sur le site Adoptium (https://adoptium.net/temurin/releases?version=11) pour la bonne target (Linux, Windows etc...)
* Le dézipper dans un répertoire temporaire, qu'on zippera toutes les opérations complémentaires terminées
* Ajouter Eclipse Mission Control (tous les dossiers dans bin) dans le dossier bin (bien prendre la version pour la bonne target) https://adoptium.net/jmc
* Vérifier que la propriété crypto.policy vaut bien unlimited dans le fichier ''conf/security/java.security''

=== Linux ===
* Vérifier que la propriété securerandom.source vaut file:/dev/./urandom dans le fichier ''conf/security/java.security''
* Ajouter Eclipse Mission Control (tous les dossiers dans bin) dans le dossier bin (bien prendre la version pour la bonne target)=&gt; https://adoptium.net/jmc
* Faire attention à ce que les fichiers dans bin soient bien executables

== 1.8 ==

=== Tests réalisés sur le jdk 1.8.0_172 ===
A partir de la version 1.8.0_172 : il existe à partir de cette version un dossier policy &gt; unlimited et limited avec les deux jar.

Par défaut, le jdk pointe sur la policy unlimited pour le changer il faut aller dans jdk/jre/lib/security/java.security la properties : crypto.policy.
&lt;source lang="html4strict"&gt;
# Cryptographic Jurisdiction Policy defaults
#
# Import and export control rules on cryptographic software vary from
# country to country.  By default, the JDK provides two different sets of
# cryptographic policy files:
#
#     unlimited:  These policy files contain no restrictions on cryptographic
#                 strengths or algorithms.
#
#     limited:    These policy files contain more restricted cryptographic
#                 strengths, and are still available if your country or
#                 usage requires the traditional restrictive policy.
#
# The JDK JCE framework uses the unlimited policy files by default.
# However the user may explicitly choose a set either by defining the
# "crypto.policy" Security property or by installing valid JCE policy
# jar files into the traditional JDK installation location.  To better
# support older JDK Update releases, the "crypto.policy" property is not
# defined by default.  See below for more information.
#
# The following logic determines which policy files are used:
#
#         &lt;java-home&gt; refers to the directory where the JRE was
#         installed and may be determined using the "java.home"
#         System property.
#
# 1.  If the Security property "crypto.policy" has been defined,
#     then the following mechanism is used:
#
#     The policy files are stored as jar files in subdirectories of
# &lt;java-home&gt;/lib/security/policy.  Each directory contains a complete
# set of policy files.
#
#     The "crypto.policy" Security property controls the directory
#     selection, and thus the effective cryptographic policy.
#
# The default set of directories is:
#
#     limited | unlimited
#
# 2.  If the "crypto.policy" property is not set and the traditional
#     US_export_policy.jar and local_policy.jar files
#     (e.g. limited/unlimited) are found in the legacy
#     &lt;java-home&gt;/lib/security directory, then the rules embedded within
#     those jar files will be used. This helps preserve compatibility
# for users upgrading from an older installation.
#
# 3.  If the jar files are not present in the legacy location
#     and the "crypto.policy" Security property is not defined,
#     then the JDK will use the unlimited settings (equivalent to
#     crypto.policy=unlimited)
#
# Please see the JCA documentation for additional information on these
# files and formats.
#
# YOU ARE ADVISED TO CONSULT YOUR EXPORT/IMPORT CONTROL COUNSEL OR ATTORNEY
# TO DETERMINE THE EXACT REQUIREMENTS.
#
# Please note that the JCE for Java SE, including the JCE framework,
# cryptographic policy files, and standard JCE providers provided with
# the Java SE, have been reviewed and approved for export as mass market
# encryption item by the US Bureau of Industry and Security.
#
# Note: This property is currently used by the JDK Reference implementation.
# It is not guaranteed to be examined and used by other implementations.
#
#crypto.policy=unlimited
&lt;/source&gt;

==== test sous eclipse ==== 
Le cas de test est le suivant : Nous voulons tester qu'on pointe bien sur crypto.policy=unlimited

&lt;source lang="java"&gt;
public static void main(String[] args) {
   try {
     int maxKeyLen = Cipher.getMaxAllowedKeyLength("AES");
     System.out.println(maxKeyLen);
   } catch (Exception e) {
     System.out.println("Sad world :(");
   }
 }
&lt;/source&gt;

résultat console : en unlimited : 2147483647 , limited : 128

= Intégrer une nouvelle version du Jdk dans l'usine logicielle =
[[Guide de migration du JDK]]

* générer le tar.gz dans artifactory à l'aide du job https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinelogiciellerelease/job/Ftools/job/Fjdk/job/jdk.create-new-version-zip
* mettre à jour les images : https://gerrit.efluid.uem.lan/c/etools/+/247489
* mettre à jour le pom parent : https://gerrit.efluid.uem.lan/c/efluidUtilsPom/+/247490
* générer le nouveau rpm : https://gerrit.efluid.uem.lan/c/etools/+/274670 + https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinelogiciellerelease/job/Ftools/job/Fetools/job/etools-rpm-java.release/
* mettre à jour les images embedded et batch : https://gerrit.efluid.uem.lan/c/scriptInstalleur/+/260020
* mettre à jour le wiki : https://wikefluid.efluid.uem.lan/index.php/Mod%C3%A8le:Outil.jdk.version

= Bugs répertorié =
== Problème de latence dans les jobs ==

* Problème de lenteur jobs Jenkins : Dans chaque répertoire /opt/jdk1.*/jre/lib/security/java.security
** Modifier la ligne : securerandom.source=file:/dev/urandom --&gt; Par : securerandom.source=file:/dev'''/./'''urandom</text>
      <sha1>oaqziwk9roc4f3idjscd3qbxghzwvvb</sha1>
    </revision>
  </page>
  <page>
    <title>Guide d'installation de tomcat</title>
    <ns>0</ns>
    <id>600478</id>
    <revision>
      <id>4068189</id>
      <parentid>4065789</parentid>
      <timestamp>2023-01-16T16:08:30Z</timestamp>
      <contributor>
        <username>Poutiss</username>
        <id>171</id>
      </contributor>
      <origin>4068189</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="832" sha1="pwwh1xrwbomevcpjd55cvv4yexdzhve" xml:space="preserve">[[Category:outil]]
[[Category:tomcat]]

= Prérequis =

Tomcat nécessite [[installation JDK|l’installation d’un JDK]].

= Installation de Tomcat via l'archive classique =
== Récupération de l'archive ==

Le fichier Zip permettant l’installation de [[Tomcat]] se trouve à l'adresse suivante : https://archive.apache.org/dist/tomcat/tomcat-10/v{{outil.tomcat.version}}/bin/apache-tomcat-{{outil.tomcat.version}}.zip

== Installation de Tomcat ==
=== Dézippage de l'archive ===

* Dé-zippez le fichier d’archive zip dans le répertoire « D:\Programs\tomcat ». Le sous-répertoire « apache-tomcat-X.X.X » est créé dans le dossier « D:\Programs\tomcat »

= Paramétrage de l'installation =

* Suivez [[Tomcat#Parametrage_du_serveur_tomcat_pour_les_JSP|cette documentation]] pour paramétrer le comportement des JSP.</text>
      <sha1>pwwh1xrwbomevcpjd55cvv4yexdzhve</sha1>
    </revision>
  </page>
  <page>
    <title>ArtifactoryRules</title>
    <ns>0</ns>
    <id>603892</id>
    <revision>
      <id>4069617</id>
      <parentid>1305408</parentid>
      <timestamp>2023-07-17T07:20:06Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Documentation */</comment>
      <origin>4069617</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="300" sha1="26dlk59xpro999lfhv48p0zl2x9nhe0" xml:space="preserve">[[Category:outil]]

{{Modèle:Infobox Outil
 | nom               = artifactory-rules
 | version           = {{outil.artifactory-rules.version}}
 | supportTechnique  = {{usinelogicielle|subject=artifactory-rules}}
}}

= Documentation =
https://wikefluid.efluid.uem.lan/docInstalleur/artifactory-rules/</text>
      <sha1>26dlk59xpro999lfhv48p0zl2x9nhe0</sha1>
    </revision>
  </page>
  <page>
    <title>JMH</title>
    <ns>0</ns>
    <id>643507</id>
    <revision>
      <id>1616877</id>
      <timestamp>2016-05-23T07:34:21Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <comment>Page créée avec « {{Modèle:Infobox Outil  | nom               = JMH  | siteInternet      = http://openjdk.java.net/projects/code-tools/jmh/  | faq               = [[FAQ:JMH|FAQ JMH]] }} »</comment>
      <origin>1616877</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="168" sha1="jn8a3sx983zw98nwuz0hrh0kfqrn126" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = JMH
 | siteInternet      = http://openjdk.java.net/projects/code-tools/jmh/
 | faq               = [[FAQ:JMH|FAQ JMH]]
}}</text>
      <sha1>jn8a3sx983zw98nwuz0hrh0kfqrn126</sha1>
    </revision>
  </page>
  <page>
    <title>Conventions SQLMigrator</title>
    <ns>0</ns>
    <id>647819</id>
    <revision>
      <id>4069709</id>
      <parentid>4069524</parentid>
      <timestamp>2023-08-01T11:52:11Z</timestamp>
      <contributor>
        <username>Pierrer</username>
        <id>435</id>
      </contributor>
      <comment>/* Liste relecteurs SQL */</comment>
      <origin>4069709</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="36327" sha1="nmwmiu4wtlgxzeo57e4trxghykvz7qf" xml:space="preserve">[[Category:outil]]

{{Modèle:Infobox Outil
 | nom               = sqlMigrator
 | version           = {{outil.sqlMigrator.version}}
 | supportTechnique  = {{usinelogicielle|subject=sqlMigrator}}
}}

= Présentation SqlMigrator =

Vous trouverez la dernière présentation sqlmigrator ainsi que le ppt associé ici : https://wikefluid.efluid.uem.lan/partage/sqlmigrator/ 
= Liste relecteurs SQL =

* Gabriel Barthelemy (Relance/contentieux/cac)
* Brice Castagna (Contrat)
* Anthony Bainville (Référentiel)
* Victor Cholley-Barroyer (Courbe/enercom/échange)
* Marie Coste (UL)
* Carole Favier  (Intervention)
* Roderick Pierre (Consommation)
* Stéphane Poirot (Consommation)
* Vincent Poutissou (Composants)
* Mickael Storck (eot / conso / relève)
* Didier GRZEJSZCZAK (eot / conso / relève / Intervention)
* Heloise Turquais (offre)

= Documentation sqlMigrator =

Pour rappel la plupart des cas sont décrits dans : [http://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/liquibase.html# Documentation sqlMigrator]

= Structure du changeSet =
'''Conditions à vérifier : '''
* Présence des attributs obligatoires avec la bonne convention d'écriture décrite ci-dessous :
** ''[obligatoire]'' '''author''' : auteur du changeSet : il faut mettre son login défini dans l’annuaire LDAP (c’est normalement la valeur par défaut renseignée par map4J).
** ''[obligatoire]'' '''id''' : suivefluid-&lt;Numéro d'événement suivefluid&gt;-dml|ddl
** ''[obligatoire]'' '''labels''' : &lt;id ChangeSet&gt;, v12|v13, dml|ddl (les labels n'influe pas sur le checksum)
** ''[optionnel]'' '''context''' : Chaque contexte doit être séparé d'une virgule et écrit en minuscule. Un contexte peut être écrit edfsei_* pour définir tous les sites edfsei [http://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/liquibase.html#contexts Liste des contextes existants]

Attention : les attributs context et labels sont sensible à l'orthographe. Il s'agit donc bien de '''context''' et '''labels'''

* Un ChangeSet déjà livré ne peut en aucun cas être modifié. En effet, chaque ChangeSet sql migrator se voit affecté un hash calculé à partir de 3 éléments :
** L’ID du ChangeSet 
** Le chemin absolu du ChangeSet 
** Le contenu du ChangeSet (y compris le script sql lié si présent)

A chaque exécution de sql migrator, pour chaque ID de ChangeSet donné, le hash est recalculé pour vérification : si l’on modifie le chemin et/ou le contenu du script sans en modifier l’ID, un hash différent va être calculé et cela va faire planter sql migrator.

Dans certains cas, on peut modifier un ChangeSet déjà livré (par exemple une coquille dans le fichier sql) mais pour cela il faut donc s'assurer de '''changer le change ID''' tout en s'assurant aussi que cela '''ne posera pas de problème à l'exécution''' : en effet, si le change '''n'est pas rejouable''' (create...), il y aura des erreurs (doublons de tables, etc...). C'est pour cela que cette tolérance '''ne doit être appliquée qu'aux données (dml) ou aux changes liés aux vues requêteur''' (car chaque script commence par la clause CREATE OR REPLACE : c'est donc rejouable sans problème sql).

* La mise à jour des ddl (CREATE/DROP) doit être livré systématiquement à chaque fois qu'on ajoute un upgrade ddl
* '''Une modification ddl ne doit jamais comporter de contexte, c'est systématiquement du produit'''
* '''Il faut privilégier la livraison d'un fichier dans le cas de trop gros blocs SQL.'''
* '''Dans le cas de plusieurs modifications de structure dans un même change GERRIT, il faut livrer un changeSet sqlMigrator par modification. '''

= Utilisation du PARALLEL dans Oracle =

Pour rappel, une convention s'applique sur l'utilisation de la variable PARALLEL. Cette dernière ne doit être utilisée que pour Oracle.
En fonction de l'utilisation dans un .sql ou un .xml, sa définition diffère : https://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/sqlmigrator/conventions_vocabulaire.html

Evt en cours : 401934

Cet evt a été créé afin d'automatiser une règle de relecture. En effet suite à des anomalies ouvertes par Enedis, nous nous sommes rendus compte qu'ils surchargeait la valeur de ce paramètre. Lors de nos réinits, les montées de versions sont donc KO.
Afin d'éviter ce problème, lors de l'utilisation de la variable PARALLEL dans un script, il est demandé d'ajouter la balise &lt;validCheckSum&gt;ANY&lt;/validCheckSum&gt; qui permet de ne pas rencontrer de soucis.


= Cas de régularisation =
Dans le cas d'une régularisation de colonne ou d'une table, le changeset doit obligatoirement comporter des pré conditions. [http://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/liquibase.html#pre_conditions cf Documentation Pre conditions]

= Correspondance entre les types liquibase, Oracle et PostgreSQL =

{| class="wikitable"
|-
! Liquibase !! PostgreSQL !! Oracle
|-
| boolean || BOOLEAN || NUMBER(1)
|-
| tinyint || SMALLINT || NUMBER(3)
|-
| int || INT || INTEGER
|-
| mediumint || MEDIUMINT || MEDIUMINT
|-
| bigint || BIGINT || NUMBER(38, 0)
|-
| float || FLOAT || FLOAT
|-
| double || DOUBLE PRECISION || FLOAT(24)
|-
| decimal || DECIMAL || DECIMAL
|-
| number || numeric || NUMBER
|-
| blob || BYTEA || BLOB
|-
| function || FUNCTION || FUNCTION
|-
| UNKNOWN || UNKNOWN || UNKNOWN
|-
| datetime || TIMESTAMP WITHOUT TIME ZONE || TIMESTAMP
|-
| time || TIME WITHOUT TIME ZONE || DATE
|-
| timestamp || TIMESTAMP WITHOUT TIME ZONE || TIMESTAMP
|-
| date || date || date
|-
| char || CHAR || CHAR
|-
| varchar || VARCHAR || VARCHAR2
|-
| nchar || NCHAR || NCHAR
|-
| nvarchar || VARCHAR || NVARCHAR2
|-
| clob || TEXT || CLOB
|-
| currency || DECIMAL || NUMBER(15, 2)
|-
| uuid || UUID || RAW(16)
|}

= Modifications de schema =
Cette partie présente les modifications de schéma autorisées et la manière dont il faut les livrer.
Le leitmotiv justifiant l'existance de ces procédures de livraison est le suivant: La version '''N du code source''' d'efluid doit pouvoir fonctionner sur une version '''N+1 de la base de données''' migrée à l'aide de SQLMigrator. Ceci assure une rétro-compatibilité entre application et base de données et permet une montée de version au fil de l'eau (d'abord la base, puis les différents serveurs d'application).

Peu importe le cas, s'il y une partie "initialisation" dans un fichier .ddl et une partie "upgrade" dans un fichier changelog.xml, il faut veiller à ce que l'orthographe des objets traités soit identique entre les 2 fichier.

== Cas de suppression ==

* Cas 1: Il n'est fait aucune mention de ma colonne/table dans le code source de mon application en version N.  
* Solution: 
** Je peux livrer mon script de suppression de colonne/table en version N

* Cas 2: Des références à ma colonne/table existent encore dans le code source de l'application en version N
* Solution: 
** Je supprime les références à cette colonne/table dans le code source de l'application. 
** Je livre ces modifications de code en version N. 
** Je livre le script de suppression de colonne/table en version N+1, pour assurer une compatibilité entre la version N de mon code source et la version N+1 de ma base de données.

Exception : si la colonne/table est supprimée dans la même version où elle a été créée, cette procédure n'est pas nécessaire : on peut effectuer la suppression dans la version N.

== Création d'une table ==

'''Conditions à vérifier : '''
* Vérifier l'utilisation de tablespaces
* Vérifier qu'un drop et un create de ddl associé à bien été livré avec l'upgrade
* Dans le cas d'une création de table temporaire, le tablespace ne doit pas être renseigné.
* Dans le cas d'une création de table batchs (BATCH_*), le tablespace doit être renseigné et pointer le tablespace dédié aux tables batchs.
* Dans le cas d'une création de table batchs (BATCH_*), elle doit être en mode NOLOGGING.
&lt;pre&gt;
create table MA_TABLE_BATCH(
COL1 VARCHAR2(10),
COL2 DATE,
...
COLN VARCHAR2(10)
) NOLOGGING tablespace &amp;&amp;TBS_BATCH_DATA.;
&lt;/pre&gt;

* Dans le cas d'une création de table batchs (BATCH_*), créer un index composite sur PROGRAM_ID,TECH_LOT_ID, rajouter CODE_BATCH à l'index si plusieurs batchs utilisent la même table.

La création d'une table peut être faite comme suit : 
* Fichier sql comportant une création de table standard.

Pas besoin d'alimenter le fichier DescriptionIndex.csv : les créations d'index sont présentes dans le DDL ou dans le script d'upgrade.

== Renommage d'une table ==

'''Conditions à vérifier : '''

Le renommage d'une table peut être fait de deux manières : 
* Fichier sql comportant un ddl de renommage de la table standard (&lt;tt&gt;ALTER TABLE &lt;OLDTABLE&gt; RENAME TO &lt;NEWTABLE&gt;;&lt;/tt&gt;).
* Manière liquibase avec des balises &lt;renameTable&gt; [http://www.liquibase.org/documentation/changes/rename_table.html Documentation]
Dans les 2 cas il faudra livrer aussi un script de renommage de la contrainte et de l'index de clé primaire à exécuter après le renommage de la table:
* &lt;tt&gt;ALTER TABLE &lt;NEWTABLE&gt; RENAME CONSTRAINT PK_&lt;OLDTABLE&gt; TO PK_&lt;NEWTABLE&gt;;&lt;/tt&gt;
* &lt;tt&gt;ALTER INDEX PK_&lt;OLDTABLE&gt; rename to PK_&lt;NEWTABLE&gt;;&lt;/tt&gt;
La nouvelle PK doit aussi être mise à jour dans le ddl de création de la table.

Et mettre à jour le nom de la table pour les index (hors PK) dans le fichier de référentiel des index DescriptionIndex.csv.

Vérifiez l'existence de dml d'init (de test ou non).

== Suppression d'une table ==

'''Conditions à vérifier : ''' 
* Vérifier la présence de pré conditions
* Vérifier que la suppression se fait dans le bon dossier (cf Cas de suppression au dessus)

La suppression d'une table peut être fait de deux manières : 
* Fichier sql comportant un drop de table standard avec purge (&lt;tt&gt;DROP TABLE XXXX PURGE ;&lt;/tt&gt;).
* Manière liquibase avec des balises &lt;dropTable&gt; [http://www.liquibase.org/documentation/changes/drop_table.html Documentation]

Supprimer Les lignes contenant le table droppée dans le fichier de référentiel des index (DescriptionIndex.csv).

Vérifier l'existence de dml d'init (de test ou non).

== Ajout d'une colonne ==

'''Conditions à vérifier : '''

Si la colonne créée est une colonne XXX_ID (ou SOURCE/DEST dans le cas des tables de lien), vérifier qu'un index associé a été ajouté dans le fichier DescriptionIndex.csv, ''sauf'' si l'ajout se fait sur une table batch.

La création d'une colonne peut être fait de deux manières : 
* Fichier sql comportant un alter table standard.
* Manière liquibase avec des balises &lt;addColumn&gt; [http://www.liquibase.org/documentation/changes/add_column.html Documentation]
** Lors d'un ajout de colonne, si cette dernière possède une defaultValue, précisez la defaultValueNumeric (ou default prévue pour votre champ) mais ne pas préciser en plus l'attribut value. Ce dernier va ralentir la montée de version et n'apporte pas quelque chose de supplémentaire
** A noter que si l'attribut "type" de la balise "column" vaut "varchar" et non "varchar'''2'''" (la documentation Oracle préconisant de ne ''pas'' utiliser varchar et de lui préférer varchar'''2'''), liquibase réalise la conversion automatiquement. Cette dernière n'est cependant mentionnée nulle part dans la documentation, à surveiller donc.

Vérifier l'existence de dml d'init (de test ou non).

== Modification de structure d'une colonne ==
=== Augmentation de la taille d'une colonne ===

'''Conditions à vérifier : '''
* Vérifier qu'il n'existe pas d'index fonction ou bitmap de jointure sur la colonne dans le référentiel des index, le cas échéant :
: - Passer par un script SQL
:: 1) Supprimer l'index fonction/bitmap de jointure : DROP INDEX NOM_INDEX
:: 2) Modifier la colonne: ALTER TABLE MODIFY...
:: 3) Recréer l'index fonction/bitmap de jointure

Dans les autres cas, l'augmentation de la taille d'une colonne peut être faite de deux manières : 
* Fichier sql comportant un alter table modify standard. 
* Manière liquibase avec des balises modifyDataType/newDataType [http://www.liquibase.org/documentation/changes/modify_data_type.html Documentation]

=== Renommage d'une colonne ===

'''Conditions à vérifier : '''
* Vérifier qu'il n'existe pas d'index dans le fichier DescriptionIndex.csv référençant la colonne qui va être renommée, auquel cas ajouter une version de fin à l'ancien index et recréer un nouvel index.

Le renommage d'une colonne doit se faire de la façon suivante : 
* Ajout d'une colonne avec le nouveau nom dans la version majeur N.
* Suppression de le la colonne avec l'ancien nom dans la version majeur N+1.

* Il est conseillé de migrer les données de l'ancienne colonne vers la nouvelle juste après avoir créé la colonne dans le fichier d'upgrade ddl (exception où l'on peut mettre du dml dans du ddl) : en effet, les ddl étant tous joués séquentiellement (dans leur ordre d'inclusion dans le changeLog parent), puis la même chose avec tous les dml, si on code la migration dans la partie dml, un possible autre script dml affectant la nouvelle colonne pourrait livré par la suite mais pourrait être inclus avant notre script de migration, corrompant alors les données (puisque notre script de migration, s'il passe après, va écraser les valeurs).

Le renommage de colonne dans une même version majeur pose des problèmes au niveau des bases de référence ainsi que des modifications de vue.

Vérifier l'existence de dml d'init (de test ou non).

=== Modification du type d'une colonne ===
La modification de type d'une colonne doit faire l'objet d'une demande au pôle études et performance car nécessiterait une gestion de conversion des données déjà présentes dans la colonne

'''Conditions à vérifier : '''

Dans l'état actuel des choses le processus suivant ne permet pas d'assurer une rétrocompatibilité code/BDD

La modification de type se fait par livraison d'un seul script SQL à livrer dans le répertoire &lt;tt&gt;ddl/upgrade/&lt;versionN&gt;/...&lt;/tt&gt; (pour ce cas spécifique le script SQL contient à la fois des DDL et DML)

Ce script contiendra les étapes suivantes :
* Création d'une colonne &lt;tt&gt;&lt;nomColonneAMigrer&gt;_2&lt;/tt&gt; du nouveau type
* Recopie des données de la colonne d'origine &lt;tt&gt;&lt;nomColonneAMigrer&gt;&lt;/tt&gt; vers la nouvelle colonne &lt;tt&gt;&lt;nomColonneAMigrer&gt;_2&lt;/tt&gt; (utiliser les mécanismes PARALLEL/NOLOGGING pour accélérer la mise à jour des données)
* Suppression de la colonne d'origine &lt;tt&gt;&lt;nomColonneAMigrer&gt;&lt;/tt&gt;
* Renommage de la colonne &lt;tt&gt;&lt;nomColonneAMigrer&gt;_2&lt;/tt&gt; vers &lt;tt&gt;&lt;nomColonneAMigrer&gt;&lt;/tt&gt;

Exemple :
&lt;source lang='sql'&gt;
alter table tmodeleobjetmetier  add TYPEESPACE_NEW NUMBER(2);
update tmodeleobjetmetier set TYPEESPACE_NEW = TYPEESPACE;
commit;
alter table tmodeleobjetmetier drop column TYPEESPACE;
alter table tmodeleobjetmetier rename column TYPEESPACE_NEW to TYPEESPACE;
&lt;/source&gt;

Ou via SQLMigrator si faible volumétrie et petite modification structurelle comme augmenter la taille :

Exemple :
&lt;source lang='xml'&gt;
 &lt;changeSet author="bouthino" id="suivefluid-350700-ddl" labels="suivefluid-360645-ddl, v15, ddl" objectQuotingStrategy="LEGACY"&gt;
  &lt;modifyDataType columnName="TYPEESPACE" newDataType="NUMBER(2)" tableName="TMODELEOBJETMETIER"/&gt;
 &lt;/changeSet&gt;
&lt;/source&gt;

Les index éventuels supprimés seront automatiquement reconstruits par le process de mise à jour des index.

Vérifier l'existence de dml d'init (de test ou non).

== Suppression d'une colonne==

'''Conditions à vérifier : '''
* Vérifier la présence de pré conditions
* Vérifier que la suppression se fait dans le bon dossier (cf Cas de suppression au dessus)
* '''En v14 uniquement''', vérifier que l'appel à la reconstruction des indexs avant le drop est bien faite : &lt;tt&gt;ModificationStructure.rebuildIndexesBeforeDrop('TABLENAME','COLUMNNAME')&lt;/tt&gt;
** Attention ici : comme cette fonction est spécifique oracle, il faut ajouter un attribut "dbms=oracle" sur le tag &lt;sql&gt; qui inclut cette clause.
** '''A partir de la v15, ne plus utiliser cette fonction'''
** Plus d'infos sur la migration vers postgresql : http://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/migration_postgre.html#compatiblite

La suppression d'une colonne peut être fait de deux manières : 
* Fichier sql comportant un drop de colonne standard.
* Manière liquibase avec des balises &lt;dropColumn&gt;

Vérifier l'existence de dml d'init (de test ou non).

== Séquence et Vue ==
=== Création ===

'''Conditions à vérifier : '''
* Pour une vue, vérifier la présence d'un "create or replace"

La création d'une séquence ou d'une vue peut être fait de deux manières : 
* Fichier sql comportant un create standard.
* Manière liquibase avec des balises &lt;addSequence&gt; ou &lt;addView&gt; [http://www.liquibase.org/documentation/changes/add_sequence.html Documentation séquence]
[http://www.liquibase.org/documentation/changes/add_view.html Documentation vue]
* Le cache des séquences doit être positionné à 20

Comme pour toute création/modification de structure : '''pas de context'''. Quand bien même les séquences véhiculent des informations concernant des clients en particuliers (typiquement les séquences de numérotation de factures), ne pas avoir les séquences de créées chez tout le monde de la même façon peut poser des soucis lorsqu'on veut diagnostiquer des anomalies de montée de version sur des BDD issues d'un client différent de celui à l'origine de l'anomalie (c'est déjà arrivé par le passé). De plus, aucune directive officielle concernant le caractère sensible de ces séquences n'a été donnée, en conséquence, il vaut mieux observer un principe de précaution et créer les séquences de la même manière chez tous les clients.

=== Suppression ===

'''Conditions à vérifier : '''
* Vérifier la présence de pré conditions
* Vérifier que la suppression se fait dans le bon dossier (cf Cas de suppression au dessus)

La suppression d'une séquence ou d'une vue peut être fait de deux manières : 
* Fichier sql comportant un drop de séquence/vue standard.
* Manière liquibase avec des balises &lt;dropSequence&gt; ou &lt;dropView&gt; [http://www.liquibase.org/documentation/changes/drop_sequence.html Documentation séquence]
[http://www.liquibase.org/documentation/changes/drop_viewe.html Documentation vue]

== Procédure PL/SQL == 

'''Conditions à vérifier : '''
* Les caractères spéciaux &amp;, &lt;, &gt; doivent être remplacés par leurs char correspondant. [http://www.asciitable.com/index/asciifull.gif]
* Dans le cas d'une procédure complexe, le script doit être livré dans des blocs &lt;createProcedure&gt; afin que sqlMigrator se joue correctement [http://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/liquibase.html#procedure_complexe Procédure complexe] '''

== Suivefluid/Suiveclient == 

'''Cas des synonyms et des grant'''
Lors de la livraison de synonyms ou de grant, il faut :
* Inclure un nouveau changeset qui inclut un fichier SQL uniquement !!! Les fichiers xml ne fonctionnent pas. Les balises sql non plus !
* Créer un fichier sql avec uniquement les create or replace de synonyms et de grant avec les bonnes variables.

== Index == 
=== Création d'un index depuis la V15 ===

Le fichier DescriptionIndex.csv n'existe plus. Il a été migré et remplacé par un nouveau fichier contenant directement les "changeset" de création des index. Il s'agit donc d'un fichier xml contenant les commandes liquibase de création d'index.
Le nouveau fichier trouve dans le dossier "ddl/upgrade/NUMERO_VERSION_PRODUIT/changelog/index". Dans le fichier, les changeset sont concaténés.

Ajouter le code suivant pour créer un index : 
&lt;source lang='xml'&gt;
&lt;changeSet author="XXX" labels="NOM_INDEX" id="CREATE_NOM_INDEX"&gt;
  &lt;preConditions onFail="MARK_RAN"&gt;
    &lt;not&gt;
      &lt;indexExists indexName="NOM_INDEX"/&gt;
    &lt;/not&gt;
  &lt;/preConditions&gt;
  &lt;createIndex indexName="NOM_INDEX" tableName="Nom_TABLE" tablespace="${tablespace.index}"&gt;
    &lt;column name="NOM_COLONNE_A_INDEXER"/&gt;
  &lt;/createIndex&gt;
&lt;/changeSet&gt;
&lt;/source&gt;

Pour plus de détails, voir la documentation officielle de liquibase : https://docs.liquibase.com/change-types/create-index.html

Il faut aussi ajouter les instructions SQL de création d'index pour chaque base de données : Oracle, et PG SQL.
Se rendre dans les fichiers :
* "sql/database/efluid/ddl/create/oracle/04_index/index.sql"
* "sql/database/efluid/ddl/create/postgresql/04_index/index.sql"

Exemple : 
&lt;source lang='sql'&gt;
CREATE INDEX NOM_INDEX ON NOM_TABLE(NOM_COLONNE) TABLESPACE &amp;&amp;TBS_INDEX. ; 
&lt;/source&gt;

-----------------------------------------------------------------------------------------------------------------------
La section ci-dessous concerne la manière de faire avant la V15

Pour raison de performances, il est demandé aux développeurs d'ajouter un index sur une colonne d'une table servant par exemple de clef étrangère. Ces colonnes ont un nom de la forme XXXXX_ID. Le pôle performance peut aussi demander l'ajout d'index sur d'autres colonnes d'une table. Il faut donc faire bien attention à ajouter ou supprimer ces index à chaque fois qu'on fait une modification dans la structure d'une table. Les cas d'utilisations les plus rencontrés sont : l'ajout de colonne, la modification de colonne, la suppression de colonne, la suppression de table...

'''Attention''' : dans certains cas il faut se poser la question si l'index est déjà présent dans un autre produit. Ce dernier est parfois une brique applicative utilisée par plusieurs autres produits. Par exemple, Il faut vérifier la présence d'un index dans Ecore avant de l'ajouter dans Efluid. Et s'il n'existe pas dans cet autre produit, alors il faut se demander s'il ne devrait pas y être. Puis en terminant le raisonnement par la création de l'index dans le produit final concerné (par exemple Efluid). Ceci est important à prendre en compte aussi dans le cas de rattrapage en masse des index à ajouter ou à migrer de produit.



La mise à jour des index se fait dans un fichier portant le nom : DescriptionIndex.csv. On ne supprime pas de ligne dans le fichier. On ne fait que en ajouter ou en modifier.
Il existe un fichier par produit (Ecore, Efluid, etc...). Le fichier se trouve dans le dossier ddl/index.  Ex : sql/database/efluid/ddl/index/DescriptionIndex.csv

Le fichier CSV comporte 7 colonnes :

'''Evénement''' : le numéro d'événement Suivefluid portant la création/modification de l'index.

'''Nom de l'index''' : le nom de l'index limité à 30 caractères. Par convention le nom commence toujours par IDX_XXXXXXXXX.

'''Table''' : le nom de la table concernée. Même limitation du nombre de caractères.

'''Colonne(s)''' : le nom de la colonne de la table concernée. Même limitation du nombre de caractères. Dans des cas plus rares, on peut être amené à créer un index sur un couple de colonnes. Dans ce cas, chaque nom de colonne doit être séparé par une virgule. On rencontre ce genre de cas parfois sur les tables servant de liens. On place donc un index sur le couple : DEST, SOURCE. On rencontre aussi ce genre de cas pour optimiser les batchs (voir exemple ligne 2).

'''Tablespace''' : le tablespace concerné. Il y en a deux pour ainsi différencier le domaine d'utilisation (batch et non batch) :  ${tablespace.batch.index}, ${tablespace.index}.

'''Version d'ajout''' : la version du produit dans lequel l'index est créé.

'''Version de suppression''' : la version du produit dans lequel l'index est supprimé. Attention dans le cas d'une suppression de colonne, il faut bien mettre la version dans laquelle la colonne de la table est supprimée du code et non pas mettre la version N+1. Exemple : Suppression d'une colonne en 14.17. Alors, je mets 14.17.100 dans la dernière colonne du fichier CSV tout en appliquant les mêmes autres consignes concernant la suppression de la colonne de la table (script de suppression placé en V15).

{| class="wikitable"
|-
! événement !! Nom de l'index !! Table !! Colonne(s) !! Tablespace !! version d'ajout !! Version de suppression
|-
| 152611 || IDX_TELTPOPRELEVE_LOT || TELEMENTDEPOPULATIONRELEVE || LOT_ID || ${tablespace.index} || 12.15.100 || 13.1.100
|-
| 234178 || IDX_BTCH_IMPFICH_PROG_COD_LOT || BATCH_IMPORT_FICHIER || PROGRAM_ID,CODE_BATCH,TECH_LOT_ID || ${tablespace.batch.index} || 13.13.100 ||
|}

= Cas de suppression d'un changeSet =

Un développeur peut être amené à faire un revert ou une suppression d'un changeSet livré.
Dans ce cas le développeur doit suivre la procédure suivante : 
* Faire un revert du commit dans lequel se trouve le script à retirer
* Se placer sur le change gerrit afin de le modifier et d'ajouter un script (sous format changeSet) faisant les modifications inverses 
* Obtenir un +1 d'un relecteur SQL et de l'usine logicielle
* Merger le change

A la fin de cette procédure, la base doit avoir repris un état comme si aucun script n'avait été passé.

Plus d'informations : http://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/liquibase.html#cas_revert

= Scripts impactant des tables hautes volumétries =
Les tables hautes volumétries sont listées ici : http://wikefluid.uem.lan/index.php/Scripts_migration_haute_volum%C3%A9trie#Liste_des_tables.

Si un script effectue des actions sur une de ces tables, alors le développeur propriétaire du change doit mesurer le temps d'exécution des actions en question sur des bases UEM, ES et Enedis et en mesurer le temps d'exécution. Si ce dernier dépasse les "quelques secondes" (à l'appréciation du relecteur SQL), alors le développeur propriétaire du change doit obtenir la validation de l'équipe études et performances, puis en notifier le relecteur SQL une fois que c'est fait.

= Vérification des scripts d'habilitations =

* Lorsqu'un nouveau risque est ajouté dans l'archi, il est créé avec un code dans HermesCodesRisques.java
* C'est à partir de ce code que l'on construit les habilitations en BDD :
** Ajout du risque dans THERMESRISQUE en utilisant ce code pour la colonne RISKDESCRIPTOR
** Ajout du/des privilèges liés à ce risque dans THERMESPRIVILEGE
** Ce privilège est associé à un groupe d'utilisateurs, en l'affectant à un profil via la table PROFILHABILITATION_LISTOFPRI7D

= Points d'attention =
Voici une liste de pratiques qui sont habituellement réalisées dans le cadre de changes sql, bien qu'aucune règle spécifique n'existe

* Si un script d'upgrade doit être livré sur plusieurs branches (par exemple, maintenance_14 et develop), il faut toujours commencer par développer sur la version la plus ancienne puis cherry-pick vers les branches les plus récentes. En effet, le dossier dans lequel est placé le script (dans ce cas, /14/) doit être le même partout sous peine de voir sql migrator planter (le chemin absolu du change set est l'un des trois éléments qui entrent en jeu lors du calcul du checksum, pour un ID de changeset donné).

* Dans le cas d'insertions dans les fichiers dml, on peut faire précéder ces insertions du delete correspondant, cela permet ainsi rendre le script rejouable et plus facile à corriger dans le cas d'un script complexe. Cela permet aussi de moins polluer les fichiers dml dans le cas d'une correction (au lieu de créer un nouveau changeSet qui va faire un update, on va juste modifier le script existant et changer l'ID du changeSet en lien).

* Le commit à la fin d'un fichier sql de données n'est normalement plus obligatoire (sql migrator fait des commit après chaque changeSet) mais reste conseillé car, dans le cas de gros scripts PL/SQL, il devient obligatoire entre certains blocs pour une question de perf. Le mettre dans tous les cas à la fin peut donc être une bonne chose afin de s'en souvenir.

* D'une manière générale, il faut toujours renseigner les acteur et date modification lorsque l'on fait un update. Cependant, si l'update concerne une colonne purement technique (par exemple ROLE si l'on veut passer d'un rôle court à un rôle long et inversement), on peut s'en passer. En effet, cela ne correspond pas une vraie modification de l'objet et l'on pourrait perdre l'acteur/la date de la dernière vraie modification de l'objet.

* Il faut éviter au maximum de mettre des contraintes sur les colonnes des tables (par exemple, NOT NULL ou DEFAULT 0). Cela fait suite à une décision prise il y a longtemps qui a pour but d'éviter le plantages lors de l'insertion de données en masse dans les tables. Il est donc demandé de gérer toutes les contraintes niveau code.

* Dans les &lt;changeSet&gt; des changeLog.xml il n'est pas nécessaire d'ajouter l'instruction ''objectQuotingStrategy="LEGACY"'' car il s'agit de la valeur par défaut.

* Veiller à ne pas oublier les attributs ''onFail'' et ''onFailMessage'' lors de l'utilisation de la balise &lt;preConditions&gt;. En effet, sql migrator plante si la pré-condition n'est pas vérifiée et qu'aucun comportement n'a été prévu dans le onFail. Par défaut, on renseigne onFail="MARK_RAN" (= considéré comme exécuté).

* Lorsqu'il faut reporter la création d'un index dans DescriptionIndex.csv d'une branche plus ancienne vers une branche plus récente, il faut conserver l'info concernant la version d'ajout provenant de la branche de maintenance (donc la plus ancienne). On applique donc la règle simple du cherry-pick de la version la plus ancienne vers la version la plus récente, sans rien changer à la ligne d'index créée.

* Dans le cas du requêteur, on peut supprimer un changeSet existant et le remplacer par un autre portant sur la vue que l'on modifie (bien évidemment toujours en changeant le change ID), car chaque fichier sql contient un CREATE OR REPLACE, ce qui garantit qu'aucun problème de table déjà existante ne sera rencontré lors du lancement de sql migrator. Le fichier sql en lien peut ainsi être réutilisé (éventuellement renommé si son nom contient le numéro de l'événement précédent). Le but est de ne pas avoir toute une flopée de changeSet qui font des CREATE OR REPLACE sur une même vue (perte de perf et de lisibilité dans les changeLog). On peut ainsi résumer : pour une vue requêteur, un seul fichier d'upgrade lié à un seul fichier sql, à remplacer à chaque fois qu'une modification doit être faite sur cette vue.  Un exemple ici : https://gerrit.efluid.uem.lan/c/efluid/+/173111

== Cas de la migration Oracle vers PostgreSql ==
* Les répertoires /oracle/ et /postgresql/ sont à présent disponibles pour archi, ecore, efluid et efluidNet en develop.
* A présent, ''uniquement à partir de la version develop'', il ne sera plus nécessaire de livrer les drop des tables dans les dossiers ddl/drop : https://eforum.uem.lan/viewtopic.php?f=14&amp;t=3484
* Il n'est donc nécessaire de gérer la distinction oracle/postgresql qu'en develop, cependant afin de simplifier les reports on peut déjà inclure, sur les branches v14 et dans le cas des changelog uniquement, des changeset portant à la fois des dbms="oracle" et dbms="postgresql". Cela n'est pas impactant, postgre n'étant pas géré en v14.
* Les index doivent être à présent créés respectivement dans les dossiers ddl/create/oracle/05_index/index.sql et ddl/create/postgresql/05_index/index.sql
* Le type oracle &lt;tt&gt;NUMBER&lt;/tt&gt; est dans tous les cas mappé vers le type postgre &lt;tt&gt;numeric&lt;/tt&gt;, que ce soit un entier : NUMBER(X) ou un double : NUMBER(X,Y). Sur ce point, une conversion automatique des types est en général réalisée par sql migrator, ce qui fait que bien souvent un seul changeSet est nécessaire (plus besoin d'en faire deux avec un attribut "dbms" différent pour chacun). Plus d'infos ici : https://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/migration_postgre.html#liquibase_spec
* En v14, lors de la création d'un changeSet de suppression de colonne, il convient de faire habituellement un appel à &lt;tt&gt;ModificationStructure.rebuildIndexesBeforeDrop('TABLENAME','COLUMNNAME')&lt;/tt&gt;. Cependant, comme cette fonction est spécifique oracle, il faut ajouter un attribut "dbms=oracle" sur le tag &lt;sql&gt; faisant l'appel à cette fonction. '''L'appel à cette fonction ne doit plus être fait en develop'''. Une passe sur les changes de suppression v16 sera faite par l'équipe UL afin de les corriger le cas échéant, dès que des bases v16 seront disponibles.
* Deux changeSet complémentaires (faisant la même chose mais l'un étant dbms="oracle" et l'autre dbms="postgresql") peuvent partager le même change ID : en effet, aucune erreur de doublon ne peut se produire dans ce cas.
* Sous Oracle, une DATE gère les heures, ce qui n'est pas le cas de PostgreSql. Il faut pour cela remplacer DATE par TIMESTAMP, et la fonction de conversion TO_DATE par TO_TIMESTAMP. De même, lors d'une mise à jour de données, la date concernant les acteurs création, modification et suppression devrait être remplacée par ''current_timestamp'' : http://wikefluid.efluid.uem.lan/docInstalleur/archi/develop/documentation/architecture/base_de_donnee/FICHE_utilisation_des_dates.html
* Les scripts de migration de type &lt;tt&gt;UPDATE&lt;/tt&gt; doivent être écrits de manière à être compatible Oracle et PostgreSql. Pour cela, il ne faut pas utiliser l'alias pour décrire les colonnes à mettre à jour dans la partie &lt;tt&gt;SET&lt;/tt&gt;. L'alias peut tout de même être défini pour une utilisation dans la clause &lt;tt&gt;WHERE&lt;/tt&gt; ou dans des sous requêtes.
* Dans le cas du requêteur, postgresql ne gère pas la suppression d'une colonne dans un &lt;tt&gt;create or replace view&lt;/tt&gt;, ni l'ajout d'une colonne si celle-ci ne se fait pas en dernier. Pour corriger :
** En upgrade, faire un changeset liquibase contenant un &lt;dropView&gt; placé juste avant le changeset classique contenant notre fichier sql qui fait le &lt;tt&gt;create or replace&lt;/tt&gt;. Ne pas oublier les préconditions. Un exemple ici : https://gerrit.efluid.uem.lan/c/efluid/+/217903
* De manière plus générale, un problème peut intervenir dans le cas où l'on veut modifier le type d'une colonne appartenant à une table qui est référencée par une ou plusieurs vues. Cela n'est effet pas possible avec postgresql. Pour corriger :
** Ajouter un changeSet de drop de la vue problématique avec préconditions, uniquement pour postgresql (dbms="postgresql")
** Faire suivre par le changeSet de modification du type de la colonne
** Enfin, repérer le changeSet qui crée la vue requêteur et lui ajouter l'attribut runAlways="true" afin de forcer la recréation de la vue (les vues étant jouées en dernier, on est sûr que notre colonne aura eu son type modifié avant). Attention, plusieurs changeSet peuvent créer la même vue pour le requêteur, ainsi la bonne pratique est de n'en garder qu'un seul (le dernier). Si toutefois le cas de plusieurs changeSet se présente, ajouter l'attribut runAlways="true" sur le dernier afin de s'assurer d'avoir la dernière version de la vue.
* '''Attention''' : certaines vues requêteur n'ont pas pu être migrées vers PG. Un fichier dans efluid/sql/database nommé TODO_PG.txt a été créé avec vues en question et les raisons pour lesquelles ces vues n'ont pas pu être migrées. Ce fichier est à traiter par les domaines et à tenir à jour.
* Création d'une BDD temporaire de tests postgresql pour l'archi : https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinelogiciellecompilation/job/Farchi/job/archi.compile-and-test-PG/
* Création d'une BDD temporaire de tests postgresql  pour ecore : https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/usinelogiciellecompilation/job/Fecore/job/ecore.compile-and-test-PG/
* Plus d'infos sur la migration vers postgresql : http://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/migration_postgre.html#compatiblite
* En particulier, pour les changements v14/v15 concernant les différences d'encodage et le checksum : https://wikefluid.efluid.uem.lan/docInstalleur/sqlMigrator/migration_utf8.html
* Enchaînements réalisés au moment où un nouveau patch est publié sur gerrit :
** Création d'une base from scratch : exécution des ddl create puis dml init
** Exécution des TU/TI
** Drop du schéma et recréation par une copie de la base de référence
** Exécution de l'upgrade SQL (avec context s'il y a)
** Dans le cas PG, création d'un schéma PG par copie d'une base de référence PG
** Exécution de l'upgrade SQL PG</text>
      <sha1>nmwmiu4wtlgxzeo57e4trxghykvz7qf</sha1>
    </revision>
  </page>
  <page>
    <title>VSCode</title>
    <ns>0</ns>
    <id>648408</id>
    <revision>
      <id>1677571</id>
      <parentid>1658223</parentid>
      <timestamp>2016-06-08T12:43:00Z</timestamp>
      <contributor>
        <username>Desforg</username>
        <id>306</id>
      </contributor>
      <comment>/* Configuration VSCode */</comment>
      <origin>1677571</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1473" sha1="b8duqnydp8qxjz9akoal6ggdmnjpkfs" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = VSCode
 | siteInternet      = https://code.visualstudio.com/
 | guideInstallation = Guide d'installation de VSCode
 | version           = {{outil.vscode.version}}
}}
[[Category:VSCode]]
C'est un éditeur de code javascript pour les développeurs.

== Installation VSCode ==
Récupérér le zip sur le site https://code.visualstudio.com/download.

Déziper le fichier dans "D:\Programs\VSCode"

== licence ==

La licence du logiciel est disponnible ici : 
https://code.visualstudio.com/License

La licence du code source est la :
https://github.com/Microsoft/vscode

== Configuration VSCode ==
A mettre dans les users settings : 

&lt;source lang="javascript"&gt;
// Place your settings in this file to overwrite the default settings
{
    	"files.encoding": "windows1252",
        "editor.tabSize": 2,
        "terminal.integrated.shell.windows" : "C:\\Program Files\\Git\\bin\\bash.exe"
}
&lt;/source&gt;

== Plugin complémentaires (non inclus dans l'installation standard) ==
=== Intellisense du code interne ===
il faut rajouter la routine suivante en début de fichier de spec :
&lt;source lang="javascript"&gt;
/// &lt;reference path="../../tomcat/hermes/jsp/arc/commun/js/masques.js" /&gt;
&lt;/source&gt;

=== Intellisense de jasmine (au d'autre librairie) ===
Prendre le fichier suivant et le glisser dans un dossier visible par VSCode et le mettre en gitignore : https://github.com/DefinitelyTyped/DefinitelyTyped/blob/master/jasmine/jasmine.d.ts</text>
      <sha1>b8duqnydp8qxjz9akoal6ggdmnjpkfs</sha1>
    </revision>
  </page>
  <page>
    <title>Node.js</title>
    <ns>0</ns>
    <id>649641</id>
    <revision>
      <id>1671648</id>
      <parentid>1671624</parentid>
      <timestamp>2016-06-07T08:30:46Z</timestamp>
      <contributor>
        <username>Desforg</username>
        <id>306</id>
      </contributor>
      <origin>1671648</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="669" sha1="6v9jswa11t8uy97tkv8x3ryb1d5aisa" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Node.js
 | siteInternet      = https://nodejs.org/
 | guideInstallation = Guide d'installation de Node.js
 | version           = {{outil.nodejs.version}}
}}
[[Category:nodejs]]
C'est un serveur d'application js et fourni également un outils de gestion de projet js : npm (équivalent de maven pour le js).
C'est surtout NPM qui nous intéresse afin de gérer les dépendances et de bénéficier d'outils de transpilation comme Babel etc...

Les maquettes de l'ergonomie phase 3 ont été développé avec ces technologies.

== Licence == 
Licence assimilé MIT
https://raw.githubusercontent.com/nodejs/node/master/LICENSE</text>
      <sha1>6v9jswa11t8uy97tkv8x3ryb1d5aisa</sha1>
    </revision>
  </page>
  <page>
    <title>Ansible</title>
    <ns>0</ns>
    <id>669376</id>
    <revision>
      <id>2539154</id>
      <parentid>2538919</parentid>
      <timestamp>2017-02-08T09:37:44Z</timestamp>
      <contributor>
        <username>Wozniak</username>
        <id>307</id>
      </contributor>
      <origin>2539154</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1265" sha1="poh4eb55h340ikssk7f5dls5xngdkbj" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = ansible
 | logo              = logo_ansible.png
 | siteInternet      = https://www.ansible.com/
 | version           = {{outil.ansible.version}}
 | supportTechnique  = {{usinelogicielle|subject=ansible}}	
 | guideInstallation = Guide d'installation de Ansible
 | faq               = [[FAQ:Ansible|FAQ Ansible]]
}}

[[Category:ansible]]

== Guide d'utilisation ==
* [[Guide d'utilisation de Ansible]]

== Documentation ==
* Scripts : http://wikefluid/docInstalleur/documentationScriptsOracleTools/

==== Inventaire : /etc/ansible/hosts ====
Plus d'info : http://docs.ansible.com/ansible/intro_inventory.html

== Formation ==
* Notes prises en formation : http://wikefluid/docInstalleur/formationAnsible/
** Pour contributions la source est ici : etools\ansible\formation\src\site\asciidoc (redéploiement automatique au merge du changeSet Gerrit via http://usinelogicielle/job/FjobsUtilitaires/job/etools.deploy-formation-ansible-documentation/)

== Liens internes ==
Bug utilisation module docker_container en 2.2 : http://wikefluid/index.php/Guide_d%27utilisation_de_Ansible#Bug_module_ansible_docker_container_18461

== Liens externes ==
* {{en}} [http://docs.ansible.com/ansible/index.html Documentation officielle]</text>
      <sha1>poh4eb55h340ikssk7f5dls5xngdkbj</sha1>
    </revision>
  </page>
  <page>
    <title>Ironjacamar</title>
    <ns>0</ns>
    <id>671668</id>
    <revision>
      <id>2532912</id>
      <parentid>2532901</parentid>
      <timestamp>2017-02-06T21:38:59Z</timestamp>
      <contributor>
        <username>Collign</username>
        <id>9</id>
      </contributor>
      <comment>/* Récuperation d'une nouvelle version */</comment>
      <origin>2532912</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1314" sha1="s1pp1ydhv0ds35ppx1xfq26icgt0dez" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = IronJacamar
 | logo              = Ironjacamar logo.png
 | siteInternet      = http://www.ironjacamar.org/
 | version           = {{outil.ironjacamar.version}}
 | supportTechnique  = {{usinelogicielle|subject=ironjacamar}}	
}}

[[Category:ironjacamar]]
[[Category:embedded]]

== Modification effectuées ==
* Permettre une surcharge de RADeployer en tant que deployer custom : https://github.com/ironjacamar/ironjacamar/pull/559
** Intégrée dans 1.3.5.Final
* Permettre une surcharge de DsXmlDeployer en tant que deployer custom : https://github.com/ironjacamar/ironjacamar/pull/576
** Intégrée dans 1.3.5.Final

== Récuperation d'une nouvelle version ==
* Modifier la variable ironjacamar.version vers la nouvelle version dans le pom efluid-parent
* Cela récupérera les nouveaux artifacts mais il y a un livrable à générer manuellement et à uploader dans artifactory :
** '''org.jboss.ironjacamar:jdbc-xa''' est de type RAR dans maven central, hors nous avons besoin en JAR, il faut donc : 
*** le récupérer sous forme de RAR
*** placer le RAR dans un nouveau jar et renommer le rar à l'intérieur du jar "jdbc-xa.rar"
*** l'uploader dans artifactory sous org.jboss.ironjacamar:jdbc-xa:&lt;version&gt;:jar dans ext-release-local avec un pom généré minimal</text>
      <sha1>s1pp1ydhv0ds35ppx1xfq26icgt0dez</sha1>
    </revision>
  </page>
  <page>
    <title>Git-LFS</title>
    <ns>0</ns>
    <id>673364</id>
    <revision>
      <id>3600689</id>
      <parentid>3600686</parentid>
      <timestamp>2017-11-02T14:08:59Z</timestamp>
      <contributor>
        <username>Marmill</username>
        <id>240</id>
      </contributor>
      <comment>/* connexion par ssh */</comment>
      <origin>3600689</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7877" sha1="r0npuv14hxm9uq4sfepggg47g04tujm" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Git Large File Storage
 | logo              = git-lfs.png
 | siteInternet      = https://git-lfs.github.com/
 | version           = {{outil.git-lfs.version}}
 | supportTechnique  = [[Samuel Marcaille]] &amp;&amp; [[Thomas Collignon]] 
 | guideInstallation = 
 | faq               = 
}}

Une extension open source de Git pour le versioning des fichiers volumineux

Git Large File Storage (LFS) remplace des fichiers volumineux tels que des échantillons audio, des vidéos, des jeux de données et des graphiques avec les pointeurs de texte à l'intérieur de Git, tout en stockant le contenu du fichier sur un serveur distant comme Artifactory.

== Installation ==
pré-requis : git version &gt;= 1.8.2

téléchargement : https://github.com/github/git-lfs/releases

Disponible dans BMC en version {{outil.git-lfs.version}}

== Configuration générale ==
* Il faut ajouter des options lfs particulières dans git config, via les commandes suivantes
  git config --system filter.lfs.required true
  git config --system filter.lfs.smudge = "git-lfs smudge -- %f"
  git config --system filter.lfs.clean = "git-lfs clean -- %f"

== Configuration Artifactory ==

https://www.jfrog.com/confluence/display/RTF/Git+LFS+Repositories

=== Configuration sur serveur Linux ===

=== connexion par ssh ===
==== chantier en cours ====
suivi du chantier par l'évènement : [http://suivefluid/suivefluid_UEM/jsp/arc/commun/evenement.AccesEvenement.go?reference=219011 219011]
* Actuellement on n'utilise pas le mode "connexion par ssh" mais à terme il faudrait l'implémenter (Cf https://www.jfrog.com/confluence/display/RTF/Git+LFS+Repositories#GitLFSRepositories-AuthenticatingwithSSH)

==== Liens utiles ====
* http://blogs.collab.net/git/scm/gerrit-productivity-hack-handling-large-binary-files-with-gerrit-artifactory-and-git-lfs#.Wfrzj1vWzRZ
* https://www.jfrog.com/knowledge-base/how-to-make-git-lfs-work-and-configure-it-with-artifactory-in-5-min/
==== Installation ==== 
* côté artifactory suivre la doc : https://www.jfrog.com/confluence/display/RTF/Git+LFS+Repositories#GitLFSRepositories-AuthenticatingwithSSH
==== Verification ====
* Pour vérifier si la communication est OK on peut envoyer la commande : 
&lt;source lang="dos"&gt; ssh &lt;ServerName&gt; -p &lt;port&gt; git-lfs-authenticate artifactory/&lt;reponame&gt; download idLFSArtifactory &lt;/source&gt; 
* exemple : [[Fichier:NotifLFSArtifactory.JPG|NotifLFSArtifactory]]

==== trouble shooting ====
&lt;source lang="java"&gt;
2017-10-31 18:26:59,661 [sshd-SshServer[15bcce34]-nio2-thread-2] [WARN ] (o.a.s.s.c.ChannelSession:102) - Error processing channel request exec
java.lang.IllegalStateException: No match found
        at java.util.regex.Matcher.group(Matcher.java:536) ~[na:1.8.0_91]
        at org.artifactory.addon.gitlfs.GitLfsAuthenticateCommand.parseCommandDetails(GitLfsAuthenticateCommand.java:44) ~[artifactory-addon-git-lfs-4.16.1.jar:na]
        at org.artifactory.security.ssh.command.AbstractAuthenticateCommand.&lt;init&gt;(AbstractAuthenticateCommand.java:73) ~[artifactory-core-4.16.1.jar:na]
        at org.artifactory.addon.gitlfs.GitLfsAuthenticateCommand.&lt;init&gt;(GitLfsAuthenticateCommand.java:37) ~[artifactory-addon-git-lfs-4.16.1.jar:na]
        at org.artifactory.addon.gitlfs.GitLfsAddonImpl.createGitLfsCommand(GitLfsAddonImpl.java:44) ~[artifactory-addon-git-lfs-4.16.1.jar:na]
        at org.artifactory.security.ssh.ArtifactoryCommandFactory.createCommand(ArtifactoryCommandFactory.java:56) ~[artifactory-core-4.16.1.jar:na]
        at org.apache.sshd.server.channel.ChannelSession.handleExec(ChannelSession.java:441) ~[sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.server.channel.ChannelSession.handleRequest(ChannelSession.java:311) ~[sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.server.channel.ChannelSession$ChannelSessionRequestHandler.process(ChannelSession.java:602) ~[sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.server.channel.ChannelSession$ChannelSessionRequestHandler.process(ChannelSession.java:600) ~[sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.channel.AbstractChannel.handleRequest(AbstractChannel.java:100) ~[sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.session.AbstractConnectionService.channelRequest(AbstractConnectionService.java:274) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.session.AbstractConnectionService.process(AbstractConnectionService.java:153) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.session.AbstractSession.doHandleMessage(AbstractSession.java:431) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.session.AbstractSession.handleMessage(AbstractSession.java:326) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.session.AbstractSession.decode(AbstractSession.java:780) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.session.AbstractSession.messageReceived(AbstractSession.java:308) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.AbstractSessionIoHandler.messageReceived(AbstractSessionIoHandler.java:54) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.io.nio2.Nio2Session$1.onCompleted(Nio2Session.java:184) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.io.nio2.Nio2Session$1.onCompleted(Nio2Session.java:170) [sshd-core-0.14.0.jar:0.14.0]
        at org.apache.sshd.common.io.nio2.Nio2CompletionHandler$1.run(Nio2CompletionHandler.java:32) [sshd-core-0.14.0.jar:0.14.0]
        at java.security.AccessController.doPrivileged(Native Method) [na:1.8.0_91]
        at org.apache.sshd.common.io.nio2.Nio2CompletionHandler.completed(Nio2CompletionHandler.java:30) [sshd-core-0.14.0.jar:0.14.0]
        at sun.nio.ch.Invoker.invokeUnchecked(Invoker.java:126) [na:1.8.0_91]
        at sun.nio.ch.Invoker$2.run(Invoker.java:218) [na:1.8.0_91]
        at sun.nio.ch.AsynchronousChannelGroupImpl$1.run(AsynchronousChannelGroupImpl.java:112) [na:1.8.0_91]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_91]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_91]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_91
&lt;/source&gt;
* Problème dû a une incompatibilité entre git LFS (version &lt; 2.0.0) et artifactory &lt; 5.6.2 : (cf ticket sur jfrog  :https://www.jfrog.com/jira/si/jira.issueviews:issue-html/RTFACT-14672/RTFACT-14672.html )
** pour résoudre le problème il faut monté git LFS et artifactory

=== connexion basic via git credentials ===
* La connexion se fait donc via une authentification basic à Artifactory qui doit être déclarée à GIT via les "git credentials". Pour se faire il faut : 
** Créer un fichier .git-credentials dans le repertoire HOME de l'utilisateur (exemple : /home/ulouser) contenant l'URL avec login/mot de passe, exemple
 http://&lt;username&gt;:&lt;password&gt;@eartifact.uem.lan
** Ajouter les options suivantes dans git config afin de déclarer que l'on veut utiliser un store git par credentials, et d'indiquer les login pour chaque url : 
 git config --system credential.helper store
 git config --system credential.http://eartifact.uem.lan/.username usinelogicielle

=== Configuration poste de dev === 

Activer ''wincred'' sous windows pour ne pas avoir à saisir à chaque appels les certificats Artifactory. (normalement par défaut à l’installation)
 git config --global credential.helper wincred

== FAQ ==

Vous avez une difficulté si quelqu'un commit un fichier binaire et le pousse. Après rebase tout le monde aura ce fichier en stage, il ne peut pas être enlevé ou réinitialisé.
=&gt; https://shuhrat.github.io/programming/git-lfs-tips-and-tricks.html

 1. Turn off Git LFS
 2. Hard reset, git reset --hard JUNK_COMMIT_PREV_SHA
 3. Turn on Git LFS
 4. Push with force, git push origin +dev</text>
      <sha1>r0npuv14hxm9uq4sfepggg47g04tujm</sha1>
    </revision>
  </page>
  <page>
    <title>Prise en compte d'une nouvelle interface basée sur JMS dans efluid</title>
    <ns>0</ns>
    <id>696754</id>
    <revision>
      <id>4024367</id>
      <parentid>3036729</parentid>
      <timestamp>2018-10-12T07:21:35Z</timestamp>
      <contributor>
        <username>Leoutre</username>
        <id>41</id>
      </contributor>
      <origin>4024367</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2157" sha1="a7dp1w0j3pw9ta62swcugxwhn7ajtkf" xml:space="preserve">[[Category:JMS]]
[[Category:Tutoriaux]]

{{Modèle:Infobox Outil
 | nom               = Prise en compte d'une nouvelle interface basée sur JMS / composants
 | logo              = Integration_continue.jpeg
 | supportTechnique  = {{usinelogicielle|subject=Assemblage}}
 | siteInternet      = http://en.wikipedia.org/wiki/Continuous_integration
}}

[[Category:Outil]]
[[Category:Intégration Continue]]
[[Category:Jenkins]]

= Checklist à adresser =

Lors d'une demande de prise en compte d'une nouvelle interface basée sur JMS, les opérations et composants  suivants doivent être mis à jour:
* '''Demande de paramètrage''' à créer pour suivi avec IT
* '''jms-config.xml :''' dans efluid, mettre à jour le fichier jms-config.xml qui centralise la déclaration des interfaces et objets JMS pour l'embedded. 
* '''documentation installeur :''' la table définissant les files JMS à créer doit être complétée: scriptInstalleur/src/site/asciidoc/installation_prerequisites.adoc.vm. 
* '''script wlst de création des files JMS éditeur :''' la file JMS et la connectionFactory associée doivent être créées dans scriptInstalleurComposant/wlst/deployerWeblogic/deployerWeblogic_app.py
* '''anonymisation technique :''' les paramètres de transmission de la nouvelle interface doivent être prise en compte dans l'anonymisation technique: dans le repo efluid, outils/datamaskingpolicy/changeParamTechnique/src/main/resources/*. 
* '''referentielConfiguration :''' :
** valorisation de l'anonymisation technique: une fois l'anonymisation technique ajoutée livrée, mise à jour des valeurs attendues: efluid(net)-datamasking/&lt;typeEnv&gt;/&lt;env&gt;/source-.....properties
** ajout si nécessaire dans le domaine de sécurité weblogic d'un user ou groupe et de la mise en oeuvre de la policy sur l'objet en question si non déjà couvert par une politique globale sur un module: efluid/&lt;typeEnv&gt;/&lt;env&gt;/create-realm.py. 

Il faudrait, au niveau UL, se créer un evt chapeau de prise en compte de l'interface, et faire un découpage technique pour chaque étape. Si une étape n'est pas requise, le dire explicitement dans l'evènement pour tracer la raison.</text>
      <sha1>a7dp1w0j3pw9ta62swcugxwhn7ajtkf</sha1>
    </revision>
  </page>
  <page>
    <title>Virtualbox</title>
    <ns>0</ns>
    <id>697068</id>
    <revision>
      <id>2741100</id>
      <parentid>2741099</parentid>
      <timestamp>2017-04-05T06:20:56Z</timestamp>
      <contributor>
        <username>Denis</username>
        <id>464</id>
      </contributor>
      <minor/>
      <comment>/* Configuration sur une VM CentOS */</comment>
      <origin>2741100</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7033" sha1="0n2jrjunxr2yv38jrld8ebw79bitr6s" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = virtualbox
 | logo              = logo_virtualbox.png
 | siteInternet      = https://www.virtualbox.org/
 | version           = {{outil.virtualbox.version}}
 | supportTechnique  = {{usinelogicielle|subject=virtualbox}}	
 | guideInstallation = Guide d'installation de virtualbox
 | faq               = [[FAQ:VirtualBox|FAQ VirtualBox]]
}}

[[Category:outil]]

= Guide utilisateur =
À quoi sert la virtualisation ?

Lancer  plusieurs  systèmes  d’exploitation  en  même  temps.
VirtualBox  vous  permet
d’exécuter plus d’un système d’exploitation en même temps.   De cette façon,  vous pou-
vez  lancer  des  logiciels  écrits  pour  un  système  d’exploitation  dans  un  autre  (par  ex-
emple  un  logiciel  Windows  sur  Linux  ou  Mac)  sans  devoir  redémarrer  pour  l’utiliser.
Comme vous pouvez configurer les types de matériels “virtuels” connectés à chaque sys-
tème d’exploitation, vous pouvez installer un vieux système d’exploitation tel que DOS ou
OS/2 même si le matériel de votre machine physique n’est plus supporté par ce système
d’exploitation.

'''L'installation d'une application cracké ou de hacking quelconque est interdit.'''

== Démarrer avec une image ISO ==
Pour démarrer une vm avec une image vous pouvez :
Cliquez sur ''Nouvelle''
Choisir le nom de la machine et sont type.
&lt;pre&gt;
Exemple:
Nom: Debian
Type: Linux
Version: Debian(64bit)
https://drive.google.com/open?id=0B_rPMWF1mpNnTloyc3J2ajdtY0k
&lt;/pre&gt;

Attention: Si vous n'avez pas le 64bit dans le menu déroulant, faite une demande au 6000 pour qu'ils vous activent la "Technologie virtualisation" dans le bios.

Cliquer sur ''Créer''

* ''Emplacement du fichier'' vous allez choisir le l'emplacement (attention par défaut l'emplacement est sûr le SSD (C:\Users\&lt;VOUS&gt;\VirtualBox VMs\&lt;NOM_VM&gt;)).
* ''Taille du fichier'' vous allez definir la taille du disque dur virtuel.
* ''Type de fichier de disque dur'' ici vous pouvez choisir .vdi qui est le format de disque qui est le mieux supporté par Vbox.
* ''Stockage sur disque dur physique'' Défini si la taille du disque dur est fix ou dynamique. (dynamique recommandé)

Sélectionnez votre nouvelle machine virtuel et lancé la.

Par défaut la première fois ou vous allez lancé une VM il vous demandera l'iso (Choisissez le disque de démarrage).

Si vous voulez réinstallé un OS sur un VM existante vous pouvez aller dans : Périphériques / lecteur optique.

== Démarrer avec un disque virtuel ==
Pour démarrer une VM avec un disque existant il faut faire ''Nouvelle''
Choisir "utiliser un fichier de disque dur virtuel existant"
* Choisir un .vdi ou .vmdk puis cliqué sur créer.

Info: on ne peux pas utiliser le même disque dur sur plusieurs machine. Si vous voulez plusieurs machine identique il faudra les cloner via Vbox

= Astuces =
== Augmenter la taille d'un disque ==

* Eteindre la VM.
* Ouvrir un CMD

Vous pouvez récupéré le lien du disque dur virtuel dans: 
* Configuration (de la VM avec le disque trop petit)
* Stockage 
* Contrôleur: SATA
Dans emplacement faire clique droit/copier.

Taper les commandes suivante:
&lt;pre&gt;
cd d:
cd D:\Programs\Vbox
VBoxManage.exe modifyhd "C:\Users\&lt;VOUS&gt;\VirtualBox VMs\Debian\Debian.vdi" --resize 10000
&lt;/pre&gt;

10000=10Go

== Gestion du network ==
=== La base ===
[[Fichier:Network vbox.png|vignette|gauche|http://wikefluid/images/6/63/Network_vbox.png]]


'''NAT:''' le réseau passe par l'hote pour se connecter.

'''Bridge:''' Se connecte directement sur le réseau (plus simple permet de ne pas router les ports dans vbox).


Récupérer son ip et nom de carte réseau sur Debian :
 ifconfig

Récupérer son ip et nom de carte réseau sur centOS et Fedora :
 ip addr

=== Configuration sur une VM CentOS et Fedora ===
Pour que la machine virtuelle récupère correctement une IP il faut faire deux modifications:

Dans le fichier /etc/sysconfig/network ajouter la ligne :
 NETWORKING=yes

Dans le fichier /etc/sysconfig/network-scripts/ifcfg-&lt;CARD&gt; ajouter les lignes:
&lt;pre&gt;
DEVICE=&lt;CARD&gt;
BOOTPROTO=dhcp
ONBOOT=yes
&lt;/pre&gt;

== Ajouter un Proxy ==
=== CentOS ===
Editer le fichier yum.conf
 vi /etc/yum.conf

&lt;pre&gt;
proxy=http://192.168.102.103:8080/
proxy_username=D_NT_UEM\&lt;USER&gt;
proxy_password=&lt;PASSWORD&gt;
&lt;/pre&gt;

=== Debian/Ubuntu ===
Editer le fichier apt.conf et ajouter la ligne suivante :

 vi /etc/apt/apt.conf

 Acquire::http::Proxy "http://D_NT_UEM\&lt;USER&gt;:&lt;PASSWORD&gt;@192.168.102.103:8080/";

=== Fedora ===
Editier le fichier dnf.conf

  vi /etc/dnf/dnf.conf

Y ajouter la configuration suivante :

&lt;pre&gt;
proxy=http://192.168.102.103:8080/
proxy_username=&lt;USER&gt;
proxy_password=&lt;PASSWORD&gt;
&lt;/pre&gt;

==== Attention ====
Toujours pour '''Fedora'''
* '''Ne pas mettre''' D_NT_UEM\ dans proxy_username.
* certains caractères spéciaux en fin de mot de passe peuvent empêcher l'identification de fonctionner (le système ne dira rien, mais vous ne pourrez pas utiliser dnf).

== Tricks ==

=== Ajouter un proxy sur git ===
1. Créer et ajouter un fichier pour que git utilise un proxy.

 vi ~/.gitconfig

2. Dans ce fichier ajouter les lignes suivante.
&lt;pre&gt;
[http]
        proxy = http://D_NT_UEM\&lt;USER&gt;:&lt;PASSWORD&gt;@192.168.102.103:8080
&lt;/pre&gt;

=== Ajout d'un proxy sur wget ===

Créer le fichier de config dans son home : 

 vi ~/.wgetrc

Ajouter les lignes suivantes:
&lt;pre&gt;
http_proxy = http://192.168.102.103:8080/
proxy_user = D_NT_UEM\&lt;USER&gt;
proxy_password = &lt;PASSWORD&gt;
use_proxy = on
&lt;/pre&gt;

=== Ajouter le proxy pour Docker ===

=== Debian et CentOS ===
Pour pouvoir faire un docker pull d'une image il faut ajouter le proxy dans un fichier.

1. On créer le dossier qui va contenir le fichier.

 mkdir -p /etc/systemd/system/docker.service.d

2. On créer le fichier qui va contenir les informations du proxy.

 vi /etc/systemd/system/docker.service.d/http-proxy.conf

Dans ce fichier on lui donne les informations suivante :
&lt;pre&gt;
[Service]
Environment="HTTP_PROXY=http://D_NT_UEM\&lt;USER&gt;:&lt;PASSWORD&gt;@192.168.102.103:8080/" "NO_PROXY=localhost,127.0.0.1,wikefluid,eartifact,usinelogicielle,ldsanbld2"
&lt;/pre&gt;

3. Redémarrer les services 

 systemctl daemon-reload &amp;&amp; systemctl restart docker

=== Fedora ===

Pour pouvoir faire un docker pull d'une image il faut ajouter le proxy dans un fichier.

1. On créer le dossier qui va contenir le fichier.

 mkdir -p /etc/systemd/system/docker.service.d

2. On créer le fichier qui va contenir les informations du proxy.

 vi /etc/systemd/system/docker.service.d/http-proxy.conf

Le proxy ne fonctionnera '''pas''' sous Fedora si on ajoute '''D_NT_UEM\''' dans l'url du proxy http.  &lt;br /&gt;
Dans le fichier on lui donne les informations suivante :

&lt;pre&gt;
[Service]
Environment="HTTP_PROXY=http://&lt;USER&gt;:&lt;PASSWORD&gt;@192.168.102.103:8080/" "NO_PROXY=localhost,127.0.0.1,wikefluid,eartifact,usinelogicielle,ldsanbld2"
&lt;/pre&gt;

3. Redémarrer les services 

 systemctl daemon-reload &amp;&amp; systemctl restart docker

Source : http://download.virtualbox.org/virtualbox/UserManual_fr_FR.pdf</text>
      <sha1>0n2jrjunxr2yv38jrld8ebw79bitr6s</sha1>
    </revision>
  </page>
  <page>
    <title>Guichet de paramétrage</title>
    <ns>0</ns>
    <id>697270</id>
    <revision>
      <id>3378484</id>
      <parentid>3378483</parentid>
      <timestamp>2017-09-20T12:31:01Z</timestamp>
      <contributor>
        <username>Costem</username>
        <id>373</id>
      </contributor>
      <comment>/* RC paire */</comment>
      <origin>3378484</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7051" sha1="h1xmqjcitjl6txmiivzu5zs1yan669t" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Livraison guichet de paramétrage 13
 | logo              = 
 | supportTechnique  = {{usinelogicielle|subject=GuichetDePArametrage}}
 | siteInternet      = http://en.wikipedia.org/wiki/Continuous_integration
}}

[[Category:Outil]]
[[Category:Intégration Continue]]
[[Category:Jenkins]]

= Evénements de guichet de paramétrage =

13.3.100 : 183867&lt;br /&gt;
13.4.100 : 189613&lt;br /&gt;
13.5.100 : 193436&lt;br /&gt;
13.6.100 : 201685&lt;br /&gt;
13.7.100 : 209294&lt;br /&gt;

= Cas de livraison des guichets de paramétrage =

'''Qu'est ce qu'un zip de remplacement ?'''
Lors de la montée de version sqlMigrator, il est possible de préciser, avec des options maven, un zip de remplacement. Celui-ci sera utilisé à la place de celui d'origine ramassé pendant la release. Il est alors possible de supprimer, modifier ou d'ajouter des scripts dans ce zip. Vous trouverez ci-dessous la manière de procéder en fonction de la version ramassée.

== RC impaire ==

Lors des RC impaires, de nouveaux scripts de paramétrages sont livrés par MBA dans l'événement suivefluid associé au guichet de paramétrage en cours.
Il faut donc mettre en place un nouveau zip de remplacement.
* Télécharger les zip sql-database de la RC pour les trois projets : efluid, migefluid, efluidnet
* Unzipper le zip et se rendre dans "sql/database/parametrage/dml/upgrade/13/changelog/parametrage/changeLog.xml"
* Ajouter un changeSet par fichier de paramétrage sous la forme : 
&lt;changeSet author="baudu" id="suivefluid-209294-2-'''REF-RC3'''" context="erdf"&gt;
	&lt;sqlFile encoding="windows-1252" path="guichet/nomDuFichierGuichetDeParametrage" relativeToChangelogFile="true" splitStatements="true" stripComments="false"/&gt;
&lt;/changeSet&gt;

* Le fichier doit être placé dans le dossier "sql/database/parametrage/dml/upgrade/13/changelog/parametrage/guichet/"
* Faire attention à bien ajouter le context=erdf et mettre un id qui prend en compte le numéro de la RC
* Le fichier xml de régionalisation doit être intégré de la manière suivante : 
** Dans le fichier changeLog.xml : &lt;include file="guichet/script_regionalisation_donnees_parametrage_v13.7_UL.xml" relativeToChangelogFile="true"/&gt;
** Dans le fichier de régionalisation, rajouter les balises de createProcedure
* Zipper l'ensemble des dossiers en ajoutant dans la nomination un "_2" (en fonction du cas, il faudra incrémenter selon si d'autres zip de remplacement ont été livrés)
* Déployer les 3 zips dans artifactory en tant que maven artifact (faire attention à la version qui doit bien compoter le "_2")
* Modifier le fichier dans eroom permettant de connaître le delta livré : [http://Lien%20eroom http://wperoom3.uem.lan/eRoom/Production/PlanificationIntegrationEfluid/0_1c623b]
* Envoyer un mail à l'it, la coordination, l'ul, MBA, HDE, MNA pour prévenir de la mise à disposition du zip

== RC paire ==

Lors des RC paires, il n'y a pas de nouvelle livraison des guichets de paramétrage. Il faut cependant mettre à disposition un zip de remplacement incluant le paramétrage de la RC précédente (notamment pour l'IT qui peut faire des montée de version nécessitant ce zip).&lt;br /&gt;
Par exemple pour une RC4 : 
* Prendre les zip de remplacement efluid-sql-database-13.7.100.RC3_2, efluidnet-sql-database-13.7.100.RC3_2, migefluid-sql-database-13.7.100.RC3_2
* Prendre les zip sql de la RC actuelle : efluid-sql-database-13.7.100.RC4, efluidnet-sql-database-13.7.100.RC4, migefluid-sql-database-13.7.100.RC4
* Copier le dossier paramétrage des anciens zip de remplacement dans les zip de la RC actuelle. Puis les renommer en ajoutant un "_2".
* Déployer les 3 zips dans artifactory en tant que maven artifact (faire attention à la version qui doit bien compoter le "_2")
* Modifier le fichier dans eroom permettant de connaître le delta livré : [http://Lien%20eroom http://wperoom3.uem.lan/eRoom/Production/PlanificationIntegrationEfluid/0_1c623b]
* Envoyer un mail à l'it, la coordination, l'ul, MBA, HDE, MNA pour prévenir de la mise à disposition du zip

== Release ==

Lors d'une release, aucun zip de remplacement n'est mis en place.
Les guichets de paramétrage doivent être inclus dans le code d'efluid, efluidNet et migefluid.

Prérequis : avoir git-lfs sur son poste

* Se placer dans le repo du projet concerné
* Ouvrir le fichier "sql/database/parametrage/dml/upgrade/13/changelog/parametrage/changeLog.xml"
* Ajouter un changeSet par fichier de paramétrage sous la forme : 
&lt;changeSet author="baudu" id="suivefluid-209294-2-'''REF-RC3'''" context="erdf"&gt;
	&lt;sqlFile encoding="windows-1252" path="guichet/nomDuFichierGuichetDeParametrage" relativeToChangelogFile="true" splitStatements="true" stripComments="false"/&gt;
&lt;/changeSet&gt;

* Le fichier doit être placé dans le dossier "sql/database/parametrage/dml/upgrade/13/changelog/parametrage/guichet/"
* Faire attention à bien ajouter le context=erdf et mettre un id qui prend en compte le numéro de la RC
* Le fichier xml de régionalisation doit être intégré de la manière suivante : 
** Dans le fichier changeLog.xml : &lt;include file="guichet/script_regionalisation_donnees_parametrage_v13.7_UL.xml" relativeToChangelogFile="true"/&gt;
** Dans le fichier de régionalisation, rajouter les balises de createProcedure
* Faire un commit et publier sur gerrit. Les fichiers seront traités par git-lfs lors du transfert sur gerrit et seront stockés sur artifactory.

= Procédure pour passer les scripts directement sur la BDD =

* Modifier les scripts de Marc pour faire pointer son spool faire le dossier /tmp/
* Placer les scripts sur le serveur de BDD dans le dossier /tmp/ : LRBDDEDT7
* Se connecter à la machine en ssh avec le compte oracle (passer par root)

Pour efluid : 

''sqlplus INT_ERDF_PARAM_FLD_13/Its4bdd_INT_ERDF_PARAM_FLD_13@RPAREDT2 @/tmp/'''${lenomdetonfichierdeparametrage.sql}''' INT_ERDF_PARAM_FLD_13_DATA INT_ERDF_PARAM_FLD_13_INDEX INT_ERDF_PARAM_FLD_13_PARAM INT_ERDF_PARAM_FLD_13_BLOB''

Pour efluidNet : 
''sqlplus INT_ERDF_PARAM_NET_13/Its4bdd_INT_ERDF_PARAM_NET_13@RPAREDT2 @/tmp//'''${lenomdetonfichierdeparametrage.sql}'''   INT_ERDF_PARAM_NET_13_DATA INT_ERDF_PARAM_NET_13_INDEX INT_ERDF_PARAM_NET_13_PARAM INT_ERDF_PARAM_NET_13_BLOB''

* Ensuite tu récupères les fichiers de logs et tu mets tout dans l’événement 189613.
* Tu redémarres l’application via le job de pilotage :
http://usinedeploiement.uem.lan/job/Finstallation/job/FsuiteEfluid/job/Ferdf/job/Fpilotage/job/suite-efluid.orchestrate-pilotage-int-param-v13/

* Si tout est ok, tu peux check avec cette page ou les liens sont cliquables pour faire les vérifInstallations : [[Environnements DEV NB et INT UL|Environnements DEV_NB]]

* – Tu peux envoyer le mail avec le job : http://usinedeploiement.uem.lan/job/Finstallation/job/FsuiteEfluid/job/Ferdf/job/Fdeploiement/job/Fparam/job/suite-efluid.orchestrate-deploy-int-param-v13/
Tu décoches tout et tu coches seulement « envoiMailFin » (en faisant gaffe parce qu’il faut une validation via jenkins pour que le mail parte).</text>
      <sha1>h1xmqjcitjl6txmiivzu5zs1yan669t</sha1>
    </revision>
  </page>
  <page>
    <title>Asciidoc</title>
    <ns>0</ns>
    <id>697864</id>
    <revision>
      <id>2962675</id>
      <timestamp>2017-06-02T14:09:38Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <comment>Page créée avec « {{Modèle:Infobox Outil  | nom               = ASCIIDoc }}   = liens = * http://asciidoctor.org/docs/asciidoc-syntax-quick-reference/  [[Category:outil]] [[Category:ASCIID... »</comment>
      <origin>2962675</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="175" sha1="t4odnoorv8z1qiu25adlt5qxo50j5kk" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = ASCIIDoc
}}


= liens =
* http://asciidoctor.org/docs/asciidoc-syntax-quick-reference/

[[Category:outil]]
[[Category:ASCIIDoc]]</text>
      <sha1>t4odnoorv8z1qiu25adlt5qxo50j5kk</sha1>
    </revision>
  </page>
  <page>
    <title>CJE</title>
    <ns>0</ns>
    <id>698053</id>
    <revision>
      <id>4067524</id>
      <parentid>4067523</parentid>
      <timestamp>2022-07-18T15:35:21Z</timestamp>
      <contributor>
        <username>Carriers</username>
        <id>234</id>
      </contributor>
      <comment>/* cje Prod */</comment>
      <origin>4067524</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="64045" sha1="9vqb59ah5cvf98gal1poa3jx37h0k3x" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Jenkins CJE
 | logo              = JenkinsDragon.jpg
}}

== Troubleshooting ==
=== The absolute guide ! ===
https://docs.cloudbees.com/docs/cloudbees-jenkins-enterprise/latest/admin-guide/troubleshooting#troubleshooting-build-agent-provisioning

https://docs.cloudbees.com/docs/cloudbees-jenkins-enterprise/latest/admin-guide/troubleshooting#troubleshooting-mesos-marathon

=== Les slaves des différentes usines ne prennent plus aucun job, la file des jobs en attente ne cesse de grossir ===

Il faut suspecter un souci au niveau du composant responsable de la gestion de l'offre de ressources dans le cluster pour Jenkins : palace
* Contrôler la page sous Mesos permettant de voir l'état de l'offre de ressources physiques dans le cluster de workers Jenkins :
 http://mesos-cje.efluid.uem.lan/#/offers

En nominal, on observe les serveurs Workers disponibles et la quantité de ressources proposées :

[[image:offreMesosNominale.png |1000px|]]

'''Si la page est vide, il faut alors redémarrer depuis Marathon le composant palace : '''
 http://marathon-cje.efluid.uem.lan/ui/#/apps/%2Fjce%2Fpalace
* Sélectionner jce_palace.xxxxxxxxx
* Cliquer sur Restart dans la barre de boutons au dessus

[[image:marathonRestartPalace.png |1000px|]]



Les serveurs Workers devraient réapparaitre dans la page offers sous Mesos.

== Documentation ==

* TROUBLESHOUTING CJE : https://go.cloudbees.com/docs/cloudbees-documentation/admin-cje/troubleshooting/

* COMMANDES UTILES pour admin depuis CJE Workstation : https://support.cloudbees.com/hc/en-us/articles/360001976792-How-to-use-cje-command-line-tools

* Guide d'administration du cluster CJE: https://go.cloudbees.com/docs/cloudbees-documentation/pse-admin-guide/

* Génération d'un Bundle dans le cadre d'un ticket auprès du support Cloudbees: https://go.beescloud.com/docs/cloudbees-documentation/admin-cje/reference/cli/#generating-support-bundle

* Migration d'un Master sans upgrade CJE : https://support.cloudbees.com/hc/en-us/articles/115000078131-How-to-configure-last-CloudBees-Jenkins-docker-images-manually-without-upgrade

* https://go.cloudbees.com/docs/cloudbees-documentation/admin-cje/reference/cli/

* https://go.beescloud.com/docs/cloudbees-documentation/admin-cje/operating/

* https://www.cloudbees.com/products/cloudbees-jenkins-platform/team-edition/features/role-based-access-control-plugin

* [cjoc] 1. https://support.cloudbees.com/hc/en-us/articles/223406287-I-changed-the-security-realm-and-since-then-bees-pse-operations-are-failing

* [cjoc] 2. https://support.cloudbees.com/hc/en-us/articles/229298168-How-to-disable-CJOC-authorization-in-PSE

* https://jenkins.io/doc/book/pipeline/shared-libraries/#using-third-party-libraries

* Scripts groovy pour diverses tâches d'admin: https://github.com/cloudbees/jenkins-scripts

* Configuration SSL: https://support.cloudbees.com/hc/en-us/articles/222098288-Set-up-SSL-on-a-CJOC-environment-with-a-self-sign-SSL-certificate

* Accès à Docker registry (Using private Docker registries): https://go.cloudbees.com/docs/cloudbees-documentation/admin-cje/cd-as-a-service/

* Libérer une VM master worker des managed masters qui tournent dessus: https://support.cloudbees.com/hc/en-us/articles/115000738111?input_string=cje%3A+managed+masters+dispatching+among+master+workers

* LTS upgrade Guide : https://jenkins.io/doc/upgrade-guide/

== Préparation des serveurs ==

Sur les serveurs hébergeant les Masters Jenkins, et les Slaves, configurer les précos de Cloudbees relatives à NFS :

*  /etc/nfsmount.conf (en cours de validation)
** Defaultvers=3
* /etc/sysconfig/nfs 
** RPCNFSDCOUNT=16 (8 par défaut)

* /etc/sysctl.d/30-nfs.conf : à créer avec les paramètres suivants :
 sunrpc.tcp_slot_table_entries = 128   ( =&gt; was set to 2 in our environment.)
 sunrpc.tcp_max_slot_table_entries = 65536
 net.core.rmem_default = 262144
 net.core.rmem_max = 16777216
 net.core.wmem_default = 262144
 net.core.wmem_max = 16777216
 net.ipv4.tcp_rmem = 4096 262144 16777216
 net.ipv4.tcp_wmem = 4096 262144 16777216
 net.ipv4.tcp_window_scaling = 1
 net.ipv4.tcp_sack = 0
 net.ipv4.ip_local_port_range = 1024 65000

Test en cours 12/12/2018 sur lpcjemtredt1 à 3, pour ne plus swapper alors qu'il reste de la mémoire

https://success.docker.com/article/node-using-swap-memory-instead-of-host-memory

* /etc/sysctl.conf
 vm.swappiness=0
 vm.overcommit_memory=1

Pour prise en compte immédiate
 sysctl vm.swappiness=0
 sysctl vm.overcommit_memory=1

Pour vérifier 
 sysctl -a | grep -E 'vm.swappiness|vm.overcommit_memory'

== Platforms identification ==

=== CJE Workstation ===

Controller Workstation pour environnement de Prod et de Test: lpcjewstedt1 (192.168.119.81)

Se connecter et passer ulouser

Pour travailler sur le CJE de prod : 
 setProd

Pour travailler sur le CJE de test tstcje1 : 
 setTst

Quelques fonctions/alias utiles (des fonctions sont dispos dans ~/.libUtilsCJE) :
  help

=== cje Prod ===

* CJE : '''http://cje.efluid.uem.lan'''
* Mesos : '''http://mesos-cje.efluid.uem.lan/#/'''
* Marathon : '''http://marathon-cje.efluid.uem.lan/'''

CJE project: sur lpcjewstedt1 (ulouser) 
 =&gt; /data/EDT/files/cje_prod_1_project/

'''Secrets''': ${PROJECT}/.dna/secrets

DNS : http://wikefluid/index.php/Dns_efluid

Controller Workstation: lpcjewstedt1 (192.168.119.81)
Load balancer 1: lpcjelbaedt1 (192.168.119.61) 
Load balancer 2: lpcjelbaedt2 (192.168.119.80) 

{| class="wikitable"
|-
!   !! cje_prod_1_project !! Core !! RAM
|-
| Controller-1 || lpcjecntedt1 (192.168.106.66) ||  ||
|-
| Controller-2 || lpcjecntedt2 (192.168.106.67) || ||
|-
| Controller-3 || lpcjecntedt3 (192.168.106.106)|| ||
|-
| &lt;s&gt;Worker-1&lt;/s&gt; || &lt;s&gt;lpcjemtredt1 (192.168.106.233) (Master jenkins)&lt;/s&gt;||&lt;s&gt; 6 &lt;/s&gt;|| &lt;s&gt;35 Go &lt;/s&gt;
|-
| &lt;s&gt;Worker-2&lt;/s&gt; || &lt;s&gt;lpcjemtredt2 (192.168.106.234) (Master jenkins)&lt;/s&gt;||&lt;s&gt; 6 &lt;/s&gt; ||&lt;s&gt; 35 Go &lt;/s&gt;
|-
| &lt;s&gt;Worker-3&lt;/s&gt; || &lt;s&gt;lpcjemtredt3 (192.168.106.235) (Master jenkins)&lt;/s&gt;||&lt;s&gt; 6 &lt;/s&gt; ||&lt;s&gt; 35 Go &lt;/s&gt;
|-
| &lt;s&gt;Worker-4&lt;/s&gt; || &lt;s&gt;lpdrogonedt1 (192.168.119.78) (Agent Worker) &lt;/s&gt; || &lt;s&gt;96 &lt;/s&gt;|| &lt;s&gt;188 Go&lt;/s&gt;
|-
| &lt;s&gt;Worker-5&lt;/s&gt; || &lt;s&gt;lpviseriedt1 (192.168.119.79) (Agent Worker) &lt;/s&gt;||&lt;s&gt;96 &lt;/s&gt; || &lt;s&gt;188 Go &lt;/s&gt;
|-
| Worker-6 || lpcjeelkedt1 (192.168.119.58)  || ||
|- 
| Worker-7 || lpcjeelkedt2 (192.168.119.59) || ||
|-
| Worker-8 || lpcjeelkedt3 (192.168.119.60) || ||
|-
| Worker-9 || NONE (mauvaise manip) || ||
|-
| &lt;s&gt;Worker-10&lt;/s&gt; || &lt;s&gt;lprhaegaedt1 (192.168.119.88)  (Agent Worker)&lt;/s&gt;||&lt;s&gt; 64 &lt;/s&gt;||&lt;s&gt; 188 Go &lt;/s&gt;
|-
| Worker-11 || lptyrionedt1 (192.168.118.8)  (Agent Worker)||28 || 188 Go 
|-
| &lt;s&gt;Worker-12&lt;/s&gt; || &lt;s&gt;lpcjewkredt1 (192.168.119.115)(Agent Worker)&lt;/s&gt; || &lt;s&gt;176 &lt;/s&gt; || &lt;s&gt;187 Go&lt;/s&gt; 
|-
| &lt;s&gt;Worker-13&lt;/s&gt; || &lt;s&gt;lpcjewkredt2 (192.168.119.116)(Agent Worker)&lt;/s&gt; || &lt;s&gt;176 &lt;/s&gt; || &lt;s&gt;187 Go&lt;/s&gt;
|-
| Worker-14 || lpcjewkredt3 (192.168.119.117)  (Agent Worker)||176 || 187 Go 
|-
| &lt;s&gt;Worker-15 &lt;/s&gt;|| &lt;s&gt;lpcjewkredt4 (192.168.119.118)  (Agent jenkins)&lt;/s&gt;|| &lt;s&gt;176&lt;/s&gt; || &lt;s&gt;187 Go&lt;/s&gt; 
|-
| Worker-16 || lprededt2 (192.168.106.101)  (Master Worker)|| 32 || 190 Go 
|}

=== cje tst1 ===

* CJE : '''http://tstcje1.efluid.uem.lan'''
* Mesos : '''http://mesos-tstcje1.efluid.uem.lan/#/'''
* Marathon : '''http://marathon-tstcje1.efluid.uem.lan/'''

Se reporter à http://wikefluid/index.php/Suivi_des_stages_Process_de_Fabrication pour détails sur mise en oeuvre pltf de tests.

Controller Workstation: lpcjewstedt1 (192.168.119.81)

Load balancer 1: lpcjelbaedt2 (nginx) (192.168.119.80) 

{| class="wikitable"
|-
!    !! tstcje1_project
|-
| Controller-1 ||  lpsrvulo1 (192.168.106.230)
|-
| &lt;s&gt;Worker-1&lt;/s&gt; || &lt;s&gt; lrcjemtredt1 (192.168.119.82)&lt;/s&gt;
|-
| &lt;s&gt;Worker-2&lt;/s&gt; || &lt;s&gt; lrcjemtredt2 (192.168.119.83)&lt;/s&gt;
|-
| &lt;s&gt;Worker-3&lt;/s&gt; || DELETED - &lt;s&gt;lprhaegaedt1 (192.168.119.88)  (Agent Worker)&lt;/s&gt;
|-
| &lt;s&gt;Worker-4&lt;/s&gt; || DELETED - &lt;s&gt;lpsrvulo2 (192.168.106.231) (ELK)&lt;/s&gt;
|-
| &lt;s&gt;Worker-5&lt;/s&gt; || DELETED - &lt;s&gt;lrcjewkredt1 (192.168.119.98)  (Agent Worker)&lt;/s&gt;
|-
| &lt;s&gt;Worker-6&lt;/s&gt; || DELETED - &lt;s&gt;lrcjewkredt2 (192.168.119.99)  (Agent Worker)&lt;/s&gt;
|-
| Worker-7 || DELETED - lpcjeredwkr1 (192.168.106.139)  (Agent Worker)
|-

|}

DNS primaire: lrcjemtredt1 (192.168.119.82) (bind, webmin: https://lrcjemtredt1:10000/, mdp dans keypass PerfUl)
 docker ps: 
 85eff8efb2ca        sameersbn/bind:9.9.5-20170129   "/sbin/entrypoint...."   4 weeks ago         Up 4 weeks          0.0.0.0:53-&gt;53/tcp, 0.0.0.0:10000-&gt;10000/tcp, 0.0.0.0:53-&gt;53/udp   cjetest_primary_dns

DNS secondaire: lrcjemtredt2

MESOS : mesos-tstcje1.efluid.uem.lan/
MARATHON : marathon-tstcje1.efluid.uem.lan/

== Pilotage des noeuds ==

  usage: dna [-h] COMMAND ...

  optional arguments:
    -h, --help       show this help message and exit

  COMMAND
    init-project   Initialize a project directory
    create         Create a new server
    status         Show the status of the project or servers
    servers        List servers managed by DNA
    start          Start a new server
    stop           Stop a running server
    init           Initialize a server
    reinit         Synonym for init command (backward compatibility)
    bind           Bind a server to a server instance
    unbind         Unbind a server from a server instance
    run            Run a script on one or more servers
    start-job      Start a job on a server
    connect        Connect to a server
    convert        Convert an old-style DNA document to a new server
    init-env       Initialize a DNA environment
    render         Render a script for a server
    shell          Start a DNA shell
    encrypt        Encrypt a file
    decrypt        Decrypt a file
    reencrypt      Reencrypt a file
    render-template
                   Render a template
    volumes-analyze
                   Analyze volume(s)
    volumes-attach
                   Attach existing volume(s) to the instance
    volumes-detach
                   Detach volume(s) attached to the instance
    ansible        Invoke ansible against the server

== Ouvrir un ticket au support Cloudbees ==
Pour ouvrir 1 ticket au support Cloudbees : https://support.cloudbees.com/hc/en-us

Il faut systématiquement joindre un Bundle Support à l'ouverture du ticket.
Si problème sur 1 master particulier, alors générer le bundle à partir du Master en cause. La page est disponible depuis la page principale du master, menu à gauche : "Support".
 ex : http://cje.efluid.uem.lan/usinelogiciellecompilation/support/

Si problème plus vaste, alors joindre un pse support bundle en suivant la procédure ci-dessous.

=== Obtenir un threadDump ===

Suivre cette procédure : https://support.cloudbees.com/hc/en-us/articles/115001626467-Extract-a-Heap-Thread-Dump-of-a-tenant-on-PSE

== Generate a CloudBees Jenkins Enterprise Support Bundle ==
A CloudBees Support Engineer may ask you to generate a CloudBees Jenkins Enterprise Support Bundle. This is a common step in triaging problems with your CloudBees Jenkins Enterprise instance. This 
bundle will include information that will be helpful in troubleshooting problems. To do so, run the following command:
 cje prepare pse-support
 pse-support is staged - review pse-support.config and edit as needed - then
 run `cje apply` to perform the operation.

Edit the pse-support.config file before executing the operation to choose what packages to include in the bundle.
 Note By default, this operation will generate a bundle with all of the options included. If you wish to exclude a package from the bundle, indicate 'no' instead of 'yes'.

 [tiger]
  ## Include the Support Core Plugin Bundle.
  cjoc_support_bundle = yes
  ## Include logs of this cluster's controllers and workers.
  cluster_task_logs = yes
  ## Include PSE Workspace Specific Files
  pse_workspace = yes

Then apply the operation with cje apply.

The Support Bundle archive file will be saved to the current working directory to a time-stamped file called cloudbees-pse-support-YYYY-MM-DD-HH-MM-SS.tgz.

You can then submit this Support Bundle archive file to a CloudBees Support Engineer.

'''NOTE'''
 If your archive is larger than 20Mb please use this new service to send it to us: https://uploads.cloudbees.com/#/login. This service works best in Chrome or Firefox.

== Installation procédure ==

Suivre les prérequis demandés là: http://wperoom3.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_9e8a

Le jour J:
* Se connecter ulouser sur la cjeWorkstation.

* Vérifier que les clés publiques générées sur le poste cjeWorkstation sont bien déployées sur tous les serveurs du cluster (depuis le répertoire .ssh):
  [ulouser@lpcjewstedt1 .ssh]$ ssh -i cje-ssh-key ulouser@lpcjecntedt1 id
  uid=500(ulouser) gid=988(docker) groupes=988(docker),5000(fldgrp)
  [ulouser@lpcjewstedt1 .ssh]$ ssh -i cje-ssh-key ulouser@lpcjecntedt2 id
  uid=500(ulouser) gid=988(docker) groupes=988(docker),5000(fldgrp)

* Se placer dans le répertoire cd pse_1.7.0/

  [ulouser@lpcjewstedt1 pse_1.7.0]$ cje version
  PSE Project: 5
  PSE Release: 20
  CloudBees PSE: 1.7.0
  AWS AMI Version: 1.7.0	
  Build: 140
  Tiger Storage: cloudbees/pse-castle:1.6.3
  Tiger CJOC: cloudbees/cje-oc:2.46.3.2
  Tiger CJE: cloudbees/cje-mm:2.46.3.2
  Tiger Search: cloudbees/pse-elasticsearch:1.3.1
  Tiger Router: cloudbees/pse-router:1.6.3
  Tiger Logstash: cloudbees/pse-logstash:1.6.0
  PSE SSH Gateway: cloudbees/pse-sshgateway:1.3.1
  Tiger Scheduler: cloudbees/pse-palace:1.6.4
  Mesos: 0.28.2\*
  zookeeper: 3.4.6\*
  Marathon: 0.15.3\*
  Docker: 1.13.1\*
  Topbeat: 1.1.0\*
  Pip: 1.5.4\*
  Terraform: 0.9.4-cloudbees (a5bb70b48113618e056d4039b4da5db36f50c2c7)

* En tant que root: mkdir /data/EDT/files/cje-project et chown -R ulouser:docker /data/EDT/files

* En tant que ulouser, reprendre: 

  [ulouser@lpcjewstedt1 file]$ export PROJECT=/data/EDT/file/cje_project
  [ulouser@lpcjewstedt1 file]$ cje init-project $PROJECT anywhere
  Using anywhere template
  Project created in /data/EDT/file/cje_project
  Please run
  $ cd /data/EDT/file/cje_project
  $ cje prepare cluster-init
  to start creating the cluster.

  [ulouser@lpcjewstedt1 file]$  cd /data/EDT/file/cje_project

  [ulouser@lpcjewstedt1 cje_project]$ cje prepare cluster-init
  cluster-init is staged - review cluster-init.config and cluster-init.secrets and edit as needed - then run 'cje apply' to perform the operation.

  [ulouser@lpcjewstedt1 cje_project]$ vim cluster-init.config
La configuration sauvegardée se trouve sous : /data/EDT/files/cje_prod_1_project/operations/20170628T082234Z-cluster-init/config

  [ulouser@lpcjewstedt1 cje_project]$ vim cluster-init.secrets
La configuration sauvegardée se trouve sous : /data/EDT/files/cje_prod_1_project/operations/20170628T082234Z-cluster-init/secrets

  [ulouser@lpcjewstedt1 cje_project]$ cje verify
  cluster-init is ready to apply

  [ulouser@lpcjewstedt1 cje_project]$ cje apply
  Setup 3 controllers
  Setup 8 workers
  Updating project configuration
  Updating project secrets
  Initializing DNA project at /data/EDT/file/cje_project/.dna
  Extending initialization to /home/ulouser/pse_1.7.0/share/setup-templates/core
  Creating credentials
  unable to write 'random state'
  unable to write 'random state'
  ...

* Si problème, relancer individuellement: 
  dna init worker-1
  dna init controller-1

* Une fois tout OK:
  cje run display-outputs
  
* Start a browser

* Sur la CJEWorkstation:
  cje run echo-secrets cjoc_username
  cje run echo-secrets cjoc_password

Utiliser ces infos pour se connecter admin à Jenkins

* Login to the browser

== Upgrade procédure (ex: de 1.7.0 vers 1.7.1) ==

=== Préparation ===

Demande de support à migration : https://support.cloudbees.com/hc/en-us/articles/115001919212?q=assisted%20upgrade


En cas de mise à jour recommandée:
[[image:upgradeAvailable.png |600px|]]

 
'''https://support.cloudbees.com/hc/en-us/articles/115000112392-How-to-upgrade-CJE'''

* '''Avant de lancer l'upgrade''', vérifier que:
** Le cluster elasticSearch est (script '''checkElkStatus.sh''' depuis lpcjewstedt1 -&gt; connecté ulosuer -&gt; setProd ou setTst):
*** Green sur Prod
*** Yellow sur Test
Si pas dans l'état attendu, lancer le script fixEsShards.sh puis relancer le checkElkStatus.sh.
** (plus utile) &lt;del&gt;/nfs/cjoc appartient bien à ulouser:docker, surtout pas à jenkins4docker. Si ce n'est pas le cas, réaffecter le bon user et groupe.&lt;/del&gt;
** Se placer dans le répertoire du projet à migrer sur lpcjewstedt1 (/data/EDT/files/cje_prod_1_project ou /data/EDT/files/tstcje1_project) et faire un git difftools de manière à s'assurer qu'il n'y a pas de modification non souhaitée sur la configuration de référence avant de lancer l'upgrade. Ex : s'assurer que dans les fichiers .dna/servers/worker-XX/dna.config, dans la section [castle], le paramètre user_name est bien à 1000 (user jenkins) et pas à 500 (user ulouser). 

* Télécharger la dernière version pse_x.y.z requise sur le site: https://downloads.cloudbees.com/pse/latest/ (depuis lpcjewstedt1, ulouser)
 export https_proxy=http://lpsrvpxy.uem.lan:8080/
 export http_proxy=http://lpsrvpxy.uem.lan:8080/
 wget https://downloads.cloudbees.com/pse/latest/pse_1.X.Y_linux_amd64.tar.gz


* Extraire l'archive dans le home de ulouser: 
  $ cd ~
  $ tar zxvf pse_1.7.1_linux_amd64.tar.gz
  $ export PATH=~/pse_1.7.1/bin:$PATH
  $ Vérifier que le PATH est OK : which cje =&gt; doit résoudre avec le nouveau répertoire extrait.

* '''Désactiver dans le PSE désarchivé la mise à jour docker : '''
** Editer le fichier ./share/setup-templates/core/templates/tiger/configure-docker et supprimer le contenu de la fonction '''docker-config()'''. Remplacer par l'instruction 
  echo "CUSTO efluidsas : NOP"

* '''Redéfinir la valeur 8 pour l'algorithme de pack des masters dans Marathon : '''
** Editer le fichier ./share/setup-templates/core/templates/palace/marathon.json et dans la section env, ajouter entre 2 variable existantes (cf https://docs.cloudbees.com/docs/cloudbees-jenkins-enterprise/latest/references/#_binpack_algorithm) :
  "CONSTRAINTS": "8",

Note : fait sur pse_1.11.22 , pse_1.11.26 et pse_1.11.29

=== Migration ===

* Se placer dans le projet à migrer et positionner la variable PROJECT: 
  $ cd /data/EDT/files/cje_prod_1_project
  * export PROJECT=$PWD

* Préparer l'upgrade: 
  $ cje upgrade-project

Note: la plupart du temps, cette commande semble sans effet (upToDate). Poursuivre avec l'upgrade.


*(plus utile) Mettre à jour le fichier .dna/secrets afin d'y mettre le login et mot de passe d'un compte administrateur pouvant être utilisé le temps de l'upgrade (propriétés cjoc_username et cjoc_password).

* Lancer l'upgrade: 
  $ cje upgrade

* '''Avant de migrer les MASTERs''', vérifier que:
** sur le cjoc, dans la configuration système globale, partie paramètres avancés de la section "Mesos Master Provisioning" : le champ "Docker Container User" vaut 1000 et pas 500. Si valeur 500, le changer avant de migrer les Master, sinon, ils ne pourront pas démarrer en raison de "Permission denied" sur /nfs/&lt;master&gt;/jenkins_home/configure-jenkins.groovy.d.

* Migrer 1 managed master à la main afin de s'assurer que la montée de version se passe bien sur 1 des masters au choix, via l'interface du CJOC:
 ** manage -&gt; stop du master, 
 ** configure =&gt; mettre à jour la version d'image. 
 ** save =&gt; redémarre automatiquement le master.
 
* Une fois l'upgrade du managed master de test terminé, mettre à jour depuis l'interface CJOC tous les autres masters Jenkins en utilisant le jobs suivant (version cible à configurer dans le job par édition):
 ** http://cje.efluid.uem.lan/cjoc/view/All/job/Fadmin/job/managed-masters.upgrade-images/configure

NOTE: éviter, lors de la mise à jour de plugin, d'avoir une version non supportée par le CAP (Cloudbees Assurance Program).

* Editer le fichier .bashrc du compte ulouser pour remettre à jour le PATH pour cet envirnnement.


 '''Note: '''
 Le répertoire /home/ulouser/cjeConfigurations est un clone du repo Git cjeConfigurations permettant l'archivage des confs au fil des montées de version.
 Le répertoire /data/EDT/files/cje_prod_1_project est un lien symbolique qui pointe le référentiel: /home/ulouser/cjeConfiguration/cje_prod_1_project.
 De la même manière, le répertoire /data/EDT/files/tstcje1_project est un lien symbolique qui pointe le référentiel: /home/ulouser/cjeConfiguration/tstcje1_project.
 '''Avant une migration, s'assurer que le clone est synchroniser avec le remote.'''
 '''Après migration, publier les modification dans gerrit pour archivage: git commit -a -m "98875: Montée de version sur [Prod|Test] en version pse_1.x.0"''';git pub

=== Contrôles post-migration  ===

Après migration du CJOC, points à vérifier :
* http://cje.efluid.uem.lan/cjoc/credentials/store/system/domain/_/credential/mesos/ : remettre le scope en Global si repassé en Système.

Les jobs de validation à lancer pour contrôler une nouvelle version :
* Fadmin (backups):
** [http://cje.efluid.uem.lan/cjoc/job/Fadmin/job/backup.jobs/ backup jobs]
** [http://cje.efluid.uem.lan/cjoc/job/Fadmin/job/backup.system/ backup system]
** [http://cje.efluid.uem.lan/cjoc/job/Fadmin/job/cjoc.agent-templates-backup/ cjoc  agent templates backup]
** [http://cje.efluid.uem.lan/cjoc/job/Fadmin/job/cjoc.backup-system/ cjoc backup system]

* usine Validation Jenkins :
** [http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/run.all-jenkinsConfigurations-tests-once-a-day/ jenkinsConfigurations validation] 
** [http://cje.efluid.uem.lan/usinevalidationjenkins/job/FsharedLibrary/job/jenkinsSharedLibrary.compile/job/develop/ sharedLibrary compilation]
** [http://cje.efluid.uem.lan/usinevalidationjenkins/job/FsharedLibrary/job/jenkinsSharedLibrary.validation-gerrit/ sharedLibrary  validation gerrit]

* usine Recette :
** validation plugins: les jobs du dossier http://cje.efluid.uem.lan/usinerecette/job/FnonRegressionTests/job/FdslExample/

=== Patchs sur PSE ===

Problème avec les repos Docker arrêtés : 

Docker has restored the repositories that were unavailable causing CloudBees Jenkins Enterprise (CJE) 1.x controllers and workers to not initialize earlier today.  However, Docker will be permanently shutting down repositories on which CJE1.X relied on March 31, 2020 

In order to avoid controller and worker failures, you must either:
* upgrade to version 1.11.27  OR 
* patch controllers and workers on older versions (The patch can only be applied to versions 1.11.15 and higher.)

For more details, please see the CloudBees Knowledge Base article: https://support.cloudbees.com/hc/en-us/articles/360040577951-Workers-do-not-complete-a-restart-operation.

If left in its current state, after Docker shuts down these repositories on March 31, 2020 CJE 1.X controllers and workers will not initialize. To clarify, these are the virtual machines that are created and managed by the ‘cje’ command line tool, not Operations Center, Managed Masters, nor build agents.

'''Patch récupéré : '''
https://cloudbees-jenkins-scripts.s3.amazonaws.com/cplt2-6275/1.11.26.patch

Appliqué manuellement sur :
* pse_1.11.22
* pse_1.11.26

== Tests de migration d'un Master sur une nouvelle version CJE ==

Faire la migration CJE souhaitée sur TSTCJE1

Importer un Master de Prod sur l'environnement de test en suivant la procédure décrite (connecté jenkins4docker sur lpcjewstedt1): http://wikefluid/index.php/Suivi_des_stages_Process_de_Fabrication#Import_Master_de_Prod_vers_Test

Exemple : ./launchCreateManagedMaster.sh envRecette.properties jenkinsDEV:f4c519dda39d9ef1ca3de610cb06a5af47

Dans le fichier FileDesc à passer en paramètre, bien mettre la version de Master de prod. C'est ce Master, une fois importé, qui sera monté en version cible de l'environnement de test.

Une fois le Master importé, le migrer en suivant la procédure de montée de version des Masters.

Et maintenant, y a plus qu'à tester !!!

== Exploitation ==

=== Modifier la durée de rétention des conteneurs de build sur les workers Mesos slaves ===

* Pour ce besoin, l'option à configurer au niveau mesos-slave est '''docker_remove_delay'''. Sa valeur par défaut est 6hrs. Pour toutes les options possibles, se reporter à http://mesos.apache.org/documentation/latest/configuration/agent/

* Se connecter sur chacun des serveurs mesos-slaves et passer '''root''' : lpcjewkredtX, lpdrogonedt1, lpviseriedt1, lptyrionedt1, lprhaegaedt1

* Se placer dans le répertoire /etc/mesos-slave. Il y a là 1 fichier par option configurable pour un agent mesos, le fichier contenant la valeur du paramètre.

* Lancer la commande :
 echo "1hrs" &gt; docker_remove_delay
ou 
 echo "30mins" &gt; docker_remove_delay
 
* Redémarrer le service mesos-slave : 
 systemctl restart mesos-slave

* Contrôler que le paramètre est bien actif :
 ps -ef | grep delay    =&gt; le paramètre doit apparaitre sur la ligne correspondant au process mesos-slave

=== Intégrer un nouveau worker ===

* Se connecter ulouser sur lpcjewstedt1

* Se placer dans le bon projet : setTst pour TSTCJE1 et setProd pour Prod

* cje prepare worker-add
worker-add is staged - review worker-add.config and edit as needed - then run 'cje apply' to perform the operation.
%

* vim worker-add.config
** Définir worker-x pour identifier le ou les workers à intégrer et y configurer les paramètres demandés:
  count = 1
  workload_type = build
  addresses = &lt;ip address&gt;
  #ssh_identity_file = default
  #ssh_user = ulouser (jenkins4docker pour l'environnement de test)

* cje apply

* cje status pour contrôle

=== Reinitialisation d'un worker ===

Cette procédure permet de remettre complètement à jour 1 worker, si on détecte une ano ou 1 service qui a disparu (ex : logstash conteneur plus présent).
Attention : cette procédure redémarre docker =&gt; éviter de la lancer si activité dessus

* dna init &lt;worker-X&gt;

=== Redémarrage d'un worker ===

* Se connecter ulouser sur lpcjewstedt1

* Se placer dans le bon projet : setTst pour TSTCJE1 et setProd pour Prod

* dna stop &lt;worker-X&gt;

* dna start &lt;worker-X&gt;

=== Redémarrage logstash sur worker ===

Le conteneur logstash est démarré par 1 service =&gt; si problème, passer par les commandes systemctl

* systemctl status cloudbees-logstash

* systemctl restart cloudbees-logstash

=== Arrêt d'un worker temporairement ===

La procédure permettant de désactiver un worker du cluster n'existe plus (cje prepare worker-disable)
Il faut désormais passer par des commandes transmises directement au master Mesos afin de sortir un noeud du cluster (https://mesos.apache.org/documentation/latest/maintenance/).

Pour vérifier si des opérations de maintenance sont déjà en cours sur le Cluster, lancer l'URL suivante : 
  
  http://lpcjecntedt1:5050/maintenance/status

Si pas d'opération en cours, retourne {}
Si des opérations sont en cours, on a une info du genre :
  {"down_machines":[{"hostname":"192.168.118.8","ip":"192.168.118.8"}]}

Cela indique que le serveur d'IP indiquée est down au niveau Cluster, donc sorti.

Les étapes à suivre pour faire une maintenance sur 1 serveur du cluster sont :

* Se connecter sur lpcjewstedt1, compte ulouser, et se placer dans le bon contexte prod ou test : setProd ou setTst

* Préparer le serveur à sortir du cluster : drainage. Pour cela, utiliser le script ./prepare.sh &lt;nomServer&gt;  (ex : ./prepare.sh lprhaegaedt1). Il n'y a rien de spécial à attendre, on peut passer à l'étape suiante (observations : cette étape semble ne servir à rien).
* Sortir le serveur du cluster : mis en mode down. Plus aucun job ne sera provisionné sur ce serveur, si des conteneurs tournent dessus, ils seront stoppés, et reventilés ailleurs par Marathon. Pour cela, utiliser le script ./down.sh &lt;nomServer&gt;  (ex : ./down.sh lprhaegaedt1)
* Une fois la maintenance terminée :
** Remettre le serveur en état : dna init &lt;worker-??&gt; (vérifier le nom du worker via la commande lswkr). Cette étape permet notammet de relancer logstash et redémarrer docker.
**  Remettre le serveur dans le cluster : ./up.sh &lt;nomServer&gt;  (ex : ./up.sh lprhaegaedt1)

=== Suppression d'un worker ===

* Se connecter sur lpcjewstedt1, compte ulouser, et se placer dans le bon contexte prod ou test : setProd ou setTst

* cje prepare worker-remove
=&gt; NE MARCHE PAS DU TOUT =&gt;
https://support.cloudbees.com/hc/en-us/articles/360015997052-Recycling-CJE-1-Anywhere-servers

* Sortir le serveur du cluster maraton : prepare/down
* Stopper tous les servies :
   systemctl disable mesos-slave
   systemctl stop mesos-slave
   systemctl disable cloudbees-logstash
   systemctl stop cloudbees-logstash
   docker rm -v $(docker ps -a -q)
   docker rmi -f $(docker images -qa)

* Stopper docker : 
  systemctl disable docker
  systemctl stop docker


Supprimer les fichiers :
 /etc/.*-installed

Supprimer mesosphere &amp; co :
 yum remove mesosphere-zookeeper-3.4.6-0.1.20141204175332.centos7.x86_64
 yum remove mesos-0.28.2-2.0.27.centos701406.x86_64 mesosphere-el-repo-7-3.noarch


Supprimer les répertoires et tous les contenus:
 rm -rf /etc/zookeeper /etc/jce /etc/mesos* /var/log/router /var/log/mesos /var/lib/mesos*

* Faire un up.sh de fin de maintenance
* Contrôler que l'agent a bien été supprimé de la liste : 
 cje run support-mesos ms-slaves | grep hostname

Voir commande cje run support-mesos pour plus de détails

Supprimer le worker côté workstation
* cje prepare worker-remove

* Supprimer les montages NFS :
 umount /nfs /nfstst1
 cat /etc/fstab et supprimer : 
  lpnfssan1-edt:/NFS_SHARE_UL_DTA2_A04 /nfstst1 nfs defaults,soft,intr 0 0
  lpnfssan1-edt:/NFS_SHARE_UL_DTA_A04 /nfs nfs defaults,soft,intr 0 0

Pour purger les "DELETED" workers : 
 https://support.cloudbees.com/hc/en-us/articles/115000634632-How-to-purge-deleted-workers-

=== Redémarrage d'un worker temporairement ===

* Se connecter ulouser sur lpcjewstedt1

* Se placer dans le bon projet : setTst pour TSTCJE1 et setProd pour Prod

* cje prepare worker-enable

* vim worker-enable.config
** Définir worker-x pour identifier le ou les workers à remettre en service.

* cje apply

* dna start &lt;worker-X&gt;

* cje status pour contrôle


=== Réinitialiser le LV thinpool docker sur un worker (OBSOLETE avec overlay2) ===

Cette procédure est à suivre en cas de survenue trop fréquente d'alertes Nagios indiquant une saturation du thinpool docker (cf lvs)

* Sortir le noeud en question du cluster CJE
** Se connecter ulouser sur lpcjewstedt1
** Se placer dans le bon projet : setTst pour TSTCJE1 et setProd pour Prod
** cje prepare worker-disable
 worker-disable is staged - review worker-disable.config and edit as needed - then run 'cje apply' to perform the operation.
 %
** vim worker-disable.config
 Définir worker-x pour identifier le serveur à sortir 
** cje apply
*  Supprimer le LV sur le serveur cible
** Se connecter sur le serveur en question et arrêter docker
 sudo systemctl stop docker 
** Supprimer le VG (ca détruira le LV aussi)
 sudo vgremove docker
 =&gt; répondre yes aux deux questions
 sudo rm -rf /var/lib/docker/*
*  Recréer le LV sur le serveur cible grâce au playbook ansible
** Depuis un serveur Linux du repo oracleTools, se placer dans le répertoire ansible et jouer le playbook dockerservers.yml
 cd ansible
 ansible-playbook -i inventory/common --ask-vault-pass -e @inventory/ul/vault.yml -e "variable_host=&lt;serveurCible&gt;" dockerservers.yml


* Réintégrer le noeud dans le cluster CJE
** Se connecter ulouser sur lpcjewstedt1

** Se placer dans le bon projet : setTst pour TSTCJE1 et setProd pour Prod

** cje prepare worker-enable
worker-enable is staged - review worker-enable.config and edit as needed - then run 'cje apply' to perform the operation.
%
** vim worker-enable.config
 Définir worker-x pour identifier le serveur à sortir 

** cje apply

** dna init worker-x (permet de remettre le worker à niveau après ré-intégration)

== Monitoring ==

Evaluation en cours : https://blog.eleven-labs.com/fr/monitorer-ses-containers-docker/

=== cadvisor ===
Attention, ne pas lancer cadvisor en mode docker, car lock les volumes et empêche les conteneurs monitorés d'être supprimés =&gt; DEAD

Pour les serveurs CJE : cadvisor binaire Go présent sur /nfs/cje-share-dir/tools

Démarrage de cadvisor sur chaque serveur à monitorer :
   sudo /nfs/cje-share-dir/tools/cadvisor -port 8085&amp;

Déjà en place :

 http://lpcjemtredt1:8085/containers
 http://lpcjemtredt2:8085/containers
 http://lpcjemtredt3:8085/containers
  http://lpcjewkredt1:8085/containers
  http://lpcjewkredt2:8085/containers
  http://lpcjewkredt3:8085/containers
  http://lpcjewkredt4:8085/containers
  http://lpviseriedt1:8085/containers
  http://lpdrogonedt1:8085/containers
  http://lprhaegaedt1:8085/containers
  http://lptyrionedt1:8085/containers



Et pour les env NB/INT :
#  http://noobaleine:8085/containers/
 http://ironwhale:8085/containers/
#  http://lpdocedt8:8085/containers/

=== prometheus ===

https://prometheus.io/docs/prometheus/latest/installation/

A installer...

== Suivi des versions ==

{| class="wikitable"
|-
! CJE workstation !! Version CJOC !! Version Master !! cje_prod_1_project !! tstcje1_project
|-
| pse_1.7.0 || 2.46.3.2-rolling || cloudbees/cje-mm:2.46.3.2 ||style="text-align:center;"| X ||style="text-align:center;"|n/a
|-
| pse_1.7.1 || 2.60.1.1-rolling || cloudbees/cje-mm:2.60.1.1 ||style="text-align:center;"| X ||style="text-align:center;"|X
|-
| pse_1.8.0 || 2.60.2.2-rolling || cloudbees/cje-mm:2.60.2.2 ||style="text-align:center;"| X ||style="text-align:center;"|X
|-
| pse_1.9.0 || 2.60.3.1-rolling || cloudbees/cje-mm:2.60.3.1 ||style="text-align:center;"| X ||style="text-align:center;"|X
|-
| pse_1.9.1 || 2.73.1.2-rolling || cloudbees/cje-mm:2.73.1.2 ||style="text-align:center;"| X ||style="text-align:center;"|X
|-
| pse_1.11.16 || 2.164.1.2-rolling || cloudbees/cje-mm:2.164.1.2 ||style="text-align:center;"| X ||style="text-align:center;"|X
|-
| pse_1.11.22 || 2.176.4.3-rolling || cloudbees/cje-mm:2.176.4.3 ||style="text-align:center;"| X ||style="text-align:center;"|X
|-
| pse_1.11.26 || 2.204.4.2-rolling || cloudbees/cje-mm:2.202.4.2 ||style="text-align:center;"| A finaliser||style="text-align:center;"|X
|-
| pse_1.11.29 || 2.222.1.1-rolling || cloudbees/cje-mm:2.222.1.1 ||style="text-align:center;"| TODO ||style="text-align:center;"|test en cours
|}

==== Résumé migration à 2.176.4 ====

=====Actions=====

*'''Monter de version  permissive security script en version 0.6'''
*'''Ajouter -Dpermissive-script-security.enabled=no_security en argument de la JVM des masters'''


=====Impacts étudiés de la montée de version :=====

*Guide de migration : https://jenkins.io/doc/upgrade-guide/2.176/

* &lt;del&gt;Montée de Git client plugin en 2.7.7.1 préconisée (beekeeper assistant) =&gt; depuis update center master : vérifier puis appliquer et redémarrer le master. A faire sur chaque master. &lt;/del&gt; Ne pas faire car problème de dépendances ensuite sur pas mal de plugins du bundle

* Montée du  Security Plugin en version 1.63: 
::''Impacts''
::: Nouvelles signatures définies comme problématiques
::: Le [https://plugins.jenkins.io/permissive-script-security permissive security script] verison 0.3 loggue à présent toutes les signatures problématiques même celles whitelistées. 
::''Résolution''
::: Monter la version du permissive security script en version 0.6 afin de ne pas logguer les signatures whitelistées. 
::: Passer la propriété -Dpermissive-script-security.enabled=no_security à la JVM des master afin d'accepter les scripts dont les signatures ne sont pas whitelistés sans log dans la console.

* Amélioration de la protection CSRF:
&lt;blockquote&gt;"CSRF tokens (crumbs) are now only valid for the web session they were created in to limit the impact of attackers obtaining them. Scripts that obtain a crumb using the /crumbIssuer/api URL will now fail to perform actions protected from CSRF unless the scripts retain the web session ID in subsequent requests."&lt;/blockquote&gt;  
::La crumbIssuer  api est utilisée dans les jobs d'action sur les master (stop/start/restart...) et dans le job verifiant les job en cours depuis trop longtemps.
::Les tests sur tstcje1 en 2.176.4 montrent que ces jobs ne sont pas impactés par l'amélioration de la protection CSRF.

*Autres problèmes rencontrés lors des tests : (problèmes de configuration de la plateforme de tests)
::- Evt 299037 : git Host key verification failed.
::- Credentials non présents ou mot de passe erroné
::- Manque settings-frontal.xml dans /nfs/cje-share-dir/tool/maven/conf
::- Manque des settings d'authentification à rartifactorydocker.efluid.uem.lan dans /nfs/cje-share-dir/registryCredentials/.docker/config.json
::- Problème de time zone :  set user.timezone=Europe/Paris dans les system properties du master
::- Tests nécessitant l'usineLogicielleRelease de Prod: exclusion des ces tests dans les changes gerrit [https://gerrit.efluid.uem.lan/c/jenkinsSharedLibrary/+/116523 116523] et [https://gerrit.efluid.uem.lan/c/jenkinsConfigurations/+/116499 116499]

== Configuration pour environnement efluid ==

=== Using private Docker registries ===

* Pour permettre de "puller" nos images customs dans l'Artifactory depuisles Agent CJE, il faut préparer un "credential package" et le rendre accessible de tous les Workers via le partage NFS.
  * Pour créer le "credentials package": il faut archiver dans un fichier docker.tar.gz le contenu du répertoire .docker (.docker/config.json) contenant le credential suivant: 
 [root@lprhaegaedt1 nfs]# cd
 [root@lprhaegaedt1 ~]# cd .docker/
 [root@lprhaegaedt1 .docker]# ll
 total 4
 -rw------- 1 root root 173 13 juil. 21:34 config.json
 [root@lprhaegaedt1 .docker]# cat config.json
 {
   "auths": {
     "partifactorydocker.uem.lan": {
       "auth": "dXNpbmVsb2dpY2llbGxlOkFQOXh4VzU4ZEJKWkRBTFNLbjdua1A2NlM2TA==",
       "email": "info@xyz.com"
     }
   }
 }

=&gt; 
 $ tar -tvf ~/docker.tar.gz
   drwx------ root/root         0 2015-07-28 02:54 .docker/
   -rw------- root/root       114 2015-07-28 01:31 .docker/config.json
   
Ensuite, il faut configurer au niveau de chaque "Docker Agent Template" le champ "'''Additional URI'''" avec le chemin d'accès à ce "credential package" et sélectionner "'''Extract'''":

[[image:additionalURI.png|400px|]]


'''Note: cette archive est disponible dans le repo Git: cjeConfigurations/registryCredentials'''

=== Volumes requis dans les images Agent template docker ===

Chaque image doit définir les volumes dont elle aura besoin en fonction des tâches à exécuter, celles-ci ayant besoin de disposer de ressources locales dans les conteneurs. Les volumes suivants ont été identifiés (motivation donnée pour chaque volume):

* L'utilisateur dans l'image doit être jenkins

* Remote root directory = /home/jenkins

* '''/nfs/cje-share-dir/tools/maven/conf:/opt/mvnDockerDefault/conf'''
=&gt; requis pour la configuration Maven permettant l'authentification de UsineLogicielle à l'Artifactory (settings.xml) dans les jobs.

* '''/nfs/cje-share-dir/cloneReferentiels:/data/EDT/cloneReferentiels '''
=&gt; pour des raisons de performance, permetde faire des Git shallow clone dans les jobs.

* '''/nfs/cje-share-dir/registryCredentials/.ssh_jenkins:/home/jenkins/.ssh'''
=&gt; permet de disposer des clés ssh du user d'id 1000 dans son HOME (monté) pour permettre les commandes ssh (ssh, scp, git): toute commande n'utilisant pas les "credentials Jenkins via plugin SSH-agent"

* '''/nfs/workspaces/workspaceTST1:/home/jenkins/work'''  (+ définir "Remote root directory"=/home/jenkins/work)
=&gt; permet de disposer d'un workspace sur partage NFS (hors conteneur). Ce workspace sert de synchro entre PROD et TST1: sur le PROD, /nfs/workspaces/workspaceTST1 est un lien vers /nfstst1/workspaces/workspaceTST1).

==== Dans le cas ou l'on veut faire du docker depuis un agent template ====

* Dans ce cas de figure l'utilisateur de l'image doit etre root, car il faut pouvoir écrire dans /mnt/mesos/sandbox/jenkins

* Remote root directory = /mnt/mesos/sandbox/jenkins

* '''/nfs/cje-share-dir/registryCredentials/.docker:/root/.docker ''' en readonly
=&gt; permet de disposer des credentials pour les commandes docker faites depuis les pipelines dans les conteneurs (pull, push)

* '''/var/run/docker.sock:/var/run/docker.sock''' 
=&gt; permet de contacter le démon docker de l'hote depuis un slave contenant le client Docker pour ne pas faire du "Docker in Docker".

=== CJOC Update Center ===

Pour permettre la mise à jour régulière du CJOC (interrogation de l'UpdateCenter Cloudbees), il est nécessaire de configurer le proxy HTTP. Pour cela, aller dans "Administrer Jenkins" -&gt; "Gestion des plugins" -&gt; Onglet "Avancé"

Saisir les informations suivantes (user pour le proxy: '''usinelogicielle'''):

[[image:httpProxyPlugin.png |1200px|]]

=== Update Credentials ===

Une fois une installation CJE terminée (depuis poste lpcjewstedt1) et LDAP configuré (depuis GUI CJOC), le mot de passe administrateur utilisé lors de l'installation n'est plus valide au niveau du projet sur le poste CJE Workstation. Il faut alors mettre à jour les credentials avec un user permettant une connexion au CJOC.

Se connecter '''ulouser''' sur poste lpcjewstedt1 et sélectionner le projet dans lequel on souhaite faire la mise à jour.

Depuis $PROJECT:
 [ulouser@lpcjewstedt1 tstcje1_project]$ cje prepare credentials-update

Modifier le fichier .dna/secrets pour reconfigurer les properties '''cjoc_username''' et '''cjoc_password'''

Appliquer la modification:
 [ulouser@lpcjewstedt1 tstcje1_project]$ cje apply


=== Update cjoc et managed masters UID ===

Ticket 51488: https://support.cloudbees.com/hc/en-us/requests/51488?page=1

Se connecter ulouser sur la CJE Workstation. Se placer dans le bon projet à modifier.

Editer le fichier .dna/project.config et modifer les valeurs attendues. 

Ensuite, appliquer :
 [ulouser@lpcjewstedt1 tstcje1_project]$ cje upgrade --config-only --force

=== Système de synchronisation des templates de jobs ===

Les templates sont centralisés: 
* http://cje.efluid.uem.lan/usineadministration/job/FjobsTemplate/

De plus, 1 job permet de synchroniser ces templates de UA vers UsineTarget à préciser: 
* http://cje.efluid.uem.lan/usineadministration/job/FjobsTemplate/job/jenkins.synchronize-template-between-master/. 

Ce job est à appeler par toute usine souhaitant récupérer une synchro de template.
Exemple: 
* http://cje.efluid.uem.lan/usinedeploiement/job/FjobsUtilitaires/job/template.orchestrate-template-synchronized-from-UA-to-UD/build?delay=0sec


=== Backups ===
Tous les Masters sont backupés au travers de jobs "Cluster Operations", qui permettent de lancer une opération d'exploitation depuis le CJOC sur l'ensemble des Managed Masters créés dans le Cluster Mesos.
Les backups de chaque master sont faits en 2 étapes: 
* Backup système: http://cje.efluid.uem.lan/cjoc/view/All/job/backup.system/
* Backup des jobs: http://cje.efluid.uem.lan/cjoc/view/All/job/backup.jobs/

Les backups réalisées (format tar.gz) sont transférés sur NFS (/nfs/backups/&lt;cjeCluster&gt;) via sftp sur le serveur lpcjewstedt1, en utilisant le compte jenkins4docker (credential créé avec sa clé privée saisie directement depuis l'interface Jenkins).

Ces 2 jobs sont déclenchés tous les soirs avec une rétention de 7 jours.

=== Logger des masters ===

Pour arrêter les logs de niveau INFO trop verbeux sur les masters (/var/lib/dockre/containers/*.json) du Logger "org.jenkinsci.plugins.permissivescriptsecurity.PermissiveWhitelist", un script Groovy a été ajouté dans /nfs/cje-share-dir/init.groovy.d-all/logging.groovy :
 import java.util.logging.LogManager
 import java.util.logging.Logger
 import jenkins.model.Jenkins
 import java.util.logging.Level
 def logger = Logger.getLogger("org.jenkinsci.plugins.permissivescriptsecurity.PermissiveWhitelist")
 logger.setLevel(Level.WARNING)
 LogManager.getLogManager().addLogger(logger)

Un lien (hard) a ensuite été créé dans le jenkins_home de chaque Master pour profiter de ce fichier :
 Se connecter sur 1 lpcjemtredtX en tant que jenkins4docker
 cd /nfs/usinerecette/jenkins_home/init.groovy.d
 ln /nfs/cje-share-dir/init.groovy.d-all/logging.groovy logging.groovy

== Tips ==
=== Création d'un nouveau MASTER ===

La création d'un nouveau Master se fait depuis l'interface du CJOC. Mais lors de la mise en oeuvre du Cluster CJE, le user utilisé était ulouser (uid:500).
Ce user a ensuite été modifié à jenkins4docker (uid=1000) pour le démarrage des Master et Agent. Mais lors de la création d'un nouveau Master, le répertoire sur NFS de ce nouveau Master est toujours fait avec ulouser comme propriétaire: cd /nfs; ls -altr
Ceci empêche le Master de démarrer car il n'est pas propriétaire (jenkins4docker) du répertoire mis à disposition (ulouser). Pour observer ce phénomène:
* Créer 1 nouveau Master
* Se connecter root sur lpcjemtredt1 ou 2 ou 3
* docker ps -a =&gt; on voit les tentatives de démarrage du master créé, mais en echec
* docker logs &lt;contenerId du dernier failed&gt;
 
 Curl_http_done: called premature == 0
 Connection #0 to host localhost left intact
 DEPLOY GROOVY INIT SCRIPTS
 ln: failed to create symbolic link '/var/jenkins_home/configure-jenkins.groovy.d': Permission denied
 cp: cannot create directory '/var/jenkins_home/configure-jenkins.groovy.d': Permission denied
 
CORRECTION: '''chown -R jenkins4docker /nfs/&lt;nomDuNouveauMaster&gt;'''

=&gt; Le master démarrera automatiquement.

==== Complément à ajouter dans le jenkins_home des masters ====
Le plugin LogParserPublisher nécessite la présence d'un fichier de règles, qui ne sera lu qu'à partir du master.
* création d'un lien physique du fichier se trouvant sur le nfs vers le jenkins_home. Permet de partager le même fichier de règle entre les masters.
** se connecter en tant que root : 
** mkdir -p /nfs/&lt;nomMaster&gt;/jenkins_home/interneUL/rules 
** chown -R ulouser:docker /nfs/&lt;nomMaster&gt;/jenkins_home/interneUL
** se connecter en tant que ulouser
** ln /nfs/cje-share-dir/interneUL/rules/bdd_parse_error.rule /nfs/&lt;nomMaster&gt;/jenkins_home/interneUL/rules/bdd_parse_error.rule
&lt;br&gt;
* Copier le fichier /nfs/&lt;nomMaster&gt;/jenkins_home/.groovy/grapeConfig.xml d'un autre master vers le nouveau master
* Créer le repertoire (avec les bon droits) /nfs/&lt;nomMaster&gt;/jenkins_home/.groovy/grapes
* Vérifier la présence du répertoire /nfs/&lt;nomMaster&gt;/jenkins_home/.groovy/grapes/com.oracle après le lancement du premier job car apparemment celui-ci n'est pas encore récupéré automatiquement
&lt;br&gt;
* Copier le répertoire ssh d'un master existant vers le nouveau : /nfs/&lt;nomMaster&gt;/jenkins_home/.ssh

==== Configuration à faire dans le master (dans jenkins) ====
* Au premier démarrage du master, fermer la fenêtre d'installation des plugins car on ne peut pas le faire par la, il faut se rendre directement sur l'interface classique de jenkins
* Activer l'update automatique au démarrage des plugins dans le beekeeper assistant (sinon les plugins bundles genre Pipeline API ne seront pas la et rien ne marchera)
* Ajouter les plugins nécessaires en se basant sur une liste de plugins d'un autre master
* Recopier la configuration de l'administration du master à partir d'un autre master
* Recopier la configuration du serveur Gerrit du master à partir d'un autre master
* Recopier la configuration de l'administration de sécurité du master à partir d'un autre master

==== Redémarrage ====
Une fois toutes les opérations précédentes réalisées, il faut absolument faire un redemarrage du master sinon des configurations de plugins par exemple ne seront pas prise en compte, et on obtiendra des erreurs bizarres

=== Configuration TimeZone ===

==== Sur un Master ====
Au niveau de la configuration d'un Master, dans les paramètres avancés de l'image, ajouter dans la partie System Properties (param pris en compte par la JVM): org.apache.commons.jelly.tags.fmt.timeZone=Europe/Paris

Redémarrer le Master pour prise en compte depuis l'interface CJOC =&gt; Manage-&gt;Restart

==== Sur le CJOC ====

Se connecter ulouser sur lpcjewstedt1 et se placer dans le bon projet (ex: /data/EDT/files/cje_prod_1_project).

S'assurer que la variable d'environnement PROJECT pointe bien sur ce répertoire.

Préparer la configuration CJOC
  $ cje prepare cjoc-update

Editer le fichier cjoc-update.config et modifier la valeur jvm_options:
  jvm_options = -Xmx1024m -XX:+PrintGCDetails -Dorg.apache.commons.jelly.tags.fmt.timeZone=Europe/Paris

Sauver et quitter.

Lancer la configuration :
  $ cje apply

=&gt; Le cjoc sera redémarré en utilisant le TimeZone configuré.

=== Create a Jenkins Slave Docker Image ===

To create a slave image. The image should contain the following minimum configurations to act as a slave.
# sshd service running on port 22.
# Jenkins user with password.
# All the required application dependencies for the build. For example, for a java maven project, you need to have git, java, and maven installed on the image.

Make sure sshd service is running and can be logged into the containers using a username and password. Otherwise, Jenkins will not be able to start the build process.

=== Comment configurer le proxy HTTP sur le CJOC pour l'updateCenter ? Car var dans le conteneur ===

[[image:httpProxyConf.jpg|600px|]]


=== Composants actifs sur une plateforme CJE ===

[[image:composants.jpg|700px|]]

=== Déclencher un build via API REST ===

Il faut que l'utilisateur existe sur le master où on souhaite déclencher le build. 
L''''api token''' se génère via le profil d'utilisateur dans Jenkins.

* Récupérer le crumb pour pouvoir utiliser l'api
  curl -sS -XGET --user &lt;username&gt;:&lt;api token&gt; '&lt;masterUrl&gt;/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,":",//crumb)' &gt; crumb

* Déclencher le build 
  curl -sS -XPOST --user &lt;username&gt;:&lt;api token&gt; -H "$(cat crumb)" "&lt;masterUrl&gt;/&lt;job&gt;/build"

=== Pipeline from scm ===
* Attention à la petite case à cocher "lightweight checkout" dans les pipeline from scm du CJE, ça risque de foutre la merde, par défaut il ne faut pas la cocher, et voir ensuite au cas par cas (en gros il ne fait pas de checkout du référentiel et il recupere un jenkinsfile directement dans un cache certainement)

=== Faire du JmxRemote dans un job CJE en parant d'un Jenkinsfile ===
* Pour cela il faut valoriser les paramètres suivants dans le job (attention un seul job peut-etre lancé à la fois à cause du mapping de port)
** activeJmxRemote : true
** jmxRemotePort : une valeur entre 31000 et 32000 (si non saisi alors c'est 31010 par défaut)
** jmxRemoteHost : le nom du Worker ou va être lancé le job (pas facile à connaitre à priori ...) =&gt; si cette valeur n'est pas positionné alors jenkins la valorise tout seul
** nodeLabel : utiliser le nom d'un template Docker dans lequel un mapping de port a été effectué en prenant la valeur de jmxRemotePort

=== Cache des masters pour la jenkinsSharedLibrary ===

Après redémarrage d'un master, on peut avoir des erreurs de load de driver jdbc qui utilise l'annotation Grab en groovy.
Il semblerait que cette annotation se base sur le cache du master. Au redémarrage ce dernier étant vidé, les drivers ne sont plus présent.
Pour palier à ce soucis, il faut recharger les driver de manière brute comme dans l'exemple suivant : http://gerrit.uem.lan/#/c/69213/18/src/com/efluid/bdd/legacy/BddFunc.groovy

=== ELK en erreur ===
Si les dashboards CJE (build analytics) ne fonctionne plus alors voici des astuces/pages d'aides à la résolution du problème
* Case Cloudbees de référence : https://support.cloudbees.com/hc/en-us/requests/57029
* Faire un check de l'état du cluster
** Se rendre sur la workstation lpcjewstedt1
** Se mettre en utilisateur ulouser
** Se mettre sur la prod : setProd
** Lancer le script de check :  '''./checkElkStatus.sh'''
** Ce script va donner un retour de l'état du cluster, dans l'atribut json status, si c'est rouge pas bon !
** Il faut ensuite regarder s'il y a des shared non assignés, et pour cela faire un ''cat shards.txt'' et regarder les lignes UNASSIGNED, s'il y en a =&gt; pas bon !
** Il existe une procédure pour les ré-assigner ici : https://support.cloudbees.com/hc/en-us/articles/115000089811-ElasticSearch-troubleshooting-guide  =&gt; rubrique '''Unassigned Shards''', cela peut corriger le problème =&gt; '''./fixEsShards.sh''' , il faut ensuite refaire un check status pour voir si ça repasse vert
** Si c'est toujours pas vert alors il va falloir supprimer les index en erreur, pour cela la doc précédente propose une solution, qui consiste à lancer le script  ./deleteRedIndices.sh (sans le mode DRY RUN)
 DRY_RUN=false ./deleteRedIndices.sh

Après tout cela l'état du cluster doit redevenir vert, mais par contre les dashboard Kibana sont potentiellement plus la, pour les reconstruire il faut redemarrer le CJOC.
Si besoin de réindexer les masters alors il faut lancer une tache de réindexation via le CJOC comme décrit ici : “Reindexing for CloudBees Jenkins Analytics” section here: https://go.cloudbees.com/docs/cloudbees-documentation/cjoc-user-guide/index.html#analytics

=== ELK : suppression de SNAPSHOTS si saturation des inodes/espace ===
** Se rendre sur la workstation lpcjewstedt1
** Se mettre en utilisateur ulouser
** Se mettre sur la prod : setProd
** Lancer la suppression en indiquant en paramètre le nombre de SNAPSHOT que l'on souhaite garder (si pas de param, 30 par défaut)  :  '''./deleteEsSnapshots.sh [NBtoKEEP]'''

== Inspect d'un Master dans CJE ==

Montages volumes:

 Source: /var/lib/mesos/slaves/a68f9de8-c267-42c5-94a4-683c5a4072e2-S11/frameworks/a68f9de8-c267-42c5-94a4-683c5a4072e2-0000/executors/masters_demomaster2.744bd770-5c17-11e7-a4e8-02425ce5de65/runs/8339d825-6eaf-43df-a797-16da03775581
 Destination: /mnt/mesos/sandbox

  Source: /var/lib/docker/volumes/fd8d6aba668f0904510926214b5bb76ee810e7438039513fd53ddee553856608/_data
  Destination: /var/jenkins_home

Variables: 
            "Env": [
                "MARATHON_APP_VERSION=2017-06-28T15:35:46.222Z",
                "HOST=192.168.106.234",
                "MARATHON_APP_RESOURCE_CPUS=0.1",
                "PORT_10012=31077",
                "MARATHON_APP_DOCKER_IMAGE=cloudbees/cje-mm:2.46.3.2",
                "MESOS_TASK_ID=masters_demomaster2.744bd770-5c17-11e7-a4e8-02425ce5de65",
                "PORT=31075",
                "MARATHON_APP_RESOURCE_MEM=1024.0",
                "PORT_10011=31076",
                "PORTS=31075,31076,31077",
                "PORT1=31076",
                "MARATHON_APP_RESOURCE_DISK=0.0",
                "MARATHON_APP_LABELS=",
                "PORT_10010=31075",
                "MARATHON_APP_ID=/masters/demomaster2",
                "PORT0=31075",
                "PORT2=31077",
                "MESOS_SANDBOX=/mnt/mesos/sandbox",
                "MESOS_CONTAINER_NAME=mesos-a68f9de8-c267-42c5-94a4-683c5a4072e2-S11.8339d825-6eaf-43df-a797-16da03775581",
                "EVALUATION_MODE=no",
                "JAVA_OPTS=-Xmx716m -Xms716m -DMASTER_GRANT_ID=\"512692bb-175b-42cf-bd07-eacfb39ca063\" -Dhudson.slaves.NodeProvisioner.initialDelay=\"0\" -DMASTER_INDEX=\"1\" -DMASTER_OPERATIONSCENTER_ENDPOINT=\"http://cje.efluid.uem.lan/cjoc/\" -DMASTER_NAME=\"demomaster2\" -DMASTER_ENDPOINT=\"http://cje.efluid.uem.lan/demomaster2/\"",
                "JENKINS_OPTS=--prefix=/demomaster2/",
                "SIGNATURE=ak0VNh+/zNVIoUHQj63fIzQxR1eVLTD05UyK8ZavOuBCGKJ78JQVQKx6euyWajD4qDVdJURSiXAwJ2eKt7a9YGdlGcfPpHcAl6DAF8XJxTLTfoLy2FURcUg/dqncaPF9zE0w/mK2qRP2ZCx2FnOnmTmMK93s9A+jUzELaYl9lKDMx8OVtBFsxShZQNdoWG8aWFNlnGHI+EA+MckH0YIqARU+LWSnd15UEKLOq9A+w1GaUhLMI2sjpTaWFlujwfc13HwOD3GlGGGUFGQL7wylRUvJxGs90dCANDIDys+Vr7U1oA0O2cxMcBgUrbDXAqNqewn7+Ny9UGb15pe91M2cWQ==",
                "TENANT=demomaster2",
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "LANG=C.UTF-8",
                "JAVA_HOME=/docker-java-home",
                "JAVA_VERSION=8u131",
                "JAVA_DEBIAN_VERSION=8u131-b11-1~bpo8+1",
                "CA_CERTIFICATES_JAVA_VERSION=20161107~bpo8+1",
                "JENKINS_HOME=/var/jenkins_home",
                "JENKINS_SLAVE_AGENT_PORT=50000",
                "TINI_VERSION=0.9.0",
                "TINI_SHA=fa23d1e20732501c3bb8eeeca423c89ac80ed452",
                "MESOS_VERSION=0.28.2*",
                "REF_DIR=/usr/share/jenkins/ref",
                "VOLUME_SERVICE=http://localhost:31080",
                "HOME_DIR=/usr/share/jenkins/home",
                "CACHE_DIR=/tmp/jenkins",
                "COPY_REFERENCE_FILE_LOG=/var/jenkins_home/copy_reference_file.log",
                "TRY_UPGRADE_IF_NO_MARKER=true"
            ],

== Monitoring ==
* Charge des Workers : [[Perf_cje]]

== Jacoco ==
Mettre en place la couverture de test sur un master : 

* modifier les paramètres Java du master et ajouter :  -javaagent:/var/jenkins_home/jacoco/jacocoagent.jar=destfile=/var/jenkins_home/jacoco/result/jacoco.exec,append=false,includes=com.efluid.*,excludes=*#*cps*,classdumpdir=/var/jenkins_home/jacoco/classDumpDir
** Essayer avec excludes=**/*/___cps*

Puis générer le rapport de test (après avoir récupérer le .exec et le classDumpDir)

* java -jar lib/jacococli.jar report result/jacoco.exec --classfiles classDumpDir/ --html html

== Docker agent template (sur CJE PROD) ==
* efluid : 20 CPU, 10Go RAM
* migefluid : ?
* suivefluid / enercom / ethaque / eldap / ael / efluid.net : 5 CPU, 4Go RAM
* archi / edk / ecore / edoc : 5 CPU, 4Go RAM
* base : 1CPU, 1Go RAM

=&gt; en terme de agent docker template
* XXX-base =&gt; 1CPU, 1G RAM
* XXX-2G =&gt; 3CPU, 2G RAM
* XXX-4G =&gt; 6CPU, 4G RAM
* XXX-6G =&gt; 10CPU, 6G RAM
* XXX-10G =&gt; 20CPU, 10Go RAM

=== agent-socle-jenkins-maven-docker-13-10G===
Fonctionne avec USER ROOT, et le workspace arrive sous /data au niveau du Host
* labels : socle-jenkins-maven-docker-13-10G
* CPU : 1
* Memory : 40000
* JVM Memory : 512
* Filesystem : /mnt/mesos/sandbox/jenkins
* Image : partifactorydocker.uem.lan/socle-jenkins-maven-docker:3.3.9.6-1
* Additional URI : file:///nfs/cje-share-dir/registryCredentials/docker.tar.gz + Extract
* Volumes :
** /nfs/cje-share-dir/tools/maven/conf:/opt/mvnDockerDefault/conf
** /nfs/cje-share-dir/cloneReferentiels:/data/EDT/cloneReferentiels
** /nfs/cje-share-dir/registryCredentials/.ssh_jenkins:/root/.ssh
** /nfs/cje-share-dir/registryCredentials/.docker:/root/.docker RO
** /var/run/docker.sock:/var/run/docker.sock
** /dev/shm:/dev/shm
* Parameters :
** cpus : 8.0

=== agent-socle-jenkins-maven-docker-13-4G ===
Fonctionne avec USER ROOT, et le workspace arrive sous / au niveau du Host
* labels : socle-jenkins-maven-docker-13-4G
* CPU : 1
* Memory : 4096
* JVM Memory : 512
* Filesystem : /mnt/mesos/sandbox/jenkins
* Image : partifactorydocker.uem.lan/socle-jenkins-maven-docker:3.3.9-6
* Additional URI : file:///nfs/cje-share-dir/registryCredentials/docker.tar.gz + Extract
* Volumes :
** /nfs/cje-share-dir/tools/maven/conf:/opt/mvnDockerDefault/conf
** /nfs/cje-share-dir/cloneReferentiels:/data/EDT/cloneReferentiels
** /nfs/cje-share-dir/registryCredentials/.ssh_jenkins:/root/.ssh
** /nfs/cje-share-dir/registryCredentials/.docker:/root/.docker  RO
** /var/run/docker.sock:/var/run/docker.sock
** /dev/shm:/dev/shm

=== agent-socle-jenkins-maven-docker-13-10G-NONROOT ===
Fonctionne avec USER Jenkins, et le workspace arrive sous /data au niveau du Host
* labels : socle-jenkins-maven-docker-13-10G-NONROOT
* CPU : 1
* Memory : 40000
* JVM Memory : 512
* Filesystem : /home/jenkins
* Image : partifactorydocker.uem.lan/socle-jenkins-maven-docker-nonroot:3.3.9-6
* Additional URI : file:///nfs/cje-share-dir/registryCredentials/docker.tar.gz + Extract
* Volumes :
** /nfs/cje-share-dir/tools/maven/conf:/opt/mvnDockerDefault/conf
** /nfs/cje-share-dir/cloneReferentiels:/data/EDT/cloneReferentiels
** /nfs/cje-share-dir/registryCredentials/.ssh_jenkins:/home/jenkins/.ssh
** /nfs/cje-share-dir/registryCredentials/.docker:/home/jenkins/.docker  RO
** /var/run/docker.sock:/var/run/docker.sock
** /dev/shm:/dev/shm
** /data/mesos/sandbox/workspaces:/home/jenkins/workspace

=== agent-socle-jenkins-maven-13-2G ===
Fonctionne avec USER Jenkins, et le workspace arrive sous / au niveau du Host
* labels :socle-jenkins-maven-13-2G
* CPU : 1
* Memory : 2048
* JVM Memory : 128
* Filesystem : /home/jenkins
* Image : partifactorydocker.uem.lan/socle-jenkins-maven:3.3.9-6
* Additional URI : file:///nfs/cje-share-dir/registryCredentials/docker.tar.gz + Extract
* Volumes :
** /nfs/cje-share-dir/tools/maven/conf:/opt/mvnDockerDefault/conf
** /nfs/cje-share-dir/cloneReferentiels:/data/EDT/cloneReferentiels
** /nfs/cje-share-dir/registryCredentials/.ssh_jenkins:/home/jenkins/.ssh
** /dev/shm:/dev/shm


== Recette CJE post migration ==

* Valider que les backup fonctionnent toujours : 
** http://cje.efluid.uem.lan/cjoc/view/All/job/Fadmin/job/backup.system/
** http://cje.efluid.uem.lan/cjoc/view/All/job/Fadmin/job/backup.jobs/

* Valider que la sharedLibrary compile toujours :
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FsharedLibrary/job/jenkinsSharedLibrary.compile/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FsharedLibrary/job/jenkinsSharedLibrary.validation-gerrit/

* Valider que les jobs du jenkinsConfiguration fonctionnent toujours:
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluid-create-dynamic-bdd/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluid-UEM_NONREG_JENKINSCONFIG_EMBEDDED_V13_restart_application/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluid.changeCacheApplication-DEV_UEM_NONREG_JENKINSCONFIG_EMBEDDED/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluid.compile-dev_nonRegJenkins_141100/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluid.launch-batchs-UEM_NONREG_JENKINSCONFIG_EMBEDDED/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluid.testIntegration-dev_nonRegJenkins_141100/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluid.upgradeBddDev-dev_nonRegJenkins_141100/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluid.validation-gerrit/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/efluidnet.validation-gerrit/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/enercom.launch-batchs-DEV_UEM_MOB_NB_MAINTENANCE_V13/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/suite-efluid.orchestrate-deploy-weblogic-DEV-ENEDIS-TST-SUP-1/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/suite-efluid.orchestrate-nightly-build-workflow-develop-UEM-NONREG_JENKINSCONFIG_WEBLOGIC/
** http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/FjenkinsConfigurationNonReg/job/suite-efluid.orchestrate-nightly-build-workflow-develop-UEM_NONREG_JENKINSCONFIG_EMBEDDED/

* Valider que la validation du jenkinsConfiguration fonctionne toujours:
** tous les jobs qui commencent par http://cje.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/job/jenkinsConfiguration.test-

* Validation des plugins:
** les jobs du dossier http://cje.efluid.uem.lan/usinerecette/job/FnonRegressionTests/job/FdslExample/</text>
      <sha1>9vqb59ah5cvf98gal1poa3jx37h0k3x</sha1>
    </revision>
  </page>
  <page>
    <title>Jdk11</title>
    <ns>0</ns>
    <id>701699</id>
    <revision>
      <id>4067596</id>
      <parentid>4067595</parentid>
      <timestamp>2022-08-09T08:05:17Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <comment>/* Installation du JDK 11 */</comment>
      <origin>4067596</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="864" sha1="kdw4z9cr36r1t11uv24exlc0b4m0kl9" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Java Development Kit
 | logo              = Duke-11.png
 | siteInternet      = https://adoptopenjdk.net/index.html?variant=openjdk11&amp;jvmVariant=hotspot
 | version           = 11.0.8
 | supportTechnique  = {{usinelogicielle|subject=eclipse}}
 | faq               = [[FAQ:JDK|FAQ JDK]]
}}


== Installation du JDK 11 ==

Récuperez la version du jdk 11.0.8 dans {{F_INSTALL|path=\jdk\}} (il s'agit d'un zip) puis dézippez l'archive dans le répertoire d'installation classique des jdks :
* D:\Programs\jdk\jdk11.0.8


[[Fichier:DezipJDK8_01.jpg]]

== Mettre à jour la variable d'environnement JAVA_HOME == 
N'oubliez pas de mettre vos variables d'environnements à jour en suivant la procédure [http://wikefluid/index.php/Guide_d%27installation_du_JDK#Mise_.C3.A0_jour_de_la_variable_d.27environnement_JAVA_HOME ici]</text>
      <sha1>kdw4z9cr36r1t11uv24exlc0b4m0kl9</sha1>
    </revision>
  </page>
  <page>
    <title>Guide Eclipse Photon</title>
    <ns>0</ns>
    <id>701597</id>
    <revision>
      <id>4059443</id>
      <parentid>4026776</parentid>
      <timestamp>2020-06-04T11:50:55Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>4059443</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3109" sha1="q2oi9j0f6o8t4ezkrcvvj7gb0ublnvp" xml:space="preserve">[[Catégorie:Eclipse]]

{{Modèle:Infobox Outil
 | nom               = Eclipse photon
 | logo              = Photon_splash.jpg
 | siteInternet      = http://www.eclipse.org
 | version           = 2018-09 (4.9.0)
 | plugins           = eGit ({{outil.egit.version}})&lt;br/&gt;m2e ({{outil.m2e.version}})
 | guideInstallation = Guide d'installation d'éclipse
 | supportTechnique  = {{usinelogicielle|subject=eclipse}}
 | faq               = [[FAQ:Eclipse|FAQ Eclipse]]
}}

[[Category:outil]]
[[Category:eclipse]]

== préalable == 

Cette version d'éclipse a été packagé pour pouvoir développer avec le JDK 11.

Si vous n'avez pas le JDK 11, suivez les étapes ci-dessous :  
* Téléchargez le JDK 11 packagé (zip) : [http://eartifact.uem.lan/artifactory/eclipse-local/com/efluid/jdk/11.0.1/jdk-11.0.1.zip JDK 11.0.1]
* Rendez vous sur le tutoriel pour l'installation : [[Jdk11#Installation_du_JDK_11|http://wikefluid/index.php/Jdk11#Installation_du_JDK_11]]

== Récupération du zip eclipse et de son master workspace associé ==

Afin de simplifier et d'harmoniser les versions d'Eclipse au sein des environnements développeurs; une solution packagée d'Eclipse à été constituée à partir :
* d'une version d'Eclipse : ('''''actuelle: 2018-09 (4.9.0)''''')
* d'une version du masterWorkspace photon ; ('''''actuel: 2.0.0''''')

{{alert|texte=Pour une version d'Eclipse, il est obligatoire d'utiliser le &lt;span style="color:red"&gt;'''masterWorkspace associé'''&lt;/span&gt;. Sans celà, nous ne pouvons pas assurer le bon fonctionnement d'Eclipse.}}&lt;br /&gt;

La version d'Eclipse peut être récupérée sur Artifactory en suivant ce lien : [http://eartifact.uem.lan/artifactory/eclipse-local/com/efluid/eclipse/eclipse-photon/2.0.0/eclipse-photon-2.0.0.zip Eclipse 2018-09 (4.9.0)]&lt;br /&gt;

La version du masterWorkspace associée à cet version d'eclipse peut être récupéré sur Artifactory en suivant ce lien : [http://eartifact.uem.lan/artifactory/eclipse-local/com/efluid/workspace/eclipse-photon-master-workspace/2.0.0/eclipse-photon-master-workspace-2.0.0.zip masterWorkspace 2.0.0]

== Installation Eclipse/JDK == 

=== Installer le JDK ===
**Aller dans Window &gt; Java &gt; Installed JREs puis cliquez sur Add...
[[Fichier:ImportJDK11.PNG]]
*Choissiez Standard VM puis appuyez sur Next
[[Fichier:ImportAddJDK11.PNG]]
*dans JRE home : il faut aller chercher le chemin du JDK 11.0.1
**appuyez sur Finish
[[Fichier:JDKDefinition.PNG]]
&lt;br/&gt;

=== mettre le "Compiler compliance level" à 11 ===
* pour ce faire aller dans Window &gt; Preferences &gt; Java &gt; Compiler
[[Fichier:CompilerComplanceLevel.PNG]]

=== Tester efluid avec JDK 11 ===
En attendant le merge définitif du JDK 11 pour tester il faut : 
* récupérer le code du change gerrit : http://gerrit.uem.lan/#/c/72256/27
* Créer ou modifier le Webby 
** provider : tomcat9x
** JRE : Alternate JRE : choisir JDK11.0.1
* Lancer

= Gestion des sources pour les tests =

Dans photon, le connecteur m2e censé gérer l'ajout de sources au projet ne fonctionne, a priori, plus.
Il faut donc les ajouter à la main au build path et indiquer qu'il s'agit de test</text>
      <sha1>q2oi9j0f6o8t4ezkrcvvj7gb0ublnvp</sha1>
    </revision>
  </page>
  <page>
    <title>IDE</title>
    <ns>0</ns>
    <id>701759</id>
    <revision>
      <id>4048415</id>
      <parentid>4039038</parentid>
      <timestamp>2019-01-18T07:35:27Z</timestamp>
      <contributor>
        <username>Collign</username>
        <id>9</id>
      </contributor>
      <origin>4048415</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1992" sha1="92lbo8eelumuk3ucllmwnecvu496iez" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = IDE
 | supportTechnique  = [[Helios Gilles]] &lt;br/&gt;&lt;br/&gt; [[Vincent Poutissou]] &lt;br/&gt;&lt;br/&gt; [[Clément Sainton]] &lt;br/&gt;&lt;br/&gt; [[Vincent Bouthinon]] &lt;br/&gt;&lt;br/&gt; [[Gabriel Barthelemy]] &lt;br/&gt;&lt;br/&gt; [[Grzejszczak Didier]] &lt;br/&gt;&lt;br/&gt; [[Reitz Nicolas]] &lt;br/&gt;&lt;br/&gt; 
}}

[[Category:outil]]

= Généralités =

L'IDE étant l'outil de travail de base du développeur, c'est à lui qu'en incombe la responsabilité première. Chaque développeur doit maitriser son IDE.
Le développeur peut choisir l'IDE qu'il souhaite sous réserve qu'il soit dans la liste des logiciels validés au niveau licence (si ce n'est pas le choix, il faut alors que le développeur fasse le formulaire d'ajout du logiciel en question). Si le logiciel est payant (exemple : IntelliJ) alors il faut également que le développeur s'assure qu'il ait aussi la licence pour la partie payante.

= Support =

Le premier niveau de support doit se faire au niveau de l'équipe du développeur. Celui-ci doit en effet commencer par demander dans son équipe (section/division/filière) de l'aide s'il ne s'en sort pas tout seul. La plupart du temps cela suffit à régler la majorité des problèmes.
Le second niveau de support est l'équipe "d'expert IDE" qui est constituée de personnes volontaires (dont les noms sont écrits dans l'encadré en haut à droite) qui n'hésites pas à faire de la veille techno pour améliorer leurs connaissances et compétences sur ce sujet. Cette équipe est à contacter via le forum dans cette catégorie : http://eforum.uem.lan/viewforum.php?f=16). Veillez déjà à regarder si votre problème n'est pas déjà présent dans le forum.

= Packaging =

Le packaging des IDE est fourni pour certains IDE, pas pour tous. Cf la liste suivante.

== Eclipse ==

Le zip d'eclipse "officiel" est constitué par l'équipe "expert IDE" assistée de l'équipe "Usine logicielle". Le détail de constitution de ce zip est présent ici : [[Zip_d%27%C3%A9clipse]].</text>
      <sha1>92lbo8eelumuk3ucllmwnecvu496iez</sha1>
    </revision>
  </page>
  <page>
    <title>Arthas</title>
    <ns>0</ns>
    <id>701926</id>
    <revision>
      <id>4065635</id>
      <parentid>4061571</parentid>
      <timestamp>2021-09-21T12:41:59Z</timestamp>
      <contributor>
        <username>Bouthino</username>
        <id>7</id>
      </contributor>
      <origin>4065635</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1114" sha1="bu6isowtyxlpva6c2vqn0cu5h51r10i" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Arthas
 | logo              = Arthas_logo.png
 | siteInternet      = https://github.com/alibaba/arthas
 | version           = 2019-09 (3.1.3)
 | guideInstallation = Guide d'installation d'Arthas
 | supportTechnique  = https://alibaba.github.io/arthas/en/#
 | faq               = [[FAQ:Arthas|FAQ Arthas]]
}}

[[Category:outil]]
[[Category:arthas]]

Créé par Alibaba, Arthas est un outil ''open source'' qui permet aux développeurs de diagnostiquer des applications Java en cours d'exécution sans les redémarrer ni les suspendre.

== Guide d'utilisation ==
* [[Guide d'utilisation d'Arthas]]
* [https://eforum.uem.lan/viewtopic.php?f=30&amp;t=3313&amp;hilit=arthas Eforum vidéo]
* [http://wperoom4.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_2785ca Vidéo de présentation]


== Liens externes ==
* {{en}} [https://alibaba.github.io/arthas/en/# Documentation officielle]
* [https://blog.oxiane.com/2020/01/22/monitoring-debogage-et-diagnostic-de-problemes-dans-une-jvm-avec-arthas/ Description de JM Doudoux]
* [https://github.com/alibaba/arthas Github arthas]</text>
      <sha1>bu6isowtyxlpva6c2vqn0cu5h51r10i</sha1>
    </revision>
  </page>
  <page>
    <title>Quarkus</title>
    <ns>0</ns>
    <id>701937</id>
    <revision>
      <id>4053932</id>
      <parentid>4053930</parentid>
      <timestamp>2019-08-07T06:09:42Z</timestamp>
      <contributor>
        <username>Collign</username>
        <id>9</id>
      </contributor>
      <origin>4053932</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="798" sha1="ivmb0k36fl00s5v8ivy1lvrjqkdw68l" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Quarkus
 | logo              = quarkus_logo_mini.png
 | siteInternet      = https://quarkus.io/
 | version           = {{outil.quarkus.version}}
 | supportTechnique  = {{usinelogicielle|subject=quarkus}}
}}

[[Category:java]]

== Utilisation d'une version SNAPSHOT de Quarkus ==

* Récuperez le projet github https://github.com/quarkusio/quarkus (éventuellement sur une branche particulière si l'on veut builder une PR)
* Changez le distributionManagement (afin de pointer sur artifactory) dans les pom.xml suivants : 
** pom.xml
** independent-projects/arc/pom.xml
** independent-projects/bootstrap/pom.xml
* Lancer la commande maven : 
 mvn clean deploy -Denforcer.skip=true -DskipTests
* Cela déploiera une version '''999-SNAPSHOT''' de quarkus</text>
      <sha1>ivmb0k36fl00s5v8ivy1lvrjqkdw68l</sha1>
    </revision>
  </page>
  <page>
    <title>Wireshark</title>
    <ns>0</ns>
    <id>701962</id>
    <revision>
      <id>4065277</id>
      <parentid>4065276</parentid>
      <timestamp>2021-08-06T13:01:52Z</timestamp>
      <contributor>
        <username>Henryg</username>
        <id>251</id>
      </contributor>
      <comment>/* Utilisation de Wireshark : */</comment>
      <origin>4065277</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1309" sha1="81ja6kt1n0euuwtni3kpjacs63q3i7p" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Wireshark
 | logo              = 330px-Wireshark_icon.svg.png
 | siteInternet      = https://www.wireshark.org/
}}

[[Category:Outil]]

Application permettant le contrôle des communications réseau d'un poste de travail.

==Lien pour télécharger l'installateur de Wireshark : ==

https://www.wireshark.org/download.html

== Documentation de Wireshark : ==

https://gitlab.com/wireshark/wireshark/-/wikis/home

== Utilisation de Wireshark : ==

Conformément à la documentation de Wireshark (https://gitlab.com/wireshark/wireshark/-/wikis/CaptureSetup/CapturePrivileges), afin d'utiliser Wireshark de la manière la plus sécurisée qui soit, il est nécessaire de démarrer le driver npcap (ou npf sur les versions de Wireshark &lt; 3.0) manuellement avant la capture, puis de le stopper une fois que Wireshark n'est plus utilisé.

Les droits de lancement et d'arrêt de ce service sont conditionnées par une GPO spécifique '''non appliquée par défaut'''. Un profil eldap est nécessaire afin de disposer de cette GPO: LOCAL_ADMIN_ NPCAP, se rapprocher de sa hiérarchie pour en faire la demande.
&lt;source lang="dos"&gt;
Commande de lancement du service au sein d'une invite de commande cmd: sc start npcap
Commande d'arrêt du service: sc stop npcap
&lt;/source&gt;</text>
      <sha1>81ja6kt1n0euuwtni3kpjacs63q3i7p</sha1>
    </revision>
  </page>
  <page>
    <title>Sécurisation docker éditeur</title>
    <ns>0</ns>
    <id>701985</id>
    <revision>
      <id>4056487</id>
      <parentid>4056486</parentid>
      <timestamp>2020-01-07T16:05:22Z</timestamp>
      <contributor>
        <username>Ajdonik</username>
        <id>159</id>
      </contributor>
      <origin>4056487</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4635" sha1="g7t0vlc95pt9pm1fl23hg5ybgzi9qdx" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Sécurisation Docker éditeur
 | logo              = Docker.png
 | supportTechnique  = [[Thibaut Ajdonik]]
}}

Page wiki décrivant les bonnes pratiques de sécurité liées à docker dédiées à l'éditeur.
Voir la page XXX pour les bonnes pratiques dédiées aux administrateurs système.

=== Image Docker ===

==== Confidentialité ====

''Ne laisser aucun secret directement lisible dans les Dockerfile''

Si une image docker doit utiliser un secret au moment de son build, celui-ci devra être "passé" dans un fichier temporaire supprimé dans le Dockerfile.

''L’historique de l’image peut être retrouvé grâce à la commande'' &lt;code&gt;docker history --no-trunc &amp;lt;image&amp;gt;&lt;/code&gt;

==== Confiance ====

''N’installer que des paquets vérifiés''

En utilisant uniquement des sources sûres et sécurisées (repository interne ou public mais vérifié)

==== Minimisation ====

''Ne garder que les paquets nécessaires dans les images''

Supprimer les paquets inutiles dans le Dockerfile

''Éviter de laisser un serveur ssh dans le conteneur, préférer un autre moyen pour se connecter comme'' &lt;code&gt;docker exec&lt;/code&gt;

=== Source ===

==== Version ====

''Vérifier que l’image utilisée est bien dans la version souhaitée''

En utilisant des mécanismes qui garantissent qu’il s’agit bien de la dernière version et non d’une ancienne en cache

''Éviter Le tag &lt;code&gt;latest&lt;/code&gt; est aussi vulnérable à ce genre de problème''

==== Confiance ====

''S’assurer que les images, y compris celles de base, sont vérifées''

En activant le Docker Content Trust avec la variable d’environnement &lt;code&gt;DOCKER_CONTENT_TRUST=1&lt;/code&gt;

=== Conteneur ===

==== Réseau ====

''N’ouvrir que les ports nécessaires et les mapper préférablement sur une interface précise''

En utilisant le format &lt;code&gt;10.20.30.40:5000:6000&lt;/code&gt;

''Eviter aussi de mapper des port privilégiés (&amp;lt;1024) de l’hôte sur le conteneur, sauf cas utiles''

==== Privilèges ====

''Lancer le conteneur avec un utilisateur qui n’a pas de droits avancés, ni dans le conteneur ni sur l’hôte''

En utilisant l’instruction &lt;code&gt;USER&lt;/code&gt; dans le Dockerfile et en créant si besoin l’utilisateur avec les bons IDs

''Si possible exploiter le paramètre &lt;code&gt;--security-opt=no-new-privileges&lt;/code&gt; (ou &lt;code&gt;setpriv&lt;/code&gt; une fois les paramétrages terminés)''

==== Intégrité ====

''Dans la mesure du possible, lancer le conteneur avec le système de fichiers racine en lecture seule''

En utilisant le paramètre &lt;code&gt;--read-only&lt;/code&gt;

''Les dossiers montés ne sont pas affectés par ce paramètre, aussi l’option &lt;code&gt;--tmpfs&lt;/code&gt; peut être utile''

=== Disponibilité ===

==== Surveillance ====

''Monitorer l’état du service du conteneur''

En rajoutant une instruction &lt;code&gt;HEALTHCHECK&lt;/code&gt; dans le Dockerfile ou en utilisant le paramètre &lt;code&gt;--health-cmd&lt;/code&gt;

''Cela permet à Docker de remonter l’état à un outil de supervision ou encore de redémarrer le conteneur automatiquement''

==== Restriction ====

''Paramétrer des limites pour l’utilisation des ressources''

En utilisant les paramètres &lt;code&gt;--memory&lt;/code&gt;, &lt;code&gt;--cpu-shares&lt;/code&gt; et &lt;code&gt;--pids-limit&lt;/code&gt;

''Les valeurs doivent être bien étudiées et potentiellement fournies par les administrateurs comme pour le processeur''

==== Gestion ====

''Faire le ménage dans les images et les conteneurs''

En listant les images et les conteneurs présents sur l’hôte et en retirant tous ceux qui ne sont plus nécessaires

Cela évite de monopoliser des ressources inutilement et d’instancier d’anciennes versions potentiellement vulnérables

=== Autres recommandations ===

==== Construction ====

''Ne pas laisser les instructions de mise à jour du Dockerfile être en cache''

En rajoutant des mécanismes pour que l’instruction ne soit pas placée dans le cache

''Il est aussi possible d’utiliser &lt;code&gt;docker build&lt;/code&gt; avec le paramètre &lt;code&gt;--no-cache&lt;/code&gt; pour ne pas utiliser le cache''

==== Mises à jour ====

''Surveiller et corriger les vulnérabilités de Docker''

En faisant une veille et en mettant à jour Docker

''Si besoin prendre contact avec les administrateurs''

==== Exclusion ====

''Ne jamais utiliser certaines fonctionalités''

En excluant les paramètres &lt;code&gt;--privileged&lt;/code&gt;, &lt;code&gt;--net=host&lt;/code&gt;, &lt;code&gt;--pid=host&lt;/code&gt;, &lt;code&gt;--ipc=host&lt;/code&gt;, &lt;code&gt;--uts=host&lt;/code&gt;, &lt;code&gt;--userns=host&lt;/code&gt;

''Ces options ne sont normalement absolument pas nécessaires pour ce genre de service''</text>
      <sha1>g7t0vlc95pt9pm1fl23hg5ybgzi9qdx</sha1>
    </revision>
  </page>
  <page>
    <title>CJE2</title>
    <ns>0</ns>
    <id>702007</id>
    <revision>
      <id>4059522</id>
      <parentid>4059518</parentid>
      <timestamp>2020-06-10T08:36:00Z</timestamp>
      <contributor>
        <username>Payan</username>
        <id>102</id>
      </contributor>
      <comment>Contenu remplacé par « {{Modèle:Infobox Outil
 | nom               = Jenkins Core product : cloudbees core in k8s
 | logo              = JenkinsDragon.jpg
 | guideInstallation = JenkinsCore... »</comment>
      <origin>4059522</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="384" sha1="57ogvqhxbyn2mydrnv3vscbyhp7ww6v" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Jenkins Core product : cloudbees core in k8s
 | logo              = JenkinsDragon.jpg
 | guideInstallation = JenkinsCore_-_installation
 | guideUtilisation  = JenkinsCore_-_exploitation
 | guideTechnique    = JenkinsCore_-_points_techniques
 | faq               = [[FAQ:JenkinsCore|FAQ JenkinsCore]]
}}

Page renommée en [[JenkinsCore]]</text>
      <sha1>57ogvqhxbyn2mydrnv3vscbyhp7ww6v</sha1>
    </revision>
  </page>
  <page>
    <title>OracleXE</title>
    <ns>0</ns>
    <id>702015</id>
    <revision>
      <id>4060485</id>
      <parentid>4058151</parentid>
      <timestamp>2020-08-20T07:36:48Z</timestamp>
      <contributor>
        <username>Bouthino</username>
        <id>7</id>
      </contributor>
      <origin>4060485</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9831" sha1="3d081fst4t3arm2aa43teyixxxgjgu2" xml:space="preserve">[[Category:outil]]
[[Category:BDD]]
[[Category:docker]]
{{Modèle:Infobox Outil
 | nom               = Oracle XE
 | logo              = oracle.png
 | siteInternet      = http://www.oracle.com/
 | version           = 18c
 | supportTechnique  = [[UL]]
}}

= Oracle XE =
== Téléchargement ==
* Vous déconnecter du VPN et désactiver le proxy via les paramètres de votre navigateur et télécharger l'utilitaire : https://cloud.uem-metz.fr/index.php/s/7ZtTogFpmgwgWXp
* Faire une installation docker si votre poste est en windows 10. Cette solution est en cours d'étude de notre côté pour vous apporter la procédure. Pour le moment seul la première procédure est validée.

== Installation ==
'''Prérequis'''
* Etre administrateur du poste
* Si le 6000 vous fait l'installation, demander à ce que ce soit la ligne suivante qui soit exécuté pour lancer l'installation : 

 setup.exe /v"CHAR_SET=WE8ISO8859P15" 

'''Attention à bien mettre un mot de passe que vous noterez lors de l'installation''', ce sera le mdp du compte SYS. Il vous servira à vous connecter par exemple via sql developper.
== Configuration ==
Une fois Oracle XE installé, il va falloir configurer la base pour utiliser les bons formats de date / langage.

* Connectez vous avec le compte sys via SQLPlus dans une invite de commande windows :
 sqlplus sys/VOTREMDP@//localhost:1521/XEPDB1 as sysdba 

* Entrez ces requêtes successivement :

 ALTER system SET NLS_DATE_FORMAT            ='DD/MM/RR HH24:MI' scope=spfile; 
 ALTER system SET NLS_TIMESTAMP_FORMAT       ='DD/MM/RR HH24:MI:SSXFF' scope=spfile; 
 ALTER system SET NLS_TERRITORY              ='FRANCE' scope=spfile; 
 ALTER system SET NLS_LANGUAGE               ='FRENCH' scope=spfile; 
 ALTER system SET "_replace_virtual_columns" =false scope=spfile; 
 ALTER system SET QUERY_REWRITE_ENABLED      =false scope=spfile; 
 ALTER system SET STAR_TRANSFORMATION_ENABLED=false scope=spfile; 
 SHUTDOWN IMMEDIATE; 
 STARTUP; 


== Procédure pour utiliser Oracle en local ==

=== Création d'un schéma oracle ===
'''Prérequis'''
* Il faut créer le dossier "tablespace" dans l'arborescence : "D:\java\"

* Une fois installée, il faut se connecter sur sqlDevelopper sur notre instance oracle :

** Nom de connexion : le nom que vous souhaitez donner à votre connexion
** Nom utilisateur : sys
** Mot de passe : le mot de passe défini pendant l'installation
** Rôle : SYSDBA
Dans intellij : internal_logon=sysdba&lt;br&gt;
[[Fichier:sysdbaintellij.png]]
** URL JDBC : jdbc:oracle:thin:@127.0.0.1:1521/XEPDB1
 
[[Fichier:OracleXE.PNG]]




* Executer le script suivant, ce dernier va créer un schéma EFLUID_DEVELOP :


 CREATE TABLESPACE EFLUID_DEVELOP_BATCH_DATA DATAFILE 
  'D:\java\tablespace\EFLUID_DEVELOP_BATCH_DATA01.dbf' SIZE 500M AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_BATCH_INDEX DATAFILE 
  'D:\java\tablespace\EFLUID_DEVELOP_BATCH_INDEX01.dbf' SIZE 500M AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_BLOB DATAFILE 
  'D:\java\tablespace\EFLUID_DEVELOP_BLOB01.dbf' SIZE 500M AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_DATA DATAFILE 
  'D:\java\tablespace\EFLUID_DEVELOP_DATA01.dbf' SIZE 100M AUTOEXTEND ON NEXT 50M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_INDEX DATAFILE 
  'D:\java\tablespace\EFLUID_DEVELOP_INDEX01.dbf' SIZE 100M AUTOEXTEND ON NEXT 50M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_PARAM DATAFILE 
  'D:\java\tablespace\EFLUID_DEVELOP_PARAM01.dbf' SIZE 500M AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_UPGRADE DATAFILE 
  'D:\java\tablespace\EFLUID_UPGRADE_01.dbf' SIZE 1G AUTOEXTEND OFF;
 
 alter session set "_ORACLE_SCRIPT"=true;
 CREATE ROLE HERMES_OWNER_ROLE NOT IDENTIFIED;
 -- Object privileges granted to HERMES_OWNER_ROLE
 GRANT EXECUTE ON DBMS_CRYPTO TO HERMES_OWNER_ROLE;
 GRANT EXECUTE ON DBMS_PARALLEL_EXECUTE TO HERMES_OWNER_ROLE;
 GRANT EXECUTE ON DBMS_RANDOM TO HERMES_OWNER_ROLE;

 -- System privileges granted to HERMES_OWNER_ROLE
 GRANT CREATE JOB TO HERMES_OWNER_ROLE;
 GRANT CREATE MATERIALIZED VIEW TO HERMES_OWNER_ROLE;
 GRANT CREATE SYNONYM TO HERMES_OWNER_ROLE;
 GRANT CREATE VIEW TO HERMES_OWNER_ROLE;
 GRANT QUERY REWRITE TO HERMES_OWNER_ROLE;

 -- Roles granted to HERMES_OWNER_ROLE
 GRANT CONNECT TO HERMES_OWNER_ROLE;
 GRANT RESOURCE TO HERMES_OWNER_ROLE;

 CREATE USER EFLUID_DEVELOP
  IDENTIFIED BY "efluid"
  DEFAULT TABLESPACE EFLUID_DEVELOP_DATA
  TEMPORARY TABLESPACE TEMP
  PROFILE DEFAULT
  ACCOUNT UNLOCK;
  
 GRANT HERMES_OWNER_ROLE TO EFLUID_DEVELOP;
 ALTER USER EFLUID_DEVELOP DEFAULT ROLE ALL;

 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_BATCH_DATA;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_BATCH_INDEX;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_BLOB;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_DATA;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_INDEX;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_PARAM;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_UPGRADE;

Une fois la base de donnée dans cet état 2 possibilités :

* Créer un schéma à partir des DLL (= job de création des bases de TI)
* Importer une base de PARAM.

=== Créer un schéma à partir des DLL (= job de création des bases de TI) ===

* '''ATTENTION EN LANCANT CE SCRIPT, IL PREND LES INFOS DE CONNECTION BDD DEPUIS config-dev/.../framework2.properties, si ça pointe sur une BDD autre que localhost vous allez la tuer.'''

* Mettre les infos de connections dans votre framework2.properties avec les infos de création du premier script passé sur votre BDD en tant que SYS :

 JDBC_CONNECT_STRING=jdbc:oracle:thin:@127.0.0.1:1521/XEPDB1
 JDBC_USER=EFLUID_DEVELOP
 JDBC_PASSWORD=efluid

 ORACLE_TABLESPACE_DATA=EFLUID_DEVELOP_DATA
 ORACLE_TABLESPACE_INDEX=EFLUID_DEVELOP_INDEX
 ORACLE_TABLESPACE_BATCH_DATA=EFLUID_DEVELOP_BATCH_DATA
 ORACLE_TABLESPACE_BATCH_INDEX=EFLUID_DEVELOP_BATCH_INDEX
 ORACLE_TABLESPACE_PARAM=EFLUID_DEVELOP_PARAM
 ORACLE_TABLESPACE_BLOB=EFLUID_DEVELOP_BLOB
 ORACLE_TABLESPACE_MIGRATION=EFLUID_UPGRADE

* Lancer le script : scripts/UL-destructionBDD.sh. En vous mettant dans le projet que vous souhaitez. Efluid develop vous montera une BDD en develop. Efluid maintenance_13 une BDD en 13.22.100-SNAPSHOT etc...
** A noter en v13 ajouter dans votre commande -DskipCopyFramework2SqlInit=true

* Votre schéma est désormais prêt à l'utilisation

=== Ajout du paramétrage ENEDIS sur votre base (EN COURS, NE PAS UTILISER) ===

'''Prérequis'''
* Télécharger le zip de paramétrage disponible ici [[ https://cloud.uem-metz.fr/index.php/s/FrTJp9xMwHrKdjZ]]

* Une fois téléchargé dans la version souhaité (actuellement dispo 14.8.100 ou 13.11.1800), se connecter à la base de données que vous avez montée préalablement avec l'UL-destruction et les jouer dans l'ordre


== Procédure pour utiliser Oracle en mode docker [EN COURS]  ==

'''Prérequis'''
* Avoir le poste sous windows 10
* Avoir un compte sur docker hub : https://hub.docker.com

*Installation* : 

* Avant de commencer l'installation, faire un clic gauche sur l'icone docker dans la barre des tâches et aller dans settings.
Il faut configurer le proxy afin de pouvoir sortir sur internet. (Vous pouvez récupérer ces paramètres sur la configuration proxy de votre naviguateur)

[[Fichier:Proxy Docker.PNG|vignette|Proxy Docker.PNG]]

== FAQ ==
=== Problèmes connus ===
* Message d'erreur :
 The target version 5.123.1100.73d8de4a does not match the target version in BDD 4.210.100.3c5ca7b5. You do not have the rights to make this update 
* Solution : 
 Si vous êtes dans le cas d'un upgrade, vous pouvez ajouter à la commande ./sql-upgrade.sh -DaccessMode=INT. Attention cependant à bien être conscient de la base de données ciblée.

* Message d'erreur : 
 [ERROR] Failed to execute goal com.efluid.utils.sql:sqlmigrator-maven-plugin:2.218.1:drop-init (ddl-dml-init) on project efluid-racine: Failed to execute SQLMigrator: java.sql.SQLException: ORA-12899: valeur trop grande pour la colonne "EFLUID_DEVELOP_14"."TACTIONPREDEFINIE"."LIBELLE" (réelle : 82, maximum : 80) 
* Solution : 
 L'installation oracle XE n'a pas du être faite avec la commande /v"CHAR_SET=WE8ISO8859P15". Les scripts sont donc interprété avec le mauvais encodage. Pour vérifier cette hypothèse, connecter vous à votre instance et lancer la commande : 
 select * from nls_database_parameters where parameter like '%SET%';
Si le résultat obtenu fait état de l'UTF8, il va falloir modifier ces valeurs. Pour ce faire :
# Ouvrir un sqlPlus
# Lorsqu'on vous demander en tant que quel utilisateur renseigner : sys as sysdba
# Renseigner le mot de passe saisie pendant l'installation
# Executer les lignes suivantes :
 SQL&gt; shutdown immediate;
 SQL&gt; startup restrict
 SQL&gt; select name from v$database;
 SQL&gt; ALTER DATABASE CHARACTER SET INTERNAL_USE WE8ISO8859P15;
 SQL&gt; select value from NLS_DATABASE_PARAMETERS where parameter='NLS_CHARACTERSET';
 SQL&gt; shutdown immediate;
 SQL&gt; startup
 SQL&gt; select value from NLS_DATABASE_PARAMETERS where parameter='NLS_CHARACTERSET';

En relancant votre montée de version, si vous êtes bien en ISO, tout devrait fonctionner.

* J'essaye de supprimer l'utilisateur EFLUID_DEVELOP :
 drop user EFLUID_DEVELOP cascade; 

'''Message d'erreur:'''
 ERROR at line 1: 
 ORA-28014: cannot drop administrative users 

'''Solution:'''
 alter session set "_oracle_script"=true; 
 drop user EFLUID_DEVELOP cascade;

 User dropped.

=== Problème pour désinstaller/réinstaller OracleXE ===
* Je dois réinstaller OracleXE mais au moment de réinstaller il me dit qu'un service Oracle existe encore : 
Suivre le tuto suivant : [https://community.oracle.com/thread/4209872]</text>
      <sha1>3d081fst4t3arm2aa43teyixxxgjgu2</sha1>
    </revision>
  </page>
  <page>
    <title>OracleDEVVM</title>
    <ns>0</ns>
    <id>702018</id>
    <revision>
      <id>4058168</id>
      <parentid>4058166</parentid>
      <timestamp>2020-03-25T16:43:13Z</timestamp>
      <contributor>
        <username>Bouthino</username>
        <id>7</id>
      </contributor>
      <comment>/* Installation */</comment>
      <origin>4058168</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6785" sha1="e82fuza6u56ik8wq6qreyowo2oja0e8" xml:space="preserve">[[Category:outil]]
{{Modèle:Infobox Outil
 | nom               = Oracle VM
 | logo              = oracle.png
 | siteInternet      = http://www.oracle.com/
 | version           = 19
 | supportTechnique  = [[JTA]] [[TAJ]]
}}

= VM Oracle 19 =
== Téléchargement ==
* Télécharger VirtualBox puis l'image ova depuis Oracle (il faut un compte Oracle créable facilement) : [https://www.oracle.com/database/technologies/databaseappdev-vm.html]

== Installation ==
'''Prérequis'''
* Les droits d'admin pour installer Virtual Box
* La virtualisation activée dans le BIOS 
Pour savoir si la virtualisation est activée : &lt;br&gt;&lt;br&gt;
[[Fichier:virtualisationActivee.PNG]]&lt;br&gt;&lt;br&gt;
Si vous n'avez pas ça vous aurez l'erreur suivante au démarrage de la VM :&lt;br&gt;&lt;br&gt;
[[Fichier:erreurVTXBIOS.png]]&lt;br&gt;&lt;br&gt;
Si ce n'est pas le cas, appelez le '''6000''' pour qu'ils vous communique le mdp du BIOS (vérifiez qu'il y en a un avant) : &lt;br&gt;&lt;br&gt;
[[Fichier:VTXBIOS.png]]
* désactiver Hyper-V virtualization 
Comme indiqué ici : https://superuser.com/questions/1153470/vt-x-is-not-available-but-is-enabled-in-bios&lt;br&gt;&lt;br&gt;
Lancer une console en mode administration (bouton droit) :&lt;br&gt;
[[Fichier:consoleModeAdministration.PNG]]&lt;br&gt;&lt;br&gt;
Et lancer la commande :&lt;br&gt;
 dism.exe /Online /Disable-Feature:Microsoft-Hyper-V 
[[Fichier:desactiverHyperV.PNG]]&lt;br&gt;&lt;br&gt;

== Procédure pour utiliser l'image  ==
== Importation et configuration de la VM ==

* Importer la VM depuis VirtualBox

* Configurer le réseau en "hôte seulement" pour ne pas l'exposer sur le LAN mais juste sur votre machine

[[Fichier:OracleVMReseau.PNG]]

* Ajouter un dossier partagé entre votre machine et la VM :

[[Fichier:OracleVMDossierPartage.PNG|OracleVMDossierPartage.PNG]]

== Configuration de la VM et de la BDD ==

Vous trouverez sur [[http://wperoom3.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_25b1bf eRoom]] '''Mes eRooms &gt; efluid - Qualité Développement &gt; Guides et procédures &gt; guides base de données &gt; VM Oracle 19''' les 3 fichiers à placer dans votre home (/home/oracle). Le script SH et les fichiers SQL de configuration de la BDD. Il suffit de lancer le script ./configurationVM.sh. 

'''Les 3 fichiers doivent être dans le même répertoire'''

=== Initialiser la BDD ===

* Initialisez la BDD (toujours dans le terminal via '''sqlplus''' en SYS as SYSBA) :
 CREATE TABLESPACE EFLUID_DEVELOP_BATCH_DATA DATAFILE
 '/u01/app/oracle/oradata/ORCLCDB/orcl/EFLUID_DEVELOP_BATCH_DATA01.dbf' SIZE 500M AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_BATCH_INDEX DATAFILE
 '/u01/app/oracle/oradata/ORCLCDB/orcl/EFLUID_DEVELOP_BATCH_INDEX01.dbf' SIZE 500M AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_BLOB DATAFILE
 '/u01/app/oracle/oradata/ORCLCDB/orcl/EFLUID_DEVELOP_BLOB01.dbf' SIZE 500M AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_DATA DATAFILE
 '/u01/app/oracle/oradata/ORCLCDB/orcl/EFLUID_DEVELOP_DATA01.dbf' SIZE 100M AUTOEXTEND ON NEXT 50M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_INDEX DATAFILE
 '/u01/app/oracle/oradata/ORCLCDB/orcl/EFLUID_DEVELOP_INDEX01.dbf' SIZE 100M AUTOEXTEND ON NEXT 50M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_DEVELOP_PARAM DATAFILE
 '/u01/app/oracle/oradata/ORCLCDB/orcl/EFLUID_DEVELOP_PARAM01.dbf' SIZE 500M AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;
 CREATE TABLESPACE EFLUID_UPGRADE DATAFILE
 '/u01/app/oracle/oradata/ORCLCDB/orcl/EFLUID_UPGRADE_01.dbf' SIZE 5G AUTOEXTEND OFF;

 alter session set "_ORACLE_SCRIPT"=true;
 CREATE ROLE HERMES_OWNER_ROLE NOT IDENTIFIED;
 -- Object privileges granted to HERMES_OWNER_ROLE
 GRANT EXECUTE ON DBMS_CRYPTO TO HERMES_OWNER_ROLE;
 GRANT EXECUTE ON DBMS_PARALLEL_EXECUTE TO HERMES_OWNER_ROLE;
 GRANT EXECUTE ON DBMS_RANDOM TO HERMES_OWNER_ROLE;
 -- System privileges granted to HERMES_OWNER_ROLE
 GRANT CREATE JOB TO HERMES_OWNER_ROLE;
 GRANT CREATE MATERIALIZED VIEW TO HERMES_OWNER_ROLE;
 GRANT CREATE SYNONYM TO HERMES_OWNER_ROLE;
 GRANT CREATE VIEW TO HERMES_OWNER_ROLE;
 GRANT QUERY REWRITE TO HERMES_OWNER_ROLE;
 -- Roles granted to HERMES_OWNER_ROLE
 GRANT CONNECT TO HERMES_OWNER_ROLE;
 GRANT RESOURCE TO HERMES_OWNER_ROLE;

 CREATE USER EFLUID_DEVELOP
 IDENTIFIED BY "efluid"
 DEFAULT TABLESPACE EFLUID_DEVELOP_DATA
 TEMPORARY TABLESPACE TEMP
 PROFILE DEFAULT
 ACCOUNT UNLOCK;

 GRANT HERMES_OWNER_ROLE TO EFLUID_DEVELOP;
 ALTER USER EFLUID_DEVELOP DEFAULT ROLE ALL;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_BATCH_DATA;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_BATCH_INDEX;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_BLOB;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_DATA;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_INDEX;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_DEVELOP_PARAM;
 ALTER USER EFLUID_DEVELOP QUOTA UNLIMITED ON EFLUID_UPGRADE;


=== 2 cas possible à partir de là ===
==== Cas 1 :  Script UL-Destruction / SQLUpgrade ====

Lancer les différents scripts voulus en prenant bien soin de mettre votre ip LAN de votre VM dans '''framework2.propeties'''.

=== Cas 2 : Import d'un dump ===

Vous pouvez changer les différents noms (schéma, tablespaces) si vous adaptez le script d'initialisation ci-dessus et le parfile (qui est un fichier de mapping schéma source -&gt; schéa dest).

Dans un '''sqlplus''' en SYSDBA :

create directory ORACLE_DIR as '/home/oracle';

GRANT READ,WRITE ON DIRECTORY ORACLE_DIR to system;

Ensuite faites un '''locate impdp''', placez vous dans le dossier '''bin''' trouvé et lancez

impdp system/oracle@localhost:1521/orcl DIRECTORY=ORACLE_DIR DUMPFILE=EXPDP_RPAREDT6_PARAM_ERDF_FLD_14_14.9.100.RC1_5175.dmp LOGFILE=dump.log PARFILE=par.par SCHEMAS=PARAM_ERDF_FLD_14

=== Utiliser la BDD ===
* Faites un ifconfig et cherchez l'IP de de eth0, ceci sera l'ip à configurer dans votre IJ/SqlDev sur votre poste (pas sur la VM hein). 
ex: 192.168.56.101, si jamais il n'y a pas d'ip v4 : '''sudo dhclient'''
Ce qui donnera comme jdbc connect string : '''jdbc:oracle:thin:@192.168.56.101:1521/orcl'''

* Exemple de framework2.properties :

 JDBC_CONNECT_STRING=jdbc:oracle:thin:@192.168.56.101:1521/orcl 
 JDBC_USER=EFLUID_DEVELOP 
 JDBC_PASSWORD=efluid 

 ORACLE_TABLESPACE_DATA=EFLUID_DEVELOP_DATA 
 ORACLE_TABLESPACE_INDEX=EFLUID_DEVELOP_INDEX 
 ORACLE_TABLESPACE_BATCH_DATA=EFLUID_DEVELOP_BATCH_DATA 
 ORACLE_TABLESPACE_BATCH_INDEX=EFLUID_DEVELOP_BATCH_INDEX 
 ORACLE_TABLESPACE_PARAM=EFLUID_DEVELOP_PARAM 
 ORACLE_TABLESPACE_BLOB=EFLUID_DEVELOP_BLOB 
 ORACLE_TABLESPACE_MIGRATION=EFLUID_UPGRADE

== Infos diverses ==
* Les mdp (root et compagnie) : oracle
* SID : orcl
* User (schéma) si utilisation du script d'initialisation ci-dessus : EFLUID_DEVELOP/efluid</text>
      <sha1>e82fuza6u56ik8wq6qreyowo2oja0e8</sha1>
    </revision>
  </page>
  <page>
    <title>Kubernetes</title>
    <ns>0</ns>
    <id>702050</id>
    <revision>
      <id>4068177</id>
      <parentid>4068098</parentid>
      <timestamp>2023-01-12T13:44:36Z</timestamp>
      <contributor>
        <username>Oberle</username>
        <id>709</id>
      </contributor>
      <origin>4068177</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1726" sha1="55t6dap8bpmwwq0v7ekf770en15e82d" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = kubernetes
 | logo              = logo_kubernetes.png
 | siteInternet      = https://kubernetes.io/
 | version           = {{outil.kubernetes.version}}
 | supportTechnique  = [[Vincent CARRIER]] / [[Yann OBERLE]]
 | guideInstallation = [http://wikefluid/docInstalleur/documentationScriptsOracleTools/kubernetes.html]
 | faq               = [[FAQ:kubernetes|FAQ kubernetes]]
}}

[[Category:kubernetes]]

== Guide d'utilisation ==
* {{en}} [https://v1-23.docs.kubernetes.io/docs/reference/kubectl/cheatsheet/ Cheat Sheet kubernetes v1.23]

* {{en}} [https://kubernetes.io/docs/reference/kubectl/cheatsheet/ Cheat Sheet kubernetes]

== Procédures internes ==
* [[Rotation des certificats kubernetes]]

* [[Migration HELM V2 vers HELM V3]]

* [[Upgrade cluster kubernetes via kubeadm]]

* [[Repartition des usines Jenkins pour upgrade Kubernetes|Répartition des usines Jenkins pour upgrade Kubernetes]]

* [[Upgrade cluster kubernetes via Ansible|Upgrade cluster kubernetes via Ansible]]

* [[Backup kubernetes|Sauvegarde/restauration d'un cluster Kubernetes (en cours)]]

* [[ Migration Docker vers CRI-O]]

* [[Accès API server (kubectl) - authentification par certificat client, autorisations restreintes]]

== Formation ==


== Liens internes ==

* [http://wikefluid/docInstalleur/documentationScriptsOracleTools/kubernetes.html Playbook ansible pour kubernetes]

* [http://wperoom4.uem.lan/eRoom/Prod13/SCE_Technologies/0_13386 Présentation Kubernetes faite en réunion de services]

== Liens externes ==
* {{en}} [https://v1-23.docs.kubernetes.io/docs/home/ Documentation officielle de la version v1.23]

* {{en}} [https://kubernetes.io/docs/home/ Documentation officielle]</text>
      <sha1>55t6dap8bpmwwq0v7ekf770en15e82d</sha1>
    </revision>
  </page>
  <page>
    <title>JenkinsCore</title>
    <ns>0</ns>
    <id>702077</id>
    <revision>
      <id>4067676</id>
      <parentid>4067189</parentid>
      <timestamp>2022-09-04T13:26:28Z</timestamp>
      <contributor>
        <username>Carriers</username>
        <id>234</id>
      </contributor>
      <comment>/* Montée sidecar-injector 2.1.3 -&gt; 2.2.0 */</comment>
      <origin>4067676</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="18123" sha1="8deokqjd44w29dv27wsr6omvxm4ske9" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = Jenkins Core product : cloudbees core in k8s
 | logo              = JenkinsDragon.jpg
 | guideInstallation = JenkinsCore_-_installation
 | guideUtilisation  = JenkinsCore_-_exploitation
 | guideTechnique    = JenkinsCore_-_points_techniques
 | faq               = [[FAQ:JenkinsCore|FAQ JenkinsCore]]
}}

== Jenkins==
=== PROD ===

 https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/cjoc/

instance ID : d79e3954e18079156b0532b15d09c2a0

=== REC===
 
 https://rec-k8s-cje-cloudbees-core.efluid.uem.lan/cjoc/

instance ID : b1eff3fe62adbd0baffe592a82fb51d2

== Exploitation ==

* '''Drainage des Pods dans le cluster ''' 
 http://wikefluid.uem.lan/index.php/JenkinsCore_-_exploitation#Maintenance_d.27un_Worker_kubernetes_.28Master_and_worker_Jenkins_Core_product.29

Voir page : http://wikefluid.uem.lan/index.php/JenkinsCore_-_exploitation#Kubernetes

== Kubernetes platfom ==

Evènement infra : 280813 

=== Core Prod environment ===
==== Namespaces ====
* '''cloudbees-core-prod'''
contient les pods du Cjoc, des masters et des pods servant a executer les jobs

*''' cloudbees-sidecar-injector '''
Permet l'utilisation de certificats autosignés ou un rootCA custom en injectant les certificat bundles dans tous les containers de tous les pods schedulés par jenkins

==== Serveurs ====

{| class="wikitable"
|-
!   !! core_prod_1_project !! Mem !! CPU
|-
| Pointeur DNS || pro-k8s-cje.uem.lan (192.168.106.128) || - ||-
|-
| HA proxy en HA || lpcjelbaedt3 : (192.168.106.73) || 4Go || 1 vCPU
|-
| HA proxy en HA || lpcjelbaedt4 (192.168.106.76)  || 4Go || 1 vCPU
|-
| Master-k8s || lpcjemtrkubedt1(192.168.106.53) || 10Go || 2 vCPU
|-
| Master-k8s || lpcjemtrkubedt2(192.168.106.64)  || 10Go || 2 vCPU
|-
| Master-k8s || lpcjemtrkubedt3(192.168.106.69)  || 10Go || 2 vCPU
|-
| Worker-k8s || lpkubwkredt1.uem.lan (192.168.106.151)  || 502Go || 64 vCPU
|-
| Worker-k8s || lpkubwkredt2.uem.lan (192.168.106.152) || 502Go || 64 vCPU
|-
| Worker-k8s || lpdrogonedt1 (192.168.119.78) || 188 Go|| 96 
|-
| Worker-k8s|| lpviseriedt1 (192.168.119.79) || 188 Go||96  
|-
| &lt;s&gt;Worker-k8s&lt;/s&gt; || &lt;s&gt;lptyrionedt1 (192.168.118.8)&lt;/s&gt;|| &lt;s&gt;188 Go &lt;/s&gt;||&lt;s&gt;28 &lt;/s&gt;
|-
| Worker-k8s || lpcjewkredt1 (192.168.119.115)||187 Go ||176
|-
| Worker-k8s || lpcjewkredt2 (192.168.119.116)||187 Go ||176
|-
| Worker-k8s || lpcjewkredt3 (192.168.119.117)|| 187 Go ||176 &gt;
|-
| Worker-k8s || lpcjewkredt4 (192.168.119.118)|| 187 Go || 176 
|-
| Montage NFS || /NFS_SHARE_KUBE_UL_DTA1_A06 || - || -
|}

Montage NFS pour l'ensemble des master/worker kubernetes: '''/nfsk8s'''

=== Core Test environment ===
==== Namespace ====
* '''cloudbees-core-test'''
contient les pods du Cjoc, des masters et des pods servant a executer les jobs

* '''cloudbees-sidecar-injector '''
Permet l'utilisation de certificats auto signés ou un root CA custom en injectant les certificat bundles dans tous les containers de tous les pods schedulés par jenkins

==== Serveurs ====

{| class="wikitable"
|-
!   !! core_test_1_project !! Mem !! CPU
|-
| pointeur DNS || rec-k8s-cje.uem.lan (192.168.106.129) || - || -
|-
| HA proxy en HA || lrcjelbaedt3 : (192.168.106.126) || 4Go || 1 vCPU
|-
| HA proxy en HA || lrcjelbaedt4 (192.168.106.127)  || 4Go || 1 vCPU
|-
| Master-k8s || lrcjemtrkubedt1 (192.168.106.18)  || 10Go || 2 vCPU
|-
| Master-k8s || lrcjemtrkubedt2 (192.168.106.33)  || 10Go || 2 vCPU
|-
| Master-k8s || lrcjemtrkubedt3 (192.168.106.48)  || 10Go || 2 vCPU
|-
| Worker-k8s || lrkubwkredt1 (192.168.106.80)  || 8 Go || 2 vCPU
|-
| Worker-k8s || lrkubwkredt2 (192.168.106.81)  || 8 Go || 2 vCPU
|-
| Worker-k8s || lrkubwkredt3 (192.168.106.135)  || 8 Go || 2 vCPU
|-
| Worker-k8s || lprhaegaedt1 (192.168.119.88)|| 188 Go|| 64
|-
| Montage NFS || /NFS_SHARE_KUBE_UL_DTA2_A06 || - || -
|}

Pour utiliser l'interface API kubernetes : se connecter root sur lrcjemtrkubedt1 ou 2 ou 3

Montage NFS pour l'ensemble des master/worker kubernetes: '''/nfsk8s'''

== Monitoring ==
=== Cluster K8s de prod ===
* Dashboard de monitoring pertinents PROD (dashboards fournis par VCA): 
** http://pro-k8s-cje-grafana.efluid.uem.lan/d/efa86fd1d0c121a26444b636a3f509a8/kubernetes-compute-resources-cluster?orgId=1&amp;refresh=10s&amp;from=now-12h&amp;to=now
** http://pro-k8s-cje-grafana.efluid.uem.lan/d/200ac8fdbfbb74b39aff88118e4d1c2c/kubernetes-compute-resources-node-pods?orgId=1&amp;refresh=10s
** http://pro-k8s-cje-grafana.efluid.uem.lan/d/a87fb0d919ec0ea5f6543124e16c42a5/kubernetes-compute-resources-namespace-workloads?orgId=1&amp;refresh=10s
** Etat système des nodes du cluster : http://pro-k8s-cje-grafana.efluid.uem.lan/d/hb7fSE0Zz/1-node-exporter-for-prometheus-dashboard-en-v20200628?orgId=1
** Vue Master Jenkins : http://pro-k8s-cje-grafana.efluid.uem.lan/d/8Z9-POHWz/jenkins-masters?orgId=1&amp;refresh=30s&amp;var-service=All&amp;var-namespace=cloudbees-core-prod

* Accès dashboard Kubernetes Perf (mot de passe dans keypass pour token)
 https://pro-k8s-cje-dashboard.efluid.uem.lan

* Accès Grafana Kubernetes Perf (mot de passe dans keypass pour compte admin)
 http://pro-k8s-cje-grafana.efluid.uem.lan/login

* Monitoring HAProxy (mot de passe dans keypass pour compte admin)
 http://pro-k8s-cje.efluid.uem.lan:9000/haproxy_stats

=== Cluster K8s de test ===
* Accès dashboard Kubernetes Perf (mot de passe dans keypass pour token)
 https://rec-k8s-cje-dashboard.efluid.uem.lan

* Accès Grafana Kubernetes Perf (mot de passe dans keypass pour compte admin)
 http://rec-k8s-cje-grafana.efluid.uem.lan/login

* Monitoring HAProxy (mot de passe dans keypass pour compte admin)
 http://rec-k8s-cje.efluid.uem.lan:9000/haproxy_stats

== Jenkins Core product ==
=== Documentation ===
* Architecture cloudbees core: https://docs.cloudbees.com/docs/cloudbees-core/latest/cloud-reference-architecture/ra-for-onprem/
* Demande de licence temporaire pour migration 
 https://support.cloudbees.com/hc/en-us/requests/180795

* Support : https://support.cloudbees.com/hc/en-us#
* guide de migration : https://docs.cloudbees.com/docs/cloudbees-core/latest/cje1-to-core/

=== Migration ===

Voir historique CJE-&gt; JenkinsCore : https://wikefluid.efluid.uem.lan/index.php/JenkinsCore_-_points_techniques#Migration

=== Montées de versions  ===
Les montées de versions de Jenkins Core se font via Helm. Des playbooks ont été développés pour permettre ces montées de versions :
* Scripts : http://wikefluid/docInstalleur/documentationScriptsOracleTools/kubernetes.html, paragraphe "Cloudbees Core".

A chaque montée de version, l'inventaire (REC puis PRO) doit être mis à jour avec les versions cibles des composants :
* Cloudbees Core version 2.xxx.y.z
* Cloudbees Sidecar Injector version a.b.c

Exemple : https://gerrit.efluid.uem.lan/c/oracleTools/+/178073

Lorsque les montées de versions sont trop éloignées, il est possible d'ouvrir un ticket d'assistance à la montée de version via le support. L'objectif est d'identifier avec le support les sauts de versions recommandés pour aller de la version courante à la dernière dispo, et d'avoir des infos sur les risques liés à la version.

 https://support.cloudbees.com/hc/en-us/articles/115001919212-Required-Data-Assisted-Update

Template à remplir disponible dans la room Process de Fabrication : http://WPEROOM4.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_17187 ( efluid – Process de fabrication &gt; Projets &gt; Jenkins Enterprise - CJOC- CBC / AssistedUpdateTemplate.odt)


Pour identifier les dernières versions dispoinbles pour les 2 composants donnés plus haut, se connecter par exemple sur lrcjemtrkubedt1 en tant que root. Et consulter le repo HELM pour voir son contenu puis le mettre à jour :
 [root@lrcjemtrkubedt1 ~]# helm list -A
 NAME                            NAMESPACE                       REVISION        UPDATED                                         STATUS          CHART                                   APP VERSION
 cloudbees-core                  cloudbees-core-test             28              2021-04-28 15:20:02.540688858 +0200 CEST        deployed        cloudbees-core-3.23.4+53a9d5818d07      2.249.3.3
 cloudbees-sidecar-injector      cloudbees-sidecar-injector      1               2021-06-10 11:08:45.230278549 +0200 CEST        deployed        cloudbees-sidecar-injector-2.1.3        2.1.3

Pour mettre à jour le repo HELM et synchroniser avec les dernières versions dispos chez Cloudbees :

 [root@lrcjemtrkubedt1 ~]# export https_proxy=http://usine-logicielle:XXXXXXX@lpsrvpxy:8080/                       
 [root@lrcjemtrkubedt1 ~]# helm search repo cloudbees-core
 NAME                            CHART VERSION           APP VERSION     DESCRIPTION
 cloudbees/cloudbees-core        3.37.2+7390bf58e3ab     2.303.3.3       Enterprise Continuous Integration with Jenkins

 [root@lrcjemtrkubedt1 ~]# helm repo update
 Hang tight while we grab the latest from your chart repositories...
 ...Successfully got an update from the "cloudbees" chart repository
 ...Successfully got an update from the "stable" chart repository
 Update Complete. ⎈Happy Helming!⎈

 [root@lrcjemtrkubedt1 ~]# helm search repo cloudbees-core
 NAME                            CHART VERSION           APP VERSION     DESCRIPTION
 cloudbees/cloudbees-core        3.39.7+58091444e7ae     2.319.2.7       Enterprise Continuous Integration with Jenkins

==== version 2.249.2.4 ====
https://usinelogicielle.slack.com/archives/C3S3RSRKP/p1614851701002500
CFOU : Résumé de la migration sur REC:
* j'ai installé la version 2.249.2.4 de cloudbees core. C'est la dernière version qui supporte encore helm2.
* la migration du cjoc s'est bien passée
* les masters encore dans l'ancienne version sont toujours up et  fonctionnent mais n'arrivent plus a communiquer avec le cjoc (je suis encore en train de regarder ce point pour éviter de devoir migrer tous les masters en même temps sur la prod)

* la migration des master se fait sans problèmes.
* exécution des tests de la sharedlib sont tous ok .

** &gt; j'ai eu des erreurs 503 mais c'était des erreurs temporaires
** &gt; des erreurs docker dû au fait que j'ai lancé les tests alors qu'ils tournaient deja sur la prod
** &gt; il y a toujours une erreur slack mais on a les meme sur la prod =&gt; a fixer quand meme
  Slack#callSlackApiWithGet response : {"ok":false,"error":"method_deprecated","response_metadata":{"messages":["[ERROR] This method is retired and can no longer be used. Please use conversations.history instead. Learn more: https:\/\/api.slack.com\/changelog\/2020-01-deprecating-antecedents-to-the-conversations-api."]}}
- execution des tests de jenkins conf RAS
- les backups fonctionnent toujours
- j'ai créé deux jobs pour la copie de l'usine de prod vers l'usine REC (en se basant sur le dernier backup de l'usineValidationJenkins de prod) http://wikefluid.uem.lan/index.php/JenkinsCore_-_exploitation#Tester_la_migration_sur_la_REC

==== version 2.319.2.9 ====
Opérations faites sur REC : 
===== Préparation =====
Depuis CJOC, Beekeeper Upgrade Assistant :
* Problèmes remontés sur plugins 
  https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/cjoc/beekeeper/plugins/
  =&gt; clic sur restart =&gt; redémarrage CJOC =&gt; OK sur REC et PROD

* Fix de soucis remontés sur UpdateCenter 
  https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/cjoc/beekeeper/updateCenter/ 
 =&gt; clic sur Fix =&gt; OK

https://rec-k8s-cje-cloudbees-core.efluid.uem.lan/cjoc/beekeeper/upgrade/ :
  Your current CloudBees CI Cloud Operations Center version is 2.249.3.3. Version '''2.319.2.7''' is available.


Demande d'assistance migration Cloudbees : https://docs.cloudbees.com/docs/cloudbees-common/latest/support-policies/cloudbees-ci
* Installer ce plugin : https://plugins.jenkins.io/support-core/


Procédure de migration '''faite en suivant la "Procedure avec un playbook Ansible"'''

=====Environnement REC -&gt; 2.319.2.9-rolling=====

====== Montée CJOC======
 ansible-playbook -i inventory/rec_kub_cje_cluster --ask-vault-pass -e @inventory/rec_kub_cje_cluster.vault playbooks/kubernetes/helm-deploy-cloudbees-core.yml -l lrcjemtrkubedt1
====== Montée sidecar-injector 2.1.3 -&gt; 2.2.0======

Dans inventaire ansible, modification de la version 2.1.3 en 2.2.0 :
 [carriers@lpswaulo1 inventory]$ grep sidecar *rec_kub_cje*
 rec_kub_cje_cluster:cloudbees_sidecar_injector_helm_chart_version=2.2.0
 rec_kub_cje_cluster:kubernetes_cloudbees_sidecar_injector_namespace=cloudbees-sidecar-injector
  
Reinstallation
  [carriers@lpswaulo1 ansible]$ pwd
  /home/D_NT_UEM/carriers/oracleTools/ansible
  [carrier@lpsrvprf11 ansible]$ ansible-playbook -i inventory/rec_kub_cje_cluster --ask-vault-pass -e @inventory/rec_kub_cje_cluster.vault playbooks/kubernetes/helm-deploy-cloudbees-sidecar-injector.yml -l lrcjemtrkubedt1

Après installation (04/09/2022) : 
 [root@lrcjemtrkubedt2 ~]# helm list -A
 NAME                            NAMESPACE                       REVISION        UPDATED                                         STATUS          CHART                                   APP VERSION
 cloudbees-core                  cloudbees-core-test             29              2022-02-06 16:55:40.378439667 +0100 CET         deployed        cloudbees-core-3.39.9+62d7abf51fb1      2.319.2.9
 cloudbees-sidecar-injector      cloudbees-sidecar-injector      2               2022-09-04 15:21:59.397349173 +0200 CEST        deployed        cloudbees-sidecar-injector-2.2.0        2.2.0
 ingress-nginx                   kube-system                     1               2022-08-23 09:59:41.328348044 +0200 CEST        deployed        ingress-nginx-4.1.4                     1.2.1
 kube-prometheus-stack           monitoring                      1               2022-08-23 10:22:22.181550171 +0200 CEST        deployed        kube-prometheus-stack-36.6.1            0.57.0
 kubernetes-dashboard            kube-system                     2               2022-08-23 10:26:27.8928038 +0200 CEST          deployed        kubernetes-dashboard-5.7.0              2.6.0
 metrics-server                  kube-system                     2               2022-08-23 10:27:44.972365397 +0200 CEST        deployed        metrics-server-3.8.2                    0.6.1
 nfs-subdir-external-provisioner kube-system                     1               2022-08-23 09:58:08.852146492 +0200 CEST        deployed        nfs-subdir-external-provisioner-4.0.16  4.0.2

====== CJOC (migré)======
{| class="wikitable" 
! jobs !! status mgration !! commentaires
|-
| tests job back up ||  ok || doivent etre resauvegarder
|}
====== usinevalidation (migré) ======

Test post migration :
* Monter la version de l'usineValidationJenkins
* Lancer les tests suivants :
** SharedLibrary : https://rec-k8s-cje-cloudbees-core.efluid.uem.lan/usinevalidationjenkins/job/FsharedLibrary/job/jenkinsSharedLibrary.compile/
** JenkinsConfiguration  : tous les tests du doxxier https://rec-k8s-cje-cloudbees-core.efluid.uem.lan/usinevalidationjenkins/job/FjenkinsConfigurations/
** Validation process : tous les tests du dossier https://rec-k8s-cje-cloudbees-core.efluid.uem.lan/usinevalidationjenkins/job/FvalidationProcess/
*Vérifier que les jobs de backup fonctionnent toujours


{| class="wikitable"
! jobs !! status mgration !! commentaires
|-
| tests sharedLib ||  ok   ||
|-
| tests jenkinsConf||  ok ||
|}

=====PROD -&gt; 2.319.2.9-rolling =====

Migration CJOC le 02/04/2022, depuis serveur lpswaulo1 (user carriers) pour exécution du playbook :
  ansible-playbook -i inventory/pro_kub_cje_cluster --ask-vault-pass -e @inventory/pro_kub_cje_cluster.vault playbooks/kubernetes/helm-deploy-cloudbees-core.yml -l lpcjemtrkubedt1

* Change : https://gerrit.efluid.uem.lan/c/oracleTools/+/226647

* Suivi d'installation via playbook : http://WPEROOM4.uem.lan/eRoom/Prod6/ProcessFabricationEfluid/0_17515

======Actions manuelles======
Sur le CJOC : 
* Editer et sauvegarder les jobs de backup présents sous : https://pro-k8s-cje-cloudbees-core.efluid.uem.lan/cjoc/view/All/job/Fadmin/job/Fbackups/
* Reconfigurer la version de l'image utilisée pour l'agent JNLP par défaut, au niveau du CJOC, objet " kubernetes-shared-cloud ", "pod template : default-java". Par défaut, l'image est indiquée à latest. A chaque migration, penser à configurer la version qui vient d'être installée.
** Done

Sur chaque Managed Controller migré : 

* Avertissement sur NODE_NAME : fin du terme master -&gt; built-in
[[image:migrationProd_2.319.2.9_NODE_NAME.PNG|1200px|]]
=&gt; Applied

Etat de migration des Managed Controllers"
{| class="wikitable"
! usine !! status migration
|-
| usineAdministration ||  Done 
|-
| UsineDeploiement ||   Done 
|-
| UsineInfraExploitation || Done  
|-
| UsineLogicielleCompilation || Done    
|-
| UsineLogicielleCompilationTools ||  Done 
|-
| UsineLogicielleNightlyBuild|| 14/04/2022 
|-
| UsineLogicielleQuality || Done 
|-
| UsineLogicielleRelease ||  Done  
|-
| UsinePerformance||   Done 
|-
| UsineRecette||   Done
|-
| UsineValidationApplications||   Done  
|-
| UsineValidationComposants||   14/04/2022
|-
| UsineValidationJenkins|| Done  
|}

======Problemes rencontrés pendant la migration ======
 - problème des jobs lancés en double :
	=&gt; du à IE, pas de problèmes si on utilise firefox (https://issues.jenkins.io/plugins/servlet/mobile#issue/JENKINS-66081)
  - problème de temps de lancement des pods :
	=&gt; les usines ont été redémarrées et on a plus de problème pour le moment
  - problème org.csanchez.jenkins.plugins.kubernetes.pipeline.ContainerExecDecorator.websocketConnectionTimeout currently set at 30 seconds :
	=&gt; Augmentation du nombre de connections (à 42)comme préconisé dans https://support.cloudbees.com/hc/en-us/articles/36)0054642231-Considerations-for-Kubernetes-Clients-Connections-when-using-Kubernetes-Plugin
  - java.lang.ClassNotFoundException: com.cloudbees.opscenter.server.model.ConnectedMasterPropertyDescriptor en boucle
	=&gt; Apres un redémarrage des usine, l'erreur est présente qu'au lancement de l'usine puis on ne les voit plus
  - problème d'affichage en double dasn els jobs free style:
        =&gt; du au plugin publish over ssh 
            upgrade du plugin 1.20.1 -&gt; 1.24</text>
      <sha1>8deokqjd44w29dv27wsr6omvxm4ske9</sha1>
    </revision>
  </page>
  <page>
    <title>PostgreSQL</title>
    <ns>0</ns>
    <id>702161</id>
    <revision>
      <id>4068233</id>
      <parentid>4068232</parentid>
      <timestamp>2023-01-30T12:40:08Z</timestamp>
      <contributor>
        <username>Guilmin</username>
        <id>511</id>
      </contributor>
      <comment>/* Outils */</comment>
      <origin>4068233</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4986" sha1="dvpucxiroy1ye2vfzzik835po1nk6wv" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = postgreSQL
 | logo              = PostgreSQL.jpg
 | siteInternet      = https://www.postgresql.org/
 | version           = {{outil.postgresql.version}}
 | guideInstallation = Guide d'installation de postgreSQL
 | faq               = [[FAQ:postgreSQL|FAQ postgreSQL]]
}}
[[Category:outil]]
[[Category:BDD]]

= Développeurs =
== Installations ==
=== Sur son poste de DEV ===
* En mode service Windows (démarrage automatique au démarrage du PC)
** Une demande d'installation de PG est à faire au 6000, car les droits admin sont nécessaires
* En mode zip (pas de service Windows, donc démarrage à la demande par le développeur)
** Installation à faire manuellement par le développeur, en récupérant le zip sur le site officiel : https://www.enterprisedb.com/download-postgresql-binaries
* Via Docker
** Pour les postes sous Windows 10 avec Docker installé (demande 6000 sinon pour l'obtenir) il est aussi possible d'utiliser les images officielles : https://hub.docker.com/_/postgres

== Documentation ==
* Doc du projet de migration Oracle -&gt; PG : http://wperoom4.uem.lan/eRoom/Production/GestionProjetEfluid/0_1f527e
* Syntaxe PG vs Oracle : http://wperoom4.uem.lan/eRoom/Production/GestionProjetEfluid/0_203f6c
* Règles de code pour la syntaxe BDD : [[Règles de code SQL pour la compatiblité multi-SGBD]]
* [[Conventions SQLMigrator]]

=== Utilisation d'une BDD mise à disposition par l'équipe PERF ===
{{alert|texte=Pour les mots de passes voir avec l'équipe PERF}}

* Bases actuellement disponibles : 
{| class="wikitable"
|-
! Base de données !! Port !! Schéma !! version PG
|-
| de15pgedt1 || 5432 || dev_pgsql_fld || 12.4
|}

== Utilisation ==
* Connexion à une BDD PG : 
** [[Connexion à une base de données Postgres sous Sqldeveloper]]
** Fonctionne aussi nativement avec IntelliJ : https://www.jetbrains.com/help/idea/connecting-to-a-database.html#connect-to-postgresql-database

= Infrastructure =
* [[Installation du moteur]]
* [[Création d'une instance]]
* [[Création d'une base de données]]
* [[Création d'un role et schema]]
* [[Sauvegarde/Export d'un schema]]
* [[Restauration/import d'un schema]]

= Performances =
=== Outils ===
* [[TemBoard]] :  permet de centraliser la supervision et l’administration d’un parc d’instances PostgreSQL.
** https://temboard.efluid.uem.lan  (les identifiants de connexion sont dans le keepass)
* [[pgAdmin]] : interface web d'administration pour postgreSQL
* [[PoWA]] : analyseur de trafic PostgreSQL permettant une analyse en temps réel et à postériori de l'activité de la BDD, et notamment des requêtes SQL
** https://powa.efluid.uem.lan (les identifiants de connexion sont dans le keepass)
* [[pg_profile]] : extension pour PostgreSQL permettant d'effectuer une analyse à postériori de l'activité d'une BDD, via la génération de rapports de même type que les rapport AWR côté Oracle
* [[pgBadger]] : analyseur de log pour PostgreSQL permettant de générer des rapports html présentant l'activité de la BDD.
* [[pg_activity]] : Permet de lister les sessions en cours sur une instance
** [postgres@ldbddedt1 ~]$ pg_activity -p $portInstance
* [[pev2]] : Permet de visualiser les plans d'executions des requêtes SQL
** http://pev2.efluid.uem.lan:8001/

=== Configuration ===

==== Surcharge de configuration par défaut ====
Sur le serveur hébergeant la base de donnée PG, le fichier ''postgresql.conf'' contient les valeurs par défaut mis en place par le socle DALIBO.
Il est parfois nécessaire de surcharger certaines valeurs lors de tests de performances. Pour ce faire il faut ajouter en fin de fichier ''postgresql.conf'' afin d'inclure une surcharge de configuration. 

Exemple:
   include 'surcharge.conf'

NOTE: Toutes les clés alors présentes dans le fichier ''surcharge.conf'' sont alors prioritaires par rapport au valeurs du fichier ''postgresql.conf''.

==== Configuration spécifique aux performances ====

Exemple de configuration:
  # Activation du module auto_plan
  shared_preload_libraries = 'pg_qualstats, pg_stat_kcache, pg_stat_statements, pg_wait_sampling, powa, auto_explain'
  auto_explain.log_min_duration = '0'
  auto_explain.log_analyze = true
  auto_explain.log_timing = true
  auto_explain.log_buffers = true
  # Activation log_statement 
  log_statement = 'mod'

'''module auto_plan'''

Voir plus de detail ici: https://docs.postgresql.fr/10/auto-explain.html

Ce module permet de logger les plans d'exécutions de toutes les requêtes joués dans les fichier de log postgres. Cela permet par le suite à pgBadger d'afficher les plans d'exécutions dans son rapport.

'''log_statement''' 

Voir plus de detail ici: https://www.postgresql.org/docs/13/runtime-config-logging.html

Permet de spécifier quels requêtes sont loggées. les valeurs possibles utilisées par l'équipes perf sont 'ddl' par défaut et 'mod'.
* ddl log les CREATE, ALTER, DROP, SELECT
* mod log en plus les INSERT, UPDATE, DELETE</text>
      <sha1>dvpucxiroy1ye2vfzzik835po1nk6wv</sha1>
    </revision>
  </page>
  <page>
    <title>SQL</title>
    <ns>0</ns>
    <id>181</id>
    <revision>
      <id>4065690</id>
      <parentid>4055277</parentid>
      <timestamp>2021-10-05T07:50:19Z</timestamp>
      <contributor>
        <username>Pochat</username>
        <id>27</id>
      </contributor>
      <origin>4065690</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="42773" sha1="g774auz3w2yh52axa3buoiaflm0ikn0" xml:space="preserve">{{Modèle:Infobox Outil
 | nom              = SQL
 | logo             = SQL.png
 | siteInternet     = https://fr.wikipedia.org/wiki/Structured_Query_Language
}}

[[Category:SQL]]

=Outils=
* [[sql developper]]

=Liens utiles=

* [http://wikefluid/index.php/Draft_-_R%C3%A8gles_de_code_SQL_pour_la_compatiblit%C3%A9_multi-SGBD  Règles de code SQL pour assurer la compatibilité entre plusieurs systèmes de SGBDR]
* [http://lalystar.developpez.com/fonctionsAnalytiques/ Les fonctions analytiques]
* [[Livrer_un_script_SQL|Livrer un script SQL]]
* [[Base de données clients]]
* [[Bases_de_donn%C3%A9es_de_d%C3%A9veloppement|Bases de données de développement]]
* [[Trucs et astuces SQL]]
* [http://eforum.uem.lan/viewtopic.php?f=42&amp;t=1002 Fil d'annonce ds scripts SQL passés sur les bases de développement]
* [[Procédure_de_validation_d'anonymisation_des_param%C3%A8tres_techniques]]
* [[Résumé des opérations possibles]]
* [http://wikefluid/index.php/Analyse_log_SQL Analyse automatique de logs SQL]

=Scripts SQL récurrents=

* [[scripts sql récurrents du domaine affaire générique|Affaire générique]]
* [[scripts sql récurrents du domaine contrat|Contrat]]
* [[scripts sql récurrents du domaine mensualisation|Mensualisation]]
* [[scripts sql récurrents du domaine offre|Offre]]
* [[scripts sql récurrents du domaine requêteur|Requêteur]]
* [[Groupe_de_d%C3%A9veloppement_consommation#Requ.C3.AAtes_utiles|Consommation]]
* [[scripts sql récurrents du domaine workflow|Workflow]]

= Vider le cache Oracle =
*alter system flush shared_pool;
*alter system flush buffer_cache;

http://www.aide-oracle.net/2009/04/vidage-de-cache.html

= Comparaison de chaîne de caractères =
* [http://docs.oracle.com/cd/E14072_01/appdev.112/e10577/u_match.htm UTL_MATCH Levenshtein Distance]
* [http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions148.htm Soundex (phonétique)]
* [http://docs.oracle.com/cd/B28359_01/server.111/b28286/functions027.htm Conversion du jeu de caractères]
* Ne récupérer que les chiffres : [http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions130.htm regexp_replace] regexp_replace(chaîne, '[^[:digit:]]', ' ')
* Comparer avec une expression régulière : [http://docs.oracle.com/cd/B14117_01/server.101/b10759/conditions018.htm REGEXP_LIKE]

==  Comparaison et concaténation ==
* Attention à bien forcer au niveau SQL le typage pour avoir des deux côté de la comparaison le même type =&gt; TO_CHAR(xxx) si jamais on compare une chaine de caractère et une concaténation de VARCHAR et types numériques.

=Les jointures=
==Inner Join==
Cette jointure renvoie les lignes lorsqu’il y a au moins une correspondance dans les 2 tables.

[[Image:innerJoin.png|Inner Join|250px]]

==Left Join==
Cette jointure est un alias de Left Outer Join et retourne toutes les lignes de la table de gauche en lien avec les lignes correspondantes de la table de droite. S'il n'y a pas de colones correspondantes dans la table de droite, cela renvoie des valeurs NULL.

[[Image:LeftOuterJoin.png|Left Join|250px]]

==Right Join==
Cette jointure est un alias de Right Outer Join et retourne toutes les lignes de la table de droite en lien avec les lignes correspondantes de la table de gauche. S'il n'y a pas de colones correspondantes dans la table de gauche, cela renvoie des valeurs NULL.

[[Image:RightOuterJoin.png|Right Join|250px]]

= Fonctions d'aggrégation =
* [http://www.oracle-base.com/articles/misc/StringAggregationTechniques.php Concaténation]

= Gestion du format des dates =
*Liste des options pour formater une date :
http://docs.oracle.com/cd/B19306_01/server.102/b14200/sql_elements004.htm

*Modifier l'affichage par défaut du format des dates : 
La commande ci-dessous permet d'afficher des colonnes de type date au format souhaité par défaut.
Elle permet également d'exécuter des requêtes en passant directement la date au format String sans utiliser des to_date(...). 
Exemple : 
 ALTER SESSION SET NLS_DATE_FORMAT='dd/mm/yyyy hh24:mi:ss';
 update maTable set maDate='21/01/2011 10:01:15' /* ça fonctionne */

= Les séquences =
== Modifier le nextval d'une séquence ==
[http://fadace.developpez.com/oracle/sequences/ http://fadace.developpez.com/oracle/sequences/]

* Il n'y a pas de commande ALTER SEQUENCE SEQ_TEST MODIFY LAST_NUMBER=1000. Afin d'incrémenter la séquence, il y a 3 options, dont certaines sont plus élégantes que les autres
** Exécuter des nextval successifs
** Supprimer, puis recréer la séquence
** Modifier l'incrément
&lt;source lang="SQL"&gt;
declare nseq number, nincr number ;
SELECT SEQ_MaSequence.nextval, increment  INTO nseq, nincr FROM USER_SEQUENCES WHERE SEQUENCE_NAME='SEQ_MASEQUENCE';
ALTER SEQUENCE SEQ_MASEQUENCE INCREMENT BY &amp;NouvelleValeur - nseq ;
SELECT SEQ_MaSequence.nextval from dual ;
ALTER SEQUENCE SEQ_MASEQUENCE INCREMENT BY nincr ;
&lt;/source&gt;

=Modèles de scripts=
==Requêtes pratiques==
===Script pour rechercher un id référencé dans toute table, toute colonne===
(testé sur toad et sql developper (dernière version 3.0.04))
&lt;source lang="sql"&gt;
set autoprint on;
set serveroutput ON;
DECLARE
  CURSOR CUR_ IS 
    SELECT atc.TABLE_NAME, atc.COLUMN_NAME
    FROM user_tab_columns atc
    where   (   atc.COLUMN_NAME like '%%ID'
            or  atc.COLUMN_NAME = 'SRC'
            or  atc.COLUMN_NAME = 'SOURCE'
            or  atc.COLUMN_NAME = 'DEST' );

  Trouve number;
  sqlstr varchar2 (4000);
  SearchValue varchar2(255):='CRITNAT8'; --  rentrer l’id recherché ici
BEGIN
  FOR C IN CUR_ LOOP 
    sqlstr:='select /*+ PARALLEL('||C.TABLE_NAME||') */ count(*) from '||C.TABLE_NAME||' where '|| c.COLUMN_NAME ||' = '''|| SearchValue ||'''';
    begin
      execute immediate sqlstr INTO Trouve;
    exception when others then Trouve:=0;
    end;
    IF Trouve&lt;&gt;0 then
      dbms_output.put_line('Valeur trouvée dans '||C.TABLE_NAME||'.'||c.COLUMN_NAME ||' par la requete '|| sqlstr);
    end IF;
  END LOOP;
END;
&lt;/source&gt;
Version avec inhibition du parallélisme en cas de présence d'un index sur la colonne visée et non prise en compte des tables batch et vues du requêteur :
&lt;source lang="sql"&gt;
set autoprint on;
set serveroutput on;
declare
  cursor cur is 
    select UTC.TABLE_NAME, UTC.COLUMN_NAME, listagg(UIDD.INDEX_NAME, ';') within group (order by UTC.TABLE_NAME, UTC.COLUMN_NAME) INDEX_NAME
      from USER_TAB_COLUMNS UTC
        left join USER_INDEXES_DESCRIPTION UIDD on UIDD.TABLE_NAME = UTC.TABLE_NAME
                                                  and UIDD.COLUMN_NAME = UTC.COLUMN_NAME
      where UTC.TABLE_NAME not like 'BATCH_%'
        and UTC.TABLE_NAME not like 'MV_%'
        and UTC.TABLE_NAME not like 'VRS_%'
        and UTC.TABLE_NAME not like 'VRP_%'
        and (UTC.COLUMN_NAME like '%%ID'
        or UTC.COLUMN_NAME = 'SRC'
        or UTC.COLUMN_NAME = 'SOURCE'
        or UTC.COLUMN_NAME = 'DEST')
      group by UTC.TABLE_NAME, UTC.COLUMN_NAME;
  v_trouve number;
  v_requete varchar2(4000);
  v_valeurRecherchee varchar2(255) := '#TeIJ9'; --  rentrer l’id recherché ici
begin
  for enr in cur loop 
    if enr.INDEX_NAME is null then
      v_requete := 'select /*+ ENABLE_PARALLEL_DML PARALLEL('||enr.TABLE_NAME||') */ count(*) from '||enr.TABLE_NAME||' where '|| enr.COLUMN_NAME ||' = '''|| v_valeurRecherchee ||'''';
    else
      v_requete := 'select count(*) from '||enr.TABLE_NAME||' where '|| enr.COLUMN_NAME ||' = '''|| v_valeurRecherchee ||'''';
    end if;
    begin
      execute immediate v_requete into v_trouve;
    exception
      when others then v_trouve := 0;
    end;
    if v_trouve &gt; 0 then
      dbms_output.put_line('Valeur trouvée dans '||enr.TABLE_NAME||'.'||enr.COLUMN_NAME ||' par la requete '|| v_requete);
    end if;
  end loop;
end;
/
&lt;/source&gt;

Le résultat indique la table et la colonne concernée pour chaque ligne trouvée ainsi qu'un bout de requête permettant d'aller voir directement ce qui se passe
Valeur trouvée dans TVALEURENUMERE.CRITERE_ID par la requete select count(*) from TVALEURENUMERE where CRITERE_ID='CRITNAT8'

===Script pour trouver toutes les modification apportée en base par une action TP===
&lt;source lang="sql"&gt;
SET autoprint ON;
SET serveroutput ON;
DECLARE
  cursor cur IS 
    SELECT UTC.TABLE_NAME, UTC.COLUMN_NAME
      FROM USER_TAB_COLUMNS UTC
      WHERE UTC.TABLE_NAME NOT LIKE 'BATCH_%'
        AND UTC.TABLE_NAME NOT LIKE 'MV_%'
        AND UTC.TABLE_NAME NOT LIKE 'VRS_%'
        AND UTC.TABLE_NAME NOT LIKE 'VRP_%'
        AND (UTC.COLUMN_NAME = 'DATEMODIFICATION'
        OR UTC.COLUMN_NAME = 'DATECREATION')
      GROUP BY UTC.TABLE_NAME, UTC.COLUMN_NAME;
  v_trouve NUMBER;
  v_requete varchar2(4000);
  v_dateMin varchar2(255) := '05/09/2019 10:10'; -- ? date au format dd/mm/yyyy hh24:mi
  v_dateMax varchar2(255) := '05/09/2019 10:25'; -- ? date au format dd/mm/yyyy hh24:mi
BEGIN
  FOR enr IN cur loop 
      v_requete := 'select /*+ ENABLE_PARALLEL_DML PARALLEL('||enr.TABLE_NAME||') */ count(*) 
                      from '||enr.TABLE_NAME||' 
                      where '|| enr.COLUMN_NAME ||' &gt; to_date('''|| v_dateMin ||''', ''dd/mm/yyyy hh24:mi'') 
                        and '|| enr.COLUMN_NAME ||' &lt; to_date('''|| v_dateMax ||''', ''dd/mm/yyyy hh24:mi'')';
    BEGIN
      EXECUTE immediate v_requete INTO v_trouve;
    exception
      WHEN others THEN v_trouve := 0;
    END;
    IF v_trouve &gt; 0 THEN
      dbms_output.put_line('Valeur trouvée dans '||enr.TABLE_NAME||'.'||enr.COLUMN_NAME ||' par la requete '|| v_requete);
    END IF;
  END loop;
END;
/
&lt;/source&gt;

===Script pour insérer ou updater une valeur===
&lt;source lang="sql"&gt;
MERGE INTO NOMDETABLE OBJET 
USING (SELECT
	valeur1 as nomcolonne1
	valeur2 as nomcolonne2
	valeur3 as nomcolonne3...
       FROM DUAL) NEW_OBJECT 		-- valeur finale de l'objet que l'on veut soit insérer, soit mettre à jour
ON (comparaison de valeur entre l'OBJET s'il existe et la nouvelle valeur NEW_OBJECT) –- condition qui permet de distinguer l’insert de l’update
WHEN NOT MATCHED THEN 			–- si la condition ON () est non remplie  ? on fait un INSERT classique en utilisant les nouvelles valeurs
INSERT (nomcolonne1           , nomcolonne2           , nomcolonne3...  )
VALUES (NEW_OBJECT.nomcolonne1, NEW_OBJECT.nomcolonne2, NEW_OBJECT.nomcolonne3...)
WHEN MATCHED THEN 			--si la condition  ON () est      remplie ? on fait un UPDATE classique en utilisant les nouvelles valeurs
UPDATE SET 
  OBJET.nomcolonne1 = NEW_OBJECT.nomcolonne1,
  OBJET.nomcolonne2 = NEW_OBJECT.nomcolonne2,
  OBJET.nomcolonne3 = NEW_OBJECT.nomcolonne3...
;
&lt;/source&gt;

Exemple : [[Requete SQL Exemple Merge Into]]

==Table==
===Script pour renommer la colonne MACOLONNE de la table MATABLE===
&lt;source lang="sql"&gt;
alter table MATABLE rename column MACOLONNE to MACOLONNE3;
&lt;/source&gt;

===Script pour modifier le type de la colonne MACOLONNE de la table MATABLE===
* Cas 1 : augmentation de la taille de la colonne

&lt;source lang="sql"&gt;
alter table MATABLE modify
(
    MACOLONNE VARCHAR2(120)
);
&lt;/source&gt;

* Cas 2 : diminution de la taille de la colonne
&lt;source lang="sql"&gt;
-- on ajoute une nouvelle colonne ayant la bonne taille
alter table MATABLE add ( MACOLONNE_NEW VARCHAR2(50) );

-- on met à jour la nouvelle colonne avec les données de l'ancienne
-- la fonction pour "diminuer" les valeurs existantes sont
-- chaine de caractère : substr
-- nombre : trunc
update MATABLE set MACOLONNE_NEW = substr(MACOLONNE, 1, 50);
commit;

-- on vide l'ancienne colonne pour pouvoir la supprimer
update MATABLE set MACOLONNE = NULL;
commit;

-- on supprime l'ancienne colonne
alter table MATABLE drop (MACOLONNE);

-- on renomme la nouvelle colonne
alter table MATABLE rename column MACOLONNE_NEW to MACOLONNE;
&lt;/source&gt;

* Cas 3 : modification du type de la colonne (exemple : passage d'un VARCHAR2 à un NUMBER)
&lt;source lang="sql"&gt;
-- on ajoute une nouvelle colonne ayant la bonne taille
alter table MATABLE add ( MACOLONNE_NEW NUMBER(2) );

-- on met à jour la nouvelle colonne avec les données de l'ancienne
-- la fonction pour "migrer" les valeurs existantes sont
-- chaine de caractère --&gt; nombre : to_number
-- nombre --&gt; chaine de caractère : to_char
-- chaine de caractère --&gt; date : to_date
update MATABLE set MACOLONNE_NEW = to_number(MACOLONNE);
-- ou règle particulière
update MATABLE set MACOLONNE_NEW = 1 where MACOLONNE='TOTO';

commit;

-- on vide l'ancienne colonne pour pouvoir la supprimer
update MATABLE set MACOLONNE = NULL;
commit;

-- on supprime l'ancienne colonne
alter table MATABLE drop (MACOLONNE);

-- on renomme la nouvelle colonne
alter table MATABLE rename column MACOLONNE_NEW to MACOLONNE;
&lt;/source&gt;

== Script générique de migration ==
&lt;source lang="sql"&gt;
WHENEVER SQLERROR EXIT SQL.SQLCODE

DEFINE TBS_DATA=&amp;1
DEFINE TBS_INDEX=&amp;2
DEFINE TBS_PARAM=&amp;3
DEFINE TBS_BLOB=&amp;4

DEFINE TBS_TMP='MIG_EFLUID12_TM' -- nom du TBS a utiliser pour la migration
DEFINE TBS_DATA=&amp;TBS_TMP

SET SERVEROUTPUT ON

/**
 * procedure stockee permettant d'afficher la requete executee dans la log, son temps d'execution ainsi que
 * le nombre de lignes affectees. Ne fonctionne pas avec les requetes retournant un resultat grace a une
 * clause INTO ou BULK COLLECT INTO. Si quelqu'un a une idee a ce sujet... x)
 * p_sql_request : la requete
 * p_debug_mode  : Optionnel (TRUE par defaut) . TRUE si on veut afficher la requete sans l'executer, FALSE sinon.
 */
CREATE OR REPLACE PROCEDURE log_and_execute (p_sql_request CLOB, p_debug_mode BOOLEAN DEFAULT TRUE) AUTHID CURRENT_USER IS
v_sql_request_start_time PLS_INTEGER;
v_sql_request_end_time   PLS_INTEGER;
v_rowcount               PLS_INTEGER;
v_log_message            CLOB;
v_sql_request_type       VARCHAR2(6);
BEGIN
  DBMS_OUTPUT.PUT_LINE('INFO      : ' || p_sql_request);
  
  IF NOT p_debug_mode THEN
    v_sql_request_start_time := DBMS_UTILITY.GET_TIME;
    v_sql_request_type := SUBSTR(p_sql_request, 1, 6);
    
    EXECUTE IMMEDIATE p_sql_request;
    
    v_rowcount := SQL%ROWCOUNT;
    COMMIT;
    v_sql_request_end_time   := DBMS_UTILITY.GET_TIME;
    v_log_message := 'Requete terminee en ' || ((v_sql_request_end_time - v_sql_request_start_time) / 100) || ' seconde';
    
    IF ((v_sql_request_end_time - v_sql_request_start_time) / 100) &gt;= 2 THEN
      v_log_message := v_log_message || 's';
    END IF;
    
    v_log_message := v_log_message || '. ' || v_rowcount; 
  
    IF v_rowcount &gt; 1 THEN
      v_log_message := v_log_message || ' lignes' || 
        CASE v_sql_request_type 
          WHEN 'INSERT' THEN 
            ' inserees' 
          WHEN 'UPDATE' THEN 
            ' mises a jour' 
          WHEN 'DELETE' THEN 
            ' supprimees' 
          WHEN 'SELECT' THEN 
            ' selectionnees'
          ELSE
            ' affectees'
        END || '.';
    ELSE
      v_log_message := v_log_message || ' ligne' || 
        CASE v_sql_request_type 
          WHEN 'INSERT' THEN 
            ' inseree' 
          WHEN 'UPDATE' THEN 
            ' mise a jour' 
          WHEN 'DELETE' THEN 
            ' supprimee' 
          WHEN 'SELECT' THEN 
            ' selectionnee'
          ELSE
            ' affectee'
        END || '.';
    END IF;
    
    DBMS_OUTPUT.PUT_LINE('INFO      : ' || v_log_message);
  END IF;
END;
/

DECLARE
  v_sql_request_insert_part LONG;
  v_sql_request_select_part LONG;
  
  TYPE table_column_list IS TABLE OF VARCHAR2(30);
  TYPE table_column_list_item IS RECORD (
    column_list table_column_list,
    override_global BOOLEAN DEFAULT FALSE
  );
  
  TYPE table_list IS TABLE OF table_column_list_item INDEX BY VARCHAR2(30);
  v_table_list table_list;
  v_table_column_list table_column_list;
  
  TYPE global_table_list IS TABLE OF VARCHAR2(30);
  TYPE global_table_column_list IS TABLE OF VARCHAR2(30);
  v_global_table_list global_table_list;
  v_global_column_list global_table_column_list;
  
  v_table VARCHAR2(30);
  v_column VARCHAR2(30);
  
  TYPE junction_table_column_list IS TABLE OF LONG INDEX BY VARCHAR2(30);
  v_junction_table_column_list junction_table_column_list;
  v_junction_table VARCHAR2(30);
  
  TYPE junction_column_list IS TABLE OF VARCHAR2(30) INDEX BY VARCHAR2(4);
  v_junction_column_list junction_column_list;
  v_junction_table_column VARCHAR2(30);
  v_junction_direction VARCHAR2(30);
  
  TYPE column_special_condition IS RECORD (
    condition LONG,
    override_global BOOLEAN DEFAULT FALSE
  );
  
  v_override_global BOOLEAN;
  TYPE col_special_condition_list IS TABLE OF column_special_condition INDEX BY VARCHAR2(30);
  TYPE special_condition_list IS TABLE OF col_special_condition_list INDEX BY VARCHAR2(30);
  v_special_condition_list special_condition_list;
  v_global_special_condition LONG;
  v_parsed_global_special_cnd LONG;
  v_special_condition LONG;

  v_tmp_table_suffix LONG;
  v_sql_request LONG;
  v_sql_req_ins_tmp_tbl_sel_part LONG;
  v_sql_req_ins_tmp_tbl_ins_part LONG;
  v_sql_req_ins_tmp_tbl_frm_part LONG;
  v_table_size PLS_INTEGER;
  v_free_space PLS_INTEGER;
  v_original_table_line_count PLS_INTEGER;
  v_new_table_line_count PLS_INTEGER;
  v_error_text LONG;
  e_not_enough_free_space EXCEPTION;
  e_different_line_count  EXCEPTION;
  TYPE pk_index_table IS TABLE OF LONG INDEX BY PLS_INTEGER;
  v_pk_index_table pk_index_table;
  
  TYPE constraint_table IS TABLE OF LONG INDEX BY PLS_INTEGER;
  v_constraint_table constraint_table;
  v_constraint LONG;
  
  TYPE index_table IS TABLE OF LONG INDEX BY PLS_INTEGER;
  v_index_table index_table;
  v_index LONG;
  TYPE rebuild_index_sql_req_table IS TABLE OF LONG INDEX BY PLS_INTEGER;
  v_rebuild_index_sql_req_table rebuild_index_sql_req_table;
  v_table_treatment_start_time POSITIVE;
  v_table_treatment_end_time   POSITIVE;
  v_treatment_start_time       POSITIVE;
  v_treatment_end_time         POSITIVE;
  
  v_skip_insert BOOLEAN DEFAULT FALSE;
  v_debug_mode BOOLEAN DEFAULT TRUE;
BEGIN
  v_treatment_start_time := DBMS_UTILITY.GET_TIME;
  --------------------------
  -- parametres du script --
  --------------------------
  
  -- s'il vaut TRUE, alors aucune requête ne sera éxécutée. Seule subsisteront
  -- les traces dans le log. C'est le comportement par défaut.
  -- v_debug_mode := FALSE;
  DBMS_OUTPUT.PUT_LINE('DEBUG_MODE : ' || CASE v_debug_mode WHEN TRUE THEN 'TRUE' ELSE 'FALSE' END);
  
  -- s'il vaut TRUE, alors on passe l'etape d'insertion des liens dans la
  -- table de liens. FALSE par defaut.
  -- v_skip_insert := TRUE;
  DBMS_OUTPUT.PUT_LINE('SKIP_INSERT : ' || CASE v_skip_insert WHEN TRUE THEN 'TRUE' ELSE 'FALSE' END);
  
  -- suffixe des tables temporaires
  v_tmp_table_suffix := '_MIG';
  
  -- nom de la table de liens
  v_junction_table := 'TUTILISATEURINFO';
  
  -- liste des 2 composantes du lien, avec indication du sens
  -- dans lequel on insere les liens manquants, et dans lequel
  -- on fait la migration. Les valeurs trouvees dans les attributs
  -- des tables à migrer seront inserees dans la colonne 'FROM'
  -- de la table de liens. Les valeurs des attributs des tables
  -- a migrer seront remplacees par celles de la colonne 'TO'
  -- de la table de liens
  v_junction_column_list('FROM') := 'IDENTIFIANTLOG';
  v_junction_column_list('TO')   := 'ID';
  
  -- liste des colonnes de la table de liens, avec pour chacune
  -- d'elles la valeur a inserer. Ces valeurs sont utilisees
  -- pour l'insertion des n-uplets manquants dans la table de liens.
  -- La colonne qui n'est pas indiquee est valorisee par une sous-requete
  v_junction_table_column_list('ID')               := 'GestionIdentifiant.genereIdBase62 (''useruniqueid'', '''')';
  v_junction_table_column_list('ETATOBJET')        := '0';
  v_junction_table_column_list('DATEMODIFICATION') := 'NULL';
  v_junction_table_column_list('DATECREATION')     := 'CURRENT_DATE';
  v_junction_table_column_list('DATESUPPRESSION')  := 'NULL';
  
  --/*
  -- liste des tables a migrer
  v_global_table_list := global_table_list(
    'TFACTURE',
    'TCONTEXTEFACTURATION',
    'TDEVIS',
    'TARTICLE',
    'TLIGNEHISTORIQUE',
    'TCHAPITRE'
  );
  
  -- liste des attributs a migrer communs a
  -- toutes les tables
  v_global_column_list := global_table_column_list(
    'ACTEURCREATION', 
    'ACTEURMODIFICATION', 
    'ACTEURSUPPRESSION'
  );
  --*/
  
  -- condition s'appliquant a toutes les colonnes de toutes
  -- les tables a migrer lors de la selection des valeurs
  -- a ajouter dans la table de liens
  v_global_special_condition := 'AND $COLUMN_NAME LIKE ''%|%'' OR $COLUMN_NAME LIKE ''Injecteur%''';
  
  /*
  -- liste permettant d'ajouter une condition specifique a chacune des colonnes
  -- des tables a migrer. Le champ override_global permet de specifier si
  -- cette condition doit surcharger la condition globale. Par defaut, ce champ
  -- est a FALSE, et la condition specifique vient donc s'ajouter en plus de la
  -- condition globale
  v_special_condition_list('TFACTURE')('ACTEURCREATION').condition       := 'OR ACTEURCREATION LIKE ''GBA95219_%''';
  v_special_condition_list('TFACTURE')('ACTEURMODIFICATION').condition   := 'OR ACTEURMODIFICATION LIKE ''GBA95219_%''';
  v_special_condition_list('TFACTURE')('ACTEURSUPPRESSION').condition    := 'OR ACTEURSUPPRESSION LIKE ''GBA95219_%''';
  --*/
  
  /*
  -- indique des colonnes a migrer specifiques a une table. Si override_global est a
  -- TRUE, alors ces colonnes remplaceront les colonnes definies dans
  -- v_global_column_list. Sinon, elles s'ajouteront a ces dernieres.
  v_table_list('TCONTEXTEFACTURATION').column_list := table_column_list(
    'FOO',
    'BAR'
  );
  v_table_list('TCONTEXTEFACTURATION').override_global := TRUE;
  --*/
  
  --/*
  -- on parcours la liste des tables a migrer renseignees dans v_global_table_list.
  -- Pour chacune d'entre elles, on cree une liste de colonnes vide et on regarde
  -- si il y en a une de definie
  IF v_global_table_list IS NOT NULL THEN
    FOR i IN 1..v_global_table_list.COUNT LOOP
      v_table_column_list := table_column_list();
      -- si une liste de colonnes est deja definie pour la table courant dans v_table_list
      -- et si cette liste n'a pas son attribut override_global a FALSE, ou bien s'il
      -- n'existe tout simplement pas d'entree dans v_table_list pour la table courante...
      IF (v_table_list.EXISTS(v_global_table_list(i)) AND NOT v_table_list(v_global_table_list(i)).override_global)
        OR NOT v_table_list.EXISTS(v_global_table_list(i)) THEN
        -- on ajoute les colonnes de v_global_column_list dans la liste de colonnes
        -- nouvellement creee
        FOR j IN 1..v_global_column_list.COUNT LOOP
          v_table_column_list.EXTEND;
          v_table_column_list(j) := v_global_column_list(j);
        END LOOP;
        -- on verifie qu'il y a une entree dans v_table_list pour la table courante
        IF v_table_list.EXISTS(v_global_table_list(i)) THEN
          -- si oui, on ajoute les colonnes definies dans cette entree a la suite de celles
          -- copiees de v_global_column_list dans v_table_column_list
          FOR j IN (v_global_column_list.COUNT + 1)..(v_global_column_list.COUNT + v_table_list(v_global_table_list(i)).column_list.COUNT) LOOP
            v_table_column_list.EXTEND;
            v_table_column_list(j) := v_table_list(v_global_table_list(i)).column_list(j - v_global_column_list.COUNT);
          END LOOP;
        END IF;
        -- on affecte la nouvelle liste a l'entree correspondant a la table courante
        -- dans v_table_list
        v_table_list(v_global_table_list(i)).column_list := v_table_column_list;
      END IF;
    END LOOP;
  END IF;
  
  v_table := v_table_list.FIRST;
  v_sql_request_insert_part := 'INSERT INTO ' || v_junction_table || ' (';
  v_junction_table_column := v_junction_table_column_list.FIRST;
  
  v_sql_request_select_part := 'SELECT ';
  
  -- boucle qui cree la requete d'insertion des n-uplets dans la table de liens.
  LOOP
    -- pour chacune des colonnes de la table de liens...
    EXIT WHEN v_junction_table_column IS NULL;
    -- si on est pas a la premiere iteration, on ajoute une virgule pour separer
    -- les noms des colonnes
    IF v_junction_table_column &lt;&gt; v_junction_table_column_list.FIRST THEN
      v_sql_request_insert_part := v_sql_request_insert_part || ', ';
      v_sql_request_select_part := v_sql_request_select_part || ', ';
    END IF;
    
    -- on ajoute le nom de la colonne sur laquelle on itere dans la partie
    -- INSERT et dans la partie SELECT de la requete d'insertion dans la table de
    -- liens
    v_sql_request_insert_part := v_sql_request_insert_part || v_junction_table_column;
    v_sql_request_select_part := v_sql_request_select_part || v_junction_table_column_list(v_junction_table_column);
    v_junction_table_column := v_junction_table_column_list.NEXT(v_junction_table_column);
  END LOOP;
  
  IF NOT v_junction_table_column_list.EXISTS(v_junction_column_list('FROM')) THEN
    v_junction_direction := v_junction_column_list('FROM');
  ELSE
    v_junction_direction := v_junction_column_list('TO');
  END IF;
  
  v_sql_request_insert_part := v_sql_request_insert_part || ', ' || v_junction_direction || ') ' || v_sql_request_select_part;
  
  LOG_AND_EXECUTE('ALTER SESSION ENABLE PARALLEL DML', v_debug_mode);

  LOG_AND_EXECUTE('ALTER SESSION SET SKIP_UNUSABLE_INDEXES = TRUE', v_debug_mode);
  
  -- pour chacune des tables a migrer...
  LOOP
    EXIT WHEN v_table IS NULL;
    BEGIN
      DBMS_OUTPUT.PUT_LINE('*********** Debut de traitement pour la table ' || v_table || '.');
      v_sql_req_ins_tmp_tbl_frm_part := '';
      v_table_treatment_start_time := DBMS_UTILITY.GET_TIME;
      -- on cree le debut de la requete qui determinera les donnees a inserer dans la table
      -- temporaire
      SELECT 'SELECT /*+ PARALLEL ' || v_table || ' */ ' ||  LISTAGG(table_name || '.' || column_name, ', ') WITHIN GROUP (ORDER BY column_id) || ' FROM ' || v_table || ' ' INTO v_sql_req_ins_tmp_tbl_sel_part FROM user_tab_cols WHERE table_name = v_table AND column_id IS NOT NULL;
  
      v_column := v_table_list(v_table).column_list.FIRST;
      -- pour chacune des colonnes a migrer pour la table courante
      LOOP
        EXIT WHEN v_column IS NULL;
        -- si on veut proceder a l'insertion des n-uplets dans la table de liens
        IF NOT v_skip_insert THEN
          -- on complete la requete d'insertion dans la table de liens, la partie FROM
          -- du SELECT notamment
          v_sql_request_select_part := ', ' || v_table_list(v_table).column_list(v_column)
                                       || ' FROM (' 
                                              || 'SELECT DISTINCT /*+ PARALLEL ' || v_table || ' */ '
                                              || v_table_list(v_table).column_list(v_column)
                                              || ' FROM '
                                              || v_table
                                              || ' WHERE ' || v_table_list(v_table).column_list(v_column) || ' IS NOT NULL';
          
          v_override_global   := FALSE;
          v_special_condition := '';
          
          -- si une condition specifique pour cette table et cette colonne existe, alors on l'ajoute
          -- a la suite du WHERE. On stocke la valeur de l'attribut override_global de la condition
          -- en meme temps
          IF v_special_condition_list.EXISTS(v_table) THEN
            IF v_special_condition_list(v_table).EXISTS(v_table_list(v_table).column_list(v_column)) THEN
              v_special_condition := ' ' || v_special_condition_list(v_table)(v_table_list(v_table).column_list(v_column)).condition;
              v_override_global   := v_special_condition_list(v_table)(v_table_list(v_table).column_list(v_column)).override_global;
            END IF;
          END IF;
          
          -- si une condition globale existe et que l'attribut override_global
          -- precedemment stocke est a FALSE...
          IF v_global_special_condition IS NOT NULL AND NOT v_override_global THEN
            -- on ajoute la condition globale, prealablement parsee (le $COLUMN_NAME est automatiquement
            -- remplace par le nom de la colonne courante)
            SELECT REPLACE(v_global_special_condition, '$COLUMN_NAME', v_table_list(v_table).column_list(v_column)) INTO v_parsed_global_special_cnd FROM DUAL;
            v_sql_request_select_part := v_sql_request_select_part || ' ' || v_parsed_global_special_cnd || v_special_condition;
          END IF;
          
          -- on fini par un MINUS pour ne pas prendre en compte les valeurs deja presentes
          -- dans la table de liens
          v_sql_request_select_part := v_sql_request_select_part || ' MINUS SELECT ' || v_junction_direction
                                       || ' FROM ' || v_junction_table;
          
          v_sql_request_select_part := v_sql_request_select_part || ')';
          
          LOG_AND_EXECUTE(v_sql_request_insert_part || v_sql_request_select_part, v_debug_mode);
        END IF;
        
        -- on termine la boucle en remplacant le nom de la colonne a migrer courante
        -- dans la partie SELECT de la requete d'insertion dans la table temporaire
        -- par un appel a la fonction NVL selectionnant l'autre extremite du lien (v_junction_column_list('TO'))
        SELECT REGEXP_REPLACE(v_sql_req_ins_tmp_tbl_sel_part, '([, ])' || v_table || '.' || v_table_list(v_table).column_list(v_column) || '([, ])', '\1NVL(' || v_table_list(v_table).column_list(v_column) || '_MIG.' || v_junction_column_list('TO') || ', ' || v_table || '.' || v_table_list(v_table).column_list(v_column) || ')\2') INTO v_sql_req_ins_tmp_tbl_sel_part FROM DUAL;
        v_sql_req_ins_tmp_tbl_frm_part := v_sql_req_ins_tmp_tbl_frm_part || 'LEFT OUTER JOIN ' || v_junction_table || ' ' || v_table_list(v_table).column_list(v_column) || '_MIG ON ' || v_table || '.' || v_table_list(v_table).column_list(v_column) || ' = ' || v_table_list(v_table).column_list(v_column) || '_MIG.' ||  v_junction_column_list('FROM') || ' ';
        v_column := v_table_list(v_table).column_list.NEXT(v_column);
      END LOOP;
      
      v_sql_request :=
           'SELECT megs table_size FROM (SELECT SUM (bytes) / 1048576 megs, segment_name FROM user_extents '
            || 'WHERE segment_type in (''TABLE'',''TABLE SUBPARTITION'') '
            || 'GROUP BY segment_name) ue INNER JOIN '
            || 'user_tables ON user_TABLES.TABLE_NAME = ue.segment_name '
            || 'WHERE user_TABLES.table_name = '''
            || v_table
            || '''';
      DBMS_OUTPUT.PUT_LINE('INFO      : ' || v_sql_request);
      
      IF NOT v_debug_mode THEN
        EXECUTE IMMEDIATE v_sql_request INTO v_table_size;
      END IF;
      
      v_sql_request := 'SELECT SUM(bytes)/1024/1024 FROM user_free_space WHERE tablespace_name = ''&amp;TBS_DATA'' GROUP BY tablespace_name';
      
      DBMS_OUTPUT.PUT_LINE('INFO      : ' || v_sql_request);
      IF NOT v_debug_mode THEN
        EXECUTE IMMEDIATE v_sql_request INTO v_free_space;
      END IF;
      
      v_table_size := 0;
      v_free_space := 0;

      IF v_table_size &gt; v_free_space THEN
        RAISE e_not_enough_free_space;
      END IF;
      
      -- on cree la table temporaire comme une copie vide de la table d'origine,
      -- de maniere a en avoir la structure
      LOG_AND_EXECUTE('CREATE TABLE ' || v_table || v_tmp_table_suffix || ' TABLESPACE &amp;TBS_DATA ' || 'AS  SELECT * FROM ' || v_table  || ' WHERE 1 = 0', v_debug_mode);

      -- on ajoute la partie INSERT a la requete de selection et on l'execute
      SELECT 'INSERT /*+ PARALLEL APPEND ' || v_table || v_tmp_table_suffix || ' */ INTO ' || v_table || v_tmp_table_suffix || ' (' || LISTAGG(column_name, ', ') WITHIN GROUP (ORDER BY column_id) || ') ' INTO v_sql_req_ins_tmp_tbl_ins_part FROM user_tab_cols WHERE table_name = v_table AND column_id IS NOT NULL;
      
      LOG_AND_EXECUTE(v_sql_req_ins_tmp_tbl_ins_part || v_sql_req_ins_tmp_tbl_sel_part || v_sql_req_ins_tmp_tbl_frm_part, v_debug_mode);
      
      v_sql_request := 'SELECT /*+ PARALLEL ' || v_table || ' */
           COUNT (*) FROM ' || v_table;
      IF NOT v_debug_mode THEN
        EXECUTE IMMEDIATE v_sql_request INTO v_original_table_line_count;
      END IF;
      
      v_sql_request := 'SELECT /*+ PARALLEL ' || v_table || v_tmp_table_suffix || ' */ '
        || ' COUNT (*) FROM ' || v_table || v_tmp_table_suffix;
      IF NOT v_debug_mode THEN
        EXECUTE IMMEDIATE v_sql_request INTO v_new_table_line_count;
      END IF;
      
      IF v_original_table_line_count &lt;&gt; v_new_table_line_count THEN
        RAISE e_different_line_count;
      END IF;
          
      SELECT 
        dbms_metadata.get_ddl('INDEX', index_name)
      BULK COLLECT INTO 
        v_pk_index_table
      FROM 
        user_indexes
      WHERE 
        table_name = v_table
        AND 
        uniqueness = 'UNIQUE'
      ;
      
      SELECT 
        constraint_name
      BULK COLLECT INTO 
        v_constraint_table
      FROM 
        user_cons_columns
      WHERE 
        table_name = v_table
      ;
      
      -- on desactive toutes les contraintes de la table courante
      FOR i IN 1..v_constraint_table.COUNT LOOP
        v_constraint := v_constraint_table(i);
        LOG_AND_EXECUTE('ALTER TABLE ' || v_table || ' DISABLE CONSTRAINT ' || v_constraint, v_debug_mode);
      END LOOP;
      
      LOG_AND_EXECUTE('TRUNCATE TABLE ' || v_table, v_debug_mode);
      
      SELECT 
        index_name
      BULK COLLECT INTO 
        v_index_table
      FROM 
        user_indexes
      WHERE 
        table_name = v_table
        AND
        uniqueness = 'NONUNIQUE'
      ;

      -- on met les index non uniques a UNUSABLE
      FOR i IN 1 .. v_index_table.COUNT LOOP
        v_index := v_index_table(i);
        LOG_AND_EXECUTE('ALTER INDEX ' || v_index || ' UNUSABLE', v_debug_mode);
      END LOOP;

      SELECT 
        index_name
      BULK COLLECT INTO 
        v_index_table
      FROM 
        user_indexes
      WHERE 
        table_name = v_table
        AND
        uniqueness = 'UNIQUE'
      ;

      -- on supprime les index uniques
      FOR i IN 1..v_index_table.COUNT LOOP
         v_index := v_index_table(i);
         LOG_AND_EXECUTE('DROP INDEX ' || v_index, v_debug_mode);
      END LOOP;
      
      v_sql_request :=
         'INSERT /*+ APPEND PARALLEL */ INTO ' || v_table
      || ' SELECT /*+ PARALLEL ' || v_table || v_tmp_table_suffix || ' */ * FROM ' || v_table || v_tmp_table_suffix;
      
      DBMS_OUTPUT.PUT_LINE ('INFO      : Re-import des donnees dans ' || v_table || '...');
      
      LOG_AND_EXECUTE(v_sql_request, v_debug_mode);
      
      SELECT 
        index_name
      BULK COLLECT INTO 
        v_index_table
      FROM 
        user_indexes
      WHERE 
        table_name = v_table 
        AND 
        partitioned = 'NO'
      ;

      -- reconstruction des index non partitionnes
      FOR i IN 1..v_index_table.COUNT LOOP
        v_index := v_index_table(i);
        LOG_AND_EXECUTE('ALTER INDEX ' || v_index || ' REBUILD PARALLEL COMPUTE STATISTICS', v_debug_mode);
        LOG_AND_EXECUTE('ALTER INDEX ' || v_index || ' NOPARALLEL', v_debug_mode);
        
        DBMS_OUTPUT.PUT_LINE ('INFO      : Index ' || v_index || ' reconstruit.');
      END LOOP;

      SELECT UNIQUE 
        (index_name)
      BULK COLLECT INTO 
        v_index_table
      FROM 
        user_indexes 
        INNER JOIN 
        user_ind_partitions 
        USING (index_name)
      WHERE 
        table_name = v_table 
        AND 
        partitioned = 'YES' 
        AND 
        composite = 'NO'
      ;
  
      -- reconstruction des index partitionnes non composites
      FOR i IN 1..v_index_table.COUNT LOOP
        v_index := v_index_table(i);
        
        SELECT    'ALTER INDEX '
        || INDEX_NAME
        || ' REBUILD PARTITION '
        || PARTITION_NAME
        || ' PARALLEL'
        BULK COLLECT INTO 
          v_rebuild_index_sql_req_table
        FROM 
          user_ind_partitions
        WHERE 
          index_name = v_index;
        
        FOR j IN 1..v_rebuild_index_sql_req_table.COUNT LOOP
          LOG_AND_EXECUTE(v_rebuild_index_sql_req_table(j), v_debug_mode);
        END LOOP;
        
        LOG_AND_EXECUTE('ALTER INDEX ' || v_index || ' NOPARALLEL', v_debug_mode);
        DBMS_OUTPUT.PUT_LINE ('INFO      : Index ' || v_index || ' OK avec ' || v_rebuild_index_sql_req_table.COUNT || ' partitions.');
      END LOOP;
      
      SELECT UNIQUE(index_name)
      BULK COLLECT INTO 
        v_index_table
      FROM 
        user_indexes 
        INNER JOIN 
        user_ind_partitions 
        USING (index_name)
      WHERE 
        table_name = v_table 
        AND 
        partitioned = 'YES' 
        AND 
        composite = 'YES'
      ;
      
      -- alter index sur tous les index partitionnes composites
      FOR i IN 1..v_index_table.COUNT LOOP
        v_index := v_index_table(i);
        
        SELECT    'ALTER INDEX '
        || INDEX_NAME
        || ' REBUILD SUBPARTITION '
        || SUBPARTITION_NAME
        || ' PARALLEL'
        BULK COLLECT INTO 
          v_rebuild_index_sql_req_table
        FROM 
          user_ind_subpartitions
        WHERE index_name = v_index;
        
        FOR j IN 1..v_rebuild_index_sql_req_table.COUNT LOOP
          LOG_AND_EXECUTE(v_rebuild_index_sql_req_table(j), v_debug_mode);
        END LOOP;
      
        LOG_AND_EXECUTE('ALTER INDEX ' || v_index || ' NOPARALLEL', v_debug_mode);
        DBMS_OUTPUT.PUT_LINE ('INFO      : Index ' || v_index || ' OK avec ' || v_rebuild_index_sql_req_table.COUNT || ' sous partitions');
      END LOOP;
      
      FOR i IN 1..v_pk_index_table.COUNT LOOP
        v_sql_request := v_pk_index_table(i);
        SELECT REGEXP_REPLACE(REGEXP_REPLACE(v_sql_request, chr(10), ''), ' {2}', '') INTO v_sql_request FROM DUAL;
        LOG_AND_EXECUTE(v_sql_request, v_debug_mode);
      END LOOP;
      
      SELECT 
        constraint_name
      BULK COLLECT INTO 
        v_constraint_table
      FROM
        user_cons_columns
      WHERE table_name = v_table;

      -- reactivation des contraintes

      FOR i IN 1..v_constraint_table.COUNT LOOP
        v_constraint := v_constraint_table(i);
        LOG_AND_EXECUTE('ALTER TABLE ' || v_table || ' ENABLE CONSTRAINT ' || v_constraint, v_debug_mode);
      END LOOP;

      LOG_AND_EXECUTE('SELECT TO_CHAR (SYSDATE, ''DD/MM/YYYY HH24:MI:SS'') dt_fin FROM DUAL', v_debug_mode);

      LOG_AND_EXECUTE('DROP TABLE ' || v_table || v_tmp_table_suffix, v_debug_mode);
    EXCEPTION
      WHEN e_not_enough_free_space THEN
        DBMS_OUTPUT.PUT_LINE('EXCEPTION : L''espace libre (' || v_free_space || ' Mo) dans le tablespace &amp;TBS_DATA est insuffisant pour migrer la table ' || v_table || ' (' || v_table_size || ' Mo).');
        DBMS_OUTPUT.PUT_LINE('EXCEPTION : La table ' || v_table || ' n''a pas ete migree.');
      WHEN e_different_line_count  THEN
        DBMS_OUTPUT.PUT_LINE('EXCEPTION : Le nombre de lignes dans ' || v_table || ' (' || v_original_table_line_count || ') est different de celui de la table ' || v_table || v_tmp_table_suffix || ' (' || v_new_table_line_count || '). La table source (' || v_table || ') est conservee.');
      WHEN OTHERS THEN
        DBMS_OUTPUT.PUT_LINE('EXCEPTION : ' || SQLERRM);
    END;
    v_table_treatment_end_time := DBMS_UTILITY.GET_TIME;
    IF NOT v_debug_mode THEN
      DBMS_OUTPUT.PUT_LINE('*********** Fin de traitement pour la table ' || v_table || '. Temps total : ' || ((v_table_treatment_end_time - v_table_treatment_start_time) / 100) || ' secondes.'); 
    END IF;
    v_table := v_table_list.NEXT(v_table);
  END LOOP;
  v_treatment_end_time := DBMS_UTILITY.GET_TIME;
  LOG_AND_EXECUTE('ALTER SESSION SET SKIP_UNUSABLE_INDEXES = false', v_debug_mode);
  IF NOT v_debug_mode THEN
    DBMS_OUTPUT.PUT_LINE('Fin de traitement. Temps total : ' || ((v_treatment_end_time - v_treatment_start_time) / 100) || ' secondes');
  END IF;
END;
/

UNDEF TBS_TMP
UNDEF TBS_DATA
UNDEF TBS_INDEX
UNDEF TBS_PARAM
UNDEF TBS_BLOB

EXIT;
&lt;/source&gt;

= Astuces performances =

== détecter "au moins 1" élément ==

Pour savoir si au moins 1 élément correspond à un critère dans une table sans aller lire toute la table (cas ou le critere est vrai dans plus de 10% des cas) / faire des tris en base (via un count) :

&lt;source lang="sql"&gt;
/* Renvoi 1 si au moins 1 contrat est lié à cette condition de paiement */
SELECT 1
  FROM DUAL
 WHERE EXISTS
           (SELECT 1
              FROM tcontrat cont2
             WHERE cont2.conditionpaiement_id = '$!35893826');
&lt;/source&gt;

== filtre "IS NULL" ==

Le filtre "IS NULL" dans une clause "WHERE" ne permet pas d'utiliser d'index sur la colonne filtrée.

Astuce : si le nombre de "NULL" dans la table est inférieur à 10% du nombre total de lignes et que ce filtre est le plus discriminant dans la requete, faire créer un index double dont la seconde colonne sera une constante.

Exemple :
&lt;source lang="sql"&gt;
Select * from MA_TABLE tab1 where tab1.colonne1 IS NULL;

/* Créer l'index suivant: */
create index IDX_MATABLE_C1 on MA_TABLE(colonne1,1);

&lt;/source&gt;

== HINT pour les requêtes des batchs ==

Les "HINT" sont des commentaires permettant de suggérer des accès à l'optimiseur Oracle (CBO).
Ces derniers se positionnent dans le properties ou le properties2 du batch.

=== En phase "init" ===

Lors de la phase "init", les requêtes de chargement effectuant nécessairement un "full" sur la table de travail peuvent être améliorées afin de bénéficier de la puissance du serveur de base de données:

Cas d'un INSERT avec un seul select imbriqué :

&lt;source lang="sql"&gt;
HINT_REQ_UPD_xxx=i:ENABLE_PARALLEL_DML PARALLEL(nom_de_la_table);s1 PARALLEL(tmp) LEADING(tmp) USE_NL(tmp)
&lt;/source&gt;

avec :
* nom_de_la_table : nom de la table figurant dans la clause "INTO" de l'INSERT
* tmp : alias de la table de travail dans la partie SELECT
* dans la clause USE_NL, il est possible d'ajouter '''dans l'ordre logique d’exécution''' la liste des alias des tables à lire. Exemple : USE_NL(tmp fac1 fac2 cnt)

''dans le cas d'un update, le "i" sera remplacé par un "u"''

=== En phase "MT" ===

Lors de la phase "MT",  généralement le plan de la majorité des requetes doit commencer par la table de travail (BATCH_) dont l'alias est souvent "tmp". Afin de garantir ce plan, il est possible d'ajouter les HINT :

&lt;source lang="sql"&gt;
HINT_REQ_SEL_xxx=LEADING(tmp) USE_NL(tmp)
&lt;/source&gt;

avec :
* tmp : alias de la table de travail dans la partie SELECT
* dans la clause USE_NL, il est possible d'ajouter '''dans l'ordre logique d'execution''' la liste des alias des tables à lire. Exemple : USE_NL(tmp fac1 fac2 cnt)</text>
      <sha1>g774auz3w2yh52axa3buoiaflm0ikn0</sha1>
    </revision>
  </page>
  <page>
    <title>Pg profile</title>
    <ns>0</ns>
    <id>702274</id>
    <revision>
      <id>4066482</id>
      <parentid>4066481</parentid>
      <timestamp>2021-12-06T16:07:03Z</timestamp>
      <contributor>
        <username>Guilmin</username>
        <id>511</id>
      </contributor>
      <origin>4066482</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="864" sha1="nw7dt77saln2xvuydeszv6jp2tm757z" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = pg_profile
 | siteInternet      = https://github.com/zubkov-andrei/pg_profile
 | version           = 2021-08 (0.3.4)
 | supportTechnique  = https://github.com/zubkov-andrei/pg_profile/blob/master/doc/pg_profile.md
}}

[[Category:outil]]
[[Category:pg_profile]]

Créé par Andrei Zubkov, pg_profile est une extension ''open source'' qui permet de générer des rapport de type AWR côté Oracle.

== Guide d'installation ==
*[[Guide d'installation de pg_profile]]

== Guide d'utilisation ==
* [[Guide d'utilisation de pg_profile]]

== Liens externes ==
* {{en}} [https://github.com/zubkov-andrei/pg_profile/blob/master/doc/pg_profile.md Documentation officielle]
* {{en}} [https://postgrespro.com/blog/pgsql/5967989 Présentation de pg_profile]
* {{en}} [https://github.com/zubkov-andrei/pg_profile Github pg_profile]</text>
      <sha1>nw7dt77saln2xvuydeszv6jp2tm757z</sha1>
    </revision>
  </page>
  <page>
    <title>PgBadger</title>
    <ns>0</ns>
    <id>702284</id>
    <revision>
      <id>4066485</id>
      <parentid>4066484</parentid>
      <timestamp>2021-12-06T16:17:45Z</timestamp>
      <contributor>
        <username>Guilmin</username>
        <id>511</id>
      </contributor>
      <origin>4066485</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="662" sha1="m2bd71iavi5jlnr7n4prx8ftvu9wep7" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = pgBadger
 | logo              = Logo_pgbadger.png
 | siteInternet      = https://pgbadger.darold.net/
 | gitHub            = https://github.com/darold/pgbadger
 | version           = v11.5
 | supportTechnique  = https://pgbadger.darold.net/documentation.html
}}
[[Category:outil]]
[[Category:BDD]]

Créé par Gilles Darold, pgBadger est un outil permettant d'analyser les log produits par une instance PostgreSQL, et de générer des rapports html présentant l'activité de la BDD..

== Guide d'installation ==
*[[Guide d'installation de pgBadger]]

== Guide d'utilisation ==
* [[Guide d'utilisation de pgBadger]]</text>
      <sha1>m2bd71iavi5jlnr7n4prx8ftvu9wep7</sha1>
    </revision>
  </page>
  <page>
    <title>PoWA</title>
    <ns>0</ns>
    <id>702292</id>
    <revision>
      <id>4066545</id>
      <timestamp>2022-01-05T10:32:05Z</timestamp>
      <contributor>
        <username>Guilmin</username>
        <id>511</id>
      </contributor>
      <comment>Page créée avec « {{Modèle:Infobox Outil  | nom               = PoWA  | logo              = Powa_logo.png  | siteInternet      = https://powa.readthedocs.io/en/latest/  | version… »</comment>
      <origin>4066545</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="741" sha1="kl18cshmyr2vm5gd0ttc89bftqg0mv6" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = PoWA
 | logo              = Powa_logo.png
 | siteInternet      = https://powa.readthedocs.io/en/latest/
 | version           = 4.1.2
 | supportTechnique  = https://powa.readthedocs.io/en/latest/support.html
}}
[[Category:outil]]
[[Category:BDD]]

Créé par Dalibo, PoWA est un outil permettant d'analyseur le trafic en cours sur les instances PostgreSQL par le biais de différents moyen, notamment : graphes présentant les temps d’exécution, graphe des blocks hit/read, ainsi qu’un tableau listant les requêtes les plus coûteuses sur la période sélectionnée.

== Guide d'installation ==
*[[Guide d'installation de PoWA]]

== Guide d'utilisation ==
* [[Guide d'utilisation de PoWA]]</text>
      <sha1>kl18cshmyr2vm5gd0ttc89bftqg0mv6</sha1>
    </revision>
  </page>
  <page>
    <title>VIM</title>
    <ns>0</ns>
    <id>384719</id>
    <revision>
      <id>4066761</id>
      <parentid>700625</parentid>
      <timestamp>2022-01-27T15:52:51Z</timestamp>
      <contributor>
        <username>Leoutre</username>
        <id>41</id>
      </contributor>
      <origin>4066761</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1156" sha1="cql9wetywqasanv81jfz8x6g8m5pylc" xml:space="preserve">[[Category:outil]]
* http://www.blogduwebdesign.com/developpement-vim/vim-astuce-pour-le-copier-coller/605
Aujourd'hui, faisons un focus sur une des fonctionnalités basiques de Vim que nous pouvons pousser vraiment loin : le copier/coller
= Les commandes de bases =
== copier/coller ==
Une des premières choses que l'on cherche à savoir faire sous Vim, c'est le copier/coller.
=== y ===
* y permet de copier des choses. Appuyer sur y depuis le mode visuel, avec du texte de sélectionné, pour le copier. Depuis le mode commande, yy ou Y copie la ligne complète sur laquelle nous sommes. Dans ce même mode, il est possible d'associer y avec les commandes de positionnement. y$ copie donc jusqu'à la fin de la ligne, yw copie le mot sur lequel nous sommes, ...
=== d ===
* d fonctionne de la même manière que y, mais coupe au lieu de copier. La seul commande qui diffère est D, qui imite d$ au lieu de dd.
=== p ===
* p permet de coller le texte actuellement dans le presse papier de Vim, juste après le curseur. P (la majuscule) va lui, l'insérer avant le curseur. En mode visuel, p remplace la sélection, qui se retrouve dans le presse papier.</text>
      <sha1>cql9wetywqasanv81jfz8x6g8m5pylc</sha1>
    </revision>
  </page>
  <page>
    <title>Outil de split des XML</title>
    <ns>0</ns>
    <id>702314</id>
    <revision>
      <id>4066866</id>
      <parentid>4066865</parentid>
      <timestamp>2022-02-11T15:02:12Z</timestamp>
      <contributor>
        <username>Reitz</username>
        <id>317</id>
      </contributor>
      <comment>/* Tutoriel */</comment>
      <origin>4066866</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2636" sha1="6mwop9ku0sosxtn2vxxe8t1kksn48pt" xml:space="preserve">[[Category:outil]]
[[Category:Guide d'installation]]
[[Category:échanges]]
Cet outil Java développé par [[NRE]] permet de découper un fichier XML trop volumineux en fichiers plus petits.

=Installation=

==Récupération du programme==
* Cloner ou faire un pull du projet échanges [https://gerrit.efluid.uem.lan/admin/repos/echanges repo échanges]
* En étant dans le projet echanges:
&lt;code&gt;
mvn clean install -f ExtracteurBalisesEchanges 
&lt;/code&gt;
* L’exécutable est généré dans le répertoire ExtracteurBalisesEchanges/executable

==Pour industrialiser un peu==
===Nécessitant une précompilation===
faire un script shell qui vient lancer le programme avec des options de JVM par exemple :

extracteurBalisesEchanges.sh dans ~/.bin/

&lt;code&gt;
&lt;nowiki&gt;#&lt;/nowiki&gt;!/bin/sh&lt;br&gt;
java -jar -Xms20g -Xmx20g ~/.bin/jar/extracteurBalisesEchanges.jar $*
&lt;/code&gt;

dans le path git/windows (ce avec quoi vous êtes le plus habitué) rajouter le répertoire ~/.bin

===Sans précompilation===
faire un script shell qui vient lancer le programme avec des options de JVM par exemple :

extracteurBalisesEchanges.sh dans ~/.bin/

&lt;code&gt;
&lt;nowiki&gt;#&lt;/nowiki&gt;!/bin/sh&lt;br&gt;
mvn clean install /f /d/java/workspaces/develop/echanges/ExtracteurBalisesEchanges&lt;br&gt;
java -jar -Xms20g -Xmx20g /d/java/workspaces/develop/echanges/ExtracteurBalisesEchanges/executable/extracteurBalisesEchanges.jar $*
&lt;/code&gt;

dans le path git/windows (ce avec quoi vous êtes le plus habitué) rajouter le répertoire ~/.bin

==Utilisation==
selon la configuration faite :
* &lt;code&gt;java -jar -Xms20g -Xmx20g extracteurBalisesEchanges.jar -h&lt;/code&gt;
* &lt;code&gt;extracteurBalisesEchanges.sh -h&lt;/code&gt;

=Tutoriel=
Le programme peut s'utiliser de plusieurs façon :
*faire un split d'un fichier d'entré
*agréger en fonction par format plusieurs fichiers généré par split (ne fonctionne correctement que si un split de 1 échange par fichier a été fait. le fichier d'origine ne doit pas être présent dans le répertoire contenant le fichier splitté)
*compter le nombre de balises présentes dans le fichier d'entré

Toutes les options sont disponibles via la commande :
&lt;code&gt;extracteurBalisesEchanges.sh -h&lt;/code&gt;

==Commande d'exécution d'un cas de figure simple==

*Ouvrir git bash dans le répertoire où se situe le fichier XML volumineux
*Lancer la commande suivante :
&lt;code&gt;extracteurBalisesEchanges.sh -f path/du/fichier/pub.xml -s nombre_echange_par_fichier&lt;/code&gt;

==Résultat==

Après son exécution, l'outil doit avoir généré un nombre variable de fichiers XML plus petits, préfixés de leur numéro de création.

[[Fichier:Exemple split de XML.png]]</text>
      <sha1>6mwop9ku0sosxtn2vxxe8t1kksn48pt</sha1>
    </revision>
  </page>
  <page>
    <title>Utilisateur:Marotta</title>
    <ns>2</ns>
    <id>702346</id>
    <revision>
      <id>4067561</id>
      <parentid>4067560</parentid>
      <timestamp>2022-07-27T11:48:48Z</timestamp>
      <contributor>
        <username>Marotta</username>
        <id>740</id>
      </contributor>
      <origin>4067561</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="725" sha1="jnjuin3zkflfatpdsgfk6mae9r9fjaf" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = etroove
 | logo              = Kermit-typing.gif
 | siteInternet      = https://efluid.uem.lan/etroov/
 | version           = 0.1
 | supportTechnique  = -
}}

== En bref ==
''Développeur / Stagiaire efluid - groupe [[Pole composants transverses]]''&lt;br&gt;

== En cours ==
=== Développement d'un moteur de recherche pour la documentation interne des développeurs ===
[[Fichier:Etroove-logo.png|200px]]
* Web crawler
* moteur de recherche inversée (Solr =&gt; configuration)
* interface de recherche
&lt;br&gt;

=== Web scraper ===
* récupération de la totalité des liens disponibles sur wikefluid
* suppression automatique des liens à supprimer

== Done ==

[[Category:développeur]]</text>
      <sha1>jnjuin3zkflfatpdsgfk6mae9r9fjaf</sha1>
    </revision>
  </page>
  <page>
    <title>Jonathan MAROTTA</title>
    <ns>0</ns>
    <id>702349</id>
    <revision>
      <id>4067653</id>
      <parentid>4067652</parentid>
      <timestamp>2022-08-24T07:31:34Z</timestamp>
      <contributor>
        <username>Marotta</username>
        <id>740</id>
      </contributor>
      <origin>4067653</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="548" sha1="jxpqqme8yccs56yjy9psz737bivdyid" xml:space="preserve">{{Modèle:Infobox Outil
 | nom               = etroove
 | logo              = Kermit-typing.gif
 | siteInternet      = https://wikefluid.efluid.uem.lan/docInstalleur/archi/develop/documentation/comiteTechnique/Recherche/
 | version           = 1.0
 | supportTechnique  = -
}}

== En bref ==
''Développeur / Stagiaire efluid (JMAR) - groupe [[Pole composants transverses]]''&lt;br&gt;

== Done ==
=== Développement d'un moteur de recherche pour la documentation interne des développeurs ===
[[Fichier:Etroove-logo.png|200px]]

[[Category:développeur]]</text>
      <sha1>jxpqqme8yccs56yjy9psz737bivdyid</sha1>
    </revision>
  </page>
  <page>
    <title>Guide de création de codification</title>
    <ns>0</ns>
    <id>2988</id>
    <revision>
      <id>1047583</id>
      <parentid>1047581</parentid>
      <timestamp>2015-09-24T09:36:47Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>1047583</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3421" sha1="08c4fp2ubk2x62975osa4jlpm1e5hhh" xml:space="preserve">[[category:guide]]
=Procédure de création d'une codification pour un flux=
==Principe==
Pour certains flux clients, la génération de fichiers au format externe (ou la lecture de fichiers externes) nécessite l'utilisation des codifications du client.
Les codifications sont propres à chaque client Efluid (ES, Gedia, ERDF...) et à chaque format de données (factures format F01, F03...).
Leur but est de permettre l'insertion de valeurs par défaut dans les balises des fichiers de sortie.
==Préparation==
===Création du jeu de codification===
*Ajouter une valeur dans la classe EEfluidNetTypeCodification.java 
*Ajouter une valeur dans le fichier EEfluidNetTypeCodification_fr.properties 


===Insertion des valeurs===
*Créer un script SQL ponctuel T_TCODIFICATION_MONFLUX_EVTXXXX.sql où XXX est le numéro d'événement de création/correction du flux. Dans ce script, insérer les différentes valeurs de codification voulues.
&lt;source lang='sql'&gt;
INSERT INTO TCODIFICATION ( ID, ETATOBJET, TYPECODIFICATION, CODEEXTERNE, LIBELLEEXTERNE, TYPE_CODIFIE, 
VALEUR, DATEMODIFICATION, ACTEURMODIFICATION, DATECREATION, ACTEURCREATION, DATESUPPRESSION, ACTEURSUPPRESSION ) VALUES ( 
'ECH_COD_CLIENT_MONFLUX_0101', 0, INDICE, 'Y', 'Z', 'java.lang.String', 'X', NULL, NULL, '', '', NULL, NULL);
-- Où INDICE est le numéro de la codification dans la classe EEfluiNetTypeCodification.
-- X est le code efluid
-- Y est la valeur codifiée (code) externe correspondant à X
-- Z est le libellé externe correspondant à X
&lt;/source&gt;
===Appel aux codifications===
*Dans chacune des classes MonObjetBusinessProcess de mon flux, faire un appel quand nécessaire au nouveau jeu de codification :
**Insérer l'appel à 
&lt;source lang="java"&gt;
new GenericCodificationManager(EEfluidNetTypeCodification.FLUX_F03);
&lt;/source&gt;
**Faire des appels aux méthodes getCodeCodifie et getLibelleCodifie pour récupérer les valeurs de codification voulues, en passant en paramètre le code efluid défini dans l'AFD (il peut être déterminé par une règle de correspondance incluant plusieurs attributs d'un objet métier, par exemple);
**Les insérer dans les attributs des objets métier format de sortie
==Livraison==
Pour rendre un jeu de codification valides il faut :
# Demander à l'equipe Efluid IT/au fonctionnel les environnements dans lesquels la codification doit être opérante;
# Créer un événement fils de l'événement de développement/correction du flux impacté ; cet événement sera destiné à la livraison du script SQL;
# Livrer le script dans ebuild en demandant le report sur les versions ultérieures;
# Livrer le développement sur la branche develop et le reporter sur les branches de maintenance concernées.
==Utilisation==
===Visualisation des codifications===
Les codifications sont visibles dans le menu ''administration&gt;paramétrage&gt;codification'' d'efluidNet.

[[Fichier:efluidNet.menuParametrage.png]]

[[Fichier:efluidNet.codification.png]]

===Surcharge des codifications===
Dans la plupart des cas, la surcharge des codifications est prévue. Le plus souvent elle est réalisée par le biais de paramètres entreprise.
Dans ce cas, il faut créer une classe CorrespondanceExterneMonFluxUtils prévoyant les appels aux paramétrages entreprise (se baser sur CorrespondanceExterneF03Utils qui présente le cas des ensembles de paramétrage entreprise, le cas le plus courant et le plus complexe).</text>
      <sha1>08c4fp2ubk2x62975osa4jlpm1e5hhh</sha1>
    </revision>
  </page>
  <page>
    <title>Guide de développement du domaine requêteur</title>
    <ns>0</ns>
    <id>8392</id>
    <revision>
      <id>1047608</id>
      <parentid>1047596</parentid>
      <timestamp>2015-09-24T09:38:51Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <minor/>
      <comment>Dmytryk a déplacé la page [[Requêteur - Procédure de développement]] vers [[Guide de développement du domaine requêteur]]</comment>
      <origin>1047608</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3475" sha1="ibyc2lgot38o7kegl34qyci35yl9ypu" xml:space="preserve">[[category:guide]]
[[category:requêteur]]
Cette page décrit la procédure de développement d'un écart requêteur ou d'une anomalie requêteur. Cette procédure concerne efluid mais est semblable dans le cas des autres applications (énercom, suivefluid, etc.).

== Procédure ==

=== Développement d'un écart ===

==== Actions pour le pôle fonctionnel ====

* '''Identifier les colonnes à requêter pour chaque objet'''
** ''le pôle fonctionnel doit déterminer quelles colonnes sont à requêter'' et sous quel type (normalement c'est évident), dans l'AFD, le tableau des attributs devrait contenir une colonne "requêteur".
* '''Identifier la structure des vues en fonction des objets à requêter'''
** ''le pôle fonctionnel doit déterminer quels liens sont requêtables'', dans quel sens, s'assurer qu'il n'y a pas de dépendances cycliques et identifier les jointures externes si nécessaire (avec l'aide du développeur)

==== Actions pour le développpement ====

* '''Développer les vues SQL correspondantes'''
** ''déterminer quelles colonnes en base sont nécessaires pour chaque attribut'' de chaque objet identifié et construire la vue SQL correspondante, par exemple : [[Requêteur#Vues SQL]].

* '''Développer les vues XML correspondantes'''
** ''idem pour les vues XML'', qui donneront le mapping du type SQL vers le bon type Java, par exemple : [[Requêteur#Vues XML]].

==== Actions pour la livraison du code en développement ====

* Les vues SQL doivent être livrées dans le dossier ''sql/vues'' puis dans le domaine correspondant
* Les vues XML doivent être livrées dans le dossier ''app/src/main/resources/xml''
* Les vues SQL doivent être exécutés sur les bases de développements après commit

==== Actions pour la livraison du code pour assemblage ====

* Les vues SQL doivent être livrés dans ebuild pour assemblage.
** ''modèle de livrable'' : script de migration efluid
** ''type de script'' : requeteur
** ''livrable physique'' : (comme un script normal, avec les entêtes et terminaisons)

==== Actions pour la documentation ====

* Mise à jour du fichier de paramétrage : [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid efluid - Documentation Fonctionnelle] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_415c5 AFD suite efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_d18f AFD efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_ead9 REQ - Requêteur] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4f93f AFD] &gt; [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_22d5e/Param%E9trage%20requ%EAteur%20V12.xls Paramétrage requêteur V12.xls]

=== Correction d'une anomalie ===

==== Actions pour le développement ====

En plus de toutes les actions pour le développement d'un écart, dans le cas d'une correction d'anomalie, il faut s'assurer que les colonnes et les critères impactés soient bien mis-à-jour dans la base. 

* '''Création des scripts de migration''' : 
** ''modification d'un attribut'' : il faut utiliser le script [[Requêteur - Scripts de migration requêteur#Modification d'un attribut]] pour mettre à jour toutes les tables impactées .
** ''modification d'un attribut avec changement de type'' : il faut utiliser le script [[Requêteur - Scripts de migration requêteur#Modification d'un attribut avec changement de type]] pour mettre à jour toutes les tables impactées

[[Category:requêteur]]</text>
      <sha1>ibyc2lgot38o7kegl34qyci35yl9ypu</sha1>
    </revision>
  </page>
  <page>
    <title>Guide extracteur/injecteur</title>
    <ns>0</ns>
    <id>1500</id>
    <revision>
      <id>1048302</id>
      <parentid>80760</parentid>
      <timestamp>2015-09-24T14:00:27Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>1048302</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2857" sha1="st4wv51j3waifrijd8w63lyaviardgv" xml:space="preserve">[[Category:guide]]
'''Le principe''' :

L’idée est de se connecter à une base source, extraire un  paramétrage donné et ensuite l’injecter dans une base destination. Pour ce faire, on utilise le fichier .bat  « ExtractionInjectionVerification.bat », qui posera une série de questions sur les bases des données source et  destination entre autres. 
Pour identifier les bases source et destination le système utilise des fichiers de type « jar » où sont stocké les fichiers framework2.properties. Il existe autant de jar que des bases des données sources et destination.


'''La procédure ''' : à suivre pour extraire, puis injecter un paramétrage donné est la suivante :


'''Etape 1 :''' ''Définition de la base cible et destination''. Appliquer la procédure suivante :

1.a : Aller au répertoire « \efluid\scripts\extraction\files\lib »

1.b : Vérifier que les bons jar existent. S'ils n’existent pas on les crée. Ils servent juste à surcharger le framework2.properties de la cible et la destination




'''Etape 2 :''' ''Extraction''. Appliquer la procédure suivante :

2.a : Vérifier que dans le répertoire « ..\efluid\scripts\extraction\files » le réperoire « logs » existe. Sinon le créer

2.b : Ouvrir la ligne de commande 

2.c : Lancer le fichier « ExtractionInjectionVerification.bat »

2.d : Répondre aux questions :

	Q : Quel type d’opération est à réaliser ? 

	R : 0 (extraction)

	Q : Avec ou sans suppression ?

	R : 0 (sans suppression). ATTENTION à cette réponse !!

	Q : Mode insert ou update ?

	R : 0 (update)

	Q : Choix du domaine ?

	R : saisir le numéro de votre domaine. Il apparait dans l’écran 

	Q : Choix du fichier de paramétrage ?

	R : 1 (paramétrage)

	Q : Choix du schéma à utiliser ?

	R : saisir le numéro de votre schéma. Il apparait dans l’écran

	Q : Choix de l’entité pour la confidentialité à utiliser ?

	R : le numéro de votre choix. Il apparait dans l’écran



'''Etape 3''' : ''Injection''. Dans la foulée le .bat continue à poser les questions suivantes :

	Q : Voulez-vous faire une injection ?

	R : 0 (oui)

	Q : Choix du schéma à utiliser ?

	R : saisir le numéro de votre schéma. Il apparait dans l’écran

	Q : Choix de l’entité pour la confidentialité à utiliser ?

	R : le numéro de votre choix. Il apparait dans l’écran

	Q : Choix Injection avec ou sans suppression ?

	R : 1 (avec suppression si l’on veut annuler et remplacer) 


Pour plus de détail, merci d'aller sur eRoom


http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_454c2


REMARQUES : 

•	Il ne faut pas extraire avec suppression de l’origine

•	Il faut injecter avec suppression de la cible

•	Quelques problèmes de compatibilité peuvent arriver suite à la différence de version entre la base source et 
la destination</text>
      <sha1>st4wv51j3waifrijd8w63lyaviardgv</sha1>
    </revision>
  </page>
  <page>
    <title>Guide de migration developpeur pour les projets sur le socle technique V14</title>
    <ns>0</ns>
    <id>701679</id>
    <revision>
      <id>4053107</id>
      <parentid>4052100</parentid>
      <timestamp>2019-06-04T08:30:06Z</timestamp>
      <contributor>
        <username>Sinkiew</username>
        <id>328</id>
      </contributor>
      <comment>/* Comment surcharger un paramètre dans les properties ? */</comment>
      <origin>4053107</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="23538" sha1="e056go8yquodi82nzmjoqomryq17i18" xml:space="preserve">[[category:guide]]
A partir du socle technique V14, une remodularisation Maven des projets a lieu (Cf evt 236600).&lt;br&gt;
Celle-ci engendre plusieurs modifications que les développeurs vont devoir prendre en compte pour continuer à travailler.&lt;br&gt;
Ce guide vise donc à lister et expliciter ces modifications. Certains seront spécifiques à un projet, d'autres sont génériques et concernant toutes les applications/briques.

{{alert|texte=Il est conseillé d'utiliser des workspaces eclipse différents entre des projets (ou branches GIT d'un même projet) étant sur d'ancien socle technique, et ceux sur ce nouveau socle technique V14.}}

== Re-import projet efluid-webapp dans eclipse ==

Le module efluid-webapp a été déplacé de l'emplacement '''"app"''' vers l'emplacement '''"web"''', il est donc nécéssaire de ré-importer le projet dans eclipse. Pour cela il faut supprimer le projet efluid-webapp (idéalement supprimer aussi les fichiers ''.classpath'', ''.factorypath'', ''.project'' et le dossier ''.settings'' du répertoire '''app''') , puis ré-importer le module efluid-webapp depuis l'emplacement web en suivant [[Guide d'installation d'un projet git avec eclipse#Cr.C3.A9ation_du_projet_eclipse|le guide traditionnel]]
[[Fichier:ReimportEfluidWebapp.PNG]]

Ce module efluid-webapp contient désormais uniquement les ressources web (JSP, JS, CSS, etc...), les classes et ressources se trouvent toujours dans le dossier '''app''', qui représente désormais le module efluid-jar. Il est donc important d'importer également le module efluid-jar dans eclipse toujours en suivant [[Guide d'installation d'un projet git avec eclipse#Cr.C3.A9ation_du_projet_eclipse|le guide traditionnel]].

[[Fichier:ImportEfluidJar.PNG]]

'''Attention à bien avoir la case "Resolve dependencies from Workspace projects" cochée, et le profil "dev-metz" actif sur tout vos projets efluid dans eclipse comme le montre le screen ci-dessous.'''
[[Fichier:EclipseMavenSettings.png]]

== Suppression du dossier de test integration ==

Les tests d'intégration sont déplacés des dossiers ''src/test/integration'' vers les dossiers ''src/test/java''. Cela permet de retomber dans une configuration plus classique de Maven, et ainsi éviter les problèmes de non prise en charge de ces répertoires par eclipse par exemple (Cf problèmes depuis eclipse Photon).
&lt;br&gt;
Tous les tests d'un module Maven sont donc présents dans ''src/test/java''. Les ressources ne changent pas d'emplacement et sont toujours dans ''src/test/resources''.
&lt;br&gt;
La différence entre un TU et un TI est donc uniquement son nommage. Pour rappel la norme est : 
* Test unitaire : TestXXX
* Test intégration : TestITXXX
* Si besoin de classe utilitaire dans les tests mais qui ne sont pas des tests l'utilisation de suffixe est possible : XXXTest

== Suppression de l'obligation d'utiliser les profils Maven test-unitaire et test-integration ==

Les profils test-unitaire et test-integration ne seront plus nécessaires pour lancer des TU et/ou TI avec Maven localement par les développeurs. Les tests sont pas contre "skippé" par défaut, pour les exécuter il faut donc procéder comme suit
&lt;br&gt;
Si l'on veut lancer uniquement les TU on utilise la commande Maven suivante : '''mvn clean install -DskipTests=false'''
ou alors la commande : '''mvn clean install -Ptest-unitaire'''
&lt;br&gt;
Si l'on veut lancer les TU et les TI on utilise la commande Maven suivante : '''mvn clean install -DskipTests=false -DskipITs=false'''
ou alors la commande : '''mvn clean install -Ptest-integration'''

== Nouveau module de configuration ==

=== Suppression des jars de properties UL ===

Les properties2 (framework2.properties, etc...) qui étaient injectés directement via des jars par l'UL au moment des lancements de tests dans Jenkins, sont désormais supprimés, afin que tous les properties soient présents dans le code source. Cela permettra aux développeurs de pouvoir lancer les tests sur leurs postes de façon la plus proche possible de ce que fait l'UL. Les seules différences seront : 
* La valorisation de la BDD, car les schémas sont créer automatiquement par les jobs jenkins
* La valorisation des emplacements filesystem, car l'UL est sous Linux et les développeurs sous Windows
&lt;br&gt;
Afin de pouvoir visualiser plus facilement les surcharges coté UL, le fichier framework2.properties effectif utilisé lors des builds UL sera directement archivé sur le build courant, comme le montre le screen suivant : 
[[Fichier:ArchivageFramework2.PNG]]

=== Modules de configuration ===

Il existe désormais plusieurs modules Maven déstinés à contenir la configuration technique (les fichiers properties).&lt;br&gt;
* Le module de configuration (efluid-config) contient la configuration par défaut de efluid, et cela produit un jar qui est livré aussi bien en dev, qu'en prod, et que pour les tests. Un second jar est également produit par ce module mais ne contient que la configuration par défaut pour les tests, il n'est donc disponible qu'en test. Les développeurs peuvent le consulter afin de voir comment sont paramétrés techniquement les tests, et quelles sont les surcharges par rapport à la configuration par défaut.
* Le module de configuration de dev (efluid-config-dev) va permettre de centraliser les ressources properties spécifiques aux développeurs, c'est ce qui se trouvait donc dans le répertoire properties2 de tous les modules. Ce module étant désormais centralisé, il n'y aura plus besoin d'avoir des fichiers properties disséminés dans chaque module. Ce module de configuration contient également les bundles de connexions aux BDD (qui ne sont désormais plus rangés dans des répertoires depuisParis/depuisMetz mais directement dans un répertoire bdd).
* Il existe également un module de configuration de prod, mais il n'est pas utile aux développeurs c'est simplement un pont permettant de faire fonctionner les surcharges présentes dans l'installeur des applications par exemple.
* Il existe enfin un module de configuration de batch, qui contient les propriéts spécifiques en lancement des batchs. Ce module est donc utilisé pour les lancement de batch. Lorsque on utilise ce module, on utilise pas le module de configuration de prod (c'est l'un ou l'autre).
&lt;br&gt;
Afin d'avoir la meilleure prise en charge de ces properties par les IDE il est conseillé d'importer les modules efluid-config et efluid-config-dev dans les IDE.

=== Nettoyage des properties2 ===
 
- Copier les fichiers framework2.properties, Hermes2.properties, EDK2.properties, Ecore2.properties, etc...  en les mettant respectivement dans le module config-dev/src/main/properties2
[[Fichier:Nettoyage properties2 copierfichiers.JPG]]


- Supprimer les fichiers framework2.properties, Hermes2.properties, EDK2.properties, Ecore2.properties, etc... qui se trouve dans tous les modules de efluid. (à l'exception du module config-dev)

[[Fichier:Deplacerproperties2.JPG]]

- Votre configuration est prête, si vous voulez tester vous pouvez lancer un simple test et vérifier que la JDBC_CONNECT_STRING a bien pour valeur ce que vous avez dans le framework2.properties qui se trouve dans le module config-dev/src/main/properties2

[[Fichier:ExempleBddConfigDev.JPG]]

On s'attend donc à avoir dans la log : JDBC_CONNECT_STRING=jdbc:oracle:thin:@ldbddedt3:2483/DE14EDT1

[[Fichier:Testproperties2.JPG]]

=== Comment surcharger un paramètre dans les properties ? ===

Cela ne change pas par rapport au fonctionnement d'avant, il faut toujours modifier votre framework2.properties qui se trouve maintenant dans l'unique point d'entrée : le module config-dev/src/main/properties2.
Si à l'exécution votre fichier Framework2.properties n'est pas trouvé, vérifier que le(s) projet(s) config-batch ou config-prod sont présents dans le workspace, sinon les importer.

=== Comment ajouter/modifier des properties dans le framework suite à une demande ===

Si vous avez une demande d'ajout/modification/suppression de paramètre comme par exemple modifier le POOL_MAX_CONNECTIONS, il faut aller modifier le framework.properties se trouvant dans le module config (efluid/config/src/main/resources)

[[Fichier:Ajouter modifier properties framework.JPG]]

== Paramétrage technique associés aux TU/TI ==

Auparavant le paramétrage technique s'effectuait uniquement via les fichiers properties (fmk.properties, etc...). Ainsi on avait des fichiers de properties dédiés au TU, et d'autres dédiés au TI (voir même des fichiers spécifiques pour un module particulier).&lt;br&gt;
Désormais tout cela n'est plus d'actualité, les fichiers de properties présents dans le dossier src/test/resources du module efluid-config sont pris par défaut pour les TU. Rien n'est ajouté de plus coté UL. Ainsi on a exactement le même lancement côté DEV et côté UL.&lt;br&gt;
Pour les TI on n'utilise pas d'autres fichiers de properties, les mêmes fichiers que pour les TU sont pris. Afin de gérer la configuration spécifique TI nécessaire (jdbc connexion manager pour avoir une BDD, pas de Mock de paramètres entreprises etc...) on utilise une "Rule" Junit ''ContexteTestIntegrationRule'' qui va automatiquement modifier le paramétrage technique. Cela fait qu'on peut lancer facilement des TI sans devoir toucher aux fichiers de configurations, on a ainsi encore une fois un lancement TI qui est équivalent entre UL et dev, et même un lancement TI qui est proche entre les IDE et Maven.
&lt;p&gt;
Ainsi tous les TI actuels n'héritant pas de ''AbstractTestIT'' doivent être revus afin d'ajouter la "Rule" Junit ''ContexteTestIntegrationRule''. (et on pourrait à terme se débarrasser de AbstractTestIT ou TestEfluid, etc.)
&lt;/p&gt;
&lt;p&gt;
Exemple d'utilisation de la Rule Junit pour les TI ''test.efluid.arc.commun.rule.ContexteTestIntegrationRule''
&lt;br&gt;
&lt;source lang="java"&gt;
 @Rule
  public ContexteTestIntegrationRule contexte = ContexteTestIntegrationRule.newContexteAvecMockDesParametresTechniques();

  @Test
  public void devrait_tester_quelque_chose()
  // Given
    ModeleAffaireTravaux modele = contexte.enregistrerParEntityProcess(creerModeleAffaireTravaux().type().avecModeInitialisationDemandeur(RESPONSABLE_PROJET).build());
&lt;/source&gt;

Le mock des paramètres techniques se fait à l'appel de "newContexteAvecMockDesParametresTechniques".

* Il est inutile d'utiliser la Rule ET d'hériter de "AbstractTestIT" ! (Il existe des cas dans efluid ! Ils sont censés faire la même chose.)
* Evitez de déclarer les classes testées comme "private static final" de la classe de test. En faisant ça vos différentes méthodes de test ne sont pas isolées les unes des autres, vous ne gagnez rien en terme de perf puisque l'instanciation est de l'ordre de la nano seconde, et il n'y a probablement aucune raison à ça.
par exemple : 
&lt;source lang="java"&gt;
public class TestGenerationReferencePDSProcess {
  private static final GenerationReferencePDSProcess PROCESS = new GenerationReferencePDSProcess();
&lt;/source&gt;
Si c'est vraiment justifié, dans ce cas là, 
* soit vous mockez les paramètres techniques avant d'initialiser vos autres resources statiques, puis instanciez la rule avec "newContexteSansMockDesParametresTechniques" :
&lt;source lang="java"&gt;
public class TestITGenerationReferencePDSProcess {
  
  static {
    MockProperties.addMockProperties(ParametersConfig.CONFIG_TESTS_INTEGRATION);
  }

  private static final GenerationReferencePDSProcess PROCESS = new GenerationReferencePDSProcess();

  @Rule 
  public ContexteTestIntegrationRule contexte = ContexteTestIntegrationRule.newContexteSansMockDesParametresTechniques();
 &lt;/source&gt;
* soit vous passez la Rule en ClassRule, qui sera static du coup (les @Before du ExternalResource deviendront en fait des @BeforeClass), mais vos @Test ne seront plus isolés (la transaction sera ouverte avant tous les tests et fermés après tous les tests de la classe),

* Si ça ne fonctionne pas (erreur du genre NoDBAccess), c'est qu'un autre traitement charge les paramètres techniques avant le mock. Ils sont conservés tels que chargés ad-vitam (pour une JVM).
Pour rappel, pour exécuter une classe de test (mais pas seulement) en java, on initialise celle ci en jouant, dans l'ordre dans lequel ils sont déclarés, tous les appels "static", ensuite on appelle le @BeforeClass (en prenant celui de plus haut niveau d'abord en cas d'héritage),  ensuite la classe est instanciée, et finalement on joue les @Before. En utilisant une rule, ce sont d'abord les before de la rule qui sont joués puis les méthodes annotées (@Before, @BeforeClass) de la classe.

=== Cas Particuliers ===
* Changer la connexion d'un utilisateur : il est parfois nécessaire d'avoir un utilisateur avec des attributs particuliers connecté. En utilisant la rule, à chaque lancement de test, on ouvre une connexion puis on connecte l'utilisateur. Il s'agit de modifier la méthode de connexion de l'utilisateur or il n'y a pas de méthode (actuellement) qui permette à l'instanciation de la règle de le faire. Il faut donc agir entre l'instanciation de la règle et le lancement du test =&gt; dans le constructeur du test. On a un exemple ci-dessous :
&lt;source lang="java"&gt;
  public AbstractContrat() {
    contexte.setProcedureConnexionUtilisateur(() -&gt; getUtilisateurUtils().connecterUtilisateur());
  }
&lt;/source&gt;

== Emplacement des tests ==

=== Rappel concept et historique ===

L'emplacement de chaque test est un élément important à prendre en compte par un développeur lorsqu'il ajoute un test.
En effet en fonction de l'emplacement du test, l'accès aux différentes dépendances est différent. 
Un test placé dans le module efluid-jar ne pourra pas "voir" les classes du module efluid-interfaces car efluid-jar n'a pas de dépendance vers efluid-interfaces. L'inverse est vrai par contre, un test dans efluid-interfaces pourra accéder aux classes de efluid-jar.
Avec la re-modularisation, les choses changent un peu car auparavant la plupart des tests se trouvait dans le module efluid-webapp qui était en fait un genre de meta-module permettant une agrégation de tous les modules fonctionnels. Ainsi efluid-webapp pouvait accéder à efluid-jar, mais aussi à efluid-interfaces, reversement etc... Ainsi tous les tests de efluid-webapp accédaient à quasiment tous les modules fonctionnels de l'application.
Aujourd'hui ce n'est plus le cas, efluid-webapp est redevenu un simple module contenant les ressources web, et efluid-jar n'a pas de dépendance vers les autres modules fonctionnels, car sinon on aurait des dépendances cycliques. Ainsi les tests présents dans le module efluid-jar n'ont pas accès aux autres modules. Or actuellement, il y a beaucoup de tests d'intégration qui nécessitent les autres modules car ce sont des tests transverses à de nombreux modules de l'application (ça émule le fonctionnement réel de l'application en fait).

=== Introduction du module integration ===

La remodularisation ajoute un nouveau concepte : le module integration.
Ce module contient des tests qui auront accès à l'ensemble des modules fonctionnels de l'application.
C'est un module qui est le pendant du module efluid-webapp (qui permet de lancer l'application) mais pour lancer des tests transverses.
Ce module sera exporté (dans un jar) qui sera accessible à d'autres applications (migefluid, plugin travaux, etc...) mais ne sera pas accessible aux modules internes d'efluid (pour éviter les dépendances cycliques).
Ce module accèdera également aux modules qui ont exportés leurs tests (notamment les tests du module efluid-jar).
Le module efluid-webapp n'aura aucun lien avec le module integration et inversement.
Il est donc conseillé d'importer ce module dans eclipse.
Ce module sera également créé prochainement dans les briques (c'est le module qui s'appelait demo dans archi). Dans les briques ce module contiendra en plus des objets dédiés aux fonctionnement des tests, car les briques ont souvent besoin d'émuler le comportement d'une application, ce qui n'est pas le cas dans efluid car on a déjà les vrais objets à disposition.

=== Bonnes pratiques ===

Ayant un module supplémentaire, les possibilités d'emplacement des tests sont plus nombreuses. Il est donc nécessaire de se poser encore plus la question de "où dois-je placer mon test". Voici quelques bonnes pratiques permettant de guider le choix : 

* Un test unitaire doit se trouver au plus près du code qu'il teste. Par défaut il doit donc se trouver dans le module où se trouve la classe testée.
** Si ce n'est pas possible, alors on peut le placer dans un autre module fonctionnel qui aurait plus dépendance. Exemple : placer un test d’intégration dans le module efluid-interfaces même si la classe que l'on teste se trouve dans efluid-jar, car on veut avoir accès à efluid-interfaces pour étendre le périmètre du test ou pour des cas particuliers.
** Si ce n'est toujours pas possible alors on placera le test dans le module d’intégration. Mais cela doit vraiment rester une exception, car le module d’intégration ne doit contenir que le strict nécessaire, afin de ne pas être un gros fourre-tout. Il est important d'avoir le code le plus modulaire possible, et donc les tests associés également.

* Un test d'intégration doit également se trouver au plus près du code, mais c'est souvent plus difficile notamment pour les tests d'intégration métier. 
** Si ce n'est pas possible, les règles sont ensuite les mêmes que pour les tests unitaires, mais il est admis qu'il y aura beaucoup de tests d'intégration qui se devront dans le module d’intégration (du moins tant que l'application ne sera pas plus modulaire qu'aujourd'hui).

== Lancement des batchs ==
Pour lancer un batch en dev, il existe désormais un nouveau module Maven pour cela : '''efluid-batch-launcher-dev'''. Ce module se situe dans ''efluid/batchs/launcher-dev''. Il permet de prendre en compte le module de config spécifique aux batchs, et n'inclut pas le module de config de test mais inclut le module config dev. Il est le pendant du module efluid-webapp pour le lancement de l'application.
&lt;br&gt;
Il est possible de surcharger les propriétés de configuration de dev dans ce module en ajoutant des fichiers dans src/main/properties2. Exemple : ajout d'un fichier framework2.properties dans src/main/properties2. Attention, dans ce cas on prend le pas sur le fichier complet présent dans config-dev, et ainsi il faut tout redéfinir (notamment la BDD).
&lt;br&gt;
Ainsi les lanceurs de batchs coté eclipse doivent se baser sur ce module et avoir un classpath paramétré comme le montre les screen ci-dessous.
[[Fichier:LanceurBatchEclipseDev 2.PNG]]
[[Fichier:LanceurBatchEclipseDevPNG.PNG]]

== Suppression deploy.pom et nouvelle organisation applications/ecore/archi/pom parent ==
* En socle V14 le projet EDK a été supprimé, et les artefacts ont été déplacés vers archi, ecore et les applications.
** Il ne reste donc que 2 briques : archi et ecore. A cela s'ajoute un élément important : efluid-parent. Ce pom est le père de tous les projets. Il contient la définition des profils, des plugins, et des versions de toutes les dépendances.
* Les briques logicielles en socle V13 contenant des fichiers ''deploy.pom'' qui servaient à créer un pom de consommation, c'est à dire le pom qui sera visible des applications qui veulent utiliser la brique (efluid par exemple). Le deploy.pom est donc différent du pom.xml qui lui est le pom de build. Le pom de build contient souvent des dépendances en scope compile, utilisées pour compiler la brique, alors que le pom de consommation ''deploy.pom'' contient lui plutôt des dépendances en scope runtime car non nécessaire à la compilation de l'application, mais qui doivent être présentes au runtime.
** Les fichiers deploy.pom résolvent donc le problème des consommateurs de projets au niveau Maven, mais contourne le système de base de Maven. C'est une fonctionnalité qui est discutée dans la mailing liste maven mais non implémentée Cf https://cwiki.apache.org/confluence/display/MAVEN/Build+vs+Consumer+POM. Les deploy.pom générent donc en problème au niveau développement, car ils viennent se substituer aux pom.xml, et lorsque l'on fait ''mvn clean install'' on place donc ces deploy.pom dans le repository maven local, ce qui fait que localement les consommateurs sont content, mais le projet lui même peut avoir des problèmes si l'on souhaite le compiler partiellement. Imaginons que l'on compile le projet archi. Si l'on compile tout d'un coup pas de problème, le réacteur maven voit bien les pom.xml de chaque module et le projet reste donc intègre. Par contre si on ne compile que le module archi-batch par exemple, alors ça ne marche pas, car maven va aller chercher le pom de archi-jar dans le repository maven local, et la en réalité il aura le contenu de deploy.pom de archi-batch or celui-ci à réduit les scope à runtime, donc il obtient des erreurs de compilation.
** Une autre façon de faire consiste à créer des modules d'import dans les briques, qui seront donc des modules utilisés par les consommateurs, et dans lesquels on pourra mettre les scope que l'on souhaite sur les dependances. C'est en fait des modules techniques qu'il faut ajouter dans les briques, et supprimer tous les fichiers deploy.pom. Ainsi dans le repository local maven on aura le meme contenu que les fichiers pom.xml, ce qui revient à un comportement standard Maven. Par contre les consommateurs des briques ne devront plus utiliser directement les artefacts des briques (archi-jar par exemple), mais les artefacts d'imports (archi-app-import). Les artefacts d'imports pourront englober plusieurs artefacts unitaires (exemple : archi-app-import contiendra archi-annotation, archi-log, archi-jar, etc...).
* Un autre problème en socle V13 est que tous les projets héritent de efluid-parent, or c'est efluid-parent qui décrit les versions des dépendances (via un dependencyManagement). Quand tout est synchronisé sur la même version cela ne pose pas de problème. Par contre dans l'intervalle de livraison des briques, des versions d'efluid-parent sont différentes, et donc les versions des dépendances également, ce qui cause des problèmes assez bizarres et difficilement détectables.
** Pour améliorer cette situation il faut qu'il y ait un lien fort entre applications-&gt;ecore-&gt;-archi-&gt;pom-parent, on doit donc tirer les informations du pom parent par l'archi uniquement, qui elle ne sera tirée que par ecore uniquement, et les applications ne tireront donc les versions que depuis ecore uniquement. Pour faire cela le pom efluid-parent a été divisé en deux : efluid-parent qui contient les plugins et les profiles, et efluid-bom (build of materiel) qui contient les versions de dépendances (via un dependencyManagementy). Ainsi on créé un nouveau module dans l'archi qui sera un bom au niveau archi, et qui tirera le bom efluid-bom. On fait de même dans ecore. Et dans efluid on tire le bom ecore-bom uniquement, et on ne donne plus aucune version directement, tout sera par le bom. La contrainte est que chaque modification de efluid-bom devra repasser par une release de l'archi, puis une release de ecore. Par contre toutes les briques/applications seront toujours cohérente entre elle.

== Guide de migration pour passer d'une archi V4 à V5 ==
* [[http://wikefluid/docInstalleur/archi/develop/documentation/guide-de-migration-archi-V4-vers-V5.html Guide de migration]]</text>
      <sha1>e056go8yquodi82nzmjoqomryq17i18</sha1>
    </revision>
  </page>
  <page>
    <title>Guide migration UTF-8</title>
    <ns>0</ns>
    <id>702281</id>
    <revision>
      <id>4067385</id>
      <parentid>4067058</parentid>
      <timestamp>2022-06-01T14:59:15Z</timestamp>
      <contributor>
        <username>Flatres</username>
        <id>26</id>
      </contributor>
      <minor/>
      <comment>/* Quels batchs sont concernés ? */</comment>
      <origin>4067385</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12692" sha1="ipvn575svh8ik318gkp3o83ix3m444x" xml:space="preserve">[[category:guide]]
=Liens vers le e-forum=
Cette page wikefluid regroupe les diverses informations liées à la migration du projet efluid en UTF-8
Le fil de discussion principal sur ce sujet dans le forum :&lt;br&gt;
*[https://eforum.efluid.uem.lan/viewtopic.php?f=42&amp;t=3448 Projet migration vers UTF-8]

=Gestion de l'encodage selon les versions=
&lt;p&gt;
* branches des '''versions &lt; 15.1''' : se fait en '''ISO-8859-15'''
* branches des '''versions &gt;= 15.1''' : se fait en '''UTF-8'''&lt;br&gt;
Un outil '''utf8helper''' a été créé afin de faciliter la conversion des fichiers ISO-8859-15 en UTF-8, notamment lors des reports de code. cf. paragraphe [[Guide migration UTF-8|outil utf8helper]]&lt;p&gt;
&lt;p&gt;
Concernant les reports, un contrôle bloquant a été ajouté dans Gerrit pour s'assurer que les fichiers livrés soient toujours encodés en UTF-8.&lt;br&gt;
Il y aura un -1 de l’UL en develop si jamais les fichiers ne sont pas bien encodés&lt;br&gt;
⚠️'''️Attention'''⚠️: 
* Ce contrôle ne fonctionne que dans le sens branche maintenance → branche v15. 
* Aucun contrôle n'est ajouté pour vérifier l'encodage dans le sens branche v15 → branche de maintenance. Il convient de s'assurer que les fichiers reportés sur la branche de maintenance sont bien en ISO-8859-15
&lt;/p&gt;

=SqlMigrator et livraison de scripts=
L'encodage des fichiers dépend de la branche / version :
* branches des '''versions &lt; 15.1''' : se fait en '''ISO-8859-15'''
* branches des '''versions &gt;= 15.1''' : se fait en '''UTF-8'''
** Il faut désormais éviter de spécifier dans les changeSet un encoding=windows-1252

livraison de scripts dans suivefluid : ISO-8859-15

Le fait de changer d'encodage modifie le checksum des fichiers qui se trouvent dans sql/database.&lt;br&gt;
La problématique de compatibilité du checksum est prise en charge par l'UL.

=Map4J et UTF-8=
La lecture des squelettes dans Map4J peut planter suite à la migration UTF-8. En attendant la livraison de la correction dans Map4J, ajouter au fichier '''map4j/pom.xml''' l'argument suivant pour corriger le problème : 
  &lt;argument&gt;-Dfile.encoding=UTF-8&lt;/argument&gt;

=Intellij et .editorconfig=
&lt;p&gt;
En raison du changement d'encodage à partir de la v15, il est vivement recommandé d'avoir au moins un workspace dédié pour les versions &gt;= v15 
&lt;/p&gt;
&lt;p&gt;L'encodage automatique des fichiers créés sous IntelliJ est possible en paramétrant IntelliJ via le '''plugin editorconfig'''.&lt;/p&gt;
Il s'agit d'indiquer dans un fichier .editorconfig l'encodage utilisé :
  # Configuration par défaut de tous les fichiers
  [*]
  insert_final_newline = true
  indent_style = space
  indent_size = 2
  charset = utf8
&lt;p&gt;Le fichier doit être créé à la racine du projet.&lt;/p&gt;
&lt;p&gt;Il est également livré dans le repository efluid.&lt;br&gt;
Pour le récupérer, il faut importer les modules qui nous intéressent et le projet racine. clea permet de récupérer la config .editorconfig.
&lt;/p&gt;
&lt;p&gt;Il faut également paramétrer chaque module importé dans '''Settings &gt; Editor &gt; File Encodings''' d'IntelliJ pour y indiquer l'encodage :&lt;br&gt;
[[Fichier:FileEncoding-2.jpg]]
&lt;/p&gt;

=Eclipse et .editorconfig=
Pour que le '''.editorConfig''' soit bien pris en compte sous Eclipse, il faut bien vérifier que les projets importés soit bien en "Inherited from container" et pas en "Other".&lt;br&gt;
[[Fichier:EditorConfigEclipse.png]]
&lt;p&gt;
De plus, une version de Webby pour Eclipse compatible avec le passage en UTF-8 est disponible via l'update site :&lt;br&gt;
https://github.com/roisoleil/m2eclipse-webby/raw/update-site/latest/ &lt;br&gt;
Informations complètes sur le forum : [https://eforum.efluid.uem.lan/viewtopic.php?f=16&amp;t=3519 Eclipse pour JDK17]
&lt;/p&gt;

=Outil utf8helper=
&lt;p&gt;Lors des reports ou de merges à partir d'anciens commits vers un référentiel UTF-8, on risque de récupérer des fichiers encodés en ISO-8859-15, et avoir un mix entre de l'UTF-8 et de l'ISO-8859-15 au sein même des fichiers.&lt;br&gt;
Cela pose des problèmes dans les éditeurs et des problèmes pour livrer son code dans le référentiel UTF-8.&lt;br&gt;
L'outil est à passer lors des cherry-picks, avant la résolution des conflits.
&lt;/p&gt;
&lt;p&gt;
'''utf8helper''' a été créé pour convertir les fichiers en UTF-8 et résoudre ce genre de problème.&lt;br&gt;
Il est disponible dans gerrit : [https://gerrit.efluid.uem.lan/changes/archi~204090/revisions/2/files/utf8helper.zip/download utf8helper dans gerrit]
&lt;/p&gt;
&lt;p&gt;
Pour l'installer, dézipper simplement le jar et le fichier sh dans votre répertoire binaire (pour git bash) : C:\users\&lt;nom&gt;\bin
Vous pourrez le lancer sur des répertoires pour convertir automatiquement l'iso en utf8, tout en tentant de résoudre les soucis de double encodage utf8
&lt;/p&gt;
'''Exemple d'utilisation :'''&lt;br&gt; 
Dans cet exemple, la commande est exécutée dans le répertorie archi et convertira les fichiers '''.java''' et '''.properties''' uniquement.
  $ utf8helper.sh .
  Conversion automatique de fichiers en UTF-8.
  Usage :
     utf8helper &lt;répertoire&gt; [&lt;répertoire&gt; [...]]
  Liste des répertoires à prendre en compte :
     - D:\java\workspaces\1\archi\.
  Lecture du fichier de configuration : C:\Users\sackste\.utf8helper.conf
  Configuration :
     action=CONVERT_AND_CORRECT
     excludedDirectories=target, .git, .idea, properties2
     fileExtensions=java, properties
&lt;p&gt;
'''Plus de précisions sur le forum''' : [https://eforum.efluid.uem.lan/viewtopic.php?f=25&amp;t=3531 aide à la résolution de conflits UTF-8/ISO]
&lt;/p&gt;

=Adaptations concernant les batchs=
==Stratégie de portage / tests des batchs d'interface==
=== Quels batchs sont concernés ?===
* les batchs traitant des données sans import / export de fichier n'ont à priori pas besoin d'être adaptés ni testés spécifiquement à la migration UTF-8
* les batchs créant et lisant des fichiers issus de systèmes tiers sont susceptibles d'être impactés par la migration UTF-8
** format json : normalement, les fichiers json sont nativement en UTF-8
** format XML : à priori, il faut laisser le parser traiter les fichiers. Malgré cela, il est peut-être nécessaire de tester / adapter le batch : 
*** Quand l'encodage n'est pas défini dans la balise : dans ce cas, préciser l'encodage.
*** Vérifier quel XML manager utilisé, notamment pour l'écriture du fichier XML qui pourrait être buggé (voir [[Guide migration UTF-8#Fichiers xml]])
** tout autre format (.csv, .txt, etc.) : il est nécessaire d'adapter ces batchs pour '''forcer l'encodage ISO-8859-15'''

===Comment les tester ?===
* '''De manière générale''' :
** Faire en sorte que les fichiers contiennent des caractères accentués et le signe '€' (dans une zone commentaire par exemple, une adresse, etc...)
** Si besoin, pour des tests sur poste de dév, il est possible d'indiquer à la JVM l'encodage à utiliser pour lire/écrire des fichiers : (commande -DFileEncoding ='iso-8859-18' ou 'utf8' 
** Le batch devra être testé si on intervient sur l'écriture / lecture du fichier (forçage de l'encodage, ajout / suppression d'une balise définissant l'encodage, etc.)

* '''Travailler conjointement avec la recette''' : 
** Indiquer à la recette par le biais d'événements les batchs sur lesquels il faut mener une campagne de non-regression 
** Pour les batchs d'export :
*** Idéalement, transmettre le fichier créé au système tiers pour vérifier qu'il est correctement lu. Cela nécessite de travailler avec la recette / chef de projet car le développement ne dispose pas forcément d'un SI Tiers, ni de l'environnement adéquat. 
** Pour les batchs d'import :
*** Se procurer un fichier du SI Tiers et l'injecter pour voir s'il est lu correctement.
*** Lorsque des TI métier existent sur le batch, il est fort probable qu'on puisse les utiliser pour tester. De plus, on dispose certainement de fichiers d'exemples.
*** Dans tous les cas, s'assurer que l'encodage du fichier correspond bien à l'encodage du fichier fourni par le SI Tiers.

==Batchs traitant des données sans import / export de fichier==
Ces batchs n'ont à priori pas besoin d'être adaptés.

==Batchs d'interfaces==
Ces batchs échangent des données à partir de fichiers avec un système tiers.&lt;br&gt;
Selon le format du fichier, il peut être nécessaire d'adapter ces batchs selon le format du fichier échangé,.
===Fichiers json===
Les fichiers json sont en principe encodés en UTF-8 par défaut.&lt;br&gt;
Si un encodage est spécifié au sein du fichier, il est recommandé de le supprimer.

===Fichiers xml===
&lt;p&gt;
Il est recommandé de laisser faire le parser XML sans forcer l'encodage au niveau de la lecture / écriture des fichiers.&lt;br&gt;
Généralement, les fichiers XML indiquent l'encodage du fichier dans l'entête, donc le parser devrait pouvoir se débrouiller seul.&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;Toutefois, certains fichiers peuvent être '''sans encodage''' dans l'entête. Dans ce cas :
* S'il s'agit de '''fichiers exportés''' (créés) : imposer un encodage UTF-8 et l'indiquer dans l'entête
* S'il s'agit de '''fichiers importés''' (lus) : la lecture se fait en UTF-8. Néanmoins, se renseigner vis-à-vis du client/système tiers si l'encodage ne peut pas être ajouté dans l'entête du fichier XML fourni.
* Les '''flux xml produits par efluid.net''' n'ont pas de balise définissant l'encodage : une adaptation est en cours côté échanges pour que les flux XML générés portent systématiquement l'encodage du fichier dans l'entête XML.&lt;br&gt; [https://suivefluid.uem.lan/application/evenement/364430 Evenement 364430]
&lt;/p&gt;

⚠️ '''A surveiller :'''⚠️&lt;br&gt;
* Pour l'import de fichiers XML
** Utilisation des '''AbstractXMLStreamMapper''' : l'encodage par défaut n'est pas forcément défini. Sans être précisé, ce devrait être l'encodage système (ou JVM) utilisé.
** L'encodage sera bien pris en compte lors de la lecture du fichier si la balise est présente dans le fichier.

* Pour l'export de fichiers XML
** Quand utilisation des '''SortedExportXMLStreamManager''' : se base sur du SortedExportFileManager qui est l'outil framework d'écriture XML (n'utilise pas le composant XML du jdk)
** l'encodage ne semble pas être défini par défaut. Si celui-ci n'est pas défini, on peut avoir un doute sur l'encodage du fichier exporté.
** bien vérifier que l'encodage est défini dans le gestionnaire d'export (que le setEncoding est utilisé)

* '''Il peut y avoir un bug''' en utilisant une classe héritant de '''AbstractXMLStreamMapper''' pour écrire le fichier XML : Le FileWriter instancié pour créer le fichier ne précise pas l'encodage du fichier, mais ajoute quand même la balise d'encodage lorsque l'encodage est défini.&lt;br&gt;
'''Conséquence : le fichier xml contiendra la balise encodage 'iso-88-59-15' alors que le fichier sera écrit en UTF-8&lt;br&gt;'''
Correctif en cours dans l'archi : https://gerrit.efluid.uem.lan/c/archi/+/207410 &lt;br&gt;

===Autres fichiers (fichiers textes divers, csv...)===
Il est recommandé de forcer l'encodage des fichiers en ISO-8859-15 pour ne pas impacter les systèmes tiers.&lt;br&gt;
cf. [[Guide migration UTF-8|Forcer l'encodage]] pour savoir comment procéder pour forcer l'encodage

==Forcer l'encodage==
Généralement, ces batchs héritent de AbstractImportExportProgram.
* Pour l'import : 
** il suffit d'ajouter une valeur au properties du batch ENCODING_IMPORT = ISO-8859-15
* pour l'export :
** il suffit d'ajouter une valeur au properties du batch ENCODING_EXPORT = ISO-8859-15
** il faut ensuite paramétrer le FileManager en indiquant l'encodage forcé :
  SortedExportFichierPlatManager&lt;String&gt; mgr = new SortedExportFichierPlatManager&lt;&gt;(...)
  mgr.setEnforceEncoding(true);
  mgr.setEncoding(getEncodingFichierExporte());

NB  : il est toujours possible mais non recommandé de surcharger les triggers #getEncodingFichierImporte et #getEncodingFichierExporte

Si besoin (et pour tester), il est possible de lancer le batch en forçant l'encodage utilisé par la JVM pour lire/écrire les fichiers :
Au niveau du lanceur batch, ajouter dans les VM options l'option suivante : 
  "-Dfile.encoding=utf-8" (ou iso-8859-15 selon le cas souhaité).



Exemple de de forçage de l'encodage des fichiers pour les batchs d'import / export Viena : [https://gerrit.efluid.uem.lan/c/efluid/+/202731 Change dans gerrit]

=Correction des tests en erreur=
Le code source des tests a été encodé en UTF-8.&lt;br&gt;
Il est nécessaire de convertir en UTF-8 les fichiers qui pourraient être en entrée de ces tests.&lt;br&gt;

Dans le cas des tests les batchs d'interface : les fichiers en entrée / sortie des tests doivent suivre l'encodage précisé pour chaque batch (UTF-8 ou ISO-8859-15 selon les cas).&lt;br&gt; 
Se référer au paragraphe [[guide migration UTF-8|Batchs d'interfaces]]</text>
      <sha1>ipvn575svh8ik318gkp3o83ix3m444x</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement workflow</title>
    <ns>0</ns>
    <id>817</id>
    <revision>
      <id>669502</id>
      <parentid>634623</parentid>
      <timestamp>2015-02-26T14:20:50Z</timestamp>
      <contributor>
        <username>Parenteau</username>
        <id>25</id>
      </contributor>
      <comment>/* Planification des revues de code */</comment>
      <origin>669502</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10393" sha1="fz1xjjkaa6dgx6d2kfr10khcm1ng2ue" xml:space="preserve">{{Modèle:Groupe
 | groupe= workflow
 | responsable= [[TCO]]
 | domaines= [[workflow]], [[affaire générique]], [[mde]], [[etinéraire]], [[liste de gestion]]
 | developpeurs = [[TCO]], [[MHA]], [[CBO]], [[VPO]], [[JCH]]
}}
[[Category:groupe de développement]][[Category:workflow]]

=Description du groupe=

Le groupe Workflow est de plus en plus au cœur de l’application efluid et il a la responsabilité des domaines suivants :
* Workflow ([[WKF]])
* Affaires Génériques ([[AFG]])
* Maîtrise de l’Energie ([[MDE]])
* ETinéraire ([[GRH]])
* Liste de gestion ([[LDG]])

Le domaine Workflow est un domaine regroupant une bibliothèque de composants techniques permettant de gérer des processus à étapes. Grâce à ces composants fortement réutilisables et fortement paramétrables, il est possible d'associer à un concept efluid (contrat, affaire...) un élément de population dont le cycle de vie est décrit par une suite d'étapes, ce que l'on appelle un workflow. L'élément de population évolue au sein de ce workflow au fur et à mesure de l'exécution des traitements que les utilisateurs auront programmés. Il passera donc par différentes étapes, avant d'atteindre une étape finale ou il n'évoluera plus (état "terminé" le plus souvent). Le workflow comporte un ensemble d'écrans opérationnels et de paramétrage ainsi qu'une partie batch (spécialisation de l'architecture batch classique) permettant d'exécuter des traitements en masse. Ces composants, fruit d'une conception avancée, sont très fortement paramétrable, ce qui leur offre une grande capacité à traiter de multiples cas fonctionnels. On retrouve des workflow plus particulièrement dans les domaines [[Contrat]], [[Interventions]], [[Contentieux]] et [[Agence en ligne]], la tendance est à une réutilisation maximum de ce type d'approche.

Le domaine Affaires Génériques permet quand à lui de gérer des objets métier dont une grande partie de la structure (les attributs) est définie par paramétrage. Il pourrait en fait être nommé Modèle Objet métier, car il ne s'applique pas uniquement aux affaires. Grâce aux composants de ce domaine fonctionnel, il est possible d'utiliser les attributs statiques des objets java (attributs du code) et d'ajouter de nouveaux attributs dits "dynamiques" par paramétrage. Les IHM de gestion de ces objets paramétrables est elle aussi dynamique et il est possible de paramétrer le comportement de ces IHM générées dynamiquement. Un exemple pour illustrer cela est le marketing. On peut imaginer vouloir créer une affaire de marketing à un instant T, pour promouvoir une nouvelle offre de commercialisation. Pour cela il suffit de configurer les attributs nécessaires dans une affaire générique que l'on qualifiera d'affaire marketing et on pourra faire évoluer cette affaire au travers d'un workflow qui pourra par exemple envoyer des courriers aux clients, puis ensuite recevoir les réponses des clients au travers d'un questionnaire, les exploiter en offrant des possibilités de relance ou d'établissement de propositions commerciales / souscription de services, etc...

Le domaine MDE se base totalement sur l'utilisation du workflow et des affaires génériques. Il permet de gérer les certificats d'économie d'énergie et de traiter les processus relatifs à la Maîtrise De l'Energie. Une partie des traitements est disponible dans efluid, et l'autre se trouve dans le portail partenaire. Le portail permet aux partenaires (électriciens, chauffagiste...) de créer des affaires MDE en renseignant les informations des travaux qu'ils ont effectué (exemple : pose d'un chauffe-eau solaire). Ces affaires entrent ensuite dans un workflow qui permettra aux agents back-office de lancer des traitements, d'établir des rapports à destination des organismes de l'état, de suivre l'activité MDE, mais aussi également aux partenaires, qui pourront donc interagir avec le distributeur pour entre autres obtenir les aides de l'état incitant à la maîtrise de l'énergie.

Le domaine eTinéraire permet de gérer l'activité de recrutement (pour le compte de l'UEM exclusivement à ce jour). D'une part dans efluid ou l'on va retrouver les processus de gestion des annonces, des candidats, des candidatures ou des rendez-vous programmés dans un objectif de suivi, et d'autre part via le "portail recrutement" ou les candidats peuvent postuler aux annonces en fournissant CV, lettre de motivations et autres informations relatives etc. Ce domaine se base lui-aussi sur l'utilisation massive du workflow et des affaires génériques.

= Pilotage =

== Reste à faire ==
{{Modèle:RafParGroupe
 | lot = 12
 | groupe = WORKFLOW
 | nbPersonnesNouveauxDev = 4
 | nbPersonnesMaintenance = 4
 | tauxDev = 0.4
 | tauxMaintenance = 0.4
}}

==Détails==
{{Modèle:RafParDeveloppeur
 | groupe = WORKFLOW
 | developpeurs = TCO;MHA;CBO;VPO
}}
{{Modèle:DetailRafParGroupe
 | lot = 12
 | groupe = WORKFLOW
}}
{{Modèle:DetailRafMaintenanceGroupe
 | groupe = WORKFLOW
}}

=Qualité=

==Événements supports==

* WKF : [[50257]]
* AFG : [[68088]]
* GRH : [[65604]]
* MDE : [[52591]]
* LDG : [[112717]]

==Métriques du groupe==

* [http://especteur/dashboard/index/252952 Rapport sonar ecore workflow]
* [http://especteur/dashboard/index/139112 Rapport sonar efluid workflow]

==Règles qualité==

* Pour la définition des classes, utiliser un cartouche du type :
&lt;source lang="java"&gt;
/**
 * Écrire ici la description succincte qui sera indiquée dans la javadoc .
 * 
 * (Au besoin ici la description plus complète)
 */
&lt;/source&gt;

[[Fichier:JavadocWorkflow.png]]

* Ne pas hésiter à faire un Ctrl+i pour remettre une indentation plus "propre"
* Idem avec Ctrl+Shift+o pour mieux organiser les imports et supprimer ceux qui sont inutilisés
* Ajouter l'annotation @Override au dessus de la déclaration d'une methode lorsqu'il s'agit d'une redéfinition de méthode de superclasse
* Utiliser au minimum les @SuppressWarnings et autre //$NON-NLS-1$, modifier plutôt la configuration des warnings Eclipse dans Windows/Preference puis Java/Compiler/Errors-Warnings
* Nettoyer les "// TODO Auto-generated method stub"
* Ne pas utiliser de code en dur : créer des constantes si nécessaire
* Ne laisser pas du code en commentaire
* Chaque méthode doit être documentée par une javadoc, soyez succint mais ne vous contentez pas de reprendre son nom ; n'y mettez pas les arguments @return et @param, sauf si cela apporte vraiment une information utile bien sûr. En général il est préférable de commenter ce que fait la méthode à ce niveau, plutôt que de mettre des commentaires dans le corps de la méthode.

==Planification des revues de code==
{{règle d'organisation des revue de code}}

* Planification revue de code - nouveaux devs

{{#get_web_data:url=http://ldsanbld2:9700/eRenDeServices-nb/suivefluid/revuecode/json?groupe=WORKFLOW|format=JSON|data=intitule=Intitule,reference=Reference,developpeur=Developpeur,recetteur=Recetteur,evts=evts,statut=Statut}}
{{#for_external_table:evts}}
{| class="wikitable"
! Évènement
! Libellé
! Développeur
! Relecteur
! Revue
! Correction{{#for_external_table:&lt;nowiki/&gt;
{{!}}-
{{!}} [[{{{reference}}}]]
{{!}} {{{intitule}}}
{{!}} [[{{{developpeur}}}]]
{{!}} [[{{{recetteur}}}]]
{{!}} [[Revue de code:{{{reference}}}]]
{{!}} {{{statut}}} }}
|}

* Planification revue de code - JPAR
{| class="wikitable"
|-
! évènement
! libellé
! developpeur
! relecteur
! relecture
! correction
|-
| [[104678]]
| GRH - création d'opération par copie
| [[JPAR]]
| [[CBO]]
| [[Revue de code:104678]]
| 
|}


* Planification revue de code - Maintenance CBO

{| class="wikitable"
|-
! évènement
! libellé
! developpeur
! relecteur
! relecture
! correction
|-
| [[66216]]
| GRH - ajouter un filtre "demandeur" en recherche d'annonce
| [[CBO]]
| [[TCO]]
| [[Revue de code:66216]]
| {{check}}
|}

* Planification revue de code - Maintenance MHA

{| class="wikitable"
|-
! évènement
! libellé
! developpeur
! relecteur
! relecture
! correction
|-
| [[76578]]
| G10-RC anomalie double voir + sur EDP reconduction contrat
| [[MHA]]
| [[TCO]]
| [[Revue de code:76578]]
| {{check}}
|-
| [[67204]]
| échec d'éxécution de batch WKF999 (problème sur condition d'execution sur critères d'attributs dynamiques)
| [[MHA]]
| [[JFL]]
| [[Revue de code:67204]]
| {{check}}
|}

* Planification revue de code - Autres

{| class="wikitable"
|-
! évènement
! libellé
! developpeur
! relecteur
! relecture
! correction
|-
| 118129
| Impossible de valoriser en masse des modèles d'attributs d'affaires génériques
| [[MMA]]
| [[JTA]]
| [[Revue de code:118129]]
| {{check}}
|-
| 134558
| Dépendances entre campagne et workflow via le type de lot de workflow
| [[MMA]]
| [[PPA]]
| [[Revue de code:134558]]
|-
| 135728
| Le tri des anomalies sur les EDP workflow doit être fait sur le statut de celles-ci
| [[CPI]]
| [[PPA]]
| [[Revue de code:135728]]
|
|}

== Revues de commit ==

* Chaque commit sur la develop doit être validé par un membre de l’équipe (que ce soit pour efluid, AEL, ecore, efluidPub, edk etc…) et pour n’importe quel type d’évènement. C’est aussi valable pour les script ebuild.

* C'est au développeur de choisir la personne qui validera le commit, selon le type d’évènement, et les dispos (congé etc…) de chacun. Si vous ne savez pas à qui envoyer, envoyez à tout le groupe.

* Cela se fera sous la forme d'un mail envoyé depuis le tableau de récapitulation : [[Revue des commit du groupe Workflow]]
Il suffit de cliquer sur la petite enveloppe près du numéro de l’évenement listé dans le tableau.

* Un évènement considéré comme critique ne peux pas passer livrer-it sans cette validation préalable.

* Pour qu'un événement apparaisse le tableau [[Revue des commit du groupe Workflow]], il faut se positionner sur l’onglet « analyse des problèmes » et noter dans le bloc « explication technique » : '''Validation WKF {nom du projet} {branche} : {id du commit}'''
Avec 

- '''{nom du projet}''' = au choix : efluid / AEL / efluidPub / ecore / edk ou autre

- '''{branche}''' = le nom de la branche : develop / HERMES_11 ..

- '''{id du commit}''' = l’id du commit, sachant que les 7 premiers chiffres suffisent

== Réunion de groupe ==
* [[CR de la réunion du 28 novembre 2011]]
* [[CR de la réunion du 21 novembre 2011]]</text>
      <sha1>fz1xjjkaa6dgx6d2kfr10khcm1ng2ue</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement intervention</title>
    <ns>0</ns>
    <id>850</id>
    <revision>
      <id>4053955</id>
      <parentid>4053954</parentid>
      <timestamp>2019-08-09T14:28:23Z</timestamp>
      <contributor>
        <username>Damestoy</username>
        <id>12</id>
      </contributor>
      <comment>/* Tests unitaires qui posent des difficultés */</comment>
      <origin>4053955</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5366" sha1="70qzon4re05kla1exjo4h7jqvvsnct2" xml:space="preserve">{{Modèle:Groupe
 | groupe= intervention
 | responsable= [[BDA]]
 | domaines= [[interventions]], [[campagnes]], [[requeteur]], [[planification]] 
 | developpeurs = [[BDA]], [[CFA]], [[LGU]], [[PPA]],[[EDU]]
 | analystes = Martial Weinzoepflen, Olivier Montigny
}}

=Estimation des RAF=
[[Category:groupe de développement]]
{{Modèle:RafParGroupe
| lot = 12
| groupe = INTERVENT
| nbPersonnesNouveauxDev = 3
| nbPersonnesMaintenance = 3}}

=Règles de développement=

= Docs =
[[Gestion des limitations dans le CRI|Gestion des limitations dans le CRI]]

[[Ws_intervention|Webservices utilisés dans le domaine]]


[[Catégorie:Domaine_Intervention|Liste de tutos Intervention]]

=Tests unitaires=
Il est proposé de mettre en place les tests unitaires dès qu'on modifie/crée une API dans le cadre de la réalisation d'un événement (que ce soit un nouveau développement ou une anomalie à corriger).
Actuellement, nous n'avons aucun recul pour pouvoir estimer le temps passé sur les tests unitaires par rapport à un développemment.
Pour pouvoir avoir cette information, il faut créer un événement fils ayant les caractéristiques suivantes :
* type : qualité 
* libellé : 'tests unitaires' 
Lorsqu'on réalise le test unitaires, on impute son temps comme du développement sur l'évt 'tests unitaires'.
De cette manière, on peut distinguer le temps passé pour les tests unitaires du temps passé pour le développement lui-même.

==Documentations et outils concernant les tests unitaires==
*Page [[Tests logiciels]] dans wikefluid
*Section dédiée aux tests unitaires dans le [http://eforum.uem.lan/viewforum.php?f=31 Forum] 
*Outils disponibles
** [http://cje.efluid.uem.lan/usinelogiciellecompilation/job/FsuiteEfluid/job/Fefluid/job/efluid.compile/ Page des tests unitaires de l'usine logicielle]

= Tests unitaires qui posent des difficultés =
Pour les tests unitaires ci-dessous, il est proposé d'en débattre afin de trouver la meilleure manière de les prendre en compte. Ils peuvent être ajoutés ici suite à une revue de code où des questions sur la manière de faire le test unitaire, ou tout simplement parce qu'on n'a pas réussi à réaliser le test unitaire.

= Tests intégrations =

= Tests JMeter = 
* [http://wikefluid/index.php/Sc%C3%A9narios_ITV stage test JMeter JNE]

= Trucs et astuces =

== Classe de test développeur pour les traitements workflow déporté en JMS ==

Il existe une classe de test « développeur » qui permet d’appeler un traitement comme si on dépilait le message dans la file JMS suite au déport de l'exécution du traitement workflow.
La classe de test : TestITTraitementWorkflowDeporteJMS
Pour la lancer, il est nécessaire de modifier les 3 méthodes en début de classe, qui permettent d’indiquer l’intervention, la campagne, et le traitement qui sera exécuté.

== Requêtes utiles ==
=== Changement de statut d'une affaire et insertion dans taction ===
&lt;source lang="sql"&gt;
UPDATE TAFFAIRE
SET STATUT          = 1,
  ACTEURMODIFICATION='evt 155981',
  DATEFIN           = CURRENT_DATE,
  DATEMODIFICATION  = CURRENT_DATE
WHERE REFERENCE     ='2086383';

INSERT
INTO TACTION
  (
    ID,
    ETATOBJET,
    ACTEURCREATION,
    ACTEURMODIFICATION,
    DATECREATION,
    DATEMODIFICATION,
    CODEFOURNISSEUR,
    CODEGRD,
    STATUT,
    REFERENCE,
    DATERDVDEBUT,
    DATERDVFIN,
    DATEOBJECTIF,
    OBJETMAITRE_ID,
    OBJETMAITRE_ROLE,
    RESPONSABLE_ID,
    RESPONSABLE_ROLE,
    DESTINATAIRERDV_ID,
    DESTINATAIRERDV_ROLE,
    OBJET,
    OBSERVATIONS,
    ACTEURSUPPRESSION,
    DATESUPPRESSION,
    AGENCE,
    DEMANDEDEPRISEENCOMPTE,
    ACTIONPUBLIEE,
    PUBLIEEPARFOURNISSEUR,
    REPONSEINTEGREEPARWORKFLOW,
    PARAMETRAGEACTION_ID,
    PARAMETRAGEACTION_ROLE
  )
  VALUES
  (
    uniqueid.nextval,
    '0',
    'statut|evt|155981',
    NULL,
    CURRENT_DATE,
    NULL,
    'F-ES',
    'G-ES',
    '2',
    seq_ref_action.nextval ,
    NULL,
    NULL,
    NULL,
    (SELECT ID FROM TAFFAIRE WHERE REFERENCE = '2086383'),
    (SELECT ROLE FROM TAFFAIRE WHERE REFERENCE = '2086383'),
    NULL,
    NULL,
    NULL,
    NULL,
    'affaire terminée',
    NULL,
    NULL,
    NULL,
    NULL,
    '0',
    NULL,
    '0',
    '0',
    'MDLACTINFO',
    'com.hermes.ref.affaireaction.businessobject.ModeleAction'
  );
&lt;/source&gt;

=Qualité=

==Métriques du groupe==

* [http://especteur/dashboard/index/553315?did=1 Rapport sonar intervention]

==Différents modes de planification et ordre des mises à jour des autres objets==
Dans le tableau ci dessous, les numéros représentant l'ordre naturel des mises à jour selon l'objet pivot (numéro 1) de la mise à jour
{| class="wikitable sortable" style="text-align: center;"
|-
! modePlanification!! Intervention !! Tentatives activées !!   Tentatives non activées !! Réservation     !! type Moteur Planification
|-
| planification par défaut|| 1 dateDebut || 2 dateDebut recopiée ||   N/A || N/A     || à l'ancienne, fichier excel
|-
| planification par créneau|| 2 dateDebut recopiée || 3 dateDebut recopiée ||   N/A || 1 dateDebut     || planification interne avec réservations
|-
| displanisWeb|| 2 dateDebut recopiée || 1 dateDebut ||   N/A || N/A     || planification externe avec displanis
|-
| divagamWeb|| 2 dateDebut recopiée || 1 dateDebut ||   N/A || N/A     || planification externe avec divagam
|}</text>
      <sha1>70qzon4re05kla1exjo4h7jqvvsnct2</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement facturation</title>
    <ns>0</ns>
    <id>886</id>
    <revision>
      <id>4068462</id>
      <parentid>4068461</parentid>
      <timestamp>2023-02-21T06:35:33Z</timestamp>
      <contributor>
        <username>Kraemer</username>
        <id>70</id>
      </contributor>
      <comment>/* Guides et conventions */</comment>
      <origin>4068462</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2255" sha1="tseujc8x8ykjx5pdeg1mybg7hlve3zs" xml:space="preserve">{{Modèle:Groupe
 | section=[[Section facturation]]
 | division=[[Division facturation et offre produit]]
 | responsable=[[ATA]]
 | domaines=[[contrat de prestation]], [[datamasking]], [[facturation]], [[interfaces facturation]], [[mensualisation]], [[optimisation part acheminement]], [[outil réduction bdd]], [[paramétrage requêteur]], [[pes]], [[purge données]], [[reversement]]
 | developpeurs=[[ATA]], [[DVA]], [[RKR]], [[CLI]], [[RPN]], [[BZI]], [[NMN]]
 | analystes=[[JFRO]], [[AJA]], [[ECA]]
}}
[[Category:groupe de développement]]

=Qualité/développement=
== Guides et conventions==
*Lien vers le [[Guide_du_nouveau_développeur|guide du nouveau développeur]]
*Lien vers les [[Convention_de_code_Efluid|conventions de code efluid]]
*Lien vers [[Gestion_de_la_qualité|la page de qualité générale]]
*Lien vers [[Tests_logiciels|la page dédiée aux tests logiciels]]
*Lien vers [[Guide_utilisateur_du_batch_de_script_d’import-export_(ARC300MT)|le guide ARC300MT]]
*Lien vers [https://wikefluid.efluid.uem.lan/docInstalleur/archi/develop/documentation/README.html la doc archi]
*Lien vers [https://wikefluid.efluid.uem.lan/docInstalleur/archi/develop/documentation/batchs/GUIDE_modularisation_batch.html le guide de modularisation batch]

==Trucs et astuces==
* [[Créer des énumérés persistants]]
* [[Ajouter un attribut sur un business object]] (à actualiser)
* [[Modifier des attributs sur un business object]] (à actualiser)
* [[Supprimer des getters sur un business object]] (à actualiser)
* [[Créer_un_paramètre_entreprise_avec_critères|Créer un paramètre entreprise avec critères]]
* [[Créer_un_paramètre_entreprise_sans_critères_avec_énuméré_statique|Créer un paramètre entreprise sans critères avec énuméré statique]]
* [http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_2273f5 Lancer un batch en mode deployé]

=Git/Gerrit=
* [[Format_Msg_Commits_FAC|Convention de nommage des commit]]

=SQL et outils associés=
*[[Tableau de scripts FAC|Tableau de scripts réutilisables]]
*[[Fragments_de_code_sql_des_groupes|Fragments de code sql]]

=Tests/Performances=
*[[Scénarios JMeter Facturation]]

=F.A.Q.=
* [[Foire_aux_questions_facturation|Foire aux questions expertise/dév facturation]]</text>
      <sha1>tseujc8x8ykjx5pdeg1mybg7hlve3zs</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement consommation</title>
    <ns>0</ns>
    <id>975</id>
    <revision>
      <id>4060031</id>
      <parentid>4050706</parentid>
      <timestamp>2020-07-16T15:05:16Z</timestamp>
      <contributor>
        <username>Grzejsz</username>
        <id>69</id>
      </contributor>
      <minor/>
      <origin>4060031</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5313" sha1="rg5hlev2im1cza1buat306o0rykrdve" xml:space="preserve">{{Modèle:Groupe
 | groupe= CNS
 | responsable= [[DGR]]
 | domaines= [[consommation]], [[materiel]], [[relève]], [[reconstitution des flux]], [[interface relève]]
 | developpeurs = [[SRO]], [[PFR]], [[FMO]], [[FMA]], [[DGR]], [[ALH]], [[JKEM]], [[RPI]], [[SPO]],  [[LGU]], [[TTA]] 
 | analystes = consommation [[SRA]], échanges [[CBER]], mobilité [[OBO]], [[TRA]]
}}
[[Category:groupe de développement]]

=Trucs et astuces=
== Requêtes utiles ==
* [[Domaine_consommation#Requ.C3.AAtes_utiles|Requêtes SQL utiles domaine consommation]]
* [[Domaine_BGE#Requ.C3.AAtes_utiles|Requêtes SQL utiles domaine BGE]]
* [[Domaine_materiel#Requ.C3.AAtes_utiles|Requêtes SQL utiles domaine matériel]]
* [[Domaine_rel%C3%A8ve#Requ.C3.AAtes_utiles|Requêtes SQL utiles domaine relève]]
* [[Domaine_reconstitution_des_flux#Requ.C3.AAtes_utiles|Requêtes SQL utiles domaine reconstitution des flux]]
* [[Consommation_Suivefluid#Requ.C3.AAtes_utiles|Requêtes SQL utiles pour des informations de suivi dans Suivefluid]]


=== Requête pour suivre l'avancement d'un batch v3 ===

table BATCH_RELEVE
&lt;source lang="sql"&gt;
SELECT code_batch, COUNT(*) "nb éléments", ROUND(100 * COUNT(*) / sum(count(*)) over(partition by code_batch) ,2) "%", CASE WHEN TECH_STATUT=1 THEN 'à traiter' ELSE 'traité' END "statut" 
FROM BATCH_RELEVE tmp GROUP BY code_batch, TECH_STATUT 
ORDER BY code_batch, TECH_STATUT;
&lt;/source&gt;

table BATCH_PDS 
&lt;source lang="sql"&gt;
SELECT code_batch, COUNT(*) "nb éléments", ROUND(100 * COUNT(*) / sum(count(*)) over(partition by code_batch) ,2) "%", CASE WHEN TECH_STATUT=1 THEN 'à traiter' ELSE 'traité' END "statut" 
FROM BATCH_PDS tmp GROUP BY code_batch, TECH_STATUT 
ORDER BY code_batch, TECH_STATUT;
&lt;/source&gt;

table BATCH_CONTRAT
&lt;source lang="sql"&gt;

SELECT code_batch, COUNT(*) "nb éléments", ROUND(100 * COUNT(*) / sum(count(*)) over(partition by code_batch) ,2) "%", CASE WHEN TECH_STATUT=1 THEN 'à traiter' ELSE 'traité' END "statut" 
FROM BATCH_CONTRAT tmp GROUP BY code_batch, TECH_STATUT 
ORDER BY code_batch, TECH_STATUT;
&lt;/source&gt;

table BATCH_ENERGIE_NON_FACTURE
&lt;source lang="sql"&gt;
SELECT code_batch, COUNT(*) "nb éléments", 	ROUND(100   * COUNT(*) / sum(count(*)) over(partition by code_batch) ,2) "%", CASE WHEN TECH_STATUT=1 THEN 'à traiter' ELSE 'traité' END "statut" 
FROM BATCH_ENERGIE_NON_FACTURE tmp GROUP BY code_batch, TECH_STATUT 
ORDER BY code_batch, TECH_STATUT;
&lt;/source&gt;

table BATCH_PROJECTION_COURBE
&lt;source lang="sql"&gt;
SELECT code_batch, COUNT(*) "nb éléments", 	ROUND(100   * COUNT(*) / sum(count(*)) over(partition by code_batch) ,2) "%", 	CASE 		WHEN TECH_STATUT=1 		THEN 'à traiter' 		ELSE 'traité' 	END "statut" 
FROM BATCH_PROJECTION_COURBE tmp GROUP BY code_batch, TECH_STATUT 
ORDER BY code_batch, TECH_STATUT;
&lt;/source&gt;


= Liens vers les Modèles Physiques de Données =
* CONSOMMATION :  &gt; efluid - Documentation Technique &gt; DCT suite efluid &gt; DCT efluid &gt; Domaine consommation &gt; visio

http://wperoom3.uem.lan/eRoomReq/Files/Production/DocTechniqueEfluid/0_18f4c3/MPDconso.vsd
* RELEVE :  &gt; efluid - Documentation Technique &gt; DCT suite efluid &gt; DCT efluid &gt; Domaine relève &gt; conception

http://wperoom3.uem.lan/eRoomReq/Files/Production/DocTechniqueEfluid/0_1ab3d8/MPDreleve.vsd
* MATERIEL :  &gt; efluid - Documentation Technique &gt; DCT suite efluid &gt; DCT efluid &gt; Domaine matériel &gt; conception &gt; visio

http://wperoom3.uem.lan/eRoomReq/Files/Production/DocTechniqueEfluid/0_1ab2b2/MPDmateriel.vsd

=Règles de développement=

== Suppression batchs obsolètes ==
Liste des batchs à retrouver en recherchant "Suppression batch*" dans suivefluid
[[Suppression batch conso obsolète]]


== Sécurisation des chargements dans les batchs ==
[[Sécurisation des chargements dans les batchs]]

== Liste des rôles hashcodés ==
On peut rapidement voir la liste des colonnes hashcodées pour toutes les tables du goupe dans la classe ConsommationRoleDAOUtils.
Ci-dessous un rappel du contenu de la classe (à maintenir donc...)
=== Table TRELEVE ===
* PACALENDRIER_ROLE
* ACTEUR_ROLE

=== Table TGRANDEURPHYSIQUEGENERALE ===
* ROLE

=== Table TINFORELEVE ===
* PACALENDRIER_ROLE

=== Table TGRANDEURPHYSIQUEGENERALEINFOR ===
* ROLE

=== Table TCONSOMMATIONMENSUELLE===
* PACALENDRIER_ROLE_ROLE

=== Table TELEMENTDEPOPULATIONRELEVE ===
* POINTDESERVICE_ROLE

=== Table TPACALENDRIER===
* ROLE


==Documentations et outils concernant les tests unitaires==
*Page [[Tests logiciels]] dans wikefluid
*Section dédiée aux tests unitaires dans le [http://eforum.uem.lan/viewforum.php?f=31 Forum] 
*Outils disponibles
** [http://usinelogicielle/view/Tests/ Page des tests unitaires de l'usine logicielle] 
** [http://usinelogicielle/view/Tests/ couverture des tests unitaires dans Sonar] 


= Tests de performance TP =
Les tests de performances TP sont rélaisés à l'aide de scénarios JMeter. Ceux-ci peuvent également servir à effectuer des tests de non-regression.&lt;br&gt;
La liste des scénarios JMeter réalisé est disponible sur la page des [[scénarios CNS]]


= Sujet de stage / alternance =
* enrichir les process de chargement (avec méthode des ''Loader'')
* refonte du chargement de l'historique de relève pour éviter de recharger l'historique entier à la validation d'une relève)
* revoir le chargement de l'historique de relève en TP</text>
      <sha1>rg5hlev2im1cza1buat306o0rykrdve</sha1>
    </revision>
  </page>
  <page>
    <title>Section recouvrement</title>
    <ns>0</ns>
    <id>1326</id>
    <revision>
      <id>1468469</id>
      <parentid>1468468</parentid>
      <timestamp>2016-04-01T14:54:23Z</timestamp>
      <contributor>
        <username>Barthel</username>
        <id>170</id>
      </contributor>
      <origin>1468469</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1407" sha1="2385p0qbb7q4rra9vsbxi5qahmoqbey" xml:space="preserve">{{Modèle:Groupe
 | division=[[Division_comptabilité_et_recouvrement|comptabilité et recouvrement]]
 | responsable= [[CLE]]
 | domaines= [[relance]], [[contentieux]]
 | developpeurs = [[CLE]], [[GBA]], [[SAN]]
 | analystes = [[ICA]], [[EHA]], [[JGO]]
}}
[[Category:groupe de développement]]

= Pilotage de la section =
* [[comment ça marche ?]]
* [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_1184f3|CR réunion mensuelle section RLC_MNS]

=Scripts SQL=
*[[Fragments_de_code_sql_des_groupes |Fragments de code sql]] des groupes

= Qualité =
* [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_128202 taches de fond]

== Evénements supports ==
* RLC : 31374
* CTX : 31372

==Métriques de la section==
* [http://especteur/dashboard/index/123416 sonar du groupe]

== Règles qualité ==
* Lire [[Coder proprement]]
* Lire les [[Convention_de_codage_RLC_MNS|conventions de codage]] du groupe
* Lire les [[Bonnes_pratiques_RLC_MNS|bonnes pratiques]] du groupe
* [http://blog.soat.fr/2012/11/java-performances-33-optimisation-de-code/ Optimisation de code]

= Revues de code =
{{règle d'organisation des revue de code}}
* [[Configuration et procédure des revues]]
* [[Planification des revues de code du groupe Mensu Recouvrement]]

= Reste à faire =
{{Modèle:RafParGroupe
 | lot = 11
 | groupe = IC_RELANCE
 | nbPersonnesNouveauxDev = 2
 | nbPersonnesMaintenance = 2
}}</text>
      <sha1>2385p0qbb7q4rra9vsbxi5qahmoqbey</sha1>
    </revision>
  </page>
  <page>
    <title>Division comptabilité</title>
    <ns>0</ns>
    <id>1568</id>
    <revision>
      <id>4058096</id>
      <parentid>4058095</parentid>
      <timestamp>2020-03-24T11:07:08Z</timestamp>
      <contributor>
        <username>Romero</username>
        <id>42</id>
      </contributor>
      <comment>/* Trucs et astuces */</comment>
      <origin>4058096</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3036" sha1="e394ndpq8j84hatco9fgjea3k6yp90n" xml:space="preserve">{{Modèle:Groupe
 | division=[[Division_comptabilité_et_recouvrement|comptabilité]]
 | responsable= [[nous tous]]
 | domaines= [[Comptabilite|comptabilité auxiliaire client]], [[règlement]], [[moteur comptable]], [[interface comptable]], [[relance]],[[contentieux]],[[datamasking]],
 | developpeurs = [[CLE]],[[CGI]],[[XBL]], [[LPR]], [[LMO]], [[SAN]], [[GBA]], [[AALT]], [[ORO]]
 | analystes = Elena Curuliuc
}}
[[Category:groupe de développement]]

= Présentation du groupe =
*[[Division_comptabilité_et_relance|Organisation de la division Comptabilité]]
*[[Membres du groupe CAC_IC|Membres du groupe]]


= Pilotage du groupe =
* '''Description  '''
** [[Pilotage maintenance|Pilotage Maintenance]]
** [[Pilotage nouveaux développements]]
** [[Pilotage qualité]]
** [[Pilotage Projets]]


* '''Résumé des outils de pilotage utilisés dans la division '''
** Requêtes suivefluid
** Boite mail partagée
** Chaîne slack "coordianaltion"
** Chaîne slack "anomalies-compta"
** Chaîne slack "prestations-compta"
** Fichier Excel prévisionel


= Trucs et astuces =

* '''Règles de développement''' 
** [[Règles et bonnes paratiques de codage|Règles et bonnes paratiques de codage|Règles et bonnes pratiques de codage]]
** Dès le début d’un nouveau dév : confronter son idée de conception à un autre développeur : '''même si on n'est pas bloqué'''
** En cours de dév :  faire valider l'avancement du dev, les changements éventuels de conception, etc.
** En fin de dev : faire relire son code par un autre développeur. [[Planification des revues de code CAC_IC|Planification des revues de code]]


* '''Trucs et astuces sql''' 
** [[scripts sql récurrents du domaine cac|Scripts sql récurrents]]
** [http://wperoom1/eRoom/Production/GestionProjetEfluid/0_8265b Liste des scripts génériques cac]
** [[scripts sql permettant de faire le lien entre les types de ligne et les types de transaction]]
** [[utilisation des templates dans SQL developer]]


* '''Trucs et astuces test''' 
** [[Point à verifier lors de la recette du Batch REG004MT]]
** [http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_2273f5 Lancer un batch en mode deployé]


* '''Trucs et astuces batch''' 
** [[Recommandations sur la conception d'un batch MT]]
** [[Check liste livraison nouveau batch]]
** [[Check liste livraison maintenance]]


* '''Check liste ajout d'un nouveau type de transaction'''
** Ajouter une nouvelle valeur dans l'énuméré persistant correspondant
** Définir avec l'analyste les critères dont on aura besoin pour traiter ce type de transaction
** Modifier le batch IC0001MT pour intégrer les nouvelles requetes
** Modifier le paramétrage entreprise des journaux
** Modifier le paramétrage entreprise des comptes tiers 
** Faire une notes de paramétrage pour traiter ce nouveau type de transaction (recette) 



* '''Trucs et astuces : partage de connaissances''' 
** Wiki
** eForum
** eRoom
** Boite mail partagée, sous répertoire "partage de connaissances"
** OneNote (de la division)</text>
      <sha1>e394ndpq8j84hatco9fgjea3k6yp90n</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement ebuild</title>
    <ns>0</ns>
    <id>1665</id>
    <revision>
      <id>13978</id>
      <parentid>13560</parentid>
      <timestamp>2012-07-04T13:10:39Z</timestamp>
      <contributor>
        <username>Bordon</username>
        <id>54</id>
      </contributor>
      <comment>/* Planification des revues de code */</comment>
      <origin>13978</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2719" sha1="k7wmkoe2qjgqh8jy8wm9yzdkvpfwg0m" xml:space="preserve">{{Modèle:Groupe
 | groupe= ebuild
 | responsable= [[NDE]]
 | domaines= [[ebuild]]
 | developpeurs = [[NDE]], [[ESI]]
}}
[[Category:groupe de développement]]

=Qualité=

==Règles qualité==

* Pour la définition des classes, utiliser un cartouche du type :
&lt;source lang="java"&gt;
/**
 * &lt;p&gt;Title: {nom de la classe}&lt;/p&gt;
 * &lt;p&gt;Description: {description}&lt;/p&gt;
 */
&lt;/source&gt;

* Ne pas hésiter à faire un Ctrl+i pour remettre une indentation plus "propre"
* A l'inverse éviter le formatage avec Ctrl+Maj+f car cela fait des sauts de ligne inutile dans le code
* Idem avec Ctrl+Shift+o pour mieux organiser les imports et supprimer ceux qui sont inutilisés
* Ajouter l'annotation @Override au dessus de la déclaration d'une methode lorsqu'il s'agit d'une redéfinition de méthode de superclasse
* Utiliser au minimum les @SuppressWarnings et autre //$NON-NLS-1$, modifier plutôt la configuration des warnings Eclipse dans Windows/Preference puis Java/Compiler/Errors-Warnings
* Nettoyer les "// TODO Auto-generated method stub"
* Le code « en dur » est à bannir, utiliser plutôt des constantes

==Planification des revues de code==
{{règle d'organisation des revue de code}}

* Planification revue de code - ESI
[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_a7f2f AFD_écart_evt74436.doc]

{| class="wikitable"
|-
! évènement
! libellé
! developpeur
! relecteur
! relecture
! correction
|-
| 77382
| 74436 - 3 - Création EPTypeEnvironnement
| [[ESI]]
| [[CBO]]
| {{check}}
| {{check}}
|-
| 77384
| 74436 - 4 - Modèles d'environnement
| [[ESI]]
| [[CBO]]
| [[Revue de code:77384_77386]]
| 
|-
| 77386
| 74436 - 5 - Création EEtatEnvironnement
| [[ESI]]
| [[CBO]]
| {{check}}
| {{check}}
|-
| 77386
| 74436 - 6 - Environnement (sans traitements récurrents ni mail)
| [[ESI]]
| [[CBO]]
| [[Revue de code:77384_77386]]
| 
|-
| 77387
| 74436 - 7 - Page d'accès aux environnements
| [[ESI]]
| [[CBO]]
| [[Revue de code:74436]]
| 
|-
| 77388
| 74436 - 8 - Modèles de fiche environnement
| [[ESI]]
| [[CBO]]
| [[Revue de code:77388]]
| 
|-
| 77389
| 74436 - 9 - Consultation fiche environnement depuis la page d'accès aux environnement
| [[ESI]]
| [[CBO]]
| [[Revue de code:77389]]
| 
|-
| 77392
| 74436 - 11 - Modes de traitement
| [[ESI]]
| [[CBO]]
| 
| 
|-
| 77393
| 74436 - 12 - Traitements récurrents
| [[ESI]]
| [[CBO]]
| 
| 
|-
| 77394
| 74436 - 13 - Création ETypeOrdonnanceur
| [[ESI]]
| [[CBO]]
| 
| 
|-
| 77395
| 74436 - 14 - Ordonnanceur
| [[ESI]]
| [[CBO]]
| 
| 
|-
| 77396
| 74436 - 15 - Performances Ordonnanceur
| [[ESI]]
| [[CBO]]
| 
| 
|-
| 77399
| 74436 - 16 - Listes de diffusion
| [[ESI]]
| [[CBO]]
| 
| 
|-
| 77707
| 74436 - 20 - Habilitations
| [[ESI]]
| [[CBO]]
| 
| 
|}</text>
      <sha1>k7wmkoe2qjgqh8jy8wm9yzdkvpfwg0m</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement offre moteur</title>
    <ns>0</ns>
    <id>1677</id>
    <revision>
      <id>3875341</id>
      <parentid>1300728</parentid>
      <timestamp>2018-02-28T12:49:56Z</timestamp>
      <contributor>
        <username>Flatres</username>
        <id>26</id>
      </contributor>
      <minor/>
      <origin>3875341</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2684" sha1="1swexui3953lpewzzdozofs0li3tq6h" xml:space="preserve">{{Modèle:Groupe
 | groupe= OFP
 | division=[[Division facturation et offre produit|facturation et offre produit]]
 | responsable= [[ATH]]
 | domaines= [[offre]], [[moteur de facturation]]
 | developpeurs = [[ATH]], [[AHA]], [[LRA]], [[BFR]], [[CFO]], [[PWE]]
 | analystes = [[JFRO]], [[JGO]] 
}}

[[Category:groupe de développement]]

= Mise à jour de la documentation = 
Il est indispensable de mettre à jour la documentation après un développement nouvelle fonction voire après une correction de code.
Celle-ci doit être vérifiée avec la revue de code de chaque développement (découpage technique présent pour chaque développement).

Les principaux documents à mettre à jour lors d’un développement sont :
*Les afd produit :
**afd offre produit (efluid) [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_506b9]
**afd moteur de facturation (efluid) [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_506b0]
**afd valorisation (ecore) [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_977d2]
**afd tarif (ecore) [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f678]
**afd algorithme tarification (ecore) [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_b1bfd]
*Le guide utilisateur offre [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_64a41]
*Eventuels DCT (efluid et ecore) [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_407a8]
*L’afd de l’écart s’il y a des différences entre le développement et l’analyse

= Estimation des RAF = 

== Estimation des RAF par développeur ==
{{Modèle:RafParDeveloppeur
 | groupe = OFFRE_MOT
 | developpeurs = PWE;ATH;AHA;LRA;BFR;CFO
}}

== Estimation des RAF lot 12 ==
{{Modèle:RafParGroupe
| lot = 12
| groupe = OFFRE_MOT
| nbPersonnesNouveauxDev = 4
| nbPersonnesMaintenance = 4
| tauxDev = 0.4
| tauxMaintenance = 0.3
}}

==Détails==
{{Modèle:DetailRafParGroupe
 | lot = 12
 | groupe = OFFRE_MOT
}}
{{Modèle:DetailRafEvtGroupe
 | groupe = OFFRE_MOT
 | types=DEV_EVO_TECH
}}
{{Modèle:DetailRafEvtGroupe
 | groupe = OFFRE_MOT
 | types=QUALITE
}}
{{Modèle:DetailRafEvtGroupe
 | groupe = OFFRE_MOT
 | types=PREST_PAY
}}
{{Modèle:DetailRafMaintenanceGroupe
 | groupe = OFFRE_MOT
}}

==Suivi groupe offre moteur==
[[SEFBot:Suivi OFFRE MOT]]

=Qualité=
==Scripts sql récurrents du domaine offre==
* [[Connexions aux bases clients avec SQL+]]
* [[Scripts sql récurrents du domaine offre]]
==Métriques du groupe==
* [http://especteur/dashboard/index/553320 Rapport sonar offre-moteur]
* [http://especteur/dashboard/index/532294 Rapport sonar valorisation]

==Règles de gestion du paramétrage offre==
* [[Règles de gestion du paramètre offre]]</text>
      <sha1>1swexui3953lpewzzdozofs0li3tq6h</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement editique</title>
    <ns>0</ns>
    <id>1678</id>
    <revision>
      <id>4069351</id>
      <parentid>4069350</parentid>
      <timestamp>2023-05-16T14:43:45Z</timestamp>
      <contributor>
        <username>Pochat</username>
        <id>27</id>
      </contributor>
      <origin>4069351</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4165" sha1="6d9t3hns5fxb300365g6idd02c6eh3d" xml:space="preserve">{{Modèle:Groupe
 | groupe= éditique
 | responsable= [[TMAN/CLA]]
 | domaines= [[éditique]]
 | developpeurs = [[TMAN]], [[CLA]], [[AMAR]], [[LCE]], [[APEG]], [[FAUD]]
 | analystes = [[CMZ]], [[NBE]]
 | recetteurs = [[AKL]], [[SBU]]
}}

[[Category:groupe de développement]]

= Mise à jour de la documentation = 
Il est indispensable de mettre à jour la documentation après un développement nouvelle fonction voire après une correction de code.
Celle-ci doit être vérifiée avec la revue de code de chaque développement (découpage technique présent pour chaque développement).

Les principaux documents à mettre à jour lors d’un développement sont :
*L'afd éditique [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f670]]
*Les guides utilisateur édition [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_64a3e]
*Les DCT [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_60271]
*Le référentiel des éditions [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7c173]
*Les modèles Rose dans ecore et efluid (disponible dans le reposetory git documentation)
*L’afd de l’écart s’il y a des différences entre le développement et l’analyse

=Qualité=
==Procédure de revue de code==
* [http://wikefluid/index.php/Revue_de_code_Editique Procédure de revue de code]

==Métriques du groupe==
* [http://especteur/dashboard/index/246199 Rapport sonar éditique]

= Outils techniques =

== Pour tester un flux depuis son poste ==

curl -i --request POST --data @chemin/local/vers/mon/fichier_flux.xml http://lrstredt3.uem.lan:49080/hermes &gt; mon_doc.pdf

== Demander l'accès un serveur de développement Exstream ==

Suite à la mise en place d'un nouveau serveur de développement Exstream, il convient de demander les droits d'accès à ce serveur pour pouvoir l'utiliser avec Control Center, en accès via l'explorateur de fichier et en accès aux partages de fichier.
Pour cela, il faut :
* Ouvrir une demande FootPrints :
** Depuis le catalogue des services, suivre "Demandes de services", puis "Demande d'accès", puis "Ouverture de flux réseau".
** Dans l'onglet description de la demande qui s'ouvre, un modèle de matrice de flux est proposé. Il convient de créer une nouvelle matrice à partir de ce modèle pour répindre au nouveau besoin avec les lignes suivantes :
{| class="wikitable"
|-
! Version !! Identifiant !! Site SOURCE !! Zone réseau SOURCE !! FQDN ou nom SOURCE !! Site CIBLE !! Zone réseau CIBLE !! FQDN ou nom serveur logique CIBLE !! Protocole !! Port
|-
| V1.0 || U1 || CGI (Paris et Toulouse) || L2L_CGI_STDENIS || Poste de travail || UEM || inside || ldsrvedt2.uem.lan || SMB || 445
|-
| V1.0 || U2 || CGI (Paris et Toulouse) || L2L_CGI_STDENIS || Poste de travail || UEM || inside || ldsrvedt2.uem.lan || SSH || 22
|-
| V1.0 || U3 || CGI (Paris et Toulouse) || L2L_CGI_STDENIS || Poste de travail || UEM || inside || ldsrvedt2.uem.lan || TCP || 28800
|}

== e2c : composant d'édition efluid ==

[https://gerrit.efluid.uem.lan/plugins/gitiles/efluid/+/refs/heads/develop/edition/README.md Cette page est dédié aux informations relatives à e2c, le  module d'édition efluid introduit en v15, destiné à remplacer ExStream à terme.]

== e2c : Lancement des test jest (IHM JS) avec VSCode  ==

Configuré l'environnement en suivant [https://wikefluid.efluid.uem.lan/docInstalleur/archi/develop/documentation/archi-front/guides/environnement_de_developpement/ la doc archi-front-JS]

[[Fichier:Image (12).png|vignette]]
Avec les extensions les tests jest se lance automatiquement à la sauvegarde du fichier. Il est possible de les relancer séparément ou en débug a l'aide des boutons situé au dessus du nom de la fonction ou dans la marge (voir image ci-contre)


'''/!\ Pour que les extension jest fonctionne correctement, le dossier ouvert dans VSCode doit être celui contenant le fichier "package.json" /!\'''

== edoc : validation technique d'une nouvelle version de SolR ==

La procédure de validation technique d'une nouvelle version de SolR est disponible ici : https://gerrit.efluid.uem.lan/plugins/gitiles/edoc/+/refs/heads/develop/documentation/README.md</text>
      <sha1>6d9t3hns5fxb300365g6idd02c6eh3d</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement échanges</title>
    <ns>0</ns>
    <id>1787</id>
    <revision>
      <id>4061072</id>
      <parentid>4060088</parentid>
      <timestamp>2020-09-01T16:26:43Z</timestamp>
      <contributor>
        <username>Guidon</username>
        <id>551</id>
      </contributor>
      <comment>/* Bibliothèque des pages relatives au domaine échange */</comment>
      <origin>4061072</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20334" sha1="cuxynxnoyd887dvg0k90zrg0gc2dbkd" xml:space="preserve">{{Modèle:Groupe
 | groupe= Echanges
 | responsable= [[BPO]], [[TMAN]]
 | domaines= [[efluid.net]], [[modèle EDK]]
 | developpeurs = [[TMAN]], [[BLE]], [[NRE]], [[JHOF]], [[LGU]], [[CNG]], [[LBE]], [[VGU]]
 | analystes = [[CBER]], [[ACH]], [[VDA]]
}}
[[Category:groupe de développement échanges]]
[[Category:groupe de développement]]
[[Category:échanges]]

L'objectif de cette page est de regrouper l'ensemble des informations utiles aux développeurs du groupe échange.

= Guide du développeur échanges =
== Le nouveau développeur échanges ==
Si tu viens d'intégrer le groupe échange, ce chapitre est fait pour toi. Tout d'abord bienvenue, bravo et surtout bon courage ! :)

=== Description du domaine "échanges" ===
Avant de plonger dans ce nouveau monde, qui je le sais, te passionnes déjà, voyons tout d'abord ce que c'est que "le domaine échanges".

Le domaine Échanges traite de toute la problématique d'interactions entre efluid (ou une application de la suite efluid) et une autre application (externe ou une application de la suite efluid).

Ces interactions se font sous différentes formes :
* Des échanges de flux SOAP (efluidPub &lt;-&gt; efluid.net) ;
* Des échanges de fichiers (XML, CSV) via mail, FTP, ou autre (publication ou consommation d'information vers ou en provenance d'un système externe) ;
* Des appels ou des mises à disposition de services web.

Ça ne semble pas bien compliqué comme ça, mais avant de commencer à coder avec tes petits doigts tout neufs il est nécessaire de comprendre un peu plus en détail ce que font tes collègues. C'est pas ce qu'il y a de plus marrant, mais tout le monde y est passé, il y a pas de raison que t'y échappes.

Pour cela, il t'es demandé de parcourir les différents chapitres ci-dessous et d'en maîtriser le contenu.
=== Lire les documents d'Analyse Fonctionnelle Détaillée (AFD) ===
Il est demandé et nécessaire de maîtriser et de bien comprendre les concepts exposés dans les deux AFD suivantes :
{| class="wikitable centre" width="100%"
|-
! scope=col align="center" width="8%"|Room
! scope=col align="center" width="46%"|Nom du document
! scope=col align="center" width="46%"|Commentaires
|-
|[http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2894 efluid.net]||[http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2894 AFD - Analyse globale du système d'échanges.docx]||
|-
|[http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2894 efluid.net]||[http://wperoom2.uem.lan/eRoomReq/Files/Prod11/DocFonctionnelleSuiteEfluid/0_aef7/AFD%20-%20Demande%20de%20publication.docx AFD - Demande de publication.docx]||
|-
|[http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2894 efluid.net]||[http://wperoom2.uem.lan/eRoomReq/Files/Prod11/DocFonctionnelleSuiteEfluid/0_12acf/Cartographie%20des%20flux%20efluid.net.xlsx Cartographie des flux efluid.net.xslx]||Liste l'ensemble des flux du domaine échanges
|}
En complément, les AFD présentes dans la room suivante sont également à lire : [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2894 room efluid.net]

=== Lire les Documents de Conception Technique (DCT) ===
Il est demandé et nécessaire de maîtriser et de bien comprendre les concepts exposés dans les DCT suivants :
{| class="wikitable centre" width="100%"
|-
! scope=col align="center" width="8%"|Room
! scope=col align="center" width="46%"|Nom du document
! scope=col align="center" width="46%"|Commentaires
|-
|[http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ebd edk]||[http://WPEROOM2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ede DCT - EDK - système d'échanges- concept.doc]||
|-
|[http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ebd edk]||[http://WPEROOM2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ecc DCT - EDK - Echaînement - echanger.docx]||
|-
|[http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ebd edk]||[http://WPEROOM2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_63236 DCT - EDK - Echaînement - Gérer abonnement modèle de service.doc]||
|-
|[http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ebd edk]||[http://WPEROOM2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ece DCT - EDK - Echaînement - Gérer lots échanges.doc]||
|-
|[http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ebd edk]||[http://WPEROOM2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ecf DCT - EDK - Echaînement - Gérer modèle d'échange.doc]||
|-
|[http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ebd edk]||[http://WPEROOM2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ed1 DCT - EDK - Echaînement - suivi abonnement.doc]||
|-
|[http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ebd edk]||[http://WPEROOM2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41edf DCT - EDK - Echaînement - Transfomation XSLT.doc]||
|-
|[http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_41ebd edk]||[http://WPEROOM2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_d84b8 DCT - EDK - Echaînement - Echanges de masse.docx]||&lt;b&gt;Très important !&lt;/b&gt;
|-
|}
En complément, les DCT présents dans les rooms suivantes sont également à lire : 
* [http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_49d93 room conception edk]
* [http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_407b1 room conception efluid.net]

=== Comprendre les flux d'échanges ===
Lire et comprendre la page suivante : [[Comprendre les flux d'échanges]]

=== Installer son environnement de développement ===
Maintenant que tu au niveau littéraire, tu peux passer à l'étape de configuration de ton nouvel environnement de travail.

Il y a une page dédiée pour ça, c'est par ici : [[Installation du poste de développeur échange]]

=== Exécuter la campagne de non-régression d'efluid.net ===
Afin de découvrir l'application efluid.net et la mise en œuvre d'un certain nombre de concepts vu au cours des phases de lecture d'AFD et DCT, il est demandé d'exécuter la campagne de non-régression de l'application.

=== Suivre le programme d'exercices du groupe échanges ===
Il ne reste plus qu'à se lancer et s'exercer sur les sujets suivants :
* [http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_181add/Gpe%20%E9change%20-%20Exerice%20de%20cr%E9ation%20d%27un%20flux%20de%20masse.docx Exercice de création d'un flux de masse.docx]
* [http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_181add Exercice de création d'un flux de masse.docx]

== Le développeur échanges confirmé ==
=== Feuille de route du développeur ===
Entant que développeur confirmé sur le projet efluid et donc du groupe échanges, je suis responsable des événements qui me sont confiés.
On entant par confié le fait d'être positionné comme développeur sur le dit événement.
Cela signifie que :
* Pour un nouveau développement :
** Je suis responsable de réaliser le chiffrage définitif à faire valider par TMAN en proposant un découpage en élément de chiffrage conformément au chapitre "Chiffrage et découpage en éléments de chiffrage" ci-dessous ;
** Je suis responsable de réaliser le développement conformément à l'AFD et conformément aux normes de conception et développement vues en formation et partagées au sein du projet efluid et de l'équipe de développement échanges ;
** Je suis responsable de proposer un DCT si le développement le nécessite : à présenter et faire valider en CT au besoin ;
** '''[Nouveau]''' Je suis responsable de mettre à jour les AFD impactées par mon développement à la fin de celui-ci ;
** '''[Nouveau]''' Je suis responsable de demander à l'analyste de mettre à jour l'AFD de l'écart que je suis entrain de développer si celle-ci est incomplète pendant la phase de développement ;
** Je suis responsable d'analyser les risques en termes de performance de mon développement et si cela est nécessaire, de mobiliser l'équipe performances pour organiser la réalisation de tests avec eux ;
** Je suis responsable de remonter les alertes quant à un possible dépassement de charge ou non livraison dans la version ciblée : au chef de projet, à l'expertise, à la coordination si besoin, etc... Remonter une alerte ça signifie anticiper une situation qui dérive : alerter le jour du ramassage n'est que peu productif ;
** Je suis responsable de la communication, tout au long de la phase de développement, avec l'expertise : pour obtenir des contextes de test, faire une démo, demander des compléments d'analyse, etc...
* Pour une correction d'anomalie :
** Je suis responsable de réaliser le développement conformément à l'AFD et conformément aux normes de conception et développement vues en formation et partagées au sein du projet efluid et de l'équipe de développement échanges ;
** Je suis responsable de l'ajout, lorsque cela est nécessaire, de TU ou TI permettant de couvrir le cas générateur de l'anomalie à l'avenir ;
** Je suis responsable de la bonne livraison de l'événement : '''dans toutes les versions attendues''' ;
** '''[Nouveau]''' Je suis responsable de mettre à jour les AFD impactées par mon développement à la fin de celui-ci ;
** Je suis responsable de remonter les alertes quant à une possible non livraison dans la version ciblée : au chef de projet, à l'expertise, à la coordination si besoin, etc... Remonter une alerte ça signifie anticiper une situation qui dérive : alerter le jour du ramassage n'est que peu productif ;
** Je suis responsable de la communication, tout au long de la phase de développement, avec l'expertise : pour obtenir des contextes de test, faire une démo, demander des compléments d'analyse et relotir au besoin. Là aussi, une situation menant à un relotissement s'anticipe : se rendre compte après le ramassage qu'on a pas pu livrer un événement n'est que peu productif.
* Pour le suivi de projet :
** Je participe aux réunions de suivi hebdomadaire du groupe de développement et me responsabilise, régulièrement, sur la rédaction de l'ODJ et du CR de la réunion ;
** Je participe régulièrement au turnover hebdomadaire du support des équipes d'expertise échanges.

=== Norme de qualité de développement ===
Les normes de qualité de développement sont celles en oeuvre pour l'ensemble de la filière "Applications et Flux".

On en trouvera une description ici :

http://wikefluid/index.php/Revues_de_code_de_la_fili%C3%A8re_%22Applications%22

Les règles de nommage spécifiques du groupe échanges sont proposées ici :

http://wikefluid.uem.lan/index.php/R%C3%A8gles_nommage_domaine_%C3%A9change#Autres

==== Revue de code sous Gerrit ====
Les revues de code sous Gerrit devront être menées afin de faire respecter les principes exposés dans les deux pages listées précédemment.

Il est demandé à chaque relecteur de porter une attention particulière à ce que les règles suivantes soient, à minima, bien respectées lors d'une revue de code sur tout change de branche develop (Sur une branche de maintenance, la priorité est souvent donné à la stabilité du code et une livraison rapide) :
* Le formatage imposé par le formateur Efluid (cf. [[FormatageEclipse|Formateur efluid pour Eclipse]]) est bien respecté, sinon demander un CTRL+SHIFT+F sur la classe ;
* L'organisation des imports de classe est correcte, sinon demander un CTRL+SHIFT+O ;
* Les attributs, méthodes, paramètres de méthodes, etc... sont écrits en français ;
* Les messages applicatifs sont bien traités via le système d'internationalisation ;
* Les méthodes sont bien découpées et ne font, sauf exception, pas plus de 10 lignes ;
* Des tests (TU et/ou TI) couvrent le maximum de code et de cas possible.

=== Chiffrage et découpage en éléments de chiffrage ===
Cette a pour objectif de décrire les étapes attendus lors d'une demande de proposition de chiffrage en éléments de chiffrage suite à affectation d'un développement nouvelle fonction.

Pour rappel, lorsqu’un besoin est exprimé (interne ou client), un événement de développement nouvelle fonction est créé et un analyste travail sur un document d’expression de besoin pour lequel il demande à un développeur une estimation du coût : c’est le chiffrage prévisionnel.
Une fois le sujet analysé un document d’AFD ou d’analyse d’écart rédigé, l’analyste propose le sujet en comité d’analyse sur la base de ce chiffrage prévisionnel.
Une fois le sujet validé par ce comité et l’AFD présentée à l’équipe de développement, l’événement support du sujet est « affecté à l’équipe de développement ».

A ce moment-là, un développeur est proposé pour prendre en charge le sujet et je demande alors de « proposer un chiffrage avec découpage en éléments de chiffrage ».
Cela signifie que le développeur doit affiner le chiffrage prévisionnel suite à prise de connaissance dans le détail du sujet et de l’AFD et se demander : quelles sont les étapes de mon développement et quel temps j’estime nécessaire au développement de chaque étape ?
Ces étapes sont les « éléments de chiffrage » mentionnés ci-dessus.

Pour illustrer tout cela, prenons l’exemple de l’événement 230401 - BGE Capa : Publication externe Hx1. Ce DNF devait avoir, de mémoire, un chiffrage prévisionnel à 25 jours car l’idée était d’en faire le support du développement du batch de publication de BGE tous formats confondus en plus du développement du format Hx1.
Donc, les étapes de développements identifiées ont été les suivantes :

* Développement de traitements d’action de publication (DEV+TU+TI) : estimée à 3j ;
* Développement d’un batch d’export XML (DCT+DEV+TU+TI) : estimée à 15 ;
* Développement d’un ME de consommation interne de masse de BGE (DEV) : estimé à 1j ;
* Développement d’un ME de publication externe de masse de BGE au format Hx1 (DEV+TU+TI) : estimé à 10j ;
* Réalisation de tests de bout en bout : estimée à 2j.

Soit un total de 31 jours. C’est un peu plus que ce qui a été chiffré en prévision mais dans une proportion acceptable et surtout justifié par le découpage en différentes étapes ci-dessus.

Me reste donc à renseigner tout cela dans suivefluid.
Attention, l’événement doit être affecté à l’équipe de développement pour cela.
Il faut donc se rendre dans l’onglet « analyse financière » de l’événement qui au départ est donc renseigné ainsi :
[[Fichier:chiffrage_previsionnel.png|Onglet chiffrage prévisionnel]]

Je renseigne ensuite l’ensemble de mes éléments de chiffrage avec leur charge en conservant la ligne initiale que je vide au fur et à mesure que je charge les différentes éléments :
[[Fichier:chiffrage_definitif.png|Onglet chiffrage définitif]]

Il est important de noter que :

* Un nom significatif précisant le contexte pour chaque élément est nécessaire car les événements de découpage technique qui vont être associés à chacun de ces éléments seront noyés dans la masse. Donc « Développement ME de publication externe » ne sera pas parlant ;
* Le domaine fonctionnel doit être renseigné en cohérence avec le développement à réaliser :
** Action de publication : c’est du mécanisme publication ;
** Batch d’export : c’est du mécanisme d’export batch ;
** ME de consommation/publication : c’est du mécanisme efluid.net.
** Etc…
** Pour rappel, l’ensemble des domaines du groupe échanges sont répertoriés ici : http://eforum.uem.lan/viewtopic.php?f=18&amp;t=2760 ;

Une fois ce travail réalisé, il convient d’enregistrer l’événement et de prévenir le responsable projet par mail de la réalisation du chiffrage et de l’attente de validation.
C’est suite à validation que les événements de découpage technique seront créés et affectés au développeur par le responsable projet.

Ce travail est à réaliser au sortir de chaque réunion d’organisation ou de lancement d’une version de développement comme celle que nous faisons depuis la v14 et au cours desquelles vous prenez connaissance des événements qui vous serons affectés dans la version concernée.

=== Procédures et tutoriels ===
Cette section a pour objectif de regrouper un ensemble de procédures et tutoriels utiles aux développeurs échanges.
==== Procédures ====
* Room regroupant l'ensemble des procédures d'installations techniques : [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_9296c Procédures d'installations techniques] ;
* Procédure de paramétrage des livrables génériques (installation des composants efluid.net pour les clients) : [http://wperoom2.uem.lan/eRoomReq/Files/Production/DocTechniqueEfluid/0_92982/efluid%20-%20Param%E9trage%20des%20livrables%20g%E9n%E9riques.doc efluid - Paramétrage des livrables génériques.doc] ;
* &lt;font color="red"&gt;&lt;b&gt;!&lt;/b&gt;&lt;/font&gt; Procédure de mise à jour du modèle EDK : [http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_43d37/Proc%E9dure%20-%20Mise%20%E0%20jour%20mod%E8le%20EDK.doc Procédure - Mise à jour modèle EDK.doc]
* Procédure de développement de WS :
** [[Web Services - Client | Développer un client]]
** [[Web Services - Serveur | Développer un serveur]]
** [[ Tests unitaires - Web Services | Tester]]
* Procédure pour la création de codification : [[procédure de création de codification | Procédure pour la création de codification]]
* Procédure pour le développement de factory de test : [http://WPEROOM3.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_1b9445 Procédure - Développement d'une factory de test pour efluid.net.doc]
* Procédure pour l'utilisation d'abonnements avec envoi de mails sécurisés : [http://wperoom3.uem.lan/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_1fb284 Procédure - Instructions pour l’exécution d’un abonnement comportant un mail crypté sur efluid.net.docx]

==== Tutoriels techniques ====
* Comprendre les flux d'échanges : [[Comprendre les flux d'échanges]]
* Installer un serveur FTP de développement sur son poste : [[Guide d'installation d'un FTP local]]
* Accéder au bureau à distance d'ES : [[Accès au bureau à distance d'ES]]

== Référentiel des évènements suivefluid récurrents du domaine "échanges" ==
{| class="wikitable sortable" width="100%"
|-
! scope=col align="center" width="15%"|Référence
! scope=col width="35%" class="unsortable"|Libellé
! scope=col width="50%" class="unsortable"|Commentaires
|-
|30986||congés - contrat cgi||CP, RTT, maladie, exceptionnel, ...
|-
|30988||congés - efluid SAS||CP, RTT, maladie, exceptionnel, ...
|-
|102156||pilotage groupe échange - contrat efluid sas||Événement pour imputation de tâches de pilotage pour les agents efluid (réunion groupe dév, ...)
|-
|129256||pilotage groupe échange - contrat CGI||Événement pour imputation de tâches de pilotage pour les agents CGI(réunion groupe dév, ...)
|-
|30994||pilotage activité efluid - contrat uem||Réunion de service, comité technique, etc...
|-
|30859||UEM - support technique efluid||Pour la livraison EDK, type de tâche: assistance interne
|-
|246750||Revues de code||Imputations des tâches de revue de code
|-
|246749||Correction des TU et TI||Imputations des tâches de correction de TU et TI liés au groupe "échanges", toute application confondue
|-
|246751||Correction sonar||Imputations des tâches de correction des problèmes remontés par sonar liés au groupe "échanges", toute application confondue
|}

= Bibliothèque des pages relatives au domaine échange =
Sont répertoriées dans ce chapitre les pages relatives au domaine échange mais n'ont pas vocation à être particulièrement rangées dans un chapitre dédiée :
* [[Projet ERDF - Domaine Echanges]] (&lt;font color="red"&gt;Il y a t'il encore un intérêt à garder cette page ?&lt;/font&gt;) ;
* [[Proto performance efluidNet]] ;
* [http://wikefluid/index.php/Domaine_%C3%A9changes Divers topics liés au domaine échange] ;
* [http://wikefluid.uem.lan/index.php/SRD_-_envoie_mail_en_masse Envoie de mail en masse pour le format SRD] ;
* [[Script correction fichier pub]] ;
* [[Domaine Echanges - surveillance des tests aléatoires]] ;
* [[Transformation XSLT]] ;</text>
      <sha1>cuxynxnoyd887dvg0k90zrg0gc2dbkd</sha1>
    </revision>
  </page>
  <page>
    <title>Filière Client et Portail</title>
    <ns>0</ns>
    <id>760</id>
    <revision>
      <id>4068817</id>
      <parentid>4068816</parentid>
      <timestamp>2023-03-30T08:19:27Z</timestamp>
      <contributor>
        <username>Prouve</username>
        <id>24</id>
      </contributor>
      <origin>4068817</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="23119" sha1="qth9rely7pylk4za498jq1kwoifxn61" xml:space="preserve">{{Modèle:Groupe
 | division= Contrat
 | groupe= Contrat
 | responsable= [[RTE]]
 | domaines= [[contrat]], [[simulation tarifaire]]
 | developpeurs = [[BCA]], [[FIG]], [[JPR]], [[LMO]], [[LRA]], [[MBU]], [[RTE]], [[TBO]]
 | analystes = Camille Mazataud, Jonathan Dusconi, Florian Nicole
}}

{{Modèle:Groupe
 | division= Référentiel
 | groupe= CRM &amp; Facturation
 | responsable= [[DLI]]
 | domaines= [[acteur]], [[affaire-action]], [[dg-tournées-concessions]], [[edl-pds]], [[unités fonctionnelles]], [[affaires travaux]], [[SGE]]
 | developpeurs = [[DLI]], [[NCL]], [[ABAI]], [[AWE]], [[GBER]]
 | analystes = '''[[Intervention]]''' : Mathieu Colle, Olivier Montigny
'''[[Contrat]]''' : Jonathan Dusconi, Florian Nicole
'''[[Transverse]]''' : Pauline Billotte
}}

{{Modèle:Groupe
 | division= Portail
 | groupe= Portail
 | responsable= [[EFI]]
 | domaines= [[ael fournisseur]], [[ael GRD]], [[portail GRD]], [[portail MDE]], [[etineraire]]
 | developpeurs = [[RLE]], [[EFI]], [[TKE]], [[AJU]], [[DPA]], [[LSZ]], [[GDI]]
 | analystes = Dominique Clamme
}}

[[Category:groupe de développement CRM]]
[[Category:groupe de développement]]

= Règles de développement =

* Lire les [[10_commandements_de_la_programmation_sans_ego|10 commandements de la programmation sans égo]]
* Lire les [[Convention_de_codage_CRM/FAC|conventions de codage]] de la filière Client et Portail
* Lire les [[Bonnes_pratiques_CRM|bonnes pratiques]] de la filière Client et Portail
* Dès le début d’un nouveau dév : confronter son idée de conception à un autre développeur : '''même si on n'est pas bloqué'''
* En cours de dév :  faire valider l'avancement du dev, les changements éventuels de conception, etc.
* En fin de dev : faire relire son code par un autre développeur. 
* [[Livraison partielle sous ecore]]
* [[Rédaction AFD|Convention pour rédaction AFD]]

=Trucs et astuces=
* [[Contrat:Coder une évolution|Coder une évolution]]
* [[Configurer ses saves actions]]
* [[Configurer une action "Clean Up"]]
* [[Popup]]
* [[scripts sql récurrents du domaine contrat|Scripts sql récurrents]]
* [[Trucs et astuces SQL]]
* [[Trucs et astuces Framework]]
* [[Trucs_et_astuces_JavaScript|Trucs et astuces JavaScript / JQuery]]
* [[Tutorial_ajout_overlay|Rajouter un overlay à efluid dev]]
* [[Tutorial_creation_profil|Tutorial de création d'une page profil]]
* [http://wperoom1/eRoom/Production/RecetteEfluid/0_d1218 Liste des scripts génériques crm]
* [[Astuces GIT|passer un stash d'un clone à un autre]]
* [[Aide-mémoire pour le chiffrage des écarts]]
* [http://wperoom3.uem.lan/eRoom/Production/QualiteDeveloppementEfluid/0_19bf42 Guides et procédures suivefluid par la coordination]
* [http://wperoom3.uem.lan/eRoomReq/Files/Production/SCE_Informatique/0_210a6c/G%E9n%E9rateur%20r%E9f%E9rence%20PDS%20Enedis.xlsx Générateur référence PDS Enedis]

=Pilotage=
* [http://wperoom3.uem.lan/eRoom/Production/SCE_Informatique/0_dd319 lien vers la room de la filière]

==Intégration nouvelles ressources==
=== Liens utiles ===
* Plan de progression: [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_9f9b6 plan format xls]
* CheckList [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_8dfc3 checklist]
* [[Entretien technique services web|Entretien technique]]

=== Liste des arrivants ===
Une formation est prévue à l'arrivée de chaque nouveau développeur dans le groupe CRM en suivant les supports de présentation : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_156990 Intégration nouveaux]&lt;br&gt;
Arrivées prévues :&lt;br&gt;
* juin 2009 (dans contrat) Vincent Bouthinon
* &lt;strike&gt;août 2011 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_42d16 Florence Demoulin]&lt;br&gt;&lt;/strike&gt;
* &lt;strike&gt;septembre 2011 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_8aadb Kilian Stein] / {{evt|ref=70389}} : accompagnement nouveau développeur - KST&lt;br&gt;&lt;/strike&gt;
* &lt;strike&gt;octobre 2011 : Sami Yacoub&lt;/strike&gt;
* mars 2012 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_a4fc0 Thomas Boudin] / {{evt|ref=75461}} : accompagnement nouveau développeur - TBO&lt;br&gt;
* &lt;strike&gt;aout 2012 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_b1775 Karim Tahri] / {{evt|ref=79808}} : accompagnement nouveau développeur - KTA&lt;br&gt;&lt;/strike&gt;
* février 2013 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_c9a57 Guillaume Laas] / {{evt|ref=90747}} : accompagnement nouveau développeur - GLA&lt;br&gt;
* &lt;strike&gt;mai 2013 : Xavier Schmitt&lt;/strike&gt;
* octobre 2013 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_fc970 Anthony Bainville] / {{evt|ref=102831}} : accompagnement nouveau développeur - ABA&lt;br&gt;
* &lt;strike&gt;novembre 2013 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_f0125 Toni Dias] / {{evt|ref=101542}} : accompagnement nouveau développeur - TDI&lt;br&gt;&lt;/strike&gt;
* décembre 2014 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_13a045 Brice Castagna] / {{evt|ref=127559}} : DEV accompagnement nouveau développeur - BCA (Brice Castagna) &lt;br&gt;
* &lt;strike&gt;juillet 2015 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_151e8c Jérôme Koenig] / {{evt|ref=145123}} : DEV accompagnement nouveau développeur - JKOE (Jérôme KOENIG)&lt;/strike&gt;&lt;br&gt;
* juillet 2015 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_151e87 Eric Finickel] / {{evt|ref=145130}} : DEV accompagnement nouveau développeur - EFI (Eric Finickel) &lt;br&gt;
* juillet 2015 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_15512f Alexandre Wehbe] / {{evt|ref=145131}} : DEV accompagnement nouveau développeur - AWE (Alexandre Wehbe)&lt;br&gt;
* octobre 2015 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_15d35e Damien Lienhardt] / {{evt|ref=153300}} : DEV accompagnement nouveau développeur - DLI (Damien LIENHARDT)&lt;br&gt;
* mars 2016 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_170f3d Romain Terracina] / {{evt|ref=165411}} : DEV accompagnement nouveau développeur - RTE (Romain Terracina)&lt;br&gt;
* &lt;strike&gt;mars 2016 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_1763ba Thomas Kedziora] / {{evt|ref=167351}} : DEV accompagnement nouveau développeur - TKE (Thomas Kedziora)&lt;/strike&gt;&lt;br&gt;
* &lt;strike&gt;mars 2016 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_1763b6 Cuma NEHIR] / {{evt|ref=167350}} : DEV accompagnement nouveau développeur - CNE (Cuma Nehir)&lt;/strike&gt;&lt;br&gt;
* octobre 2016 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_194b15 Tom Besnard] / {{evt|ref=185063}} : DEV accompagnement nouveau développeur - TBE (Tom BESNARD)&lt;br&gt;
* &lt;strike&gt;octobre 2016 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_18e5f3 Nicolas Prandi] / {{evt|ref=181924}} : DEV accompagnement nouvel alternant - NPR (Nicolas PRANDI)&lt;/strike&gt;&lt;br&gt;
* &lt;strike&gt;décembre 2016 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_19c211 Hazdine Messaoud] / {{evt|ref=189648}} : DEV accompagnement nouveau développeur - HME (Hazdine MESSAOUD)&lt;/strike&gt;&lt;br&gt;
* &lt;strike&gt;décembre 2016 : [http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_19c21d Hani Slaim] / {{evt|ref=189643}} : DEV accompagnement nouveau développeur - HSL (Hani SLAIM)&lt;/strike&gt;&lt;br&gt;
* &lt;strike&gt;janvier 2017 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1a05bc Benoît Thevenin] / {{evt|ref=192083}} : DEV accompagnement nouveau développeur - BTE (Benoît THEVENIN)&lt;/strike&gt;&lt;br&gt;
* avril 2017 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1baf2b Anthony Jungmann] / {{evt|ref=201380}} : DEV accompagnement nouveau développeur - AJU (Anthony Jungmann)&lt;br&gt;
* juillet 2017 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c4db8 Mathieu Buzon] / {{evt|ref=206285}} : DEV accompagnement nouveau développeur - NCL (Nathan CLAUDOT) (Metz)&lt;br&gt;
* juillet 2017 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c6bb9 Nathan Claudot] / {{evt|ref=208558}} : DEV accompagnement nouveau développeur - MBU (Mathieu Buzon)&lt;br&gt;
* &lt;strike&gt;septembre 2017 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1cd9b1 Benjamin Dansokho] / {{evt|ref=213228}} : DEV accompagnement nouveau développeur -  BDAN (Benjamin DANSOKHO)  (Metz)&lt;/strike&gt;&lt;br&gt;
* septembre 2017 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1dd79a Daniel Payet] / {{evt|ref=202070}} : DEV accompagnement nouveau développeur - DPA (Daniel PAYET)&lt;br&gt;
* &lt;strike&gt;octobre 2017 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1d2df3 Daniel Clifford] / {{evt|ref=214765}} : DEV accompagnement nouveau développeur - DCLI (Daniel Clifford)&lt;/strike&gt;&lt;br&gt;
* &lt;strike&gt;novembre 2017 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1dd6dd Stéphane Joyeux] / {{evt|ref=218119}} : DEV accompagnement nouveau développeur - SJOY (Stéphane JOYEUX) (Metz)&lt;br&gt;&lt;/strike&gt;
* &lt;strike&gt;février 2018 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1e77bb Pierre Leriche] / {{evt|ref=225814}} : DEV accompagnement nouveau développeur -  PLER (Pierre Leriche)  (Metz)(Metz)&lt;/strike&gt;&lt;br&gt;
* mai 2018 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1f38bd Rémi Magnin] / {{evt|ref=237452}} : DEV accompagnement nouveau développeur - RMA (Rémi MAGNIN) (Metz)
* &lt;strike&gt;juillet 2018 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_202be8 Thomas Legrand] / {{evt|ref=240959}} : DEV accompagnement nouveau développeur - TLE (Thomas LEGRAND) (Metz)&lt;/strike&gt;
* aout 2018 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_209dcb Florian Iggiotti] / {{evt|ref=243989}} : DEV accompagnement nouveau développeur - FIG (Florian IGGIOTTI) (Metz)
* septembre 2018 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_207aae Loic Szymanski] / {{evt|ref=245493}} : DEV accompagnement nouveau développeur - LSZ (Loic Szymanski)
* &lt;strike&gt;septembre 2018 : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_20f991 Quentin Morizot] / {{evt|ref=248117}} : DEV accompagnement nouveau développeur - QMO (Quentin MORIZOT)&lt;/strike&gt;
* &lt;strike&gt;janvier 2020 : [http://wperoom4.uem.lan/eRoom/Production/GestionProjetEfluid/0_25b14d Matthieu Marin] / {{evt|ref=292997}} : DEV accompagnement nouveau développeur - Mathieu MARIN&lt;/strike&gt;
* août 2021 : [http://wperoom4.uem.lan/eRoom/Prod18/SCE_DevtCRMetFacturation/0_7d9e Guylan Dieu] / {{evt|ref=352492}} : DEV accompagnement nouveau développeur - GDI (Guylan DIEU)
* septembre 2021 : [http://wperoom4.uem.lan/eRoom/Prod18/SCE_DevtCRMetFacturation/0_7da3 Geoffroy Bernard] / {{evt|ref=357309}} : DEV accompagnement nouveau développeur - GBE (Geoffroy BERNARD)
* septembre 2022 : [http://wperoomifr1.uem.lan/eRoom/Prod18/SCE_DevtCRMetFacturation/0_968c Loïc Grispino] / {{evt|ref=389571}} : DEV accompagnement nouveau développeur - LGI (Loïc GRISPINO)
* janvier2023 : William Bobo / {{evt|ref=398810}} : DEV accompagnement nouveau développeur - WBO (William BOBO)

===Entretien de suivi===
{| class="wikitable"
|-
! responsable
! nouveau
! 1
! 2
! 3
! 4
! 5
! 6
! 9
! 12
! 15
! 18
|-
|[[VBO]]
|[[JKO]]
|aout 2015
|[http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_15e7c4 septembre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_164cfb/Suivi%20nouveau%20d%E9veloppeur-JKOE-20151112.doc octobre 2015]
| 
|
|
|
|
|
|
|-
|[[VBO]]
|[[AWE]]
|aout 2015
|[http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_15fd2a septembre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_164d1f/Suivi_nouveau_developpeur-AWE-20151112.doc octobre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_164d1f/Suivi_nouveau_developpeur-AWE-20151112.doc novembre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_168bca/Suivi_nouveau_developpeur-AWE-20151211.doc décembre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_16bfef/Suivi_nouveau_developpeur-AWE-20160114.doc janvier 2016]
|''entretien 3ème trimestre''
|juillet 2016
|octobre 2016
|janvier 2017
|-
|[[RLE]]
|[[EFI]]
|aout 2015
|[http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_15db45 septembre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_16493f octobre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1692e9 novembre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_16c180 décembre 2015]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_16c180 janvier 2016]
|''entretien 3ème trimestre''
|juillet 2016
|octobre 2016
|janvier 2017
|-
|[[GLA]]
|[[DLI]]
|[http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_1639d3 novembre2015]
|[http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_1699c7 décembre2015]
|''entretien 1er trimestre''
|[http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_172f5f février 2016]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_185432/Suivi%20nouveau%20developpeur%205%20-%20DLI.docx mars 2016]
|''entretien 2ème trimestre''
|''entretien 3ème trimestre''
|octobre 2016
|janvier 2017
|avril 2017
|-
|[[TBO]]
|[[RTE]]
|[http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_17d1c5 avril 2016]
|''non réalisé'' 
|''entretien 1er trimestre''
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_18a135 juillet 2016]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_18dcfa août 2016]
|''entretien 2ème trimestre''
|''non-réalisé''
|''non-réalisé''
|''non-réalisé''
|''non-réalisé''
|-
|[[BCA]]
|[[CNE]]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_17d435/Suivi%20nouveau%20d%E9veloppeur-CNE%20-%2020160415.doc avril 2016]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1818db/Suivi%20nouveau%20d%E9veloppeur-CNE%20-%2020160519.doc  mai 2016]
|[http://wperoom2.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_184b24/Suivi%20nouveau%20developpeur-CNE%20-%2020160616.doc juin 2015]
|''CNE absent''
|[http://WPEROOM2.uem.lan/eRoom/Production/GestionProjetEfluid/0_18d085 aout 2016]
| -
| -
| -
| -
| -
|-
|[[AWE]]
|[[TBE]]
|novembre 2016
|décembre 2016
|janvier 2017
|février 2017
|mars 2017
|avril 2017
|juillet 2017
|octobre 2017
|janvier 2018
|avril 2018
|-
|[[VBO]]
|[[HME]]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1a4249/Suivi%20nouveau%20d%E9veloppeur-HME%20-%2020170112.doc janvier 2017]
|février 2017
|mars 2017
|avril 2017
|mai 2017
| -
| -
| -
| -
| -
|-
|[[CLA]]
|[[HSL]]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1a80da/Suivi%20nouveau%20d%E9veloppeur%20-%20HSL%20-%20janvier%202017.docx janvier 2017]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1a88e2/Suivi%20nouveau%20d%E9veloppeur%20-%20HSL%20-%20f%E9vrier%202017.docx février 2017]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1aeee4/Suivi%20nouveau%20d%E9veloppeur%20-%20HSL%20-%20mars%202017.docx mars 2017]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1b553b/Suivi%20nouveau%20d%E9veloppeur%20-%20HSL%20-%20avril%202017.docx avril 2017]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1b98d8/Suivi%20nouveau%20d%E9veloppeur%20-%20HSL%20-%20mai%202017.docx mai 2017]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1c04af/Suivi%20nouveau%20d%E9veloppeur%20-%20HSL%20-%20juin%202017.docx juin 2017]
|octobre 2017
|janvier 2018
|avril 2018
|juillet 2018
|-
|[[TBO]]
|[[BTE]]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1a05bc février 2017]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1afa0e mars 2017]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1b57b3 avril 2017]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1b9ce4 mai 2017]
| -
| -
| -
| -
| -
| -
|-
|[[EFI]]
|[[NPR]]
|[http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1ab2c0 février 2017]
|non réalisé (à l'école)
|non réalisé (à l'école)
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1bb9bf/Suivi%20nouveau%20developpeur-NPR-18-05-2017.doc mai 2017]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1c6d1e/Suivi%20nouveau%20developpeur-NPR-28-06-2017.doc juin 2017]
|juillet 2017
|aout 2017
|septembre 2017
| -
| -
|-
|[[TBO]]
|[[MBU]]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c4db8 août 2017]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c4db8 septembre 2017]
|''entretien 1er trimestre''
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c4db8 novembre 2017]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c4db8 décembre 2017]
|''entretien 2ème trimestre''
|''entretien 3ème trimestre''
|''entretien 4ème trimestre''
|non réalisé
|non réalisé
|-
|[[DLI]]
|[[NCL]]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c6bb9 août 2017]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c6bb9 septembre 2017]
|''entretien 1er trimestre''
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1c6bb9 novembre 2017]
|décembre 2017
|''entretien 2ème trimestre''
|''entretien 3ème trimestre''
|''entretien 4ème trimestre''
|non réalisé
|non réalisé
|-
|[[VBO]]
|[[BDAN]]
|octobre 2017
|novembre 2017
|décembre 2017
| -
| -
| -
| -
| -
| -
| -
|-
|[[RTE]]
|[[SJOY]]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1e177b décembre 2017]
|non réalisé (formations + congés)
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_1ed62c/Suivi%20nouveau%20d%E9veloppeur-SJOY%20-%2020180206.doc février 2018]
| -
| -
| -
| -
| -
| -
| -
|-
|[[TBE]]
|[[PLER]]
|mars 2018
|avril 2018
|[http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1fd989 mai 2018]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_2019b0/Suivi%20nouveau%20d%E9veloppeur-PLER-%2020180626.doc juin2018]   
|juillet 2018
|[http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_210716 aout 2018]
|novembre 2018
|février 2019
|mai 2019
|aout 2019
|-
|[[TBO]]
|[[RMA]]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1f38bd juin 2018]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1f38bd juillet 2018]
|''entretien 1er trimestre''
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1f38bd septembre 2018]
|[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1f38bd octobre 2018]
|novembre 2018
|février 2019
|mai 2019
|août 2019
|novembre 2019
|-
|[[RTE]]
|[[TLEG]]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_20ecee/Suivi%20nouveau%20d%E9veloppeur-TLEG-%2020180713.doc juillet 2018]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_20ecef/Suivi%20nouveau%20d%E9veloppeur-TLEG-%2020180827.doc août 2018]
|non réalisé
|départ planifié
|départ planifié
|départ planifié
|plus sur le projet
|plus sur le projet
|plus sur le projet
|plus sur le projet
|-
|[[BCA]]
|[[FIG]]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_21154e/Suivi%20nouveau%20d%E9veloppeur%20-%20FIG%20-%2026-09-2018.docx septembre 2018]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_214982/Suivi%20nouveau%20d%E9veloppeur%20-%20FIG%20-%2025-10-2018.docx octobre 2018]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_2179da/Suivi%20nouveau%20d%E9veloppeur%20-%20FIG%20-%2026-11-2018.docx novembre 2018]
|''FIG absent + congés''
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_21d733/Suivi%20nouveau%20d%E9veloppeur%20-%20FIG%20-%2010-01-2019.docx janvier 2019]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_22449f/Suivi%20nouveau%20d%E9veloppeur%20-%20FIG%20-%2019-02-2019.docx février 2019]
|mai 2019
|aout 2019
|novembre 2019
|mars 2020
|-
|[[LRA]]
|[[QMO]]
|septembre 2018 non réalisé (en cours)
|[http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_2169da octobre 2018]
|novembre 2018
|décembre 2018
|janvier 2019
|février 2019
|avril 2019
|juillet 2019
|septembre 2019
|-
|[[EFI]]
|[[LSZ]]
|octobre 2018 non réalisé (formations)
|[http://WPEROOM3.uem.lan/eRoom/Production/GestionProjetEfluid/0_2162b0 novembre 2018]
|décembre 2018
|janvier 2018
|février 2019
|mars 2019
|juin 2019
|septembre 2019
|décembre 2019
|mars 2020
|-
|[[MBU]]
|[[http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_25b14d MMAR]]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_25b150 février 2020]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_25b151 mars 2020]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_25da1d entretien 1er trimestre avril 2020]
|[http://wperoom3.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_262c81 mai 2020]
|[http://wperoom4.uem.lan/eRoomReq/Files/Production/GestionProjetEfluid/0_2695fc juin 2020]
|''entretien 2em trimestre'' (début juillet 2020)
|''entretien 3em trimestre'' (début octobre 2020)
|''entretien 4em trimestre'' (début décembre 2021)
|
|}

==Stagiaires==
[[Sujets de stage]]

== Reste à faire ==
[[Reste à faire CRM]]

==Suivi ERDF==
* [[Suivi développements ERDF]]

==Réunions de groupe==
* [http://wperoom1/eRoom/Production/GestionProjetEfluid/0_299ee Compte rendu des réunions de dev]&lt;br&gt;
* [[Réunions dev/expertise CRM]]
* [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1841de Analyses des 5 pourquoi]

==Congés==
[http://wperoom2.uem.lan/eRoom/Production/GestionProjetEfluid/0_3f49c Note de congés]

=Qualité=

==Métriques du groupe==

* [http://especteur/dashboard/index/141290 Rapport sonar contrat]
* [http://especteur/dashboard/index/144217 Rapport sonar référentiel]
* [http://especteur/dashboard/index/385774 Rapport sonar simulation tarifaire]

==Planification des revues de code==
Voir la page de [[Revue de code CRM|revue de code du groupe CRM]] ;

==Expériences==
[[La revue de code en groupe]]&lt;br&gt;
[[Le pair programming]]

==Etudes==
[[Etude_outils_de_revue_de_code | Etude des outils de revue de code]]

==Coding Dojo==
[[Coding Dojo Clients et Portail| Coding dojo]]

=Tests=

* Règles à suivre pour réaliser des tests au sein du groupe CRM : [[convention CRM test]]
* Suivi du groupe de travail sur [http://wperoom1/eRoom/Production/GestionProjetEfluid/0_b2d28 eRoom]
* Suivi des revues de code sur les tests : [[revue de code sur les tests unitaires dans le domaine CRM]]
* Aide pour la réalisation de tests : [[Quand réaliser un test ?]]

=Performances=
[[CRM:Anomalies de perf lot 11]]</text>
      <sha1>qth9rely7pylk4za498jq1kwoifxn61</sha1>
    </revision>
  </page>
  <page>
    <title>Paramétrage</title>
    <ns>0</ns>
    <id>3619</id>
    <revision>
      <id>117479</id>
      <parentid>117478</parentid>
      <timestamp>2014-01-02T16:04:07Z</timestamp>
      <contributor>
        <username>Cannic</username>
        <id>72</id>
      </contributor>
      <comment>/* dossiers en cours */</comment>
      <origin>117479</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="400" sha1="7e5k0ost9zh7v5zakqd5celjserv67t" xml:space="preserve">[[Category:recette]]
[[Category:groupe de développement]]


= généralité =
Le paramétrage est réalisé 
* soit dans une base de paramétrage appellé PARAM
* soit via la réalisation d'une [[Note de paramétrage]]


[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_64a41 Il existe des guides de paramétrage dans eroom]

= dossiers en cours =
== erdf ==

== vialis ==

== multi-eld ==</text>
      <sha1>7e5k0ost9zh7v5zakqd5celjserv67t</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement référentiel</title>
    <ns>0</ns>
    <id>12498</id>
    <revision>
      <id>1396210</id>
      <parentid>1067401</parentid>
      <timestamp>2016-02-29T09:33:28Z</timestamp>
      <contributor>
        <username>Boudin</username>
        <id>84</id>
      </contributor>
      <minor/>
      <comment>/* Règles de développement */</comment>
      <origin>1396210</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3046" sha1="e0ww86rvzfbr5ssp40nxcdwg8w484rb" xml:space="preserve">{{Modèle:Groupe
 | groupe= Contrat
 | responsable= [[JPR]], [[CLA]]
 | domaines= [[acteur]], [[affaire-action]], [[dg-tournées-concessions]], [[edl-pds]], [[unités fonctionnelles]]
 | developpeurs = [[ABAI]], [[CLA]], [[JPR]], [[KST]]
 | analystes = Martial Weinzoepflen, Camille Mazataud
}}
[[Category:groupe de développement]]

= Règles de développement =
* Lire les [[Convention_de_codage_CRM/FAC|conventions de codage]] du la division CRM
* Lire les [[Bonnes_pratiques_CRM|bonnes pratiques]] de la division CRM
* Dès le début d’un nouveau dév : confronter son idée de conception à un autre développeur : '''même si on n'est pas bloqué'''
* En cours de dév :  faire valider l'avancement du dev, les changements éventuels de conception, etc.
* En fin de dev : faire relire son code par un autre développeur. [[CRM:Organisation des développements#Planification des revues de code|Planification des revues de code]]
** Lire la [[Procédure de revue de code|façon de réaliser les revues de code]]

= Aide-mémoire =
* [[Consultation d'un acteur dans efluid]] ;

= Pilotage =
== RAF 12.5 ==
* [[CLA]]
{{Modèle:DetailRAFParDeveloppeurParVersion
 | trigramme = CLA
 | lotPrevisionnel=EFL12
 | lotPrevisionnelMineur=05
 | statutsAExclure='FERME','ABANDONNE'
}}
* [[KST]]
{{Modèle:DetailRAFParDeveloppeurParVersion
 | trigramme = KST
 | lotPrevisionnel=EFL12
 | lotPrevisionnelMineur=05
 | statutsAExclure='FERME','ABANDONNE'
}}

== RAF 12.6 ==
* [[CLA]]
{{Modèle:DetailRAFParDeveloppeurParVersion
 | trigramme = CLA
 | lotPrevisionnel=EFL12
 | lotPrevisionnelMineur=06
 | statutsAExclure='FERME','ABANDONNE'
}}
* [[KST]]
{{Modèle:DetailRAFParDeveloppeurParVersion
 | trigramme = KST
 | lotPrevisionnel=EFL12
 | lotPrevisionnelMineur=06
 | statutsAExclure='FERME','ABANDONNE'
}}


==Synthèse==
{{Modèle:RafParGroupe
 | lot = 12
 | groupe = CRM
 | nbPersonnesNouveauxDev = 3
 | nbPersonnesMaintenance = 3
 | tauxDev = 0.4
 | tauxMaintenance = 0.3
}}


{{Modèle:RafParDeveloppeur
 | groupe = CRM
 | developpeurs = ABAI;CLA;DLI
}}

==Détail==

{{Modèle:DetailRafParGroupe
 | lot = 12
 | groupe = CRM
}}
{{Modèle:DetailRafEvtGroupe
 | groupe = CRM
 | types=QUALITE
}}
{{Modèle:DetailRafEvtGroupe
 | groupe = CRM
 | types=PREST_PAY
}}
{{Modèle:DetailRafMaintenanceGroupe
 | groupe = CRM
}}

==Suivi ERDF==
* [[Suivi développements ERDF]]

==Planification des revues de code==
{{règle d'organisation des revue de code}}
===Planification revue de code - Lot 12===
{{#get_web_data:url=http://ldsanbld2:9700/eRenDeServices-nb/suivefluid/revuecode/json?groupe=CRM&amp;lotPrev=12|format=JSON|data=intitule=Intitule,reference=Reference,developpeur=Developpeur,recetteur=Recetteur,evts=evts,statut=Statut}}
{{#for_external_table:evts}}
{| class="wikitable"
! Évènement
! Libellé
! Développeur
! Relecteur
! Revue
! Correction{{#for_external_table:&lt;nowiki/&gt;
{{!}}-
{{!}} [[{{{reference}}}]]
{{!}} {{{intitule}}}
{{!}} [[{{{developpeur}}}]]
{{!}} [[{{{recetteur}}}]]
{{!}} [[Revue de code:{{{reference}}}]]
{{!}} {{{statut}}} }}
|}</text>
      <sha1>e0ww86rvzfbr5ssp40nxcdwg8w484rb</sha1>
    </revision>
  </page>
  <page>
    <title>Groupe de développement batch</title>
    <ns>0</ns>
    <id>351436</id>
    <revision>
      <id>4064460</id>
      <parentid>4063416</parentid>
      <timestamp>2021-06-23T08:13:46Z</timestamp>
      <contributor>
        <username>Bodind</username>
        <id>34</id>
      </contributor>
      <comment>/* Consignes */</comment>
      <origin>4064460</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3389" sha1="od9pwqc4viiyl5uowcjxvzer10l4li7" xml:space="preserve">{{Modèle:Groupe
 | groupe= batch
 | responsable= Christophe Thibaut, Christelle Guillemot, David Bodin
 | domaines= architecture &amp; performances
 | developpeurs = José Calvinho, Clément Sainton
 | analystes = 
}}
[[Category:groupe de développement]]

== Actualités  ==

== Création des contextes de tests pour les batchs==

== Planning d'utilisation des plateformes ==

Le planning d'utilisation des plateformes est géré à travers le [https://trello.com/b/y5ojwgIT/pfs trello] dédié.

== Consignes ==

=== Travaux sur les partages de contextes ===

Avec le projet d'intégration d'efluid chez Enedis, certains batchs ont été portés en mode partage de contexte. Ce projet de portage est désormais fermé.
Depuis, les nouveaux batchs créés dans efluid sont supposés être développés en mode partage de contexte actif. Mais il peut rester des batchs à porter : ils sont traités au cas par cas.

Un portage de batch en mode partage de contexte actif est traité par un évènement de type '''Paramétrage Nouvelle Fonction'''. Un évènement ne gère qu'un batch et un seul.

En fils de cet évènement de portage sont créés les différents travaux : 
* des tests de validation de partage de contexte
* des adaptations du batch 

Les tests de validation de partage sont géré à travers des évènements de type '''test de performance'''. Chaque portage doit comporter au minimum un évènement de ce type.

Si un rapport de test de validation de partage indique un conflit, ce dernier est traité par un évènement de type '''découpage technique'''. Un découpage technique introduit des adaptations de code, livrées via git/gerrit. &lt;br&gt;
Un découpage technique doit avoir une double validation : 
* technique (validation du partage de contexte) : elle est réalisée à travers les tests de validation dédiés au portage. Le responsable du portage décide de réaliser ces tests au cas par cas ou globalement, une fois tous les découpages techniques livrés
* fonctionnelle (non régression) : elle est réalisée à travers un évènement fils au découpage technique de type '''recette'''. Cet évènement est affecté à un recetteur fonctionnel du domaine impacté par le découpage technique

Une fois tous les travaux terminés et recettés, le paramétrage nouvelle fonction qui gère le projet de portage est validé par l'équipe performances efluid et le paramétrage est livré dans git/gerrit.

=== Anomalies de performances ===

'''En développeur :''' le responsable de la correction.&lt;br /&gt;
'''En recetteur :''' un expert performances qui doit valider la correction de perfs.&lt;br /&gt;
'''Recette fonctionnelle :''' effectuée via un évènement fils de type "recette" avec en recetteur l'expert fonctionnel en charge 
de la recette fonctionnelle. Cet évènement de recette passe au statut "livré recette" quand l'anomalie de performance est livrée.&lt;br /&gt;
Dans certains cas, l'évènement de recette peut être inutile (livraison d'un index par exemple).&lt;br /&gt;
'''Test de performance :''' il est possible de créer un ou plusieurs tests de performances en élément fils de l'anomalie de performance pour valider cette dernière.
Mais le tests peut également être directement intégré à l'anomalie : c'est au choix du développeur. Dans tous les cas, le lien vers le rapport est 
fourni dans un commentaire associé à l'anomalie de performance.</text>
      <sha1>od9pwqc4viiyl5uowcjxvzer10l4li7</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine affaire générique</title>
    <ns>0</ns>
    <id>925</id>
    <revision>
      <id>4062443</id>
      <parentid>4062442</parentid>
      <timestamp>2020-12-23T08:48:11Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <comment>/* Activation des affaires générique */</comment>
      <origin>4062443</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1491" sha1="5gkwedmij09bhp7v1v5x2v45lcxeern" xml:space="preserve">{{Modèle:Domaine
 | nom = affaire générique
}}
[[Category:domaine]]
[[Category:Affaire Générique]]
[[Category:pole composants transverses]]
= Documentation générale =
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_27fb AFD du composant]
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2801 AFD de paramétrage des modèles d'affaires]
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_64a41 Guide utilisateur du paramétrage affaire génériques]
* [http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_43e5b DCT "User guide" des modèles objets métiers]
* [[Plan de progression:Affaire Générique|Plan de progression]]

== Activation des affaires générique ==
Pour avoir accès au paramétrage d'un modèle objet métier, il faut mettre à &lt;tt&gt;true&lt;/tt&gt; le paramètre entreprise &lt;tt&gt;activeModeleObjetMetier&lt;/tt&gt;.

== Type d'affaire générique ==
* [http://wikefluid/index.php/Ma%C3%AEtrise_de_la_demande_d%27%C3%A9nergie Affaire MDE]
* Affaire Marketing
* Affaire Eclairage Public
* [http://wikefluid/index.php/Etin%C3%A9raire Affaire de Recrutement]
* Affaire Correction de facture
* Affaire Vente d'Energie

== Technique ==
* [[Créer une nouvelle sous classe d'affaire générique]]
* [[Créer un nouvel onglet statique]]

== Contraintes de paramétrage ==
* le type de l'objet maître du modèle d'affaire doit correspondre exactement au type d'affaire du workflow, lui même défini sur le modèle d'affaire.</text>
      <sha1>5gkwedmij09bhp7v1v5x2v45lcxeern</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine relance</title>
    <ns>0</ns>
    <id>1327</id>
    <revision>
      <id>1468213</id>
      <parentid>1468196</parentid>
      <timestamp>2016-04-01T14:03:55Z</timestamp>
      <contributor>
        <username>Barthel</username>
        <id>170</id>
      </contributor>
      <origin>1468213</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="467" sha1="tdle4dm5bbfgu8f7dd2w0ounk8sit8s" xml:space="preserve">{{Modèle:Domaine
 | section= [[Section_recouvrement|recouvrement]]
 | referent= [[ICA]]
 | responsable= [[CLE]]
 | recetteurs = [[DFE]]
}}
[[Category:domaine]]
=Documentation générale=
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_d615 AFD du composant]
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_d61f AFD des courriers de relance]

=Description du domaine=
A compléter

=Modèle simplifié=
A compléter

=Remarques=
A compléter</text>
      <sha1>tdle4dm5bbfgu8f7dd2w0ounk8sit8s</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine contentieux</title>
    <ns>0</ns>
    <id>1328</id>
    <revision>
      <id>1468350</id>
      <parentid>1468226</parentid>
      <timestamp>2016-04-01T14:15:55Z</timestamp>
      <contributor>
        <username>Barthel</username>
        <id>170</id>
      </contributor>
      <origin>1468350</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="482" sha1="bu0hx6xooq8a9n7h3o1xl8mpi7btcu9" xml:space="preserve">{{Modèle:Domaine
 | referent= [[ICA]]
 | responsable= [[CLE]]
 | section=[[Section_recouvrement|recouvrement]]
 | recetteurs = [[DFE]]
}}
[[Category:domaine]]
= Documentation générale =
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_59268 AFD du composant]
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_511f7 AFD Paramétrage campagne de contentieux]

=Description du domaine=
A compléter

=Modèle simplifié=
A compléter

=Remarques=
A compléter</text>
      <sha1>bu0hx6xooq8a9n7h3o1xl8mpi7btcu9</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine comptabilite</title>
    <ns>0</ns>
    <id>1438</id>
    <revision>
      <id>11312</id>
      <parentid>11309</parentid>
      <timestamp>2012-03-23T15:51:08Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <minor/>
      <comment>a déplacé [[Comptabilite]] vers [[Domaine comptabilite]]</comment>
      <origin>11312</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2033" sha1="fj2lsqlveckfwbyv552i9ys0kpyzuqd" xml:space="preserve">{{Modèle:Domaine
 | nom= [[Comptabilite]]
 | referent= [[SK]]
 | responsable= [[ORO]],[[TTA]] ,[[XBL]]
 | groupe=  REC
 | recetteurs = [[ICA]], [[ADR]],[[DFE]]
}}
[[Category:domaine]]
=Documentation générale=
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_5934d/AFD%20-%20RCV%20-%20Etude%20sous%20domaine%20comptabilit%E9%20Auxiliaire%20Client.doc AFD du domaine]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_60539/Editions%20de%20la%20comptabilit%E9_V3 AFD Edition]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_5c61c/AFD%20-%20CAC%20-%20Cas%20d%27utilisation%20G%E9n%E9rer%20les%20lignes%20de%20compte%20client.doc AFD generer ligne de compte]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_86697/AFD%20-%20CAC%20-%20Cas%20d%27utilisation%20passage%20en%20non%20valeur.doc AFD passage en non valeur]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_5934c/AFD%20-%20RCV%20-%20Bordereaux%20cas%20particuliers.doc AFD bordereaux des cas particuliers]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_60543/Edition%20CAC%20-%20UC%20-%20Etat%20des%20ASC%20non%20rembours%E9es%204.0.doc Etat bordereaux des ASC non rembourses]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_60544/Edition%20CAC%20-%20UC%20-%20Etat%20des%20d%E9comptes%20pour%20solde%204.0.doc Etat des décomptes pour solde]



=Description du domaine=
A compléter

=Modèle simplifié=
A compléter

=Sujet de discution=
'''Comment charger les lignes de comptes lorsque nous sommes en train de réaliser une opération financière sur un compte bordereau ?'''

''Idées''

Une correction en lot 11 propose de charger les lignes de compte qui remplissent les conditions suivantes :
Ligne de compte à la racine du compte

Et 

(
Le solde est &lt;&gt; zéro OU 

c'est une ligne ATTE OU 

c'est une ligne appartenant à un compte PARTENAIRE OU 

la date de solde est null
)

''Réactions ?''

=Remarques=
A complé</text>
      <sha1>fj2lsqlveckfwbyv552i9ys0kpyzuqd</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine reglement</title>
    <ns>0</ns>
    <id>1439</id>
    <revision>
      <id>13216</id>
      <parentid>13215</parentid>
      <timestamp>2012-06-12T15:34:27Z</timestamp>
      <contributor>
        <username>Tazi</username>
        <id>49</id>
      </contributor>
      <comment>/* REGLE DE DEVELOPPEMENT */</comment>
      <origin>13216</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4800" sha1="fmtx6hailr2rplzh36220yqebnybuyy" xml:space="preserve">{{Modèle:Domaine
 | nom= [[Reglement]]
 | referent= [[SK]]
 | responsable= [[ORO]],[[TTA]] ,[[XBL]]
 | groupe=  REC
 | recetteurs = [[ICA]], [[ADR]],[[DFE]]
}}
[[Category:domaine]]
=Documentation générale=
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_7263f/AFD%20-%20RCV%20-%20Etude%20sous%20domaine%20R%E8glement.doc AFD du domaine]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_579e4/UC%20-%20E-0010%20-%20Etat%20bordereaux%20de%20remise%20de%20ch%E8ques.doc Etat bordereaux de remise des cheques]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_6573b/UC%20-%20E-0010%20-%20Etat%20bordereaux%20des%20op%E9rations%20financieres%20annul%E9es.doc Etat bordereaux des opérations financieres]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_6579d/UC%20-%20E-0010%20Edition%20de%20bordereau%20d%27op%E9rations%20diverses.doc Etat bordereaux des opérations diverses]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_59001/UC%20-%20REG003%20-%20Retour%20banque.doc Interface traiter retour banque]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_59002/UC%20-%20REG004%20-%20Retour%20TIP.doc Interface traiter retour TIP]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_59165/UC%20-%20REG008%20-%20Traiter%20les%20retours%20machine%20encaissements%20ch%E8que.doc Interface traiter retour machine encaissement cheque]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_59166/UC%20-%20REG011%20-%20Paiement%20internet.doc Interface paiement internet]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_59167/UC%20-%20REG017%20-%20Encaissement%20g%E9n%E9rique.doc Interface encaissement générique]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_6487a/UC%20-%20REG018%20-%20CashCompte.doc Interface cash compte]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_59168/UC%20-%20REG019%20-%20BIP.doc Interface BIP]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_6d1da/UC%20-%20REG021%20-%20Encaissement%20telefact.doc Interface encaissement téléfact]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_59169/UC%20-%20REG022%20-%20Impay%E9s%20telefact.doc Interface impayes téléfact]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_a14ef/UC%20-%20REG024%20-%20G%E9n%E9rer%20fichiers%20de%20virement.docx Generer fichier de decaissement]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_a1517/UC%20-%20REG026%20-%20G%E9n%E9rer%20fichiers%20de%20pr%E9l%E8vement.docx Generer fichier d'encaissement]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_a150c/UC%20-%20REG027%20-%20G%E9rer%20les%20fichiers%20de%20retour%20Banque%20SEPA.docx Generer fichier retour banque SEPA]
* [http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_a1500/UC%20-%20REG028%20-%20G%E9n%E9rer%20les%20encaissements.docx Generer encaissement]

=Règle de développement =
'''GESTION EN MEMOIRE D'UN OBJET :'''

Mise en place d'une solution pour la gestion du partage en mémoire d’un objet déjà chargé :

'''Etape 1 : Appel du service.''' 
 '''private CompteClient chargeCompteClient(HttpServletRequest req, CompteClient cc) {'''
  Object arg[] = { cc };
  '''''gestionMemoireObjetCreationOperationFinanciere(req);'''''
  Object ret[] = (Object[]) sendLogicEvent("comptabilite", "GererCompteClient",     ComptabiliteConstantes.CHARGER_CONTEXTE_COMPTE_CLIENT, arg);
  return cc;
 }     

'''Etape 2 : Récupération de l'objet de type "Opération financiere" en cours de creation.''' 
 '''private OperationFinanciere getOperationFinanciereEnCours(HttpServletRequest req) {'''
  OperationFinanciere of = null;
  if (ReglementHTTPContext.getEncaissementEnCreation(req) != null) {
    of = ReglementHTTPContext.getEncaissementEnCreation(req);
  } else if (ReglementHTTPContext.getDecaissementEnCreation(req) != null) {
    of = ReglementHTTPContext.getDecaissementEnCreation(req);
  } else if (ReglementHTTPContext.getOperationDiverseEnCreation(req) != null) {
    of = ReglementHTTPContext.getOperationDiverseEnCreation(req);
  }
  return of;
 }

'''Etape 3 : Valorisation en memoire de l'objet Payeur.''' 
  '''private void gestionMemoireObjetCreationOperationFinanciere(HttpServletRequest req) {'''
  '''''OperationFinanciere of = getOperationFinanciereEnCours(req);'''''
  // -&gt; Si null alors nous ne sommes pas dans le cadre de la creation
  if (of != null) {
    List&lt;Payeur&gt; listePayeur = of.getPayeur();
    for (Payeur payeur : listePayeur) {
      '''''EventThreadContextUtil.addToThreadBOContextNextEvent(false, payeur);'''''
   }
  }
 }

=Remarques=
A complé</text>
      <sha1>fmtx6hailr2rplzh36220yqebnybuyy</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine échanges</title>
    <ns>0</ns>
    <id>1111</id>
    <revision>
      <id>4069592</id>
      <parentid>4066755</parentid>
      <timestamp>2023-06-27T08:18:20Z</timestamp>
      <contributor>
        <username>Leoutre</username>
        <id>41</id>
      </contributor>
      <comment>/* Serveur FTP, SFTP, FTPS de test */</comment>
      <origin>4069592</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="22568" sha1="dz4xwtuajgr6nnjcuc0k3zpbmsncruf" xml:space="preserve">{{Modèle:Domaine
 | nom= [[Echanges]]
 | referent= [[CBER]], [[ACH]], [[VDA]]
 | responsable= [[TMAN]]
 | recetteurs = [[FDEC]], [[MAC]]
}}
[[Category:domaine]]
[[Category:échanges]]

= Aide au diagnostic =
[[Aide au diagnostic]]

[[Tutoriel de recherche et correction d'un caractère interdit]]

= Serveur FTP, SFTP, FTPS de test =

En vu de tester des accès FTP simples et sécurisés, un serveur est mis à disposition par l'équipe sécurité (Thibaut AJDONIK).
Voici les infos nécessaires à la connexion selon les différents protocoles FTP et dérivés :
* FTP : port 21 
* FTPS : port 30000
* FTPS (2way) : port 30001
* SFTP login/pass : port 22
* SFTP avec clé ssh: port 22 

Pour toutes les connexions utiliser les identifiants vsftptest/P&amp;ss_Op

La clef privée pour le [[SFTP]] est en pièce-jointe avec comme passphrase P&amp;ss_Op :
[http://WPEROOM3.uem.lan/eRoom/Production/DocTechniqueEfluid/0_2407bc sftptest] (dans [http://wperoom3.uem.lan/eRoom/Production/DocTechniqueEfluid/0_2407b9 Mes eRooms &gt; efluid - Documentation Technique &gt; DCT suite efluid &gt; DCT efluid.net &gt; Tests &gt; Serveur FTP de test])

Le keystore est en pièce-jointe ci-dessous (avec comme passphrase P&amp;ss_Op) :
[http://WPEROOM3.uem.lan/eRoom/Production/DocTechniqueEfluid/0_2407bd yourkeystore.jks] (dans [http://wperoom3.uem.lan/eRoom/Production/DocTechniqueEfluid/0_2407b9 Mes eRooms &gt; efluid - Documentation Technique &gt; DCT suite efluid &gt; DCT efluid.net &gt; Tests &gt; Serveur FTP de test])

Les flux sont ouverts depuis ironwhale (qui héberge les environnement efluid.net de recette)

= Liens utiles = 
Ce paragraphe a pour but de répertorier les liens vers les différents documents intéressant pour le domaine Échanges.

'''Important'''

Pour modifier un fichier d'eRoom, préférer le lien vers la room plutôt que le lien direct vers le fichier.

== Gestion du domaine ==
{| class="wikitable centre" width="100%"
|-
! scope=col align="center" width="40%"|Nom de la room
! scope=col align="center" width="60%"|Commentaires
|-
|[http://wperoom1/eRoom/Production/GestionProjetEfluid/0_6bd29 Groupe échanges]||Regroupe l'ensemble des documents de gestion du domaine (BL, revue de code, CR de réunion...)
|}

[[Suivi de la charge du domaine Echanges]]

== Composant ==
{| class="wikitable centre" width="100%"
|-
! scope=col align="center" width="40%"|Nom
! scope=col align="center" width="60%"|Commentaires
|-
|[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1c325/AFD%20-%20Analyse%20globale%20du%20syst%E8me%20d%27%E9changes.doc AFD - Analyse globale du système d'échanges.doc]||Décrit l'ensemble du composant d'échanges
|-
|[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_507d0/AFD%20-%20Architecture%20des%20services%20en%20ligne.doc AFD - Architecture des services en ligne.doc]||
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4dfda Composant d'échanges]||
Regroupe l'ensemble des AFDs du composant d'échanges
|}

== Guide de développement / Guide utilisateur ==
{| class="wikitable centre" width="100%"
|-
! scope=col align="center" width="20%"|Thème
! scope=col align="center" width="20%"|Room/wiki
! scope=col align="center" width="20%"|Nom
! scope=col align="center" width="60%"|Commentaires
|-
|rowspan="3" align="center"|'''EDK'''||&lt;del&gt;[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_3707e procédure]&lt;/del&gt;||&lt;del&gt;[http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_707d8/procedure%20livraison%20EDK.doc procedure livraison EDK.doc&lt;/del&gt;]||Ancienne procédure de livraison de l'EDK (CVS + ant)
|-
|[http://rmwiki/index.php/Edk Edk]||[http://rmwiki/index.php/Edk#Proc.C3.A9dure_de_livraison Procédure de livraison]||Procédure de livraison de l'EDK (usine logicielle)
|-
|[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_3707e procédure]||[http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_43d37/Proc%E9dure%20-%20Mise%20%E0%20jour%20mod%E8le%20EDK.doc Procédure - Mise à jour modèle EDK.doc]||Procédure de mise à jour du modèle EDK
|-
|rowspan="7" align="center"|'''Service web'''||[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_1bb5d guide environnement de développement]||[http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_4ebc5/Service%20Web%20-%20R%E9alisation%20de%20tests%20avec%20SOAP%20UI.doc Service Web - Réalisation de tests avec SOAP UI.doc]||Document d'utilisation de SOAP UI.
|-
||[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_1b4b8 guides framework Hermes]||[http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_643eb/01%20-%20Pr%E9sentation%20rapide%20des%20services%20web.doc 01 - Présentation rapide des services web.doc]||Présentation générale et assez générique de ce qu'est un service web
|-
||[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_1b4b8 guides framework Hermes]||[http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_92956/Services%20Web%20%96%20Profil%20Maven%20pour%20la%20g%E9n%E9ration%20de%20stub%20Axis2.doc Service Web - Profil Maven pour la génération de stub Axis2.doc]||L’objet de ce document est de présenter la mise en place d’un profil de génération de code Maven et de donner un exemple d’utilisation.
|-
||[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_1b4b8 guides framework Hermes]||[http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_643ec/02%20-%20Etude%20sur%20les%20services%20web.doc 02 - Etude sur les services web.doc]||Résultat de l'étude ayant mené à l'utilisation d'Axis 2 (en version 1.3)
|-
||[http://wperoom1/eRoom/Production/QualiteDeveloppementEfluid/0_1b4b8 guides framework Hermes]||[http://wperoom1/eRoomReq/Files/Production/QualiteDeveloppementEfluid/0_643ed/03%20-%20Guide%20du%20d%E9veloppeur%20efluid%20pour%20les%20services%20web.doc 03 - Guide du développeur efluid pour les services web.doc]||Guide de développement des services web exposés par efluid
|-
||[http://wperoom1/eRoom/Production/GestionProjetEfluid/0_75546 webservices]||[http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_86248/Description%20des%20WebServices%20efluid%20et%20AEL.doc Description des WebServices efluid et AEL.doc]||Résumé fonctionnel des services web déployés dans la suite efluid
|-
||[http://wperoom1/eRoom/Production/GestionProjetEfluid/0_75546 webservices]||[http://wperoom1/eRoomReq/Files/Production/GestionProjetEfluid/0_754e1/liste%20des%20services%20web.xls liste des services web.xls]||Document excel listant les différents services web exposés dans la suite efluid et fournissant le lien vers le service déployé sur le nightly build
|}

== Documents de référence ==
{| class="wikitable centre" width="100%"
|-
! scope=col align="center" width="40%"|Nom
! scope=col align="center" width="60%"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4e087 Room des documents de référence]||Regroupe l'ensemble des document de références du domaine échanges. C'est-à-dire les documents fournis par les '''organismes extérieurs''' exposant des services web [ERDF, GRDF, ...]). On y retrouve la description: &lt;ul&gt; &lt;li&gt;des services web d'information sur les PDS, de changement de fournisseur...&lt;/li&gt;&lt;li&gt;les documents de description des flux produits par les organismes externes (R04, RE6M, REMM...)&lt;/li&gt;&lt;/ul&gt;
|}


== Modèle EDK ==
{| class="wikitable centre" width="100%"
|-
! scope=col align="center" width="8%"|Room
! scope=col align="center" width="32%"|Nom
! scope=col align="center" width="60%"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_56d0c/AFD%20-%20EDK%20-%20%20mod%E9lisation%20affaire%20g%E9n%E9rique.doc AFD - EDK - modélisation affaire générique.doc]||Description du modèle EDK des affaires génériques
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1ea71/AFD%20-%20EDK%20-%20%20mod%E9lisation%20Affaire.doc AFD - EDK - modélisation Affaire.doc ]||Description du modèle EDK des affaires
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1ea7b/AFD%20-%20EDK%20-%20%20mod%E9lisation%20EDL.doc AFD - EDK - modélisation EDL.doc]||Description du modèle EDK des EDL
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1ea6c/AFD%20-%20EDK%20-%20%20mod%E9lisation%20Mat%E9riel.doc AFD - EDK - modélisation Matériel.doc]||Description du modèle EDK du package Matériel
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_33c2c/AFD%20-%20EDK%20-%20%20mod%E9lisation%20RDF%20gaz.doc AFD - EDK - modélisation RDF gaz.doc]||Description du modèle EDK du package RDF Gaz
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1c2f7/AFD%20-%20EDK%20-%20%20mod%E9lisation%20RDF.doc AFD - EDK - modélisation RDF.doc]||Description du modèle EDK du package RDF
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1ea67/AFD%20-%20EDK%20-%20%20mod%E9lisation%20Rel%E8ve.doc AFD - EDK - modélisation Relève.doc]||Description du modèle EDK du package Relève
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1ea76/AFD%20-%20EDK%20-%20mod%E9lisation%20Acteur.doc AFD - EDK - modélisation Acteur.doc]||Description du modèle EDK du package Acteur
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1c2fa/AFD%20-%20EDK%20-%20mod%E9lisation%20Contrat.doc AFD - EDK - modélisation Contrat.doc]||Description du modèle EDK du package Contrat
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd49 1 - edk]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1c2f9/AFD%20-%20EDK%20-%20mod%E9lisation%20Facture.doc AFD - EDK - modélisation Facture.doc]||Description du modèle EDK du package Facture
|}

== Flux ==
Remarque : c'est toujours efluid.net qui initie un échange.

Remarque : le point de vue pris pour les termes consommation et publication est celui d'efluid.net.

{| class="wikitable centre" width="100%"
|-
! scope=col align="center" width="40%"|Nom
! scope=col align="center" width="60%"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4cd46 3 - AFD flux]||Regroupe l'ensemble des AFD des développements concernant les flux
|}


'''A mettre en place'''

Ce qui serait intéressant c'est de mettre à disposition, pour chacun des flux publiés ou consommés par efluid.net, un certain nombre d'information, notamment:
* les clients chez lesquels le flux est en production
* un document permettant de lister les différentes étapes permettant de publier/consommer le flux (action à réaliser dans efluid, dans le portail, exemple de fichier d'entrée à consommer [et les informations à modifier dans le fichier pour réaliser la consommation correctement])
* le DCT
* l'AFD

{| class="wikitable sortable" width="100%"
|-
! scope=col align="center" width="20%"|Modèle d'échange
! scope=col align="center" width="30%" class="unsortable"|AFD / DCT
! scope=col align="center" width="20%" class="unsortable"|Cahiers de recette
! scope=col align="center" width="20%" class="unsortable"|Clients concernés
|-
|REL Cns int relèves GRD (soap EDK)||&lt;ul&gt;&lt;li&gt;[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_1ea67/AFD%20-%20EDK%20-%20%20mod%E9lisation%20Rel%E8ve.doc AFD - EDK - modélisation Relève.doc]&lt;/li&gt;&lt;li&gt;DCT : &lt;/li&gt;&lt;ul&gt;||||
|}

===Points d'arrêt stratégiques quand on debug un flux===
====efluid.net====
#Consommation :
##Flux historique :
###&lt;b&gt;ConsommationProcess&lt;/b&gt;.consommerAbonnement
###cas transmission SOAP : ne pas oublier de mettre un point d'arrêt juste après le sendEventToPublicateur pour attraper le LogicEvent sur le retour.
##Flux de masse :
###&lt;b&gt;ConsommateurXXXDeMasseProcess&lt;/b&gt;.getFichierDeMasseInduction

#Publication :
##Flux historique :
###&lt;b&gt;PublicationProcess&lt;/b&gt;.publierAbonnement
###cas transmission SOAP : ne pas oublier de mettre un point d'arrêt juste après le sendEventToConsommateur pour attraper le LogicEvent sur le retour.
##Flux de masse : 
###&lt;b&gt;TraducteurEchangeDeMasse&lt;/b&gt;.doCreateFiles : lance le business split, puis en multi-threads : technical split etc.
###TraducteurEchangeDeMasse.processBusinessGroups : lance le technical split, etc en multi-thread. Ne pas oublier de mettre un point d'arrêt juste après pour rattraper la sortie du multi-thread.
###&lt;b&gt;TraducteurDeGroupeEchangeDeMasse&lt;/b&gt;.call : lance le technical split, transformation XSLT, merge et zip.
###XmlSplitter.split : instancie readers et writer, lance l'éclatement du fichier en entrée en "Groupes"
###XmlSplitterReader.doCall : lit le fichier en entrée, en extrait les échanges ainsi que les critères métier sur lesquels splitter, en déduit le groupe à associer à l'échange, envoie l'(échange, Groupe) à écrire dans la Queue du Writer associé au bon Groupe.
###ContexteXXX.equals : détermine à quel Groupe appartient l'échange (comparaison sur le hashcode).

====efluidPub====
Cas transmission SOAP : &lt;b&gt;AbstractSOAPServlet&lt;/b&gt;.processPostRequest ou BCClientSOAPServlet.traiterMessage.&lt;br&gt;
Ne pas oublier de mettre un point d'arrêt juste après traiterEvenement (recueil de la réponse).

====efluid====
Cas transmission SOAP  : &lt;b&gt;ConsommationEventMgr&lt;/b&gt;.handleEvent.

===Fonctionnement des XMLMgr===
Ce fonctionnement est explicité la page [[Fonctionnement des XMLMgr]].

== Services Web ==
=== Serveur ===
==== AFD spécifiques ====
Les AFD des services web doivent être classées sous eRoom de la manière suivante:
*'''Mes eRooms &gt; efluid - Documentation Fonctionnelle Suite efluid &gt; AFD suite efluid &gt; AFD efluid &gt; Web services'''
{| class="wikitable sortable" width="100%"
|-
! scope=col align="center" width="15%"|Domaine fonctionnel
! scope=col align="center" width="35%" class="unsortable"|Lien
! scope=col align="center" width="50%" class="unsortable"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_61d00 Acteur]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_62ac2/AFD%20-%20service%20web%20-%20creer%20contact.doc AFD - service web - creer contact.doc]||AFD du service web "CreerContact"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_61d00 Acteur]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_62c6b/AFD%20-%20service%20web%20-%20gerer%20client.doc AFD - service web - gerer client.doc]||AFD du service web "GererClient"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_61d00 Acteur]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_640c2/AFD%20-%20service%20web%20-%20rechercher%20client.doc AFD - service web - rechercher client.doc]||AFD du service web "RechercherClient"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_6c159 Affaires - Action]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_741d0/AFD%20-%20service%20web%20-%20cr%E9ation%20action.doc AFD - service web - création action.doc]||AFD du service web "CréationAction"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_6c159 Affaires - Action]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_741d0/AFD%20-%20service%20web%20-%20cr%E9ation%20action.doc AFD - service web - création pièce jointe sur action.doc]||AFD du service web "CreerPieceJointe"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_63819 Contrat]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_7aa7d/AFD%20-%20service%20web%20-%20facturer%20contrat.doc AFD - service web - facturer contrat.doc]||AFD du service web "FacturerContrat"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_63819 Contrat]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_6db04/AFD%20-%20service%20web%20-%20fin%20d%27un%20service%20optionnel.doc AFD - service web - fin d'un service optionnel.doc]||AFD du service web "TerminierServiceOptionnel"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_63819 Contrat]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_6565e/AFD%20-%20service%20web%20-%20modifier%20contrat.doc AFD - service web - modifier contrat.doc]||AFD du service web "ModifierContrat"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_63819 Contrat]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_653d4/AFD%20-%20service%20web%20-%20rechercher%20contrat.doc AFD - service web - rechercher contrat.doc]||AFD du service web "RechercherContrat"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_63819 Contrat]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_6381c/AFD%20-%20service%20web%20-%20souscrire%20service%20optionnel.doc AFD - service web - souscrire service optionnel.doc ]||AFD du service web "SouscrireServiceOptionnel"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_65d4f Adresse et PDS]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_6fdc7/AFD%20-%20service%20web%20-%20modifier%20edl.doc AFD - service web - modifier edl.doc]||AFD du service web "ModifierEDL"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_65d4f Adresse et PDS]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_66eae/AFD%20-%20service%20web%20-%20rechercher%20edl.doc AFD - service web - rechercher edl.doc]||AFD du service web "RechercherEDL"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_6362d Relève]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_79c17/AFD%20-%20service%20web%20-%20cr%E9er%20rel%E8ve.doc AFD - service web - créer relève.doc]||AFD du service web "CreerReleve"
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_6362d Relève]||[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_62c63/AFD%20-%20service%20web%20-%20rechercher%20rel%E8ve%20PDS.doc AFD - service web - rechercher relève PDS.doc ]||AFD du service web "RechercherReleve"
|}

==== DCT Spécifiques ====

{| class="wikitable sortable" width="100%"
|-
! scope=col align="center" width="15%"|Room
! scope=col align="center" width="50%" class="unsortable"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6bdd5 service web]||Cette room regroupe l'ensemble des DCT spécifiques des services web exposés par efluid (efluidpub)
|}


==== DCT Composant ====
{| class="wikitable sortable" width="100%"
|-
! scope=col align="center" width="15%"|Room
! scope=col align="center" width="35%" class="unsortable"|Lien
! scope=col align="center" width="50%" class="unsortable"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_41ebd conception]||[http://wperoom1/eRoomReq/Files/Production/DocTechniqueEfluid/0_41ec8/DCT%20-%20EDK%20-%20Composant%20web%20services.doc DCT - EDK - Composant web services.doc ]||DCT du composant d'exposition des services web (efluidPub principalement)
|-
|[http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_41ebd conception]||[http://wperoom1/eRoomReq/Files/Production/DocTechniqueEfluid/0_63237/EDK%20-%20Utilisation%20Client%20Services%20Web.doc EDK - Utilisation Client Services Web.doc]||Schéma d'architecture de la configuration de déploiement pour le développement de service web
|}

=== Client ===
==== AFD spécifiques ====
Les AFD des services web doivent être classées sous eRoom de la manière suivante:
*'''Mes eRooms &gt; efluid - Documentation Fonctionnelle &gt; AFD suite efluid &gt; AFD efluid &gt; XXX - DOMAINE &gt; AFD - Interfaces'''
{| class="wikitable sortable" width="100%"
|-
! scope=col align="center" width="15%"|Domaine fonctionnel
! scope=col align="center" width="35%" class="unsortable"|Nom du document
! scope=col align="center" width="50%" class="unsortable"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6948a Edl - Pds - DG]||DCT – modèle de service web – ERDF – information PDS.doc||
|-
|[http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6948a Edl - Pds - DG]||DCT – modèle de service web – GRDF – information PDS.doc||
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_63819 Contrat]||AFD – service web – ERDF – Changement de fournisseur.doc||AFD du service web client "ChangementDeFournisseur"
|}
==== DCT Composant ====
{| class="wikitable sortable" width="100%"
|-
! scope=col align="center" width="15%"|Room
! scope=col align="center" width="35%" class="unsortable"|Lien
! scope=col align="center" width="50%" class="unsortable"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_41ebd conception]||[http://wperoom1/eRoomReq/Files/Production/DocTechniqueEfluid/0_5cb50/DCT%20-%20EDK%20-%20Client%20Services%20Web.doc DCT - EDK - Client Services Web.doc]||DCT du composant d'appel de service web (fonction externe, stub axis2...)
|}
==== DCT Spécifiques ====
Les DCT des services web doivent être classées sous eRoom de la manière suivante:
*'''Mes eRooms &gt; efluid - Documentation Technique &gt; DCT suite efluid &gt; DCT efluid &gt; DOMAINE XXX &gt; services web'''
{| class="wikitable sortable" width="100%"
|-
! scope=col align="center" width="15%"|Domaine fonctionnel
! scope=col align="center" width="35%" class="unsortable"|Nom du document
! scope=col align="center" width="50%" class="unsortable"|Commentaires
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_65d4f Pds]||DCT – service web – ERDF – information PDS.doc||AFD du service web client "InformationsPds" pour ErDF
|-
|[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_65d4f Pds]||AFD – service web – GRDF – information PDS.doc||AFD du service web client "InformationsPds" pour GrDF
|-
|[http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_77b0b Contrat]||DCT – modèle de service web – ERDF – Changement de fournisseur.doc||
|}</text>
      <sha1>dz4xwtuajgr6nnjcuc0k3zpbmsncruf</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine materiel</title>
    <ns>0</ns>
    <id>974</id>
    <revision>
      <id>564756</id>
      <parentid>15249</parentid>
      <timestamp>2015-01-02T13:17:40Z</timestamp>
      <contributor>
        <username>Grzejsz</username>
        <id>69</id>
      </contributor>
      <comment>/* Requêtes utiles */</comment>
      <origin>564756</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3350" sha1="ri21lhgrtlm0rv33kw2mh3a10o0mjl2" xml:space="preserve">[[Category:domaine]]
=== AFDs ===
[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_d3f5 eRoom]
Les AFDs "archivées" ne sont pas représentées ci-dessous.

* AFD - Comp - complémentaire conso et contrat_SJ.doc
** Cas d'utilisation "Créer configurations matérielles"
** Cas d'utilisation "Mettre à jour et éditer provisoirement des contrats"
** Cas d'utilisation "Gérer P.A.M."

* AFD - MAT - Matériel.doc
** Concepts
** Cas d'utilisation "Créer les matériels"
** Cas d'utilisation "gérer les enregistrements de matériels"
** Cas d'utilisation "Gérer les opérations effectuées en laboratoire"
** Cas d'utilisation "Affecter un matériel à Agent ou a une entité extérieure"
** Cas d'utilisation "Gérer les P.A.M."
** Cas d'utilisation "Administrer une P.A.M."
** Cas d'utilisation "Gérer les disjoncteurs"
** Cas d'utilisation "Contrôler le stock"
** Cas d'utilisation "Contrôler le matériel affecté à Agent"
** Cas d'utilisation "Gérer les types de matériels"
** Cas d'utilisation "Gérer les désignations matérielles"
** Cas d'utilisation "Gérer les types de matériels"
** Indicateurs
== Requêtes utiles ==
=== Renuméroter les constructeurs par ordre alphabétique ===
Requête utile à mettre à la fin des scripts qui ajoutent de nouveaux constructeurs de matériels.

&lt;source lang="sql"&gt;
create table TMP_ENUM  (code varchar2(10), type varchar2(10), lgcode number(2), ordre NUMBER(5,0) );

insert into TMP_ENUM 
SELECT code, type, lgcode, to_number(row_number() over (order by shortlabel))
FROM TENUM WHERE TYPE = 'MATCONSTRU' and etatobjet = 0 ORDER BY SHORTLABEL;

update tenum a set itemorder = (select ordre from TMP_ENUM b where a.code=b.code and a.type=b.type and a.type = 'MATCONSTRU' and a.etatobjet =0 and a.lgcode = b.lgcode)
where exists(select ordre from TMP_ENUM b where a.code=b.code and a.type=b.type and a.type = 'MATCONSTRU' and a.etatobjet=0 );

drop table TMP_ENUM ;
&lt;/source&gt;


=== Contrôles de cohérence des matériels ===
Les requêtes suivantes servent à vérifier qu'il n'y a pas d'incohérence dans les matériel et le paramétrage associé.

==== Matériels sans type de matériel cohérent ====
&lt;source lang="sql"&gt;
select mat.id, mat.reference, mat.role, tm.id, tm.libelle, tm.etatobjet
from tmateriel mat 
	left join ttypemateriel tm on (mat.typemateriel_id = tm.id)
where mod(mat.etatobjet,2) = 0 
	and (tm.id is null or mod(tm.etatobjet,2) = 1)
order by  mat.role, mat.typemateriel_id nulls last, mat.reference;
&lt;/source&gt;


==== Matériels utilisant une désignation ayant un type de matériel supprimé ====
&lt;source lang="sql"&gt;
select mat.id, mat.reference, mat.role, mat.designation_id
from tmateriel mat 
where mat.designation_id in 
	(SELECT d.id
	FROM tdesignation d
		join ttypemateriel tm on (d.typemateriel_id    = tm.id)
	where mod(tm.etatobjet,2)  = 1
		and mod(d.etatobjet,2) = 0
	)              
	and mod(mat.etatobjet,2) = 0
order by mat.role, mat.reference ;
&lt;/source&gt;

==== Matériels ayant une type de matériel différent de celui porté par sa désignation ====
&lt;source lang="sql"&gt;
select mat.id, mat.reference, mat.role, mat.typemateriel_id, d.typemateriel_id
from tmateriel mat
	join tdesignation d on (mat.designation_id = d.id)
where mod(mat.etatobjet,2) = 0
	and mat.typemateriel_id != d.typemateriel_id 
order by mat.role, mat.reference;
&lt;/source&gt;</text>
      <sha1>ri21lhgrtlm0rv33kw2mh3a10o0mjl2</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine workflow</title>
    <ns>0</ns>
    <id>851</id>
    <revision>
      <id>4068020</id>
      <parentid>4068019</parentid>
      <timestamp>2022-11-28T14:15:44Z</timestamp>
      <contributor>
        <username>Piersonc</username>
        <id>247</id>
      </contributor>
      <comment>/* Technique */</comment>
      <origin>4068020</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7788" sha1="c06euco4ucy5c8yj94fugoal4gam3nq" xml:space="preserve">[[Category:domaine]]
[[Category:Workflow]]
[[Category:pole composants transverses]]
= Documentation générale =
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_8b19 AFD du composant]
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_25b8 AFD des traitements génériques]
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_25b8 AFD des traitements spécifiques efluid]
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_27fe AFD de paramétrage des campagnes]
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_64a41 Guide utilisateur du paramétrage workflow]
* [http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_4909a DCT Workflow]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_8c2de DCT Batch Workflow V3]
* [http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_49096 DCT des campagnes]
* [[Plan de progression:Workflow|Plan de progression]]
* [[Chiffrage:Workflow|Chiffrages Workflow]]
* [[FAQ:Workflow|FAQ Workflow]]
* Évènement permanent 50257 "Action qualité - Domaine Workflow"
* Évènement 132245 homogénéisation des risques des campagnes workflow
* [[Qualité Domaine workflow|Améliorations/qualité de code Domaine workflow]]
* Répertoire partagé pour le DEV (eRoom) : [http://wperoom3.uem.lan/eRoom/Production/GestionProjetEfluid/0_1a2c42 efluid - Gestion de Projet &gt; Gestion des domaines &gt; domaine Listes de gestion / Workflow]  &gt; DEV_Repertoire_de_partage
* [[Batman]]

= Campagnes Workflow =

== ecore ==
* Campagne de gestion des objets génériques - type de campagne '''500'''
* Campagne de construction de courbes - type de campagne '''501'''

== efluid ==

* [[Echange GRD-F côté GRD]] - type de campagne '''11'''
* [[Campagne workflow de contentieux]] - type de campagne '''12'''
* [[Contrat TPN]] - type de campagne '''17'''
* [[DI sans déplacement]] - type de campagne '''18'''
* '''Supprimée''' - [[''Relance des propositions commerciales'']] - type de campagne '''19'''
* [[Alerte relève]] - type de campagne '''20'''
* [[Campagne de relance relève]] - type de campagne '''22'''
* [[Campagne workflow de raccordement de production]] - type de campagne '''23'''
* [[Suivi diagnostic gaz]] - type de campagne '''24'''
* [[Suivi des autorisations de prélèvement]] - type de campagne '''25'''
* [[Suivi des demandes diverses]] - type de campagne '''26'''
* '''Supprimée''' - [[Suivi des reconductions des contrats]] - type de campagne '''27'''
* [[Suivi des contrats AEL]] - type de campagne '''28'''
* [[Campagne workflow de MDE]] - type de campagne '''29'''
* [[Campagne workflow de marketing]] - type de campagne '''30'''
* '''Désactivée''' - [[''Campagne workflow de raccordement'']] - type de campagne '''31'''
* [[Campagne workflow de suivi de traitement sur anomalies de relèves]] - type de campagne '''32'''
* [[Campagne workflow de suivi des installations inactives]] - type de campagne '''33'''
* '''Supprimée''' - [[Campagne workflow de suivi du recrutement]] - type de campagne '''34''' (suite à l'extinction d'etineraire)
* '''Désactivée''' - [[Echanges GRD-F côté F]] - type de campagne '''36'''
* [[Suivi des modifications de RIB]]  - type de campagne '''37'''
* [[Suivi des mandats SEPA]]  - type de campagne '''39'''
* [[Campagne workflow de suivi des affaires génériques]]  - type de campagne '''40'''
* [[Campagne workflow de suivi des interventions EP]]  - type de campagne '''41'''
* [[Campagne workflow d'intervention]]  - type de campagne '''42'''
* [[Campagne workflow de suivi des abonnements cycliques de relève]]  - type de campagne '''44'''
* [[Campagne workflow d'analyse de recevabilité dans les demandes de prestations]]  - type de campagne '''46'''
* [[Campagne workflow de suivi des affaires de correction de factures]] - type de campagne '''48'''
* [[Campagne workflow de suivi des affaires de vente d'énergie]] - type de campagne '''49'''
* [[Campagne workflow de suivi des demandes de cotation]] - type de campagne '''51'''
* [[Campagne workflow de suivi des propositions commerciales]] - type de campagne '''52'''
* [[Campagne workflow de simulation des chiffres d'affaire futurs]] - type de campagne '''53'''
* [[Campagne workflow de calcul des bilans globaux d'énergie]] - type de campagne '''54'''
* [[Campagne workflow de suivi d'import de barèmes]] - type de campagne '''55'''
* [[Campagne workflow de gestion de la période mobile]] - type de campagne '''56'''
* [[Campagne workflow de gestion des données climatiques]] - type de campagne '''57'''
* [[Campagne workflow de suivi des services souscrits de mesure]] - type de campagne '''58'''
* [[Campagne workflow de gestion du caractère communicant des compteurs]] - type de campagne '''59'''
* [[Campagne workflow de suivi des affaires de prestation]] - type de campagne '''60'''
* [[Campagne workflow de suivi des actions]] - type de campagne '''61'''
* [[Campagne workflow de programmation relève]] - type de campagne '''62'''
* [[Campagne workflow de suivi des échanges avec des GRDs externes]] - type de campagne '''63'''
* [[Campagne workflow de suivi des demandes d'intervention réseau]] - type de campagne '''64'''
* [[Campagne workflow de gestion des raccordements]] - type de campagne '''65'''
* [[Campagne workflow des services souscrits]] - type de campagne '''66'''
* [[Campagne workflow de calcul de la CAR]] - type de campagne '''67'''
* [[Campagne workflow de suivi des éditions personnalisées sur publication]] - type de campagne '''68'''
* [[Campagne workflow de suivi des PDS objet de DI]] - type de campagne '''70'''
* [[Campagne workflow de gestion des demandes groupées]] - type de campagne '''71'''
* [[Campagne workflow d'import de la CAR]] - type de campagne '''72'''
* [[Campagne workflow de suivi des opérations bancaires]] - type de campagne '''74'''
* [[Campagne workflow de suivi des relevés bancaires]] - type de campagne '''75'''
* [[Campagne workflow de suivi des acteurs (RGPD)]] - type de campagne '''76'''
* [[Campagne workflow de suivi des demandes d'opération financière]] - type de campagne '''77'''
* Campagne de suivi du déploiement - type '''83'''
* Campagne d'intégration des données de mesure - type '''84'''
* Campagne de suivi comptes clients - type '''85'''
* Campagne de suivi des signatures - type '''86'''
* Campagne de contrôle cohérence d'offre - type '''87'''
* Campagne de valorisation de périmètre autoconso collective - type '''88'''
* Campagne de suivi des engagements contractuels - type '''93'''

== travaux (efluid) ==

* [[Campagne workflow de suivi des affaires de travaux]] - type de campagne '''200'''

== enercom ==

* [[Campagne workflow d'affectations entrées/sorties de périmètre]] - type de campagne '''1'''
* [[Campagne workflow des demandes de cotation]] - type de campagne '''2'''
* [[Campagne workflow de calcul de bilans global énérgie agrégés ]] - type de campagne '''3'''
* [[Campagne workflow de calcul des barèmes]] - type de campagne '''4'''
* [[Campagne workflow de gestion des données climatiques]] - type de campagne '''5'''

== eot==

* [[Campagne workflow d'exécution des téléaction]] - type de campagne '''1'''

= Technique =
* La plupart des guides et tutos sont dorénavant consultables dans la doc archi =&gt; https://wikefluid.efluid.uem.lan/docInstalleur/archi/develop/documentation/composants_metiers/workflow/workflow.html
* [[Processus de création des EDP]]
* [[Scripts sql récurrents du domaine workflow]]
* [[Paramètre technique batch workflow]]
* [[Créer un traitement d'alimentation]]
* [[Créer une anomalie]]
* [[Type chargement batch|Type de chargement pour les batchs]]
* [[Traitement fil de l'eau]]
* [[WKF997]]
* [[Cache Workflow]]
* [[Cas particuliers d'appel au moteur Workflow]]</text>
      <sha1>c06euco4ucy5c8yj94fugoal4gam3nq</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine grille</title>
    <ns>0</ns>
    <id>283</id>
    <revision>
      <id>4024066</id>
      <parentid>11514</parentid>
      <timestamp>2018-10-11T13:02:02Z</timestamp>
      <contributor>
        <username>Buzon</username>
        <id>496</id>
      </contributor>
      <comment>/* Risques */</comment>
      <origin>4024066</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1681" sha1="okykscm82t4ca6shobx9aelhhzyfq20" xml:space="preserve">[[Category:domaine]]
= Présentation =

Le domaine grille contient le concept d'ensemble. Les ensembles permettent non seulement de retourner une quantité mais aussi n’importe quel autre type d’objet tel qu’un énuméré dynamique/statique, un booléen ou une sélection d'énuméré. Ainsi ce concept peut être utilisé n’importe où dans l’application afin de définir un résultat conditionné par une grille de valeurs.

= Utilisation =

Les ensembles sont pour le moment utilisés par les applications efluid et efluid.net.

= Risques =

Pour pouvoir créer des ensembles et critères sur une application, l’utilisateur doit posséder a minima les habilitations suivantes :
* pour avoir le lien dans le menu: risque R1
* pour pouvoir créer modifier les critères : R1006, R1007, R1008
* pour pouvoir enregistrer la grille de valeur : R21: 'Création, modification et suppression offre produit, service et bareme de prix'

Les risques R428 et R4299 (créer/modifier les ensembles) ne sont pas utilisés dans l'application et le risque R21 ne devrait pas être utilisé à cet endroit. Pour rétablir une situation correcte, un événement suivefluid qualité a été créé: 64289.

= Tables utilisées =

De plus ce concept utilise une multitude de table dont le détail est contenu dans les fichier ddl:
*TENSEMBLE
*TCRITERE
*TVALEUR
*TMATRICEDEVALEURS
*MATRICEDEVALEURS_CRITERES
*TCOMBINAISONDEVALEURS
*COMBINAISONDEVALEURS_OPERANTES
*TVALEURBOOLEEN
*TVALEURENUMERE
*TVALEURCRITERE
*TVALEUROBJET
*TVALEURPERIODE
*TVALEURTEXTE
*TVALEURINTERVALLEQUANTITE
*TCOMBINAISONCOMPLEXE
*COMBINAISONCOMPLEXE_OPERANTES
*TCOMBINAISONCOMPLEXELIEE
*COMBINAISONCOMPLEXELIEE_OP</text>
      <sha1>okykscm82t4ca6shobx9aelhhzyfq20</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine contrat</title>
    <ns>0</ns>
    <id>800</id>
    <revision>
      <id>4063832</id>
      <parentid>4061596</parentid>
      <timestamp>2021-04-12T11:04:33Z</timestamp>
      <contributor>
        <username>Terraci</username>
        <id>397</id>
      </contributor>
      <comment>/* Aide mémoire */</comment>
      <origin>4063832</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3101" sha1="kkucfhu7khu0abms6qaujcyup2tgtg3" xml:space="preserve">[[Category:domaine]]
[[Plan de progression:Contrat|Plan de progression]]


= Aide mémoire =
* [[Détermination du responsable d'équilibre (RE), du fournisseur, des profils RDF|Détermination du responsable d'équilibre (RE), du fournisseur, des profils RDF]]
* [[Contrat:Contrat de regroupement|Contrat de regroupement]]
* [[Dates sur les objets du domaine contrat]]
* [[Annotations des attributs des services souscrits]]
* [[CA Futur]]
* [[Feuillet de gestion]]
* [[Requeteur]]
* [[GRD Externe]]
* [[Commande Arthas]]

= Documentation Générale =
==Analyse fonctionnelle==
[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4d898 eRoom]
* AFD - CTR - contrat.doc
** Concepts
** Cas d'utilisation : Souscrire et reprendre un contrat standard (reliquat de ce qui n'est pas encore reporté dans AFD - CTR - souscription de contrat.doc)
** Cas d'utilisation : Changement de fournisseur (reliquat de ce qui n'est pas encore reporté dans AFD - CTR - souscription de contrat.doc) 
** Cas d'utilisation : Gérer une condition de paiement par bordereau
** Cas d'utilisation : Gérer un envoi groupé 
** Cas d'utilisation : Gérer un contact facture 
** Cas d'utilisation : Gérer un créancier SEPA
* AFD - CTR - souscription de contrat.doc (''en cours de rédaction'')
** Cas d'utilisation : Souscrire et reprendre un contrat standard
** Cas d'utilisation : Valider souscription contrat
** Cas d'utilisation : Valider cessation contrat
** Cas d'utilisation : Suspendre un contrat standard
** Cas d'utilisation : Éditer proposition commerciale
** Cas d'utilisation : Optimiser un contrat standard
** Cas d'utilisation : Gérer date effet souhaitée
** Classification des services
** Paramètres de l'application
* AFD - CTR - contrat deuxième partie.doc
** Cas d'utilisation : consulter contrat
** Cas d'utilisation : administrer contrat
** Cas d'utilisation : modifier service régulier
** Cas d'utilisation : administrer service régulier
** Cas d'utilisation : modifier PACR
** Cas d'utilisation : cesser contrat / service
** Cas d'utilisation : mettre à jour contrat
** Cas d'utilisation : réactiver contrat
** Cas d'utilisation : annuler contrat
** Cas d'utilisation : renouveler contrat
** Cas d'utilisation : éditer liste de contrats en suivi
** Cas d'utilisation : éditer liste des contrats pour bilan qualité
** Cas d'utilisation : éditer feuiller de gestion
** Cas d'utilisation : ajouter nouvelle activité
** Cas d'utilisation : détecter les opportunités
** Cas d'utilisation : créer un mandat
** Cas d'utilisation : gérer un mandat
** Étude des statuts
** Gestion de la mise à jour suite à intervention
** Gestion des dates d'effet au niveau des services souscrits

==Conception technique==
*[[Composant action trace]]
*[[Composant Combinaison Complexe Liée]]
*[[Service Souscrit Chauffage Urbain]]
*[[Implémentation Services Optionnels]]
*[[Implémentation Mettre A Jour Contrat]]

= Supports de développement =
* [[Contrat:Coder une évolution|Coder une évolution]]
* [[Contrat:Créer des contextes|Créer des contextes]]
* [[Créer des énumérés persistants]]</text>
      <sha1>kkucfhu7khu0abms6qaujcyup2tgtg3</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine temps</title>
    <ns>0</ns>
    <id>1390</id>
    <revision>
      <id>24104</id>
      <parentid>14466</parentid>
      <timestamp>2013-03-07T12:27:05Z</timestamp>
      <contributor>
        <username>Grzejsz</username>
        <id>69</id>
      </contributor>
      <origin>24104</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="868" sha1="rz4ph8th6rq5q502b65bviuqjxuycf3" xml:space="preserve">{{Modèle:Domaine
 | nom= Temps
 | trigramme= TMP
 | referent= [[NBE]]
 | responsable= [[ADU]]
 | recetteurs = [[NBE]] / [[TSC]] / [[CGR]]
}}
== ecore ==

=== Documentation ===

[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid efluid - Documentation Fonctionnelle] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_415c5 AFD suite efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f645 AFD ecore] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f67b TMP - Domaine temps]

== efluid==

Les classes EntityProcess et DAO des classes StructuresHorosaisonniere et PosteHorosaisonnier sont surchargés dans le domaine [[Consommation|consommation]] efluid afin d'ajouter des contrôles sur leur utilisation vis à vis des concepts efluid.

== enercom ==

TODO

== Liens externes ==

[[Category:ecore]]
[[Category:domaine]]</text>
      <sha1>rz4ph8th6rq5q502b65bviuqjxuycf3</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine relève</title>
    <ns>0</ns>
    <id>972</id>
    <revision>
      <id>4067735</id>
      <parentid>4067450</parentid>
      <timestamp>2022-09-26T13:57:27Z</timestamp>
      <contributor>
        <username>Lhuillia</username>
        <id>469</id>
      </contributor>
      <comment>Ajout du script de purge de campagne en PostGreSQL</comment>
      <origin>4067735</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="36887" sha1="21h5kv381igdu2mt6xl7gpvkg8t85ic" xml:space="preserve">[[Category:domaine]]
== AFDs ==
[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_d69b eRoom]
Les AFDs d'interface ne sont pas représentées ci-dessous.

* AFD - REL - Campagnes de relève et télérelève.doc
** Pré-études et réflexions connexes
** Cas d'utilisation "Gérer le paramétrage du domaine Relève"
** Cas d'utilisation "Gérer la liste des releveurs"
** Cas d'utilisation "Paramétrer un modèle de campagne de relève / télé-relève"
** Cas d'utilisation "Planifier un modèle de campagne de relève / télé-relève"
** Cas d'utilisation "Suivre une campagne de relève / télé-relève"
** Cas d'utilisation "Traiter un lot de relève par TSP"
** Cas d'utilisation "Traiter un lot de télé-relève"
** Cas d'utilisation "Traiter un lot d'isolés de relève / télé-relève"
** Cas d'utilisation "Traiter un élément de population de relève / télé-relève"
** Cas d'utilisation "Gérer les absences de la relève d'une campagne de relève"
** Cas d'utilisation "Réinitialiser un lot de relève / télé-relève"
** Concepts
** Indicateurs

* AFD - REL - Foliotage.doc
** Concepts
** Cas d'utilisation "Mettre à jour la table EDL - Tournée"
** Cas d'utilisation "Refolioter une tournée"
** Cas d'utilisation "Modifier le folio d'un PDS"
** Cas d'utilisation "Refolioter au retour relève"
** Impacts

* AFD - REL - Tournées.doc
** Cas d'utilisation "Gérer une tournée"
** Cas d'utilisation "Gérer les consignes d'une tournée"
** Cas d'utilisation "Gérer le foliotage depuis une tournée"
** Cas d'utilisation "Contrôler l’affectation des données géographiques et des EDL par PDS"
** Cas d'utilisation "Gérer le rattachement à une tournée de relève depuis un PDS"
** Concepts
** Indicateurs

== Requêtes utiles ==
=== Sélection des relèves de la PACM courante d'un PDS ===

&lt;source lang="sql"&gt;
SELECT *
FROM treleve
WHERE pacm_id =
  (SELECT id
  FROM tpacm
  WHERE pointdeservice_id =
    (SELECT id FROM tpointdeservice WHERE REFERENCE = 'REFPDS'
    )
  AND datefin IS NULL
  ) order by datereleve desc;
&lt;/source&gt;

=== Supprimer une relève ===
Il faut aussi penser à :
*supprimer les grandeurs physiques générales
*passer les élément de population relève au statut "absent relève" et suppression du lien vers la relève
*supprimer les liens entre les factures et la relève
Si nécessaire :
*supprimer les grandeurs physiques mensuelles ?
*gérer les événements facturation ?
&lt;source lang = "sql"&gt;
define RELEVE_ID = 36393001
 
-- suppression relève
UPDATE TRELEVE                   SET ETATOBJET = 1, ACTEURSUPPRESSION = 'evt XXXXX', DATESUPPRESSION = CURRENT_DATE  WHERE ID = '&amp;RELEVE_ID';
-- suppression grandeur physique générale
UPDATE TGRANDEURPHYSIQUEGENERALE SET ETATOBJET = 1, ACTEURSUPPRESSION = 'evt XXXXX', DATESUPPRESSION = CURRENT_DATE  WHERE releve_id = '&amp;RELEVE_ID';
-- passage des edp relève au statut "absent relève"
UPDATE TELEMENTDEPOPULATIONRELEVE SET statut = 4, releve_id = NULL WHERE releve_id = '&amp;RELEVE_ID';
-- suppression du lien entre les factures et la relève
DELETE FROM facture_releves where dest = '&amp;RELEVE_ID';

&lt;/source&gt;

=== Purge d'une campagne de relève ===
Purge pour script client
&lt;source lang = "sql"&gt;
define CAMPAGNE_ID =XXXXX;
define EVT = 'evt XXXXX';

-- suppression des relèves
UPDATE tgrandeurphysiquegenerale
SET    etatobjet = 1,
       acteursuppression = '&amp;EVT',
       datesuppression = current_date
WHERE  id IN (SELECT GPG.id
              FROM   tgrandeurphysiquegenerale GPG,
                     treleve R,
                     telementdepopulationreleve E,
                     tlot L
              WHERE  GPG.RELEVE_ID = R.ID
                     AND ( r.id = e.releve_id
                            OR r.id = e.relevecomplementaire_id )
                     AND l.id = e.lot_id
                     AND l.campagne_id = '&amp;CAMPAGNE_ID'
                     AND MOD(r.etatobjet, 2) = 0)
       AND MOD(etatobjet, 2) = 0;

UPDATE treleve
SET    etatobjet = 1,
       acteursuppression = '&amp;EVT',
       datesuppression = current_date
WHERE  id IN (SELECT edp.releve_id
              FROM   telementdepopulationreleve edp,
                     tlot l
              WHERE  edp.lot_id = l.id
                     AND l.campagne_id = '&amp;CAMPAGNE_ID'
                     AND edp.releve_id IS NOT NULL
                     AND MOD(edp.etatobjet, 2) = 0
              UNION
              SELECT edp.relevecomplementaire_id
              FROM   telementdepopulationreleve edp,
                     tlot l
              WHERE  edp.lot_id = l.id
                     AND l.campagne_id = '&amp;CAMPAGNE_ID'
                     AND edp.relevecomplementaire_id IS NOT NULL
                     AND MOD(edp.etatobjet, 2) = 0)
       AND MOD(etatobjet, 2) = 0;

-- suppression des inforelèves
UPDATE tgrandeurphysiquegeneraleinfor
SET    etatobjet = 1,
       acteursuppression = '&amp;EVT',
       datesuppression = current_date
WHERE  id IN (SELECT GPG.id
              FROM   tgrandeurphysiquegeneraleinfor GPG,
                     tinforeleve R,
                     telementdepopulationreleve E,
                     tlot L
              WHERE  gpg.releve_id = r.id
                     AND r.id = e.inforeleve_id
                     AND l.id = e.lot_id
                     AND l.campagne_id = '&amp;CAMPAGNE_ID'
                     AND MOD(r.etatobjet, 2) = 0)
       AND MOD(etatobjet, 2) = 0;

UPDATE tinforeleve
SET    etatobjet = 1,
       acteursuppression = '&amp;EVT',
       datesuppression = current_date
WHERE  id IN (SELECT EDP.inforeleve_id
              FROM   telementdepopulationreleve EDP,
                     tlot L
              WHERE  EDP.lot_id = L.id
                     AND L.campagne_id = '&amp;CAMPAGNE_ID'
                     AND EDP.inforeleve_id IS NOT NULL
                     AND MOD(EDP.etatobjet, 2) = 0)
       AND MOD(etatobjet, 2) = 0; 
-- suppression des anomalies
UPDATE tanomalie SET etatobjet = 1, acteursuppression = '&amp;EVT', datesuppression = CURRENT_DATE
WHERE ID IN (SELECT A.ID FROM tanomalie A, telementdepopulationreleve edp, tlot l
             WHERE A.elementpopulation_id = edp.ID AND edp.lot_id = l.ID AND l.campagne_id = '&amp;CAMPAGNE_ID' AND mod(edp.etatobjet,2)=0  )
AND mod(etatobjet,2) = 0;

-- Suppression des tâches LDG
update ttache set etatobjet = 1, 
       acteursuppression = '&amp;EVT',
       datesuppression = CURRENT_DATE
 where mod(etatobjet,2) = 0
   and elementdetravail_id in ( SELECT EDP.id
              FROM   telementdepopulationreleve EDP,
                     tlot L
              WHERE  EDP.lot_id = L.id
                     AND L.campagne_id = '&amp;CAMPAGNE_ID'
                     AND MOD(EDP.etatobjet, 2) = 0
              UNION SELECT ano.id
              FROM   tanomalie ano,
                     telementdepopulationreleve EDP,
                     tlot L
              WHERE  ano.elementpopulation_id = edp.id
                     AND EDP.lot_id = L.id
                     AND L.campagne_id = '&amp;CAMPAGNE_ID'
                     AND MOD(EDP.etatobjet, 2) = 0
              UNION SELECT top.id 
              FROM TTOURNEEOPERATIONNELLE top where exists (select 1 
                from tlot l 
                where l.id = top.LOTDERELEVE_ID 
                and l.campagne_id = '&amp;CAMPAGNE_ID')
             );

-- suppression des edp
UPDATE telementdepopulationreleve SET etatobjet = 1, acteursuppression = '&amp;EVT', datesuppression = CURRENT_DATE
WHERE lot_id IN ((SELECT l.ID FROM tlot l WHERE l.campagne_id = '&amp;CAMPAGNE_ID' )
          UNION (SELECT c.lotisole_id FROM tcampagne c WHERE c.id = '&amp;CAMPAGNE_ID' and lotisole_id is not null))
AND mod(etatobjet,2) = 0;

-- mise à jour des statistiques
UPDATE tlot SET nbelements=0, nbelementstraites=0,selectionrealisee=0, acteurmodification = '&amp;EVT', datemodification = CURRENT_DATE
WHERE campagne_id = '&amp;CAMPAGNE_ID';
UPDATE tlotdereleve SET ETATTRAITEMENTSELECTION=0 WHERE id in (select id from tlot where campagne_id = '&amp;CAMPAGNE_ID');

UPDATE tcampagne SET nombreelements=0, nombreelementstraites=0, acteurmodification = '&amp;EVT', datemodification = CURRENT_DATE
WHERE id = '&amp;CAMPAGNE_ID';

UPDATE tstatistique SET quantite = 0, acteurmodification = '&amp;EVT', datemodification = CURRENT_DATE
WHERE (campagne_id = '&amp;CAMPAGNE_ID' 
       OR lot_id IN (SELECT l.ID FROM tlot l  WHERE l.campagne_id = '&amp;CAMPAGNE_ID'));

UPDATE TTOURNEEOPERATIONNELLE top
SET etatobjet = 1, acteursuppression = '&amp;EVT', datesuppression = CURRENT_DATE
WHERE EXISTS (SELECT 1 
FROM tlot l 
WHERE l.id = top.LOTDERELEVE_ID 
AND l.campagne_id = '&amp;CAMPAGNE_ID');

undef CAMPAGNE_ID;
undef EVT;
&lt;/source&gt;

Purge pour développement (suppression définitive)
&lt;source lang = "sql"&gt;

SELECT id, libelle FROM tcampagne WHERE libelle LIKE '%Campagne LANILDUT (Steph) - 14/08/2009%' AND statut = 0;

-- id de la campagne à traiter
define CAMPAGNE_ID = '21237226010';

BEGIN
   EXECUTE immediate 'DROP TABLE suppression_reinit_lot_releve';
EXCEPTION
   WHEN OTHERS THEN
      IF SQLCODE != -942 THEN
         RAISE;
      END IF;
END;
/

CREATE TABLE suppression_reinit_lot_releve (
     edp_id VARCHAR2(25),
     anomalie_id VARCHAR2(25),
     tache_id VARCHAR2(25),
     releve_id VARCHAR2(25),
     gpg_id VARCHAR2(25),
     inforeleve_id VARCHAR2(25),
     gpginforeleve_id VARCHAR2(25),
     echange_id VARCHAR2(25)
);

INSERT INTO suppression_reinit_lot_releve (edp_id, releve_id, inforeleve_id)
SELECT edp.id, edp.releve_id, edp.inforeleve_id
FROM tlot l
     JOIN telementdepopulationreleve edp  ON edp.lot_id = l.id
WHERE l.campagne_id = '&amp;CAMPAGNE_ID'
union all
SELECT null, edp.relevecomplementaire_id, null
FROM tlot l
     JOIN telementdepopulationreleve edp  ON edp.lot_id = l.id
WHERE l.campagne_id = '&amp;CAMPAGNE_ID';

INSERT INTO suppression_reinit_lot_releve (anomalie_id)
SELECT ano.id 
FROM tlot l
     JOIN telementdepopulationreleve edp  ON edp.lot_id = l.id
     JOIN tanomalie ano  ON ano.elementpopulation_id = edp.id
WHERE l.campagne_id = '&amp;CAMPAGNE_ID';

INSERT INTO suppression_reinit_lot_releve (tache_id)
SELECT tache.id 
FROM ttache tache where exists (select 1 from suppression_reinit_lot_releve tmp where tache.elementDeTravail_id = coalesce(tmp.edp_id, '§§'))
union all 
SELECT tache.id 
FROM ttache tache where exists (select 1 from suppression_reinit_lot_releve tmp where tache.elementDeTravail_id = coalesce(tmp.anomalie_id, '§§'));

INSERT INTO suppression_reinit_lot_releve (gpg_id)
SELECT gpg.id 
FROM tgrandeurphysiquegenerale gpg where exists (select 1 from suppression_reinit_lot_releve tmp where gpg.releve_id = coalesce(tmp.releve_id, '§§'));

INSERT INTO suppression_reinit_lot_releve (gpginforeleve_id)
SELECT gpg.id 
FROM tgrandeurphysiquegeneraleinfor gpg where exists (select 1 from suppression_reinit_lot_releve tmp where gpg.releve_id = coalesce(tmp.inforeleve_id, '§§'));

INSERT INTO suppression_reinit_lot_releve (echange_id)
SELECT pub.id 
FROM techange pub where exists (select 1 from suppression_reinit_lot_releve tmp where PUB.OBJETMAITRE_ID = coalesce(tmp.releve_id, '§§'))
UNION ALL
SELECT pub.id 
FROM techange pub where exists (select 1 from suppression_reinit_lot_releve tmp where pub.OBJETMAITRE_ID = coalesce(tmp.inforeleve_id, '§§'));

DELETE FROM techange pub WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE pub.id = tmp.echange_id);
DELETE FROM tgrandeurphysiquegenerale g WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE g.id = tmp.gpg_id);
DELETE FROM tgrandeurphysiquegeneraleinfor g WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE g.id = tmp.gpginforeleve_id);
DELETE FROM treleve r WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE r.id = tmp.releve_id);
DELETE FROM tinforeleve r WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE r.id = tmp.inforeleve_id);
DELETE FROM ttache t WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE t.id = tmp.tache_id);
DELETE FROM tanomaliereleve ano WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE ano.id = tmp.anomalie_id);
DELETE FROM tanomalie ano WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE ano.id = tmp.anomalie_id);
DELETE FROM telementdepopulationreleve edp WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE edp.id = tmp.edp_id);

DELETE
FROM ttache
WHERE MOD(etatobjet,2)   = 0
AND elementdetravail_id IN
  (SELECT top.id
  FROM TTOURNEEOPERATIONNELLE top
  WHERE EXISTS
    (SELECT 1
    FROM tlot l
    WHERE l.id        = top.LOTDERELEVE_ID
    AND l.campagne_id = '&amp;CAMPAGNE_ID'
    )
  );

delete from TTOURNEEOPERATIONNELLE top
where exists (select 1 
from tlot l 
where l.id = top.LOTDERELEVE_ID 
and l.campagne_id = '&amp;CAMPAGNE_ID');

UPDATE tcampagne
SET    nombreelements = 0,
       nombreelementstraites = 0
WHERE  id = '&amp;CAMPAGNE_ID'; 

UPDATE tlot
SET    nbelements = 0,
       nbelementstraites = 0
WHERE  campagne_id = '&amp;CAMPAGNE_ID';

UPDATE tstatistique s
SET quantite        = 0
WHERE ( s.campagne_id = '&amp;CAMPAGNE_ID'
OR EXISTS
     (SELECT 1 FROM TLOT L WHERE s.lot_id=l.id AND l.campagne_id = '&amp;CAMPAGNE_ID'
     )); 
 
-- ajouts v13
UPDATE tlot l SET selectionrealisee = 0 WHERE campagne_id = '&amp;CAMPAGNE_ID';
UPDATE tlotdereleve SET ETATTRAITEMENTSELECTION=0 WHERE id in (select id from tlot where campagne_id = '&amp;CAMPAGNE_ID');

UPDATE tlignestatistique ligne SET quantite = 0
WHERE EXISTS 
  (SELECT 1 FROM tstat s WHERE s.AXESTATISTIQUE_ID = '&amp;CAMPAGNE_ID' AND s.id = ligne.statistique_id);

UPDATE tlignestatistique ligne SET quantite = 0
WHERE EXISTS 
  (SELECT 1 FROM tstat s 
    JOIN tlot l ON l.id = s.axestatistique_id
    WHERE l.campagne_id = '&amp;CAMPAGNE_ID' AND s.id = ligne.statistique_id);

-- attention ça fait le commit!
TRUNCATE TABLE suppression_reinit_lot_releve;
DROP TABLE suppression_reinit_lot_releve;

&lt;/source&gt;

Purge pour développement (suppression définitive) en PostGreSQL (A tester et/ou vérifier)
&lt;source lang = "sql"&gt;

do
$$
    declare
        -- id de la campagne à traiter
        ID_CAMPAGNE CONSTANT varchar := '?';
    begin
        DROP TABLE suppression_reinit_lot_releve;
        CREATE TABLE suppression_reinit_lot_releve
        (
            edp_id           VARCHAR(25),
            anomalie_id      VARCHAR(25),
            tache_id         VARCHAR(25),
            releve_id        VARCHAR(25),
            gpg_id           VARCHAR(25),
            inforeleve_id    VARCHAR(25),
            gpginforeleve_id VARCHAR(25),
            echange_id       VARCHAR(25)
        );

        INSERT INTO suppression_reinit_lot_releve (edp_id, releve_id, inforeleve_id)
        SELECT edp.id, edp.releve_id, edp.inforeleve_id
        FROM tlot l
                 JOIN telementdepopulationreleve edp ON edp.lot_id = l.id
        WHERE l.campagne_id = ID_CAMPAGNE
        UNION ALL
        SELECT NULL, edp.relevecomplementaire_id, NULL
        FROM tlot l
                 JOIN telementdepopulationreleve edp ON edp.lot_id = l.id
        WHERE l.campagne_id = ID_CAMPAGNE;

        INSERT INTO suppression_reinit_lot_releve (anomalie_id)
        SELECT ano.id
        FROM tlot l
                 JOIN telementdepopulationreleve edp ON edp.lot_id = l.id
                 JOIN tanomalie ano ON ano.elementpopulation_id = edp.id
        WHERE l.campagne_id = ID_CAMPAGNE;

        INSERT INTO suppression_reinit_lot_releve (tache_id)
        SELECT tache.id
        FROM ttache tache
        WHERE EXISTS(SELECT 1
                     FROM suppression_reinit_lot_releve tmp
                     WHERE tache.elementDeTravail_id = COALESCE(tmp.edp_id, '§§'))
        UNION ALL
        SELECT tache.id
        FROM ttache tache
        WHERE EXISTS(SELECT 1
                     FROM suppression_reinit_lot_releve tmp
                     WHERE tache.elementDeTravail_id = COALESCE(tmp.anomalie_id, '§§'));

        INSERT INTO suppression_reinit_lot_releve (gpg_id)
        SELECT gpg.id
        FROM tgrandeurphysiquegenerale gpg
        WHERE EXISTS(SELECT 1
                     FROM suppression_reinit_lot_releve tmp
                     WHERE gpg.releve_id = COALESCE(tmp.releve_id, '§§'));

        INSERT INTO suppression_reinit_lot_releve (gpginforeleve_id)
        SELECT gpg.id
        FROM tgrandeurphysiquegeneraleinfor gpg
        WHERE EXISTS(SELECT 1
                     FROM suppression_reinit_lot_releve tmp
                     WHERE gpg.releve_id = COALESCE(tmp.inforeleve_id, '§§'));

        INSERT INTO suppression_reinit_lot_releve (echange_id)
        SELECT pub.id
        FROM techange pub
        WHERE EXISTS(SELECT 1
                     FROM suppression_reinit_lot_releve tmp
                     WHERE PUB.OBJETMAITRE_ID = COALESCE(tmp.releve_id, '§§'))
        UNION ALL
        SELECT pub.id
        FROM techange pub
        WHERE EXISTS(SELECT 1
                     FROM suppression_reinit_lot_releve tmp
                     WHERE pub.OBJETMAITRE_ID = COALESCE(tmp.inforeleve_id, '§§'));

        DELETE
        FROM techange pub
        WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE pub.id = tmp.echange_id);
        DELETE
        FROM tgrandeurphysiquegenerale g
        WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE g.id = tmp.gpg_id);
        DELETE
        FROM tgrandeurphysiquegeneraleinfor g
        WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE g.id = tmp.gpginforeleve_id);
        DELETE FROM treleve r WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE r.id = tmp.releve_id);
        DELETE
        FROM tinforeleve r
        WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE r.id = tmp.inforeleve_id);
        DELETE FROM ttache t WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE t.id = tmp.tache_id);
        DELETE
        FROM tanomaliereleve ano
        WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE ano.id = tmp.anomalie_id);
        DELETE
        FROM tanomalie ano
        WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE ano.id = tmp.anomalie_id);
        DELETE
        FROM telementdepopulationreleve edp
        WHERE EXISTS(SELECT 1 FROM suppression_reinit_lot_releve tmp WHERE edp.id = tmp.edp_id);


        UPDATE tcampagne
        SET nombreelements        = 0,
            nombreelementstraites = 0
        WHERE id = ID_CAMPAGNE;

        UPDATE tlot
        SET nbelements        = 0,
            nbelementstraites = 0
        WHERE campagne_id = ID_CAMPAGNE;

        UPDATE tstatistique s
        SET quantite = 0
        WHERE (s.campagne_id = ID_CAMPAGNE
            OR EXISTS
                   (SELECT 1 FROM TLOT L WHERE s.lot_id = l.id AND l.campagne_id = ID_CAMPAGNE
                   ));

        -- ajouts v13
        UPDATE tlot l SET selectionrealisee = 0 WHERE campagne_id = ID_CAMPAGNE;
        UPDATE tlotdereleve
        SET ETATTRAITEMENTSELECTION = 0
        WHERE id in (select id from tlot WHERE campagne_id = ID_CAMPAGNE);

        UPDATE tlignestatistique ligne
        SET quantite = 0
        WHERE EXISTS
                  (SELECT 1 FROM tstat s WHERE s.AXESTATISTIQUE_ID = ID_CAMPAGNE AND s.id = ligne.statistique_id);

        UPDATE tlignestatistique ligne
        SET quantite = 0
        WHERE EXISTS
                  (SELECT 1
                   FROM tstat s
                            JOIN tlot l ON l.id = s.axestatistique_id
                   WHERE l.campagne_id = ID_CAMPAGNE
                     AND s.id = ligne.statistique_id);

        -- attention ça fait le commit!
        TRUNCATE TABLE suppression_reinit_lot_releve;
        DROP TABLE suppression_reinit_lot_releve;
    exception
        -- Ne pas jeter d'exception si la table suppression_reinit_lot_releve n'existait pas déjà
        when sqlstate '42P01' then
    end;
$$
language plpgsql;

&lt;/source&gt;

=== Nombre d'éléments par statut d'EDP des lots d'une campagne donnée ===
Cette requête sert notamment à contrôler que les statistiques d'une campagne et des lots correspondent à la réalité (nombre d'éléments et nombre d'éléments traités)
&lt;source lang="sql"&gt;
define CAMPAGNE_ID = 38375002 /* Campagne BT PERF - 14/06/2010 */
select c.id as "id cmp"
, c.libelle as "lib cmp"
, l.id as "id lot"
, l.libelle as "lib lot"
, c.nombreelements as "nb éléments cmp"
, c.nombreelementstraites as "nb éléments traités cmp"
, l.nbelements as "nb éléments lot"
, l.nbelementstraites as "nb éléments traités lot"
, elt.statut as "statut edp"
, count(*) as "nb par statut"
from telementdepopulationreleve elt, tlot l, tcampagne c
where elt.lot_id = l.id
and l.campagne_id = c.id
and c.id = &amp;CAMPAGNE_ID
group by c.id, c.libelle, l.id, l.libelle
, c.nombreelements 
, c.nombreelementstraites
, l.nbelements 
, l.nbelementstraites 
, elt.statut 
order by c.id, l.id;
&lt;/source&gt;

=== Liste des EDP + leurs statuts &amp; anomalies des campagnes ===
&lt;source lang="sql"&gt;
define CAMPAGNES_ID = in ('6431096003','6431096001','6431096002','6431096004','6431096005')
select pds.reference, elt.statut, elt.enanomalie, ano.typeanomalie, ano.commentaire, ano.donneecontextuelle, c.libelle, l.libelle
from tcampagne c, tlot l, telementdepopulationreleve elt, tpointdeservice pds, tanomalie ano
where c.id = l.campagne_id and l.id = elt.lot_id and pds.id = elt.pointdeservice_id
and c.statut = 0 and l.statut = 0
and ano.elementpopulation_id(+) = elt.id
and c.id &amp;CAMPAGNES_ID
order by c.libelle, l.libelle, pds.reference, ano.typeanomalie, ano.commentaire, ano.donneeContextuelle;
&lt;/source&gt;

=== Requêtes préparant les requêtes de sélection du batch REL001MT ===
Ces requêtes sont exécutées en début de batch REL001MT, avant les requêtes de sélection des PDS dans la table BATCH_PDS à proprement parler. Il faut préalablement passer ce script pour que les requêtes pour avoir une chance de sélectionner des PDS dans la table avec les requêtes de sélection des PDS.
&lt;source lang="sql"&gt;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (1, 1, 1) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (1, 4, 4) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (1, 3, 3) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (1, 5, 5) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (1, 2, 2) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (2, 1, 1) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (2, 4, 4) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (2, 3, 3) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (2, 5, 5) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (2, 2, 2) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (5, 1, 1) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (5, 4, 4) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (5, 3, 3) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (5, 5, 5) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (5, 2, 2) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (7, 1, 1) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (7, 4, 4) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (7, 3, 3) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (7, 5, 5) ;
 insert into TMP_BATCH_ENUMSOUSETAT (activite, SousEtatCampagne, SousEtatPDS) values (7, 2, 2) ;

 insert into TMP_BATCH_LOT (ID, ROLE, MODELELOT_ID, CAMPAGNE_ID, MODELECAMPAGNE_ID, TYPELOT, TYPEMODELELOTPERMANENT, CATEGORIESTOURNEE, ACTIVITES, SOUSETATSPDS, AVEC_CONF_MAT, AVEC_TOURNEE_LOT, AVEC_TOURNEE_CAMP, ESTIMATIVE) 	select l.id, l.role, l.modeleDeLot_id, camp.id, camp.modeleCampagne_id, ml.typelot, ml.typemodelelotpermanent , ';'||nvl(ml.categoriestournee, mc.categoriestournee)||';' as categoriestournee , ';'||nvl(ml.activites, mc.activites)||';' as activites , ';'||mc.SOUSETATSPDS||';' as SOUSETATSPDS , (select count(1) from MDLCMPRELEVE_CONFIGMATERIELLE MDLCONF     where  MDLCONF.SOURCE = mc.id and rownum &lt; 2 ) as avecConfigMat , (select count(1) from MdlLotReleveTSP_Tournee MDLTO     where  MDLTO.SOURCE = ml.id and rownum &lt; 2 ) as avecTourneesLot, (select count(1) from MDLCMPRELEVE_TOURNEE MDLTO      where  MDLTO.SOURCE = mc.id and rownum &lt; 2 ) as avecTourneesCampagne , decode(camp.echeancedeclenchee_id, null, 0, (select e.estimative from techeancedereleve e     where e.id = camp.echeancedeclenchee_id)) as estimative 	from tlot l 	inner join tcampagne camp on camp.id = l.campagne_id   AND mod(camp.ETATOBJET,2)=0 	inner join tmodeledelotreleve ml on ml.id = l.modeledelot_id 	inner join tmodeledecampagnereleve mc on mc.id = camp.modelecampagne_id  where  (ml.typelot = 7   or ( ml.typelot = 6        and ml.TYPEMODELELOTPERMANENT = 5   )  or ( ml.typelot IN (0, 1)       and nvl(l.nbelements, 0) = 0 )   )	and l.statut = 0  AND mod(l.ETATOBJET,2)=0;

&lt;/source&gt;

=== Requête de comparaison des EDP Relève ===
Cette requête est utile lorsqu'on souhaite comparer l'exécution de batchs de relève (notamment REL001MT et REL005MT) avant et après des développements pour vérifier s'il n'y a pas de regressions.&lt;br&gt;
En plus des EDP des campagnes servant de test, la requête renvoie la réf. du PDS et les anomalies qui ont pu être créées.
Cela donne une bonne indication de la manière dont les EDP de relève ont été traités et permet de détecter rapidement les plus grosses regressions.
&lt;source lang="sql"&gt;
select pds.reference, elt.statut, elt.enanomalie, ano.typeanomalie, ano.commentaire, ano.donneecontextuelle, c.libelle, l.libelle
from tcampagne c, tlot l, telementdepopulationreleve elt, tpointdeservice pds, tanomalie ano
where c.id = l.campagne_id and l.id = elt.lot_id and pds.id = elt.pointdeservice_id
and c.statut = 0 and l.statut = 0
and ano.elementpopulation_id(+) = elt.id
and c.id in (
&lt;mettre les id des campagnes qui servent au test&gt;
)
order by c.libelle, l.libelle, pds.reference, ano.typeanomalie, ano.commentaire, ano.donneeContextuelle;
&lt;/source&gt;
=== Simulation d'un retour TSP pour toutes les relèves de campagnes ===
Les requêtes suivantes permettent de simuler l'injection de fichiers de relève (DVO, SaturneRL...) :
* passage des EDP du statut 'sélectionné' au statut 'relevé'
* mise à jour de la relève à calculer : date = date de la relève précédente + 1jour
* mise à jour des index : valeur = valeur de l'index précédent + 10

Il est ensuite possible de passer le batch REL005MT pour qu'il calcule les consommations des relèves.&lt;br&gt;
Les scripts doivent être exécutés après sélection des EDP de relève (REL001MT).

* Script 1 : sélection des id des campagnes dont on souhaite traiter les relèves (exemple de requête). &lt;br&gt;
Les id des campagens récupérées doivent être mis dans la variable ID_CAMPAGNES défini comme dans l'exemple ci-dessous.
&lt;source lang="sql"&gt;
select id, libelle from tcampagne where libelle in 
('Relève BT 02 - 30/01/2012','Relève BT 08 - 31/01/2012')
or datecreation &gt; to_date('06/08/2012','dd/mm/yyyy') 
and statut = 0
and modelecampagne_role = 'com.hermes.itv.releve.businessobject.ModeleDeCampagneDeReleve';

-- déclaration de la variable contenant tous les id de campagnes dont on va metre à jour les relèves
define ID_CAMPAGNES = ('5796407002','5799223003','5799223008','5797105001','5799223007','5799223012','5799223005','5799223010','5799223004','5799223009','5799223001','5799223006','5799223011','5799223002')
;
&lt;/source&gt;

* Script 2 : Mise à jour des EDP, Relèves et grandeurs physiques de type relevé :
** temps moyen requête 1 : 12 sec.
** temps moyen requête 2 : 16 sec.
** temps moyen requête 3 : 500 sec.
&lt;source lang="sql"&gt;
-- Passage des EDP au statut 'relevé'
update telementdepopulationreleve e set statut = 3 
where statut = 0 
and e.lot_id in (select l.id from tlot l , tcampagne c
where l.campagne_id in &amp;ID_CAMPAGNES );

-- Mise à jout de la date de la relève à calculer : date relève = date relève précédente + 1 jour
update treleve rel set datereleve = (select relprec.datereleve +1
from treleve relprec where rel.releveprecedente_id = relprec.id)
where rel.statutreleve = 3 -- en cours de traitement
and exists (select * from telementdepopulationreleve elt, tlot l
where elt.releve_id = rel.id
and elt.statut = 3 -- statut relevé
and elt.lot_id = l.id
and l.campagne_id in &amp;ID_CAMPAGNES
);

-- Mise à jour des grandeurs physiques de type index : valeur = valeur index précédent + 10
update tgrandeurphysiquegenerale gp set valeur = (select gpprec.valeur +10
from tgrandeurphysiquegenerale gpprec, treleve rel, treleve relprec
where gp.releve_id = rel.id
and rel.releveprecedente_id = relprec.id
and gpprec.releve_id = relprec.id
and gpprec.modelegrandeurphysique_id = gp.modelegrandeurphysique_id)
where exists (select * from telementdepopulationreleve elt, tlot l, tmodelegrandeurphysique mgp, tgrandeurphysiquegenerale gp1
where elt.releve_id = gp1.releve_id
and elt.statut = 3 -- relevé
and elt.lot_id = l.id
and mgp.id = gp1.modelegrandeurphysique_id
and mgp.releveoucalcule = 0 -- relevé uniquement
and mgp.typegrandeur = 1 -- energie
and mgp.soustype = 1 -- active
and mgp.structureinformation = 1 --index
and l.campagne_id in &amp;ID_CAMPAGNES
and gp1.id = gp.id
);
&lt;/source&gt;

==== Validation des releves en anomalies ====
* Dans le cas ou certaines releves sont non conformes, il est possible de faire une "validation manuelle" via le script :
&lt;source lang="sql"&gt;
-- validation manuelle des anomalies
UPDATE tanomalie
SET statutanomalie=2
WHERE id         IN
(SELECT a.id
FROM tanomalie a,
  telementdepopulationreleve e
WHERE a.elementpopulation_id=e.id
AND e.lot_id                 IN (SELECT id from tlot where campagne_id IN &amp;ID_CAMPAGNES)
AND a.typeanomalie         IN ('810','800','801','1210','820') and a.statutanomalie=0
);

&lt;/source&gt;
Il faut ensuite repasser REL005MT.

== Détection des PDS avec plusieurs modalités de relève ==
Requête utile pour détecter des cas en anomalie avec REL001MT 

&lt;source lang="sql"&gt;
SELECT PDS.REFERENCE
FROM TPOINTDESERVICE PDS
	JOIN TSERVICESOUSCRIT SS 	ON SS.POINTDESERVICE_ID = PDS.ID
	JOIN TCONTRAT CTR 	ON CTR.ID = SS.CONTRAT_ID
	JOIN TMODALITERELEVE MREL	ON MREL.ID = CTR.MODALITERELEVE_ID
	JOIN TOFFREPRODUIT OFP	ON OFP.ID = CTR.OFFREPRODUIT_ID
	JOIN TMODALITEFACTURATION MPAY	ON MPAY.ID = OFP.MODALITEFACTURATION_ID
	JOIN TCONDITIONPAIEMENT CP 	ON CP.ID = CTR.CONDITIONPAIEMENT_ID
	LEFT JOIN TECHEANCIERPMTPARMENSU ECH ON (ech.id = cp.echeancierpaiement_id and mod(ech.etatobjet,2) = 0)
WHERE PDS.activite              != 4
	AND SS.TYPESERVICESOUSCRIT       = 0
	AND SS.STATUT                   IN (1, 3)
	AND SS.DIRECTEUR                 = 1
	AND CTR.STATUTEXTRAIT           IN (1, 2, 3)
	AND OFP.FOURNITUREOUACHEMINEMENT = 2
	AND mod(ss.etatobjet,2)          =0
	AND mod(pds.etatobjet,2)         =0
	AND mod(ctr.etatobjet,2)         =0
	AND mod(mrel.etatobjet,2)        =0
	AND mod(ofp.etatobjet,2)         =0
	AND mod(mpay.etatobjet,2)        =0
GROUP BY PDS.REFERENCE,	PDS.ID
HAVING COUNT(*)&gt;1;
&lt;/source&gt;

== Statistiques de durée de relève et du nombre d'estimation ==
La requête suivante se base sur la dernière relève présente sur un PDS élec bt actif. Elle permet se base toujours sur la dernière relève du PDS
* ANC_DERNIERE_RELEVE : ancienneté de la relève (moyenne en nb de jours)
* ANC_RELEVE_PREC : durée moyenne par rapport à la relève précédente
* ANC_RELEVE_REELLE_PREC : durée moyenne par rapport à la relève réelle précédente
* PRCT_RELEVE_REELLE : pourcentage de relèves réelles
* PRCT_RELEVE_PREC_REELLE : pourcentage de relèves précédentes réelles 
* PRCT_RELEVE_PREC_NON_ESTIMEE : pourcentage de relèves pour lesquelles la relève précédente et la relève réelle précédente sont identiques
* PRCT_LINKY : pourcentage de relève utilisant une PACalendrier
* NB_PDS : nb de PDS traités

&lt;source lang="sql"&gt;
with PACM as (
  select pacm.id as PACM_ID, dernierereleve.ID as DERNIERERELEVE_ID,
  DERNIERERELEVE.RELEVEPRECEDENTE_ID as RELEVE_PRECEDENTE_ID,
  DERNIERERELEVE.RELEVEREELLEPRECEDENTE_ID as RELEVE_REELLE_PRECEDENTE_ID,
  dernierereleve.DATERELEVE as DATEDERNIERERELEVE 
  from tpointdeservice pds
  join tpacm pacm on pds.id = pacm.pointdeservice_id
    and mod(pacm.etatobjet,2) = 0
    and pacm.datefin is null
    and pacm.statutvalide = 1
  join treleve dernierereleve on dernierereleve.pacm_id = pacm.id
    and mod(dernierereleve.etatobjet,2)=0
    and not exists (select 1 from treleve rsuivante 
        where mod(rsuivante.etatobjet,2) = 0 
        and rsuivante.datereleve &gt; dernierereleve.datereleve 
        and rsuivante.pacm_id = dernierereleve.pacm_id)
  where mod(pds.etatobjet,2) = 0
  and pds.etat = 4
  and PDS.NIVEAUDETENSION=3
  and pds.activite=0),
stats as (select current_date - TMP.DATEDERNIERERELEVE as ANCIENNETE_DERNIERE_RELEVE,
  TMP.DATEDERNIERERELEVE - (select datereleve from treleve r where r.id = tmp.RELEVE_PRECEDENTE_ID) as DUREERELEVE,
  TMP.DATEDERNIERERELEVE - (select datereleve from treleve r where r.id = tmp.RELEVE_REELLE_PRECEDENTE_ID) as DUREERELEVEREELLE,
  (select nvl2(r.pacalendrier_id,1,0) from treleve r where r.id = tmp.DERNIERERELEVE_ID) as AVEC_CALENDRIER,
  (select decode(r.naturereleve, 1,1,41,1,51,1, 6,1,0) from treleve r where r.id = tmp.DERNIERERELEVE_ID) as RELEVE_REELLE,
  (select decode(r.naturereleve, 1,1,41,1,51,1, 6,1,0) from treleve r where r.id = tmp.RELEVE_PRECEDENTE_ID) as RELEVE_PRECEDENTE_REELLE,
  case when TMP.RELEVE_PRECEDENTE_ID = TMP.RELEVE_REELLE_PRECEDENTE_ID THEN 1 else 0 end as SANS_RELEVE_ESTIMEE_PRECEDENTE
from PACM TMP)
select 
  (select avg(ANCIENNETE_DERNIERE_RELEVE) from stats where ANCIENNETE_DERNIERE_RELEVE &gt; 0) as ANC_DERNIERE_RELEVE,
  (select avg(DUREERELEVE) from stats where DUREERELEVE &gt; 0)  as ANC_RELEVE_PREC,
  (select avg(DUREERELEVEREELLE) from stats where DUREERELEVEREELLE &gt; 0) as ANC_RELEVE_REELLE_PREC,
  (select 100*avg(RELEVE_REELLE) from stats where RELEVE_REELLE is not null) as PRCT_RELEVE_REELLE,
  (select 100*avg(RELEVE_PRECEDENTE_REELLE) from stats where RELEVE_PRECEDENTE_REELLE is not null) as PRCT_RELEVE_PREC_REELLE,
  (select 100*avg(SANS_RELEVE_ESTIMEE_PRECEDENTE) from stats where SANS_RELEVE_ESTIMEE_PRECEDENTE is not null) as PRCT_RELEVE_PREC_NON_ESTIMEE,
  (select 100*avg(AVEC_CALENDRIER) from stats where AVEC_CALENDRIER is not null) as PRCT_LINKY,
  (select count(*) from stats) as NB_PDS
  from dual;
&lt;/source&gt;

=Interface/releve=
==LKY06==
[[Utilisation des classes de simulation pour LKY06]]

==Historique de mesures (SMO)==
Historique de mesures (ou SMO, Systèmes de Mesures Optionnels)

Fonctionnellement, un client peut s'abonner à un service optionnel de mesure pour récupérer le détail de ses consommations à une période donnée.
Pour cela, efluid met à disposition deux mécanismes, dits '''"historiques de mesures"''' :
* '''AEL-GRD''' qui appelle le service Rest "historique de mesures" pour récupérer les consommations (relèves et courbes) 
* '''une campagne de Workflow''' de publication en masse des historique de mesure (passe notamment par le batch CNT038MT)

Selon du paramétrage défini dans efluid, les données de consommations peuvent être récupérées de différents sources : 
* données stockées dans '''Efluid''' (résultant de recherches dans la Bdd efluid)
* données demandées au '''SEC''' (SmartEnergyCore) : appel de l'interface EF02
* données demandées au '''SI Linky''' : appel de l'interface LKY02
* données demandées au '''SI EOT''' : appel de l'interface de consultation des relèves / courbe d'EOT

efluid sert donc de passerelle '''d'un SI Tiers''' (visible du client, comme l'AEL) vers un autre SI Tiers (stockage des données de consommations) pour aller chercher les données de consommations.

Les '''natures d'action''' permettent de définir quel SI Tiers interroger pour récupérer les données de consommations.

Le processus de récupération des historiques de mesure peut être représenté par le schéma ci-dessous :

[[Fichier:HistoriqueDeMesureSynthèse.png]]

===Paramétrage et outils nécessaires pour tester un appel Rest historique de mesures===
[[Historique des mesures : Paramétrage et outils nécessaires pour tester un appel REST]]

===Description des traitements codés===
[[Historique de mesures : Description des traitements codés]]</text>
      <sha1>21h5kv381igdu2mt6xl7gpvkg8t85ic</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine prévision</title>
    <ns>0</ns>
    <id>1389</id>
    <revision>
      <id>49211</id>
      <parentid>14465</parentid>
      <timestamp>2013-07-23T08:23:50Z</timestamp>
      <contributor>
        <username>Bullot</username>
        <id>45</id>
      </contributor>
      <origin>49211</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5068" sha1="odphrdx2a94idwmz2s1jyeljhh9h79s" xml:space="preserve">{{Modèle:Domaine
 | nom= Prévision
 | trigramme= PRV
 | referent= [[NBE]]
 | responsable= [[BBU]]
 | recetteurs = [[NBE]] / [[TSC]] / [[CGR]]
}}
== ecore ==

=== Documentation ===

* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid efluid - Documentation Fonctionnelle] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_415c5 AFD suite efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f645 AFD ecore] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_9204b PRV - Domaine prévision]

=== Classification ===

==== Généralités ====

La classification est effectuée par la société Metnext (météo France) via leur service Decide. Voir la documentation sur eroom 

* [http://wperoom1/eRoom/Production/DocTechniqueEfluid efluid - Documentation Technique] &gt; [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_4063c DCT suite efluid] &gt; [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6ec1e DCT ecore] &gt; [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6ec21 Conception] &gt; [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_91f24 PRV - Domaine prévision] &gt; [http://wperoom1/eRoomReq/Files/Production/DocTechniqueEfluid/0_a6ef1/ENERCOM_DECIDE_WEBSERVICES_V7.docx ENERCOM_DECIDE_WEBSERVICES_V7.docx]

==== Tests du service avec SoapUI ====

Il est possible de tester le service de classification via SoapUI de la manière suivante :

# Télécharger et installer SoapUI.
# Trouver la définition du wsdl de Decide dans ecore, normalement "wsdl/decide/Decide.wsdl".
# Copier l'URL du wsdl (targetNamespace), normalement "http://lrsrvmxt2/en/mxtws/".
# Dans SoapUI, faire "File -&gt; New Project", puis dans la fenêtre entrer
## Project Name : ecore decide
## Initial WSDL/WASL : &lt;URL du wsdl&gt;
# Cela va créer un template. Remplir les éléments avec l'enveloppe ici-bas.
# Envoyer la demande, le résultat reçu va s'afficher à droite.

&lt;source lang="xml"&gt;
&lt;soapenv:Envelope xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:mxt="http://lrsrvmxt1/en/mxtws/"&gt;
   &lt;soapenv:Header/&gt;
   &lt;soapenv:Body&gt;
      &lt;mxt:classify soapenv:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"&gt;
         &lt;obj_classification_in xsi:type="mxt:obj_classification_in"&gt;
            &lt;!-- Entrer le dossier de sortie, il doit être disponible en écriture pour Metnetx (voir avec IT) --&gt;
            &lt;URI_in xsi:type="xsd:string"&gt;/smb/batchsenercom/DEV/files/fichierIN/decide/&lt;/URI_in&gt;
            &lt;!-- Entrer la liste de fichier à envoyer --&gt;
            &lt;array_cdc_in xsi:type="soapenc:Array" xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/"&gt;
               &lt;!-- Fichier de consommation exporté en csv --&gt;	
               &lt;item&gt;UEM_METZ_CONSO_6320_1338466279648.csv&lt;/item&gt;
            &lt;/array_cdc_in&gt;
         &lt;/obj_classification_in&gt;
      &lt;/mxt:classify&gt;
   &lt;/soapenv:Body&gt;
&lt;/soapenv:Envelope&gt;
&lt;/source&gt;

==== Paramétrage ====

Le paramétrage doit correspondre à ce qui est dans l'enveloppe (voir ici haut). Il est possible d'utiliser le serveur de batch d'enercom dans le dossier DEV, mais il faut s'assurer que les droits d'écritures sont valides. Voir [[Enercom - Emplacements serveurs et fichiers]].

&lt;source lang="bash"&gt;
# Répertoire de dépôt de fichiers pour l'interface enercom -&gt; decide, vu depuis le serveur batch enercom
REPERTOIRE_ENTREE_DECIDE=\\\\172.16.1.7\\batchsenercom\\DEV\\files\\fichierIN\\decide\\
 
# Répertoire de dépôt de fichiers pour l'interface decide -&gt; enercom, vu depuis le serveur batch enercom
REPERTOIRE_SORTIE_DECIDE=\\\\172.16.1.7\\batchsenercom\\DEV\\files\\fichierOUT\\decide\\
 
# Répertoire de dépôt de fichiers pour l'interface enercom -&gt; decide, vu depuis le serveur decide (doit se terminser par un slash)
REPERTOIRE_ENTREE_DECIDE_METNEXT=/smb/batchsenercom/DEV/files/fichierIN/decide/
 
# Répertoire de dépôt de fichiers pour l'interface decide -&gt; enercom, vu depuis le serveur decide (doit se terminser par un slash)
REPERTOIRE_SORTIE_DECIDE_METNEXT=/smb/batchsenercom/DEV/files/fichierOUT/decide/
&lt;/source&gt;

== Decide ==
L'application Decide, utilisée pour les calculs de classification et de prévision, est installée sur 4 serveurs:
- serveur de développement / intégration : lrsrvmxt2
- serveur de recette : lrsrvmxt1
- serveur de validation / pré-production : lvsrvmxt1
- serveur de production : lpsrvmxt1

Il arrive que les prévisions soient bloquées sur l'application Decide, sur une ou plusieurs famille Decide. Il convient alors de demander à S&amp;R d'effectuer les opérations suivantes sur le serveur Decide concerné :
# Relancer la machine : shutdown –r now
# Indiquer les jobs restants comme terminés
## psql –d decide –U postgres
## update job_list set job_status_id = 4 where job_status_id != 4;
## update job_unit set processing = 0 where processing != 0;
## update enercom_jobs set status = 4 where status != 4;


== enercom ==

TODO

== Liens externes ==

[[Category:ecore]]
[[Category:domaine]]</text>
      <sha1>odphrdx2a94idwmz2s1jyeljhh9h79s</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine courbe</title>
    <ns>0</ns>
    <id>1387</id>
    <revision>
      <id>14463</id>
      <parentid>14458</parentid>
      <timestamp>2012-07-16T09:38:51Z</timestamp>
      <contributor>
        <username>Dubreui</username>
        <id>76</id>
      </contributor>
      <origin>14463</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4406" sha1="jq955zmmoaqx80mg1hsdwa84psbr6nd" xml:space="preserve">{{Modèle:Domaine
 | nom= Courbe
 | trigramme= COU
 | referent= [[NBE]]
 | responsable= [[BBU]]
 | recetteurs = [[NBE]] / [[TSC]] / [[CGR]]
}}
== ecore ==

=== Documentation ===

* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid efluid - Documentation Fonctionnelle] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_415c5 AFD suite efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f645 AFD ecore] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f649 COU - Domaine courbe]

=== Algorithmes ===

La brique ecore fournit une liste d'algorithme pour traiter les courbes et les grandeurs. Ces traitement sont définis dans le document ici haut et ici sont résumés les différents appels possibles aux algorithmes.

==== Généralités ====

Tous les appels d'algorithme se font avec un ''AlgorithmeContext'' et retournent un ''AlgorithmeContext'' qui n'est pas nécessairement le même que le premier. Si c'est le même, il est garanti que l'original n'a pas subit de suppression. Le contexte d'algorithme contient un algorithme ; c'est le contexte qui est envoyé au process afin de procéder à l'exécution. L'algorithme est récupérer en base à chaque fois, il est interdit de faire l'appel new Algorithme(), qui est deprécié. Il faut faire l'appel suivant :

&lt;source lang="java" style="border:none;"&gt;
	// Récupération de l'algorithme clone
	Algorithme algorithme = AlgorithmeFactory.getInstance().get(new AlgorithmeFactory.ParAlgorithme().traitement(EAlgorithme.ALGORITHME_CLONE));
&lt;/source&gt;

Ensuite, il faut construire le contexte :

&lt;source lang="java" style="border:none;"&gt;
	// Création d'un contexte vide avec l'algorithme clone comme traitement
	AlgorithmeContext algorithmeContext = new AlgorithmeContext();
	algorithmeContext.setTraitement(algorithme);
&lt;/source&gt;

Puis faire l'appel au process :

&lt;source lang="java" style="border:none;"&gt;
	// Exécution de l'algorithme clone
	TraitementBusinessProcess traitementBusinessProcess = new TraitementBusinessProcess();
	AlgorithmeContext algorithmeContextRetour = (AlgorithmeContext) traitementBusinessProcess.doExecuter(algorithmeContext);
&lt;/source&gt;

Dans le cas ici haut, l'algorithme clone n'a pas suffisamment d'élément pour s'exécuter, il lance donc une ''TraitementException'' avec le détail des éléments manquants du contexte.

==== Algorithme clone ====

'''Entrée''' 
* Une liste de courbe OU une liste de grandeurs

'''Sortie'''
* Une liste de courbe clonées OU une liste de grandeurs clonées, dépendant de l'appel

Exemple d'appel :

&lt;source lang="java" style="border:none;"&gt;
	AlgorithmeContext algorithmeContext = new AlgorithmeContext();
	algorithmeContext.setTraitement(AlgorithmeFactory.getInstance().get(new AlgorithmeFactory.ParAlgorithme().traitement(EAlgorithme.ALGORITHME_CLONE)));
	algorithmeContext.setCourbes(courbes);

	TraitementBusinessProcess traitementBusinessProcess = new TraitementBusinessProcess();
	AlgorithmeContext algorithmeContextRetour = (AlgorithmeContext) traitementBusinessProcess.doExecuter(algorithmeContext);

        Collection&lt;Courbe&gt; courbesClonees = algorithmeContextRetour.getCourbes();
&lt;/source&gt;

=== Gestion des valeurs ===

==== Réduction du nombre de valeurs ====

Lorsqu'il y a chargement d'une courbe ou d'une grandeur, on charge toujours plus de point que ce qui est demandé, puisque le mode de stockage en base (BLOB) implique que charger une année n'est pas plus lent que de charger un seul point (ou presque). Il convient donc de faire deux opérations afin de réduire le nombre de point, sans modifier la courbe existante (et risquer de la persister avec moins de points et perdre ses valeurs), soit (1) faire un clone de la courbe (2) réduire les points.

L'algorithme clone est décrit ici haut. Pour réduire le nombre de point, l'appel suivant fonctionne, mais est assez lent.

&lt;source lang="java" style="border:none;"&gt;
	// Récupération des valeurs entre une dateDebut et une dateFin
        Collection&lt;Valeur&gt; valeurs = new ArrayList&lt;Valeur&gt;();
        for (Valeur val : grandeur.getValeurs().subMap(dateDebut, dateFin).values()) {
          valeurs.add(val);
        }

	// Suppression des valeurs courantes et rajout des valeurs
	grandeur.clearValeurs();
	grandeur.addAllToValeurs(valeurs);
&lt;/source&gt;

== efluid ==

TODO

== enercom ==

TODO

== Liens externes ==

[[category:domaine]]
[[category:ecore]]</text>
      <sha1>jq955zmmoaqx80mg1hsdwa84psbr6nd</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine courbe agrégée</title>
    <ns>0</ns>
    <id>1388</id>
    <revision>
      <id>14464</id>
      <parentid>14459</parentid>
      <timestamp>2012-07-16T09:38:53Z</timestamp>
      <contributor>
        <username>Dubreui</username>
        <id>76</id>
      </contributor>
      <origin>14464</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="630" sha1="mivvz81if5xif4a6myyg5c9c4lhlqyv" xml:space="preserve">{{Modèle:Domaine
 | nom= Courbe agrégée
 | trigramme= CAG
 | referent= [[NBE]]
 | responsable= [[BBU]]
 | recetteurs = [[NBE]] / [[TSC]] / [[CGR]]
}}
== ecore ==

=== Documentation === 

[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid efluid - Documentation Fonctionnelle] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_415c5 AFD suite efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f645 AFD ecore] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f64c COA - Domaine courbe agrégée]

== enercom ==

TODO

== Liens externes ==

[[category:ecore]]
[[category:domaine]]</text>
      <sha1>mivvz81if5xif4a6myyg5c9c4lhlqyv</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine consommation</title>
    <ns>0</ns>
    <id>138</id>
    <revision>
      <id>4069234</id>
      <parentid>4069232</parentid>
      <timestamp>2023-05-02T08:23:14Z</timestamp>
      <contributor>
        <username>Delapor</username>
        <id>761</id>
      </contributor>
      <origin>4069234</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="26495" sha1="4efrptkgg56smyc5051bey3cbge59bg" xml:space="preserve">[[category:Domaine]]
[[category:Domaine consommation]]
== Modèle simplifié ==
C'est un modèle simplifié qui n'a pas vocation à remplacer l'AFD.

[[Image:Modèle consommation.jpg]]
== AFDs ==
[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_50654 eRoom]

Documentation logigramme moteur estimation : http://wperoom3.uem.lan/eRoomReq/Files/Prod11/DocFonctionnelleSuiteEfluid/0_2bbed

Les AFDs "archivées" ne sont pas représentées ci-dessous.

* AFD - affichage historique conso sur facture.doc
** Cas d'utilisation "Gérer historique de consommation sur facture"
** Cas d'utilisation "Afficher la nature de la facture réalisée"
** Cas d'utilisation "Afficher la nature de chaque index"
** Cas d'utilisation "Afficher une consommation annuelle sur le contrat"
** Cas d'utilisation "Afficher des chiffres d'affaire HT et TTC sur le contrat"

* AFD - CNS - Calcul à la courbe de charge V3.doc
** Cas d'utilisation "Gérer les fonctions de paramétrage des installations de comptage"
** Cas d'utilisation "Gérer les grandeurs physiques"
** Cas d'utilisation "Calculer les grandeurs physiques"
** Gestion des totaliseurs
*** Définition du Cas "PSA METZ-BORNY – DLX N° 29031"
*** Définition du Cas "PSA TREMERY – DLX N° 29030 1"
*** Définition du Cas "PSA TREMERY – DLX N° 29030 1"
*** Définition du Cas "PSA TREMERY – DLX N° 29030 2"
*** Définition du Cas "GASTEC – DLX N° 21828"
*** Définition du Cas "BELLE ISLE - DLX N° 20000"
*** Définition du Cas "FC METZ – DLX N° 21829"
*** Définition du Cas "HIA LEGOUEST – DLC32 N°00055"

** Références courbes (Saturne)
*** Cas d'utilisation "Pose d'un compteur"
*** Cas d'utilisation "Échange d'un compteur"
*** Cas d'utilisation "Changement de programme d'un compteur"
*** Cas d'utilisation "Déplacement d'un compteur"
*** Cas d'utilisation "Déplacement d'un compteur"

* AFD - CNS - Consommation.doc
** Exemples de configurations matériels types
** Concepts
** Cas d'utilisation "Gérer les fonctions de paramétrage des installations de comptage"
** Cas d'utilisation "Saisir la relève et les grandeurs physiques"
** Cas d'utilisation "Gérer les instances de relève et les grandeurs physiques dans le cadre d’une saisie de carte T ou pour régularisation"
** Cas d'utilisation "Calculer les grandeurs physiques"
** Cas d'utilisation "Calculer les grandeurs physiques"
** Cas d'utilisation "Estimer des grandeurs physiques"
** Activité Gaz

* AFD - PDS en décompte validée V1.doc
** Concepts
** Création des configurations matérielles en décompte
** Paramétrage de la configuration matérielle lors du CRI
** Paramétrage de la configuration matérielle lors du CRI
** Consultation des paramètres d'une configuration matérielle en décompte
** Calcul des consommations d'une instance de relève de matérielle en décompte
** Présentation de la facture
** Description des cas en électricité

* AFD - SSC- gestion des PDS sans comptage V3.doc
** Domaine EDL - PDS
** Domaine Consommation
** Domaine Intervention
** Domaine Relève
** Domaine Offre Produit, Contrat et Moteur
** Reconstitution des flux

* AFD Calcul énergie en compteur.doc
** Impacts sur le domaine Campagne
** Impacts sur le domaine Offre Produit
** Impacts sur le domaine EDL - PDS
** Impacts sur le domaine Relève et Facturation
** Détails des traitements

* AFD complément adaptation consommation juin2006.doc
** Contrôle des séquences d'Index
** Contrôle de cohérence sur grandeur physique
** Dépendance des attributs de la relève

== Campagnes du domaine ==
[[Campagne d'énergie en compteur|Campagne d'énergie en compteur]]
[[Campagne de calcul de la CAR|Campagne de calcul de la CAR]]
[[Campagne d'import de la CAR|Campagne d'import de la CAR]]
== Documentation sur les notions de circuit électrique ==

=== Notions physiques ===

* Notions de base sur les circuits électriques et l'énergie réactive
[http://www.energieplus-lesite.be/index.php?id=16980 L'électricité : production et réseau]

* Informations sur les transformateurs
[http://www.energieplus-lesite.be/index.php?id=11485 Les transformateurs]

[http://www.tsv-transfo.com/index.mc.Fonctionnement-transformateur-pertes.rub_id.217.rub2_id.774.html A quoi sert un transformateur?]

=== Comptage ===
Cahier des charges de la CRE sur le comptage électrique : http://www.cre.fr/documents/deliberations/communication/comptage-electrique


== Requêtes utiles ==
=== Purge campagne de valorisation de l'énergie en compteur (CNS001MT) ===
&lt;source lang="sql"&gt;
define CAMPAGNE_ID =6466432001

DELETE FROM tanomalie
WHERE elementpopulation_id IN
  (SELECT edp.id FROM telementdepopulationconso edp, tlot l WHERE l.campagne_id='&amp;CAMPAGNE_ID' AND edp.lot_id=l.id
  );

DELETE
FROM telementdepopulationconso
WHERE lot_id IN
  (SELECT l.id FROM tlot l WHERE l.campagne_id='&amp;CAMPAGNE_ID'
  );
 
UPDATE tcampagne c SET c.nombreelements=0 WHERE id='&amp;CAMPAGNE_ID'; 
UPDATE tcampagne c SET c.nombreelementstraites=0 WHERE id='&amp;CAMPAGNE_ID'; 
UPDATE tcampagneenergieencompteur
SET montanttotal=0, energietotale=0,energietotalerelevee=0,montantenergietotale=0,
montantenergietotalerelevee=0, montantprimefixetotale=0, energietotalenonrelevee=0, mtprimefixegrd=0,
mtenergiefournisseur=0, mtenergiegrd=0, mtenergienonrelevegrd=0, mtenergienonrelevefournisseur=0,
mtenergierelevefournisseur=0, mtenergierelevegrd=0, mtprimefixefournisseur=0
WHERE id='&amp;CAMPAGNE_ID';
UPDATE tlot l SET l.nbelements=0, l.nbelementstraites=0, l.selectionrealisee=0 WHERE l.campagne_id='&amp;CAMPAGNE_ID'; 
DELETE tresultatdetailenergieoffre WHERE campagne_id='&amp;CAMPAGNE_ID';
DELETE tresultatdetailenergieservice WHERE campagne_id='&amp;CAMPAGNE_ID';
DELETE tresultatenergieoffre WHERE campagne_id='&amp;CAMPAGNE_ID';
DELETE tresultatenergieservice WHERE campagne_id='&amp;CAMPAGNE_ID';

&lt;/source&gt;

=== Recherche des points de service avec des historiques de conso mensuelles manquantes ===
&lt;source lang="sql"&gt;
-- recherche des PDS avec un historique de consommation mensuelles incomplet
with DOUBLONS as (select h.pds_id, count(*) as nombre from thistoriqueconsomensuelle h
where mod(h.etatobjet,2) = 0
group by h.pds_id
having count(*) != 12)
select pds.reference, d.nombre, pds.activite from tpointdeservice pds, doublons d where pds.id = d.pds_id
order by pds.activite, pds.reference;

-- création des historiques manquant
insert into THISTORIQUECONSOMENSUELLE (id, acteurcreation, datecreation, codegrd, codefournisseur, etatobjet, mois, pds_id, objetmaitre_id, objetmaitre_role)
with pds2 as (select  H.PDS_ID as pdsId, H.codeGRD, H.codeFournisseur, H.objetmaitre_role from THISTORIQUECONSOMENSUELLE h where mod(h.etatobjet,2) = 0 
  group by h.pds_id, H.codeGRD, H.codeFournisseur, objetmaitre_role having count(*) &lt; 12)
  ,numbers as ( select level as nb from dual connect by level &lt;= 12)
select uniqueid.nextval, 'evtXXXXXX', current_date, pds2.codeGRD,pds2.codeFournisseur, 0,  numbers.nb, pds2.pdsId,  pds2.pdsId, objetmaitre_role
from pds2, numbers 
where not exists (select h.id from THISTORIQUECONSOMENSUELLE h where mod(h.etatobjet,2) = 0 and h.mois = numbers.nb and h.pds_id = pds2.pdsId);
&lt;/source&gt;

=== Recherche des points de service avec plus de 12 valeurs de consommation mensuelle ===
&lt;source lang="sql"&gt;
-- recherche PACM avec plus de 12 conso mensuelles
select COUNT(*) "nb conso mensuelle", CM.PACM_ID, PDS.REFERENCE
from TCONSOMMATIONMENSUELLE CM, TPACM PACM, TPOINTDESERVICE PDS 
where CM.PACM_ID = PACM.id and PACM.POINTDESERVICE_ID = PDS.id and MOD(CM.ETATOBJET, 2)=0 
group by CM.PACM_ID, PDS.REFERENCE having COUNT(*) &gt; 12;

=== Recherche des points de service avec plus de 12 valeurs de consommation mensuelle ===
--recherche PACA avec plus de 12 conso mensuelles
SELECT COUNT(*) "nb conso mensuelle", CM.PACALENDRIER_ID, PDS.REFERENCE
FROM TCONSOMMATIONMENSUELLE CM, TPACALENDRIER PACA, TPOINTDESERVICE PDS, TPACM PACM
WHERE CM.PACALENDRIER_ID = PACA.id AND PACA.PACM_ID = PACM.id and PACM.POINTDESERVICE_ID=PDS.ID AND MOD(CM.ETATOBJET, 2)=0 group by CM.PACALENDRIER_ID, PDS.REFERENCE HAVING COUNT(*) &gt; 12;



--recherche PDS avec plus de 12 histo conso
select count(*) "nb histoconsomens", PDS.REFERENCE
from THISTORIQUECONSOMENSUELLE H, TPOINTDESERVICE PDS
where H.PDS_ID = PDS.ID and mod(H.ETATOBJET,2)=0
group by H.PDS_ID, PDS.REFERENCE having count(*) &gt; 12;

-- suppression des historiques en doublon - on garde en priorite les historiques modifies le plus récemment, sinon ceux avec la plus grande valeur
merge into THISTORIQUECONSOMENSUELLE histoModifies
using (
select hdoublon.id, hdoublon.pds_id, hdoublon.mois,  
row_number() over(partition by hdoublon.pds_id, hdoublon.mois order by hdoublon.datemodification desc nulls last, hdoublon.valeur desc nulls last, hdoublon.id desc) as rang
from THISTORIQUECONSOMENSUELLE hdoublon
where mod(hdoublon.etatobjet,2) = 0
and (hdoublon.pds_id, hdoublon.mois) in (
SELECT h.pds_id, h.mois
FROM THISTORIQUECONSOMENSUELLE H
WHERE MOD(H.ETATOBJET,2)=0
GROUP BY H.PDS_ID, h.mois  HAVING COUNT(*) &gt; 1)) tmp
on (tmp.id = histoModifies.id)
when matched then
  update set histoModifies.etatobjet = 1,
    histoModifies.datesuppression = current_timestamp,
    histoModifies.acteursuppression='evt163540'
    where tmp.rang &gt; 1;


&lt;/source&gt;

=== Suppression des historiques conso mensuelles et conso mensuelles en double ===
Penser à modifier la valeur de 'EVT' avant de passer le script (pour que le acteursuppression corresponde à une réf. d'évt)

&lt;source lang="sql"&gt;
DEFINE EVT='evt SRO-TEST'
set serveroutput on

DECLARE

TYPE REC_HISTO is record (
id THISTORIQUECONSOMENSUELLE.id%type
, pds_id THISTORIQUECONSOMENSUELLE.pds_id%type
, mois THISTORIQUECONSOMENSUELLE.mois%type
);
histo rec_histo;

-- historique conso
CURSOR C_REC_HISTO is 
select histo.id, histo.pds_id, histo.mois
from thistoriqueconsomensuelle histo, 
(select count(*), pds.id as pds_id from thistoriqueconsomensuelle h, tpointdeservice pds
where pds.id = h.pds_id
and mod(pds.etatobjet,2) = 0
and mod(h.etatobjet,2) = 0
group by pds.id
having count(*) &gt; 12) doublons
where histo.pds_id = doublons.pds_id
and mod(histo.etatobjet,2) = 0
order by histo.pds_id, histo.mois;

TYPE REC_CMENS is record (
id TCONSOMMATIONMENSUELLE.id%type
, pacm_id TCONSOMMATIONMENSUELLE.pacm_id%type
, mois TCONSOMMATIONMENSUELLE.mois%type
);
cmens REC_CMENS;

-- conso mensuelles
CURSOR C_REC_CMENS is 
select cmens.id, cmens.pacm_id , cmens.mois
from tconsommationmensuelle cmens, (
  select count(*), h.pacm_id from tconsommationmensuelle h
  where mod(h.etatobjet,2) = 0
  group by h.pacm_id
  having count(*) &gt; 12) doublons 
where cmens.pacm_id = doublons.pacm_id 
and mod(cmens.etatobjet,2) = 0
order by cmens.pacm_id, mois;

pdsPrec VARCHAR2(100);
pacmPrec VARCHAR2(100);
moisPrec number;
cpt number;

BEGIN

open C_REC_HISTO;
open C_REC_CMENS;

pdsPrec := null;
moisPrec := null;
cpt := 0;
loop
  fetch C_REC_HISTO into HISTO;
  exit when C_REC_HISTO%NOTFOUND;
  IF (pdsPrec = HISTO.PDS_ID AND moisPrec = HISTO.MOIS ) THEN
    cpt := cpt + 1;
    dbms_output.put_line('HISTO a supprimer no:'||cpt||' [id='||HISTO.ID||' / pds='||HISTO.PDS_ID||' / mois='||HISTO.mois||' ]');
    update thistoriqueconsomensuelle set etatobjet = 1, datesuppression = current_date, acteursuppression='&amp;EVT' where id=HISTO.ID;
  END IF;
  pdsPrec := HISTO.PDS_ID;
  moisPrec := HISTO.MOIS;
end loop;

pacmPrec := null;
moisPrec := null;
cpt := 0;
loop
  fetch C_REC_CMENS into CMENS;
  exit when C_REC_CMENS%NOTFOUND;
  IF (pacmPrec = CMENS.PACM_ID AND moisPrec = CMENS.MOIS ) THEN
    cpt := cpt + 1;
    dbms_output.put_line('CMENS a supprimer no:'||cpt||' [id='||CMENS.ID||' / pacm='||CMENS.PACM_ID||' / mois='||CMENS.mois||' ]');
    update tconsommationmensuelle set etatobjet = 1, datesuppression = current_date, acteursuppression='&amp;EVT' where id=CMENS.ID;
    update tgrandeurphysiquemensuelle set etatobjet = 1, datesuppression = current_date, acteursuppression='&amp;EVT' where releve_id=CMENS.ID;
  END IF;
  pacmPrec := CMENS.PACM_ID;
  moisPrec := CMENS.MOIS;
end loop;

END;
/
&lt;/source&gt;


=== copie des données d'un PDS sur un autre (apres fusion EDL) ===
Le script qui suit transfère d'une PDS source à un PDS destination les PACM (donc relève et conso mensuelle), histo conso mensuelle, PARE, PAProfil et recopie certaines info du PDS
'''Attention à s'assurer que ces concepts n'existent pas déjà sur le PDS destination, ou on risque d'avoir des doublons!'''

&lt;source lang="sql"&gt;
define PDS_SOURCE = '84911GC1';
define PDS_DEST = '84990GC1';
define EVT = 'evt 122208';

update tpacm set pointdeservice_id = (select id from tpointdeservice pds where reference ='&amp;PDS_DEST')
,datemodification= current_date, acteurmodification = '&amp;EVT'
where pointdeservice_id = (select id from tpointdeservice pds where reference ='&amp;PDS_SOURCE');

update thistoriqueconsomensuelle histo set etatobjet = 1, acteursuppression = 'evt XXX' 
where pds_id = (select id from tpointdeservice pds where reference ='&amp;PDS_DEST');

update thistoriqueconsomensuelle set pds_id = (select id from tpointdeservice pds where reference ='&amp;PDS_DEST')
,datemodification= current_date, acteurmodification = '&amp;EVT'
where pds_id = (select id from tpointdeservice pds where reference ='&amp;PDS_SOURCE');

update tperiodeactiviteprofil set pointdeservice_id = (select id from tpointdeservice pds where reference ='&amp;PDS_DEST')
,datemodification= current_date, acteurmodification = '&amp;EVT'
where pointdeservice_id = (select id from tpointdeservice pds where reference ='&amp;PDS_SOURCE');

update tperiodeactivitere set pointdeservice_id = (select id from tpointdeservice pds where reference ='&amp;PDS_DEST')
,datemodification= current_date, acteurmodification = '&amp;EVT'
where pointdeservice_id = (select id from tpointdeservice pds where reference ='&amp;PDS_SOURCE');

update tpointdeservice pds 
set (pds.dateprochainerelevereelle, pds.consoannuellereference_unit, pds.consoannuellereference_value)= 
(select dateprochainerelevereelle, consoannuellereference_unit,  consoannuellereference_value 
from tpointdeservice where reference ='&amp;PDS_SOURCE')
,datemodification= current_date, acteurmodification = '&amp;EVT'
where reference ='&amp;PDS_DEST';
 
undef PDS_SOURCE;
undef PDS_DEST;
undef EVT;
&lt;/source&gt;


=== contrôle de cohérence du paramétrage ===
==== vérification des MGP de dépassement quadratique ====
&lt;source lang="sql"&gt;
-- le service de calcul de regroupement S10 n'a pas de sens pour une dépassement quadratique, vu que la fonction de dépassement quadratique n'est pas linéaire.
-- utiliser le S21 à la place.
select id, configurationmaterielle_id, libelle from tmodelegrandeurphysique 
where servicedecalcul = 10
  and ordredecalcul is not null
  and typegrandeur=2 and soustype=6
  and mod(etatobjet,2) = 0;

-- vérifie qu'il ne manque de MGP lors d'un regroupement de dépassement quadratique. S'il manque des poste, cela peut-être signe d'un mauvais paramétrage 
-- (on pointe vers les mauvais postes)
select cm.reference "ref config", 
mgp.id "ID mgp", 
mgp.libelle "mgp", 
ph.libelle "poste regroupement", 
ph2.libelle "poste regroupé sans mgp"
from tconfigurationmaterielle cm
	join tmodelegrandeurphysique mgp on mgp.configurationmaterielle_id = cm.id
	join tpostehorosaisonnier ph on ph.id = mgp.postehorosaisonnier_id
	join postehoros_postesregrpes lien on lien.source = ph.id
	join tpostehorosaisonnier ph2 on lien.dest = ph2.id
where mgp.servicedecalcul = 21
	and mgp.typegrandeur=2 
	and mgp.soustype=6
	and mod(mgp.etatobjet,2) = 0
	and mgp.ordredecalcul is not null
	and not exists (select 1 
		from tmodelegrandeurphysique mgp2
		where ph2.id = mgp2.postehorosaisonnier_id
			and mgp.brutounet = mgp2.brutounet
			and mgp.sensdemesure = mgp2.sensdemesure
			and mgp.configurationmaterielle_id = mgp2.configurationmaterielle_id
			and mgp2.typegrandeur=2 
			and mgp2.soustype=6
			and mgp2.releveoucalcule in (0,1,6)
			and mod(mgp2.etatobjet,2) = 0
	);
&lt;/source&gt;

==== vérification de la cohérences des profils de consommation ====
Ce script retourne les part par poste et coef de répartition de sous profils incohérents (segments ou sous profils conso incompatibles avec le profil de consommation
&lt;source lang="sql"&gt;
select 'part par poste' "role", ppp.id, ppp.etatobjet, ppp.sousprofilconsommation_id, ppp.segment_id 
from tpartparposte ppp 
where mod(ppp.etatobjet,2)=0
	and not exists 
	(select 1 from tsousprofilconsommation sp, tsegment seg, tprofilconsommation prof
		where  mod(sp.etatobjet,2) = 0
                and mod(seg.etatobjet,2) = 0
                and mod(prof.etatobjet,2) = 0
                and seg.profilconsommation_id = prof.id
                and seg.id = ppp.segment_id
                and sp.profilconsommation_id = prof.id
                and sp.id = ppp.sousprofilconsommation_id)
union all
select 'coef de répartition', coef.id, coef.etatobjet, coef.sousprofilconsommation_id, coef.segment_id 
from tcoefficientrepartitionenergie coef
where mod(coef.etatobjet,2)=0
	and not exists 
	(select 1 from tsousprofilconsommation sp, tsegment seg, tprofilconsommation prof
		where  mod(sp.etatobjet,2) = 0
                and mod(seg.etatobjet,2) = 0
                and mod(prof.etatobjet,2) = 0
                and seg.profilconsommation_id = prof.id
                and seg.id = coef.segment_id
                and sp.profilconsommation_id = prof.id
                and sp.id = coef.sousprofilconsommation_id);
&lt;/source&gt;

Cette rêquête retourne les couples segment-sous profil consommation avec un nombre incorrect de part par poste et de coef de répartition
&lt;source lang="sql"&gt;
select 'part par poste' "role", s.id, sp.id
from tsegment s, tsousprofilconsommation sp
where mod(sp.etatobjet,2) = 0 and mod(s.etatobjet,2)=0
	and s.profilconsommation_id = sp.profilconsommation_id
	and 1 &lt;&gt; (select count(*) from tpartparposte ppp where mod(ppp.etatobjet,2) = 0 and ppp.segment_id = s.id and ppp.sousprofilconsommation_id = sp.id)
union all
select 'coef de répartition', s.id, sp.id 
from tsegment s, tsousprofilconsommation sp
where mod(sp.etatobjet,2) = 0 and mod(s.etatobjet,2)=0
	and s.profilconsommation_id = sp.profilconsommation_id
	and 12 &lt;&gt; (select count(*) from tcoefficientrepartitionenergie coef where mod(coef.etatobjet,2) = 0 and coef.segment_id = s.id and coef.sousprofilconsommation_id = sp.id)
&lt;/source&gt;

==== vérification de la cohérences des calendriers ====
Cette rêquête retourne les profils jour (rattachés à des profils jour génériques) dont le poste horosaisonnier ne correspondant pas à la structure horosaisonnière du calendrier.
&lt;source lang="sql"&gt;
select pj.id, TH.POSTEHOROSAISONNIER_ID from tstructuretemporelle st
join STRUCTURETEMPORELLE_PROFILJOUR stpj on stpj.source = st.id
join TPROFILJOUR pjg on pjg.id = stpj.dest
join TLIENDECLINAISONGEO lien on LIEN.PROFILJOURGENERIQUE_ID = pjg.id
join TPROFILJOUR pj on pj.id = LIEN.PROFILJOUR_ID
join TTRANCHEHORAIRE th on pj.id= TH.PROFILJOUR_ID
join TPOSTEHOROSAISONNIER ph on ph.id = TH.POSTEHOROSAISONNIER_ID
where st.reference = '9'
and PH.STRUCTHOROS_ID != ST.STRUCTUREHOROSAISONNIERE_ID;
&lt;/source&gt;

== Requêtes mise à jour données ==

==== Suppression d'une relève ====

Avec &amp;id_releve = identifiant de la relève à supprimmer, &amp;num_evenement = numéro de l'évènement


{{avertissement}} Avant la mise à jour, vérifier que la relève à supprimer ne précède pas une autre relève. La requête suivante doit toujours renvoyer 0 avant la suppression :
&lt;source lang="sql"&gt;
SELECT COUNT(*) FROM treleve WHERE (RELEVEPRECEDENTE_ID = '&amp;id_releve' OR RELEVEREELLEPRECEDENTE_ID = '&amp;id_releve')
 AND MOD(etatobjet,2) = 0;
&lt;/source&gt;

1. Mettre à jour la table de relèves (TRELEVE) champs etatobjet, datesuppression, acteursuppression
&lt;source lang="sql"&gt;
UPDATE TRELEVE set ETATOBJET = 1, DATESUPPRESSION = current_date, ACTEURSUPPRESSION = '&amp;num_evenement'
 WHERE id = '&amp;id_releve' and mod(etatobjet,2) = 0;
&lt;/source&gt;

2. Mettre à jour la table de grandeurs physiques (TGRANDEURPHYSIQUEGENERALE) champs etatobjet, datesuppression, acteursuppression
&lt;source lang="sql"&gt;
UPDATE TGRANDEURPHYSIQUEGENERALE set ETATOBJET = 1, DATESUPPRESSION = current_date,
 ACTEURSUPPRESSION = '&amp;num_evenement' WHERE releve_id= '&amp;id_releve' and mod(etatobjet,2) = 0;
&lt;/source&gt;

3. Supprimer la liaison dans la table FACTURE_RELEVES
&lt;source lang="sql"&gt;
DELETE FROM FACTURE_RELEVES WHERE dest = '&amp;id_releve';
&lt;/source&gt;

4. Mettre à jour la table d'éléments de population relève (TELEMENTDEPOPULATIONRELEVE) champs etatobjet, acteurmodification, datemodification, statut, releve_id


{{avertissement}} Avant la mise à jour des éléments de population, vérifier que l'EDP n'a pas de relèves complémentaires.
La requête suivante doit toujours renvoyer 0 avant la suppression :
&lt;source lang="sql"&gt;
select COUNT(*) from telementdepopulationreleve WHERE relevecomplementaire_id= '&amp;id_releve'
 and mod(etatobjet,2) = 0;
&lt;/source&gt;

Puis mettre à jour la table d'éléments de population relève 
&lt;source lang="sql"&gt;
UPDATE telementdepopulationreleve SET ACTEURMODIFICATION = '&amp;num_evenement',
 DATEMODIFICATION = current_date, STATUT = 5, RELEVE_ID = null
 WHERE (releve_id = '&amp;id_releve' OR relevecomplementaire_id = '&amp;id_releve') and mod(etatobjet,2) = 0;
&lt;/source&gt;

5. Mettre à jour la table d'échange (TECHANGE) champs etatobjet, datesuppression, acteursuppression
&lt;source lang="sql"&gt;
UPDATE TECHANGE SET ETATOBJET = 1, DATESUPPRESSION = CURRENT_DATE,
 ACTEURSUPPRESSION = '&amp;num_evenement' where OBJETMAITRE_ID = '&amp;id_releve' and mod(etatobjet,2) = 0;
&lt;/source&gt;

6. Mettre à jour la table des interventions (TINTERVENTION) champs indexcontresigne_id, releveestimativecomplement_id, releveexistant_id, relevenouveaucomptage_id

&lt;source lang="sql"&gt;
UPDATE TINTERVENTION itv SET INDEXCONTRESIGNE_ID = NULL WHERE INDEXCONTRESIGNE_ID = '&amp;id_releve'
 AND EXISTS ( SELECT 1 FROM TAFFAIRE aff WHERE aff.id = itv.id
 AND mod(aff.etatobjet,2) = 0);

UPDATE TINTERVENTION itv SET RELEVEESTIMATIVECOMPLEMENT_ID = NULL WHERE RELEVEESTIMATIVECOMPLEMENT_ID = '&amp;id_releve'
 AND EXISTS ( SELECT 1 FROM TAFFAIRE aff WHERE aff.id = itv.id
 AND mod(aff.etatobjet,2) = 0);

UPDATE TINTERVENTION itv SET RELEVEEXISTANT_ID = NULL WHERE RELEVEEXISTANT_ID = '&amp;id_releve'
 AND EXISTS ( SELECT 1 FROM TAFFAIRE aff WHERE aff.id = itv.id
 AND mod(aff.etatobjet,2) = 0);

UPDATE TINTERVENTION itv SET RELEVENOUVEAUCOMPTAGE_ID = NULL WHERE RELEVENOUVEAUCOMPTAGE_ID = '&amp;id_releve'
 AND EXISTS ( SELECT 1 FROM TAFFAIRE aff WHERE aff.id = itv.id
 AND mod(aff.etatobjet,2) = 0);
&lt;/source&gt;

== Fichiers sources ==
* [[Media:Modèle consommation.VSD|Modèle consommation.VSD (Visio 2003)]]

== Loggers ==
=== Moteur d'estimation ===
==== Nom spécifique ====
MOTEUR_ESTIMATION
==== Afficher les logs dans un fichier dédié ====
Pour obtenir les logs qui correspondent au logger du moteur d'estimation, il faut ajouter le fichier xml suivant dans le dossier properties2 et le nommer log4j2-test.xml
&lt;source lang="xml"&gt;
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;Configuration status="WARN"&gt;
  &lt;Properties&gt;
    &lt;Property name="logDir"&gt;${sys:user.home}/log&lt;/Property&gt;
  &lt;/Properties&gt;

  &lt;Appenders&gt;
    &lt;RollingFile name="RollingFile" filePattern="${logDir}/efluid_moteur_estimation_%d{yyyy-MM-dd}.log" includeLocation="true"&gt;
      &lt;PatternLayout&gt;
        &lt;Pattern&gt;%-5level|%thread|%mdc{User}|%mdc{Event}|%logger{1}|%class{1.}.%method : %line|%d{HH:mm:ss.SSS}|%msg%n&lt;/Pattern&gt;
      &lt;/PatternLayout&gt;
      &lt;Policies&gt;
        &lt;TimeBasedTriggeringPolicy /&gt;
        &lt;SizeBasedTriggeringPolicy size="500 MB" /&gt;
        &lt;OnStartupTriggeringPolicy /&gt;
      &lt;/Policies&gt;
    &lt;/RollingFile&gt;
  &lt;/Appenders&gt;

  &lt;Loggers&gt;
    &lt;Logger name="MOTEUR_ESTIMATION" level="debug"&gt;
      &lt;AppenderRef ref="RollingFile" /&gt;
    &lt;/Logger&gt;
  &lt;/Loggers&gt;
&lt;/Configuration&gt;
&lt;/source&gt;
Le fichier de log obtenu ira dans le dossier log dans votre home.
==== Changer la configuration ====
===== Choix du dossier =====
Le changement se passe à ce niveau :
&lt;source lang="xml"&gt;
&lt;Property name="logDir"&gt;${sys:user.home}/log&lt;/Property&gt;
&lt;/source&gt;
Il suffit de changer le chemin indiqué.
===== Choix du nom du fichier =====
Le changement se passe à ce niveau :
&lt;source lang="xml"&gt;
&lt;RollingFile name="RollingFile" filePattern="${logDir}/efluid_moteur_estimation_%d{yyyy-MM-dd}.log" includeLocation="true"&gt;
&lt;/source&gt;
Il suffit de changer le pattern du nom après "${logDir}/".
===== Choix du pattern =====
Le changement se passe à ce niveau :
&lt;source lang="xml"&gt;
&lt;Pattern&gt;%-5level|%thread|%mdc{User}|%mdc{Event}|%logger{1}|%class{1.}.%method : %line|%d{HH:mm:ss.SSS}|%msg%n&lt;/Pattern&gt;
&lt;/source&gt;
Pour modifier le pattern à votre convenance, je vous invite à vous rendre sur [https://logging.apache.org/log4j/2.x/manual/layouts.html log4j2 layouts] et aller dans la partie Pattern Layout.
===== Choix de l'appender =====
Le changement se passe à ce niveau :
&lt;source lang="xml"&gt;
&lt;AppenderRef ref="RollingFile" /&gt;
&lt;/source&gt;
Pour changer la destination des logs, il suffit de changer "ref" de "AppenderRef", ou d'ajouter un autre "AppenderRef".
Si vous voulez créer une autre Appender il faut aller voir sur [https://logging.apache.org/log4j/2.x/manual/appenders.html log4j2 appenders].&lt;br/&gt;
Sinon, voici un exemple d'Appender pour la console :
&lt;source lang="xml"&gt;
&lt;Console name="Console" target="SYSTEM_OUT"&gt;
  &lt;PatternLayout pattern="%-5level|%t|%X{User}|%X{Event}|%logger{36}|%d{HH:mm:ss.SSS}|%msg%n" /&gt;
&lt;/Console&gt;
&lt;/source&gt;
Vous copier cela dans la partie "Appenders" de votre fichier xml.
==== Utilisation ====
il faut créer le logger en tant qu'attribut de la classe :
&lt;source lang="java"&gt;
private static final Logger LOGGER_MOTEUR_ESTIMATION = LoggerFactory.getLogger(LoggersConso.MOTEUR_ESTIMATION);
&lt;/source&gt;
Puis on utilise l'API associée, exemple :
&lt;source lang="java"&gt;
LOGGER_MOTEUR_ESTIMATION.debug("log avec paramètres : {} et {}", param1, param2);
&lt;/source&gt;
=== Méthode d'estimation utilisée ===
==== Nom spécifique ====
METHODE_ESTIMATION_APPLIQUEE
==== Changer la configuration ====
voir loggers partie moteur d'estimation
==== Afficher les logs dans un fichier dédié ====
voir loggers partie moteur d'estimation
==== Utilisation ====
il faut créer le logger en tant qu'attribut de la classe :
&lt;source lang="java"&gt;
private static final Logger LOGGER_METHODE_ESTIMATION_APPLIQUEE = LoggerFactory.getLogger(METHODE_ESTIMATION_APPLIQUEE);
&lt;/source&gt;
Puis on utilise l'API associée, exemple :
&lt;source lang="java"&gt;
LOGGER_METHODE_ESTIMATION_APPLIQUEE.debug("log avec paramètres : {} et {}", param1, param2);
&lt;/source&gt;</text>
      <sha1>4efrptkgg56smyc5051bey3cbge59bg</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine mensualisation</title>
    <ns>0</ns>
    <id>525</id>
    <revision>
      <id>3875417</id>
      <parentid>3875317</parentid>
      <timestamp>2018-02-28T14:07:54Z</timestamp>
      <contributor>
        <username>Flatres</username>
        <id>26</id>
      </contributor>
      <minor/>
      <comment>/* Déroutage régularisation de mensu */</comment>
      <origin>3875417</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1398" sha1="4ryopppbz87ztbktfbw6lxnxe77n92d" xml:space="preserve">{{Modèle:Domaine
 | section=[[Groupe de développement facturation|facturation]]
 | recetteurs=[[AHAB]], [[VGA]], [[VGO]], [[CMI]]
}}
[[Category:domaine]]
= AFD =
[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_4f588 eRoom]

= Batchs =
* [[Edition des déclarations des taxes locales sur l'électricité (E-0077MT)]]
* [[MEMO_FAC:EditionEtatAvancesMensuEmisesProgram|EditionEtatAvancesMensuEmisesProgram (MNS004MT)]]
* [[MEMO_FAC:EditionEtatAvancesMensuDeduitesProgram|EditionEtatAvancesMensuDeduitesProgram (MNS003MT)]]
* [[MEMO_FAC:EditionEtatAvancesMensuNonSoldeesProgram|EditionEtatAvancesMensuNonSoldeesProgram (MNS005MT)]]
* [[MEMO_FAC:EditionEtatAvancesMensuImpayeesProgram|EditionEtatAvancesMensuImpayeesProgram (MNS007MT)]]
* [[Calcul de dérive d'échéancier de mensualisation (MNS009MT)]]

= Statuts Echéancier =
[[image:diagEtatSeqEcheancier.png]]

= Statuts Mensu =
[[image:diagEtatSeqMensu.png]]

= Déroutage régularisation de mensu =

{{alert|texte=Ceci est un schéma récapitulatif qui n'a pas vocation à remplacer l'AFD}}

[[image:deroutage regularisation.png]]

'''NB''': Si le traitement n'est pas interrompu (indication "fin du traitement"), alors efluid calcule une échéancier de paiement (à une ou deux échéances) qui sera présenté sur la facture.
Cette création d'échéancier donc lieu uniquement avec un montant sans solde inférieur au seuil 2...</text>
      <sha1>4ryopppbz87ztbktfbw6lxnxe77n92d</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine intervention</title>
    <ns>0</ns>
    <id>849</id>
    <revision>
      <id>4069403</id>
      <parentid>4069322</parentid>
      <timestamp>2023-06-01T11:52:21Z</timestamp>
      <contributor>
        <username>Damestoy</username>
        <id>12</id>
      </contributor>
      <comment>/* AFDs */</comment>
      <origin>4069403</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4906" sha1="njsg5mhw5zrut41rhfzs79hqngw18vw" xml:space="preserve">= Introduction = 
Le domaine intervention est le domaine relatif à tout ce qui concerne les interventions ou les planning intervention. Les éléments ci-dessous, sont alors des éléments fonctionnels ou du code permettant de mieux appréhender et comprendre toute l'étendue de ce domaine. &lt;br&gt;

Le domaine intervention possède aussi, pour l'instant un dossier relatif à la documentation du domaine, dans eRoom. Ce dossier [http://wperoomifr1.uem.lan/eRoom/Production/DocTechniqueEfluid/0_2d89e2 documentation intervention] permet ainsi de stocker les différents fichiers de documentation qui ne peuvent pas être directement téléversés dans le wike.

= Eléments documentés = 

== AFDs ==
Les AFD se trouvent '''dans eRoom''' et il en existe plusieurs types :
* On retrouve la [http://wperoomifr1.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_3051 documentation fonctionnelle Suite Efluid] qui correspond aux fonctionnalités génériques de l'application. Parmi ces documents, il y a à la fois les AFD initialles et les ''écarts'' qui correspondent aux fonctionnalités qui ont été rajoutées par la suite.
* On retrouve aussi la [http://wperoomifr1.uem.lan/eRoom/Production/DocFonctionnelleEfluid/0_415ca documentation fonctionnelle Projets Clients] qui elle, diffère en fonction des clients. L'application possède des différences en fonction des clients et toutes les AFD correspondant à ces différences sont des ''Projets Clients''. &lt;br&gt;

Les AFD contiennent les éléments suivants :
* Concepts
* Cas d'utilisation : 
* Classification des services
* Paramètres de l'application

== Coder une évolution ==

[[Fichier:MultiplesDI.jpg|droite|640px|vignette|Schéma décrivant les interactions entre les différentes DI contractuelles]]

* Gestion des planifications
** Pour tout moteur de planification qui store des objets en cours de route comme c'est le cas pour Displanis, displanisWeb et planification par Créneaux, ne pas oublier de voir ce qui se passe en suspension de contrat:
** en effet, l'intervention n'est pas stockée en base, mais il faut prévoir de supprimer les objets stockés en bases tels que les déplacements et/ou les réservations
&lt;br/&gt;
* 3 points d'entrée pour l'Edition d'un Bon d'Intervention
** Affaire / bouton "éditer BI"
** EDL / affaire / bouton "éditer BI"
** Intervention (comptage) (déselectionner le Responsable si besoin) / sélectionner l'intervention puis bouton "éditer sélection"
&lt;br/&gt;
* Gestion des DI dupliquée/miroir/reprise/fourniture/acheminement
** liste des cas de tests à faire pour vérifier le bon fonctionnement global.

== Tests relatifs aux créations de DIs ==

=== Les DIs contractuelles ===

Les différents tests d'intégration relatifs à la création de DIs contractuelles ont tous été répertoriés dans un fichier excel stocké dans eRoom. Il contient un schéma explicatif du cas, le fichier contenant le test et sa place dans le code ainsi que la description complète : type de compteur, générateur de contrat utilisé, contexte de départ du test. &lt;br&gt;

Vous pouvez retrouver ce fichier grâce au lien suivant :
[http://wperoomifr1.uem.lan/eRoom/Production/GestionProjetEfluid/0_2d783c Lien vers le fichier sur eRoom]

&lt;br&gt;
''À noter :'' &lt;br&gt;
* Cela ne répertorie que les tests de création de DI. 
* Ils sont tous plus ou moins complétés par des tests qui portent presque le même nom mais avec l’acronyme CRI dedans et qui s’appuie sur un contexte préCRI (donc une DI), qui fait appel au test de fabrication de la DI correspondante.

* Ce principe est à la base de tous nos TI : &lt;br&gt;
** Le contexte répondant à la question : quelle est la situation à partir de laquelle on veut tester quelque chose
** La réponse à cette question étant : sur quel test existant je m’appuie '''-&gt; GIVEN'''
** Puis on n’a plus qu’à dérouler les actions de notre test '''-&gt; WHEN'''
** Et on contrôle '''-&gt; THEN'''

=== Les DIs non contractuelles ===

Il existe différents tests basés sur la création de DI techniques sur des espaces de livraison avec ou sans contrat et dont le principe peut être exploité pour vérifier des mises à jours sur le domaine référentiel à l'issue d'un CRI.&lt;br/&gt;

'''Exemple :''' la mise à jour par le CRI du caractère HRV sur le PDS (Haut Risque Vital).

== Les différents webservices du domaine intervention ==

Il existe '''deux types de webservices''' : les webservices [[Webservices Intervention SOAP|SOAP]] et [[Webservices REST (domaine intervention)|REST]].

Concernant le développement des interfaces, une [[Développement des interfaces|documentation]] avaient été effectuée à ce propos. Cette documentation est bien sûre à compléter. &lt;br&gt;
Concernant le fonctionnement un peu plus techniques des interfaces dans eFluid on retrouve aussi le document suivant : [[Webservices]].

[[Category:Domaine]]
[[Category:Domaine Intervention]]</text>
      <sha1>njsg5mhw5zrut41rhfzs79hqngw18vw</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine reconstitution des flux</title>
    <ns>0</ns>
    <id>1791</id>
    <revision>
      <id>1360185</id>
      <parentid>1047930</parentid>
      <timestamp>2016-02-05T15:30:32Z</timestamp>
      <contributor>
        <username>Grzejsz</username>
        <id>69</id>
      </contributor>
      <comment>/* Requêtes utiles */</comment>
      <origin>1360185</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12164" sha1="pet7kceds5o5h5gutlxpn1oa3una08e" xml:space="preserve">[[Category:domaine]]
== AFDs ==
[http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_d68e eRoom]

=== AFDs éléctricité ===
* AFD - REC - Reconstitution des flux.doc
** Pré-études gestion des profils et RE
** Concepts et modélisation
** Cas d'utilisation "Gérer les profils et les RE"
** Cas d'utilisation "Gérer la spécialisation du composant campagne pour la RDF par le GRD"
** Cas d'utilisation "Gérer les traitements propres à la RDF par le GRD"
** Cas d'utilisation "Gérer la spécialisation du composant campagne pour la RDF par le fournisseur"
** Cas d'utilisation "Visualiser des courbes"

* AFD - reco flux - RE agrégés.doc
** Modélisation
** Cas d'utilisation "Valider des éléments de population"

=== AFDs gaz ===
* AFD - RDF - GAZ.doc
** Paramétrage des profils et des températures
*** Modélisation
*** Cas d'utilisation "Gérer les profils et les sous profils"
*** Cas d'utilisation "Gérer les stations météo"
*** Cas d'utilisation "Gérer manuellement les coefficients par station météo"
*** Cas d'utilisation "Intégrer automatiquement les données profil et T°C"
*** Cas d'utilisation "Intégrer les températures réelles journalières"
*** Cas d'utilisation "Actualiser la CAR et le profil du PDS"
** Bilans de consommation J+1 et M+1
*** Modélisation
*** Cas d'utilisation "Sélectionner la population"
*** Cas d'utilisation "Exécuter la RDF à J+1"
*** Cas d'utilisation "Exécuter la RDF à M+1"
*** Cas d'utilisation "Contrôler les bilans"
*** Cas d'utilisation "Valider les bilans"
*** Cas d'utilisation "Fermer la campagne"
*** Cas d'utilisation "Recalculer les quantités"
** Gestion des comptes d'écarts
*** Modélisation

== Liens utiles ==
* [[Détermination du responsable d'équilibre (RE), du fournisseur, des profils RDF|[CRM] Détermination du responsable d'équilibre (RE), du fournisseur, des profils RDF]]


== Requêtes utiles ==
=== Sélectionner un PDS gaz en modereleve téléreleve ===
&lt;source lang="SQL"&gt;
SELECT pds.reference
FROM tpointdeservice pds,tperiodeactiviteprofil paprofil
WHERE pds.id = paprofil.pointdeservice_id
AND pds.activite = 2
AND paprofil.moderelevepds = 5
AND mod(pds.etatobjet,2) = 0
AND mod(paprofil.etatobjet,2) = 0;
&lt;/source&gt;

=== Purger une campagne RDFGaz ===

&lt;source lang="sql"&gt;
define CAMPAGNE_ID = 'IDCAMPAGNE'
DELETE
FROM tanomalie
WHERE ELEMENTPOPULATION_ID IN
  (SELECT id
  FROM telementdepopulationrdfgaz
  WHERE lot_id IN
    (SELECT l.id FROM tlot l WHERE l.campagne_id='&amp;CAMPAGNE_ID'
    )
  );
DELETE
FROM tbilanquantite
WHERE EDP_ID IN
  (SELECT id
  FROM telementdepopulationrdfgaz
  WHERE lot_id IN
    (SELECT l.id FROM tlot l WHERE l.campagne_id='&amp;CAMPAGNE_ID'
    )
  );
DELETE
FROM telementdepopulationrdfgaz
WHERE lot_id IN
  (SELECT l.id FROM tlot l WHERE l.campagne_id='&amp;CAMPAGNE_ID'
  );
UPDATE tcampagne c SET c.nombreelements=0 WHERE id='&amp;CAMPAGNE_ID';
UPDATE tcampagne c SET c.nombreelementstraites=0 WHERE id='&amp;CAMPAGNE_ID';
UPDATE tlot l SET l.nbelements=0 WHERE l.campagne_id='&amp;CAMPAGNE_ID';
UPDATE tlot l SET l.nbelementstraites=0 WHERE l.campagne_id='&amp;CAMPAGNE_ID';


&lt;/source&gt;


=== Purger une campagne RDFGaz MENSUELLE en fonction de la date d'éxécution ===
* &lt;big&gt;Pour une campagne JOURNALIERE il suffit de mettre e.frequencequotidienne = 1&lt;/big&gt;
* &lt;big&gt;Ne pas oublier de mettre l'acteur suppression/modification&lt;/big&gt;
 
&lt;source lang="sql"&gt;
define DATEDEBUT = &amp;5;
define DATEDEFIN = &amp;6;

UPDATE tanomalie ano
SET ano.etatobjet           = 1,
    ano.datesuppression = CURRENT_DATE,
    ano.acteursuppression = 'Evenement xxx'
WHERE ELEMENTPOPULATION_ID IN
  (SELECT id
  FROM telementdepopulationrdfgaz
  WHERE lot_id IN
    (SELECT l.id
FROM techeance e, tcampagne c, tlot l
WHERE e.dateexecutionprevue &gt;= TO_DATE('&amp;DATEDEBUT','DD/MM/YYYY')
AND e.dateexecutionprevue &lt; TO_DATE('&amp;DATEDEFIN','DD/MM/YYYY')+1
AND e.role = 'com.hermes.itv.reconstitutiongaz.businessobject.EcheanceRDFGaz'
AND mod(e.etatobjet,2) = 0
AND l.campagne_id = c.id
AND e.frequencequotidienne = 0
AND c.echeancedeclenchee_id = e.id
    )
  );

UPDATE tbilanquantite b
SET b.etatobjet = 1,
  b.datesuppression = CURRENT_DATE,
  b.acteursuppression = 'Evenement xxx'
WHERE EDP_ID IN
    (SELECT id
  FROM telementdepopulationrdfgaz
  WHERE lot_id IN
    (SELECT l.id
FROM techeance e, tcampagne c, tlot l
WHERE  e.dateexecutionprevue &gt;= TO_DATE('&amp;DATEDEBUT','DD/MM/YYYY')
AND e.dateexecutionprevue &lt; TO_DATE('&amp;DATEDEFIN','DD/MM/YYYY')+1
AND e.role = 'com.hermes.itv.reconstitutiongaz.businessobject.EcheanceRDFGaz'
AND mod(e.etatobjet,2) = 0
AND l.campagne_id = c.id
AND e.frequencequotidienne = 0
AND c.echeancedeclenchee_id = e.id
    )
  );

update tcollectionBilanQuantite 
SET etatobjet = 1,
  datesuppression = CURRENT_DATE,
  acteursuppression = 'Evenement xxx'
where id in (
SELECT l.source
FROM collection_bilansquantite l,telementdepopulationrdfgaz edp,tbilanquantite b
  WHERE b.edp_id = edp.id
  AND b.id = l.dest
  AND edp.lot_id IN
    (SELECT l.id
FROM techeance e, tcampagne c, tlot l
WHERE  e.dateexecutionprevue &gt;= TO_DATE('&amp;DATEDEBUT','DD/MM/YYYY')
AND e.dateexecutionprevue &lt; TO_DATE('&amp;DATEDEFIN','DD/MM/YYYY')+1
AND e.role = 'com.hermes.itv.reconstitutiongaz.businessobject.EcheanceRDFGaz'
AND mod(e.etatobjet,2) = 0
AND l.campagne_id = c.id
AND e.frequencequotidienne = 0
AND c.echeancedeclenchee_id = e.id
    )
);

update techange 
set  etatobjet = 1,
  datesuppression = CURRENT_DATE,
  acteursuppression = 'Evenement xxx'
where id in (select id from techange 
where objetmaitre_role='com.hermes.itv.reconstitutiongaz.businessobject.CollectionBilanQuantite' 
and objetmaitre_id in (SELECT l.source
FROM collection_bilansquantite l,telementdepopulationrdfgaz edp,tbilanquantite b
  WHERE b.edp_id = edp.id
  AND b.id = l.dest
  AND edp.lot_id IN
    (SELECT l.id
FROM techeance e, tcampagne c, tlot l
WHERE  e.dateexecutionprevue &gt;= TO_DATE('&amp;DATEDEBUT','DD/MM/YYYY')
AND e.dateexecutionprevue &lt; TO_DATE('&amp;DATEDEFIN','DD/MM/YYYY')+1
AND e.role = 'com.hermes.itv.reconstitutiongaz.businessobject.EcheanceRDFGaz'
AND mod(e.etatobjet,2) = 0
AND l.campagne_id = c.id
AND e.frequencequotidienne = 0
AND c.echeancedeclenchee_id = e.id
    )));

update TVALEURCRITEREPUBLICATION 
set etatobjet = 1,
  datesuppression = CURRENT_DATE,
  acteursuppression = 'Evenement xxx'
where id in (select v.id 
from TVALEURCRITEREPUBLICATION v, ECHANGE_VALEURSDECRITERE l, TECHANGE e 
where l.source=e.id 
and l.dest=v.id 
and e.id in (select id from techange 
where objetmaitre_role='com.hermes.itv.reconstitutiongaz.businessobject.CollectionBilanQuantite' 
and objetmaitre_id in (SELECT l.source
FROM collection_bilansquantite l,telementdepopulationrdfgaz edp,tbilanquantite b
  WHERE b.edp_id = edp.id
  AND b.id = l.dest
  AND edp.lot_id IN
    (SELECT l.id
FROM techeance e, tcampagne c, tlot l
WHERE  e.dateexecutionprevue &gt;= TO_DATE('&amp;DATEDEBUT','DD/MM/YYYY')
AND e.dateexecutionprevue &lt; TO_DATE('&amp;DATEDEFIN','DD/MM/YYYY')+1
AND e.role = 'com.hermes.itv.reconstitutiongaz.businessobject.EcheanceRDFGaz'
AND mod(e.etatobjet,2) = 0
AND l.campagne_id = c.id
AND e.frequencequotidienne = 0
AND c.echeancedeclenchee_id = e.id
    ))));

UPDATE telementdepopulationrdfgaz edp
SET edp.etatobjet = 1,
   edp.datesuppression = CURRENT_DATE,
   edp.acteursuppression = 'Evenement xxx'
WHERE lot_id IN
    (SELECT l.id
FROM techeance e, tcampagne c, tlot l
WHERE e.dateexecutionprevue &gt;= TO_DATE('&amp;DATEDEBUT','DD/MM/YYYY')
AND e.dateexecutionprevue &lt; TO_DATE('&amp;DATEDEFIN','DD/MM/YYYY')+1
AND e.role = 'com.hermes.itv.reconstitutiongaz.businessobject.EcheanceRDFGaz'
AND mod(e.etatobjet,2) = 0
AND l.campagne_id = c.id
AND e.frequencequotidienne = 0
AND c.echeancedeclenchee_id = e.id);
  
UPDATE tcampagne c 
SET c.nombreelements=0,
c.nombreelementstraites=0,
c.statut = 0,
c.acteurmodification = 'Evenement xxx',
c.datemodification = CURRENT_DATE
WHERE c.id IN 
    (SELECT c.id
FROM techeance e, tcampagne c, tlot l
WHERE   e.dateexecutionprevue &gt;= TO_DATE('&amp;DATEDEBUT','DD/MM/YYYY')
AND e.dateexecutionprevue &lt; TO_DATE('&amp;DATEDEFIN','DD/MM/YYYY')+1
AND e.role = 'com.hermes.itv.reconstitutiongaz.businessobject.EcheanceRDFGaz'
AND mod(e.etatobjet,2) = 0
AND l.campagne_id = c.id
AND e.frequencequotidienne = 0
AND c.echeancedeclenchee_id = e.id);

UPDATE tlot l
SET l.nbelements=0,
    l.nbelementstraites=0,
    l.statut = 0,
    l.acteurmodification = 'Evenement xxx',
    l.datemodification = CURRENT_DATE
WHERE l.campagne_id IN 
  (SELECT c.id
FROM techeance e, tcampagne c, tlot l
WHERE   e.dateexecutionprevue &gt;= TO_DATE('&amp;DATEDEBUT','DD/MM/YYYY')
AND e.dateexecutionprevue &lt; TO_DATE('&amp;DATEDEFIN','DD/MM/YYYY')+1
AND e.role = 'com.hermes.itv.reconstitutiongaz.businessobject.EcheanceRDFGaz'
AND mod(e.etatobjet,2) = 0
AND l.campagne_id = c.id
AND e.frequencequotidienne = 0
AND c.echeancedeclenchee_id = e.id);

commit;

UNDEF DATEDEBUT;
UNDEF DATEDEFIN;
&lt;/source&gt;

=== Purger les PAProfil gaz pour le batch RFG001 AffecterProfilBatch ===
* &lt;big&gt;modifier les dates&lt;/big&gt;
 
&lt;source lang="sql"&gt;
update tperiodeactiviteprofil pap 
set etatobjet = 1, acteursuppression='DEV', datesuppression=current_timestamp
where pap.role = 'com.hermes.itv.reconstitution.businessobject.PeriodeActiviteProfilGaz'
and trunc(pap.datedebut) = to_date('01042016');

update  tperiodeactiviteprofil pap set datefin = null, acteurmodification='DEV', datemodification=current_timestamp
where pap.role = 'com.hermes.itv.reconstitution.businessobject.PeriodeActiviteProfilGaz'
and trunc(pap.datefin) = to_date('01042016')-1;
&lt;/source&gt;


=== Insertion des données journalière gaz (coef PCS) ===
* Crée les valeurs de coefficient PCS jusqu'à la date du jour depuis la dernière valeur trouvée sur chaque table PCS ouverte.
 
&lt;source lang="sql"&gt;-- date jusqu'à laquelle on crée des valeurs
define DATE_FIN = current_date;

DECLARE 
                 
  cursor c_tablesOuvertes is
              select t.id, t.datedebut, t.libelle
              from TTABLECOEFFICIENTPCS t 
              where mod(t.etatobjet,2) = 0 
                  and t.datefin is null and t.periodicite in (1,2);                         
    
  r_table             c_tablesOuvertes%rowtype;
  totalLignesInserees INTEGER;
BEGIN 
  totalLignesInserees := 0;
  FOR r_table IN c_tablesOuvertes LOOP

    DECLARE
      type VALEURPCS    is record(id tvaleurcoefficientpcs.id%type, 
                                    datevaleur tvaleurcoefficientpcs.datevaleur%type);
      derniereValeur    VALEURPCS;
    BEGIN
      select id, datevaleur  into derniereValeur
      from
        (select vpcs.id, vpcs.datevaleur, row_number() 
            over(partition by tablecoefficientpcs_id order by vpcs.datevaleur desc) as rang
        from tvaleurcoefficientpcs vpcs
          join ttablecoefficientpcs tablepcs on tablepcs.id = vpcs.tablecoefficientpcs_id
        where tablepcs.id = r_table.id
          and mod(vpcs.etatobjet,2) = 0)
      where rang = 1;

      insert into tvaleurcoefficientpcs (id, acteurcreation, datecreation, etatobjet, datevaleur, tablecoefficientpcs_id, valeur, statut)
        with nouvellesDates as  
          (select trunc(&amp;DATE_FIN +1 - level, 'DD') as nouvelleDate from dual 
              WHERE  trunc(&amp;DATE_FIN,'DD') &gt; trunc(derniereValeur.datevaleur, 'DD') 
            connect by trunc(&amp;DATE_FIN - level, 'DD') &gt; trunc(derniereValeur.datevaleur, 'DD') )
      select '§PCS' || to_char(current_date, 'DDMMRRHH24MI') || '_' || (totalLignesInserees + rownum), 'scriptCreationCoefPCS', 
              current_date ,0, nv.nouvelleDate, v.tablecoefficientpcs_id, v.valeur, 0
      from tvaleurcoefficientpcs v, nouvellesDates nv
      where v.id = derniereValeur.id;

      dbms_output.put_line(SQL%ROWCOUNT || ' valeurs insérées depuis le ' || derniereValeur.datevaleur 
                          || ' pour la table '|| r_table.libelle || ' (id = ''' || r_table.id || ''')' );
      totalLignesInserees := totalLignesInserees + SQL%ROWCOUNT;
    EXCEPTION
      WHEN NO_DATA_FOUND THEN 
        dbms_output.put_line('pas de valeur sur la table '|| r_table.libelle || ' (id = ''' || r_table.id || ''')' );
    END;

  END LOOP;
  

END;
/

undef DATE_FIN;

commit;
&lt;/source&gt;</text>
      <sha1>pet7kceds5o5h5gutlxpn1oa3una08e</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine commun</title>
    <ns>0</ns>
    <id>1826</id>
    <revision>
      <id>94594</id>
      <parentid>14462</parentid>
      <timestamp>2013-11-12T07:23:22Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>94594</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3227" sha1="5hn88eqxnfnqru8p2kcgwbx9v5lbfcu" xml:space="preserve">{{Modèle:Domaine
 | nom= Commun
 | trigramme= COM
 | referent= [[NBE]]
 | responsable= [[ADU]]
 | recetteurs = [[NBE]] / [[TSC]] / [[CGR]]
}}
[[category:domaine]]
[[category:ecore]]

== ecore ==

=== Documentation ===

TODO

==== businessobject ====

==== Traitement ====

TODO

=== log ===

==== PeriodicLogManager ====

Cette classe de log s'exécute à intervalle régulier via le paramètre PeriodicLogManagerParameters.LOG_MANAGER_POLL_INTERVAL_MS et log le retour de la liste de callback ajoutés via addCallback(PeriodicLogCallback). 

Afin d'utiliser ce log, la configuration suivante dans le framework2.properties du projet est nécessaire. 

&lt;source lang="java"&gt;
 LOG_MANAGER = com.efluid.ecore.commun.utils.PeriodicLogManager
&lt;/source&gt;

Voir le "DCT - Méthodologie tests de mémoire" pour plus d'infos.

==== PerformanceLogManager ====

Cette classe permet de faire des tests de performance, typiquement à partir des tests unitaires de JUnit. Afin d'utiliser la classe, la configuration suivante dans le framework2.properties du projet est nécessaire. 

&lt;source lang="java"&gt;
 LOG_MANAGER=com.efluid.ecore.commun.log.PerformanceLogManager
&lt;/source&gt;

Si la mesure de performance doit aussi contenir le temps SQL (non nécessaire), ajouter : 

&lt;source lang="java"&gt;
 JDBC_CONNECTION_MANAGER=com.hermes.arc.commun.jdbc.PerfDetailConnectionManager
&lt;/source&gt;

Le fichier de sortie du log est, par défaut, le répertoire "target" du projet dans lequel la classe est exécutée. Pour changer cette valeur, il suffit de créer un fichier "testperformance.properties" qui contient le paramétrage suivant. Voir TestPerformanceConstantes pour tout le paramétrage possible.

&lt;source lang="java"&gt;
 CHEMIN_DOSSIER_SORTIE=D:\\java\\workspaces\\developpement_dev\\ecore\\target\\
 NOM_FICHIER_SORTIE_PAR_DEFAUT=test-performance
&lt;/source&gt;

Afin d'améliorer le temps total pour les tests volumineux, il est fortement recommandé de désactiver la sortie console avec

&lt;source lang="java"&gt;
 LOG_SEVERITY=1
&lt;/source&gt;

dans le framework.properties. Par contre, seuls les messages d'erreurs vont sortir dans le fichier, il faut donc utiliser Log.error(String) (ou la méthode correspondante si le paramètre LOG_SEVERITY est moins restrictif).

Voir le DCT tests performance pour plus d'infos.

=== utils ===

==== BBCodeProcesseur ====

TODO

==== BlocChamps ====

TODO

==== BlocDonneesTechniquesMailChamps ====

TODO

==== BlocPositionnableChamps ====

TODO

==== BlocTexteChamps ====

TODO

==== BlocUtils ====

TODO

==== CelluleLabelMgr ====

TODO

==== CouleurChamps ====

TODO

==== CouleurUtils ====

TODO

==== EditionPersonnaliseeConstantes ====

TODO

==== EditionPersonnaliseeStringUtils ====

TODO

==== EditionPersonnaliseeUtils ====

TODO

==== EditionPersonnaliseeXMLParameters ====

TODO

==== EnteteTableauMgr ====

TODO

==== ExpressionReguliereSimple ====

TODO

==== FiltreClasse ====

TODO

==== FiltreDonneesTechniquesMailOuConditionAffichageVerifiee ====

TODO

==== FiltreTagXML ====

TODO

==== FiltreTagXMLObjetMetier ====

TODO

==== FluxXMLChamps ====

TODO

==== LigneRadioLabelMgr ====

TODO

==== RomanUtils ====

TODO

==== TagXMLChamps ====

TODO

==== TagXMLUtils ====

TODO

== Liens externes ==</text>
      <sha1>5hn88eqxnfnqru8p2kcgwbx9v5lbfcu</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine facturation</title>
    <ns>0</ns>
    <id>1884</id>
    <revision>
      <id>4054797</id>
      <parentid>4054796</parentid>
      <timestamp>2019-09-24T12:43:52Z</timestamp>
      <contributor>
        <username>Tauraat</username>
        <id>202</id>
      </contributor>
      <comment>/* Mensualisation */</comment>
      <origin>4054797</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1854" sha1="o0qtffdfx11btu3cdr3ashzhzpm4d5t" xml:space="preserve">{{Modèle:Domaine
 | section=[[Groupe de développement facturation|facturation]]
 | recetteurs=[[AHAB]], [[VGA]], [[VGO]], [[CMI]]
}}
[[Category:domaine]]

==AFD==
[http://WPEROOM3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2ca5 eroom]

==Aides Mémoires==
===Statuts des objets principaux===
====Facturation====
{| class="wikitable sortable"
|- 
! - !!0!!1!!2!!3!!4!!5!!6!!7!!8!!10!!11!!12
|- 
!Facture!!en cours de constitution!!constituée!!validée!!émise!!en cours d'annulation!!en cours de rectification!!annulée!!rectifiée!!abandonnée!!accepté!!refusé!!proforma
|}
{| class="wikitable sortable"
|-
! - !!0!!1!!2!!3!!4!!5!!6!!7!!8!!9!!10!!11
|- 
!EDP!!selectionné!!facturable!!non facturable!!calculé!!contrôlé!!validé!!édité!!émis!!à intégrer à bordereau!!abandonné!!à intégrer facture multi fluides!!facture vide
|- 
! - !!12!!13!!14!!15!!16!!17!!18!!19!!20!!21!!22!!23
|- 
!EDP(suite)!!mensualisé hors facture de régularisation!!écarté!!décompte de lissage à calculer!!décompte de lissage à éditer!!décompte de lissage émis!!à recalculer!!dérive à estimer!!échéancier à éditer!!dérive éditée!!à intégrer à envoi groupé!!proforma!!à réferencer
|- 
! - !!24
|- 
!EDP(suite)!!à intégrer à facture agrégée
|}

====Mensualisation====
{| class="wikitable sortable"
|- 
! - !!0!!1!!8
|- 
!Facture!!créée!!calculée!!abandonnée
|}
{| class="wikitable sortable"
|-
! - !!0!!1!!2!!12!!14!!15!!16!!17!!18!!19!!20
|- 
!EDP!!selectionné!!facturable!!non facturable!!mensualisé!!décompte de lissage à calculer!!décompte de lissage à éditer!!décompte de lissage émis!!à recalculer!!dérive à estimer!!échéancier à éditer!!dérive éditée
|}

===[[MEMO_FAC:Regroupement|Regroupement]]===

===[[MEMO_FAC:Batchs|Batchs]]===

===[[MEMO_FAC:LigneValorisation|Ligne de valorisation]]===</text>
      <sha1>o0qtffdfx11btu3cdr3ashzhzpm4d5t</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine simulation tarifaire</title>
    <ns>0</ns>
    <id>2968</id>
    <revision>
      <id>109073</id>
      <parentid>20714</parentid>
      <timestamp>2013-12-10T10:07:43Z</timestamp>
      <contributor>
        <username>Boudin</username>
        <id>84</id>
      </contributor>
      <origin>109073</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3549" sha1="fwntht8p7ymon0jvs063csi91gzts3o" xml:space="preserve">{{Modèle:Domaine
 | nom=Simulation tarifaire
 | trigramme=SIM
 | referent=[[CMZ]]
 | responsable=[[TBO]]
 | recetteurs=
}}

= Introduction =

Il s’agit de revoir le fonctionnement de l’actuel CJP en intégrant les contraintes suivantes :
*Intégrer toutes les activités, électricité, gaz et CU, quelque soit la taille du client
*Intégrer la gestion des courbes de charge
*Pouvoir faire :
**Une vente d’énergie, dans un cadre de marché ouvert, en gaz ou en CU
**Un diagnostic sur de l’existant
**Pour les courbes de charge :
*Une étude d’optimisation tarifaire
*Une demande de cotation
*Ces fonctions devront pouvoir être traitées :
**Depuis la création d’une affaire ad hoc ; dans ce cas de figure il faudra pouvoir depuis l’affaire lancer la demande de création d’un contrat sur la base d’un scénario retenu par le client
*Ou en partant d’un contrat, d’où l’on pourra créer une affaire
**L’affaire sera associée à un workflow qui permettra de paramétrer des fonctions d’édition, de validation etc..
**L’affaire spécialisera une affaire générique de sorte à permettre une souplesse d’utilisation par l’ajout de nouveaux attributs et onglets par les clients, tout en permettant un haut niveau de paramétrage du workflow associé.
**La simulation et l’étude tarifaire pourront être lancées depuis efluid et depuis énercom pour les courbes de charge, avec des fonctions supplémentaires depuis efluid, ce qui implique qu’une partie des développements devra être réalisé dans ecore.

= Documentation =
'''TODO : vérifier les liens ci-dessous'''
== Ecore ==
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid efluid - Documentation Fonctionnelle] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_415c5 AFD suite efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_7f645 AFD ecore] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_c2d7c SIM - Domaine simulation tarifaire] &gt; '''[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_c94c1/AFD%20-%20SIM%20-%20Simulation%20tarifaire%20-%20ecore.doc AFD - SIM - Simulation tarifaire - ecore.doc]'''

== Efluid ==
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid efluid - Documentation Fonctionnelle] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_415c5 AFD suite efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_d18f AFD efluid] &gt; [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_c9b99 SIM - Simulation tarifaire] &gt; '''[http://wperoom1/eRoomReq/Files/Production/DocFonctionnelleEfluid/0_c9ba3/AFD%20-%20SIM%20-%20Simulation%20tarifaire%20-%20efluid.doc AFD - SIM - Simulation tarifaire - efluid.doc]'''

== Enercom ==
* [http://wperoom1/eRoom/Production/enercom enercom] &gt; [http://wperoom1/eRoom/Production/enercom/0_6438f Système d'information] &gt; [http://wperoom1/eRoom/Production/enercom/0_8349e AFD énercom] &gt; [http://wperoom1/eRoom/Production/enercom/0_c94fc SIM - Domaine simulation tarifaire] &gt; '''[http://wperoom1/eRoomReq/Files/Production/enercom/0_c94ff/AFD%20-%20SIM%20-%20Simulation%20tarifaire%20-%20enercom.docx AFD - SIM - Simulation tarifaire - enercom.docx]'''

== Autre ==
* [[Proto performance simulation tarifaire]]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_b4dd8 DCT simulation tarifaire]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_4c83f DCT objets dynamiques (archi)]
* [[Etudes simulations tarifaires|Etudes préalables]]

[[Category:domaine]]
[[Category:simulation]]</text>
      <sha1>fwntht8p7ymon0jvs063csi91gzts3o</sha1>
    </revision>
  </page>
  <page>
    <title>Maîtrise de la demande d'énergie</title>
    <ns>0</ns>
    <id>926</id>
    <revision>
      <id>1614603</id>
      <parentid>1610631</parentid>
      <timestamp>2016-05-20T14:01:17Z</timestamp>
      <contributor>
        <username>Bordon</username>
        <id>54</id>
      </contributor>
      <comment>/* Documentation */</comment>
      <origin>1614603</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4565" sha1="sda8t9hwq0c4cnz4zqikants2uaqxut" xml:space="preserve">[[Category:domaine]]

= '''Documentation''' =
* [http://fr.wikipedia.org/wiki/Ma%C3%AEtrise_de_la_demande_en_%C3%A9nergie Qu'est-ce que la MDE ?]
* [[Plan de progression:MDE|Plan de progression]]
* Page spécifique au [[portail MDE]]

== AFDs ==
* [http://WPEROOM2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_23fe AFD du composant affaire générique]
* [http://WPEROOM2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2886 AFD de paramétrage du modèle d'affaire MDE]

== DCTs ==
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_4ca4e DCT - AFG - affairegenerique - concept - affaire MDE]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_4ca58 DCT - AFG - affairegenerique - concept - operation MDE]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_4c83c DCT affaires génériques]

== Paramétrage ==
* [http://WPEROOM2.uem.lan/eRoom/Production/DocFonctionnelleEfluid/0_a9df8 Note de paramétrage pour créer WKF et modèles d'affaires des lots suivi de l’isolation thermique, suivi de la climatisation performante, suivi du chauffe-eau solaire et suivi des lampes économiques]
* [http://WPEROOM2.uem.lan/eRoom/Production/DocFonctionnelleEfluid/0_158ace Exemple paramétrage critères pour calculs de prime]
* [http://WPEROOM2.uem.lan/eRoom/Production/DocFonctionnelleEfluid/0_8c5ce Note de paramétrage pour rendre impossible l'ajout d'une opération après une certaine étape]

== Lancement Batchs ==
* [http://wikefluid/index.php/Param%C3%A9trage_du_lancement_d%27un_batch_workflow_dans_eclipse Lancer un batch workflow WKF 999]
* Points d'arrêts utiles pour le debug des batchs MDE
** WorkflowBatch.traiterTraitement
** AffaireMDEBatchDAO.fillLoadObject
** CritereUtils.getValeurRetournerParMethode

= '''Architecture technique''' = 

* Les process liés à la maitrise de l'énergie sont codés dans [[efluid]] dans le package : MDE
* L'affaire MDE est pilotée par un workflow dans [[efluid]] : CAMPAGNE_WORKFLOW_MAITRISE_DEMANDE_ENERGIE = 29
* Le portail partenaire est codé dans l'[[Agence_en_ligne|AEL]] dans un package : MDE
* Paramétrage spécifique à la MDE dans l'AEL : [[Parametrage portail partenaire]]
* Installation du portail en développement : [[Installation_du_portail_en_developpement|Installation du portail en développement]]


= '''FAQ efluid''' = 

== Lien "créer un compte partenaire" inexistant ==
* Si le lien n'apparait pas en dessous de l'e-mail du contact c'est que le paramètre entreprise "activerCreationComptePartenaireEnModificationContact" n'est pas à TRUE. &lt;br /&gt;
Celui-ci est par défaut à FALSE, il faut donc penser à le modifier sur l'environnement en question.

== Aucun mail n'est envoyé après validation de la création de compte partenaire ==
* Si aucun mail n'est envoyé, c'est sans doute qu'aucun modèle d'édition n'a été créé pour ça.
Vérifier dans la recherche de modèle d'édition si "mail portail partenaire" existe ou s'il est correctement paramétré grâce à la [http://WPEROOM2.uem.lan/eRoom/Production/DocFonctionnelleEfluid/0_b4d39 note de paramétrage pour la création d'un compte partenaire et mails personnalisés associés].

== Traitements ou onglets non visibles ==
* Vérifier le paramétrage :
- Le traitement ou l'onglet doit être correctement associé au type de role d'operateur en question dans le modèle d'affaire/d'opération..
A vérifier dans efluid par exemple au niveau de l'écran modèle d'affaire, dans le tableau des zones actives de type consultation (en zoomant sur le type de rôle opérateur on a la liste des traitements possible par étape)

- Le user connecté doit avoir le bon type de rôle opérateur : à vérifier dans efluid via le lien info en haut à droite puis tout en bas sur l'onglet utilisateur

== Pour utiliser une version de dev de l'edk ==
# récupérer branche develop de l'edk
# faire les modifs si nécessaire
# regénérer les jar EDK : mvn clean install -P add-java-sources-in-archive
# sur le projet efluid sous Eclipse, mettre le profil maven '''edk-jar-DEV''' puis faire un maven update dependancies et un build

== Pour utiliser une version de dev d'ecore ==
Faire de même
# récupérer branche develop d'ecore
# faire les modifs si nécessaire
# regénérer les jar ecore
# sur le projet efluid sous Eclipse, mettre le profil maven '''ecore-jar-DEV''' puis faire un maven update dependancies et un build

== Pour utiliser une version de dev de l'archi ==
Sur le projet efluid sous Eclipse, mettre le profil maven '''archi-jar-DEV''' puis faire un maven update dependancies et un build</text>
      <sha1>sda8t9hwq0c4cnz4zqikants2uaqxut</sha1>
    </revision>
  </page>
  <page>
    <title>Etinéraire</title>
    <ns>0</ns>
    <id>405</id>
    <revision>
      <id>2685260</id>
      <parentid>2335656</parentid>
      <timestamp>2017-03-22T08:31:53Z</timestamp>
      <contributor>
        <username>Bouthino</username>
        <id>7</id>
      </contributor>
      <comment>/* Fichiers ael */</comment>
      <origin>2685260</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5055" sha1="ilg89pqea3dljtgd5hwu7ui07h406me" xml:space="preserve">{{Modèle:Infobox Application
 | nom              = etinéraire / portail recrutement
 | logo             = logo_etineraire.png
 | responsable      = [[Eric FINICKEL]]
}}

[[Category:application]]
[[Category:etinéraire]]
[[Category:domaine]]

= Configuration =
* utilisateur : superadmin / superadmin
* maven : portail-recrutement
== Fichiers ael ==
&lt;div class="toccolours mw-collapsible" style="width:60em"&gt;
*hermes2.properties
&lt;source lang="properties"&gt;
efluid_BCCLIENT_SOAP_URL=http://localhost:8080/efluid/bcclientaelsoap
BACKUP_SOAP_MESSAGES=true
BACKUP_SOAP_MESSAGES_DIR=D:/java/workspaces/Developpement_dev/ael/logs
LOG_SEVERITY=10
ADDITIONAL_BUNDLE=DEV_AEL
&lt;/source&gt;
*hermes2.properties
&lt;source lang="properties"&gt;
HERMES_DEBUG=true

EXCEPTION_MGR_PATTERN_ID={0,date,yyyyMMdd_HHmmssSSS}_{1}
EXCEPTION_MGR_DIRECTORY=D:\\java\\logErreursInternes\\ael
EXCEPTION_MGR_DELETE_DIRECTORY=D:\\java\\logErreursInternes\\ael\\delete

UTILISATEUR_MOT_DE_PASSE_TAILLE=0;3
UTILISATEUR_MOT_DE_PASSE_CONTROLES=false;false;false;false
UTILISATEUR_MOT_DE_PASSE_REGLES=0;0
UTILISATEUR_MOT_DE_PASSE_DICTIONNAIRE_MOTS_INTERDITS=21212121
UTILISATEUR_MOT_DE_PASSE_DATE_PARAM=03/12/2015
ADMIN_MOT_DE_PASSE_TAILLE=2;0
ADMIN_MOT_DE_PASSE_CONTROLES=false;false;false;false
ADMIN_MOT_DE_PASSE_REGLES=2;0
ADMIN_MOT_DE_PASSE_DICTIONNAIRE_MOTS_INTERDITS=password!123;motdepasse!123;21212121
ADMIN_MOT_DE_PASSE_DATE_PARAM=03/12/2015

HERMES_HELP_ROOT=http://localhost:8887
&lt;/source&gt;
&lt;/div&gt;

= '''Documentation''' = 

* [[Plan de progression:Etineraire|Plan de progression]]

== AFDs ==
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_4ced AFD Recrutement]
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_55f0 AFD - GRH - paramétrage de suivi des affaires de recrutement]

== DCTs ==
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6bda9 DCT - GRH - affairerecrutement - Enchaînement - Gérer un candidat]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6bdae DCT - GRH - affairerecrutement - Enchaînement - Gérer une annonce]

* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6e7f2 DCT - GRH - affairerecrutement - Enchaînement - Gérer la connexion à l'espace candidat.doc]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_6e99b DCT - GRH - affairerecrutement - Enchaînement - Gérer une candidature depuis un portail.doc]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_b82ca DCT - AEL - Authentification]

== Etudes ==

* Etude de la séparation de la séparation du code entre le projet etinéraire &amp; efluid : evt 123525

= '''Architecture technique''' = 

* La candidature est une affaire de recrutement (affaire générique) codée dans [[efluid]] dans un package : GRH
* L'affaire de recrutement est pilotée par un workflow dans [[efluid]] : CAMPAGNE_WORKFLOW_SUIVI_RECRUTEMENT = 34
* Le portail de recrutement est codé dans l'[[Agence_en_ligne|AEL]] dans un package : GRH
* Paramétrage spécifique à étinéraire dans l'AEL : [[Parametrage etineraire]]
* Documents d'architecture : [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_96b4e http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_96b4e]
* Installation du portail en développement : [[Installation_du_portail_en_developpement|Installation du portail en développement]]

= '''Historique du projet''' = 

* Demande de la part d'UEM de posséder une gestion du recrutement par workflow / affaire générique (spec : [[FG]])
* Intégration du domaine etinéraire dans le groupe [[workflow]]

= '''FAQ''' = 

* '''Lancement tests selenium ''' : 
- Utiliser le profil maven test-selenium dans l'AEL

- Ne pas tenir compte de l'erreur de compilation "Plugin execution not covered by lifecycle configuration: org.apache.maven.plugins:maven-dependency-plugin:2.3:copy (execution: copy-dependencies, phase: process-test-resources)" 

- Les tests sont codés dans la classe TestsPortailRecrutement, ils se lancent comme les JUnit (clic droit Run As JUnit test)

- Le selenium2.properties est nécessaire pour faire tourner les tests, il faut notamment y spécifier les paramètres suivants :

&lt;source lang="java"&gt;

# Utilisation du driver IE (Pop-up IE pour les tests)
FENETRE_IE=true

# Chemin pour l''application
APPLICATION_CHEMIN=/ecoreWar/jsp/arc/commun/frame.jsp

# Chemin du driver IE de sélénium
DRIVER_IE_CHEMIN=D:\\java\\workspaces\\resources\\IEDriverServer.exe

BASE_URL=http://localhost:8090/ael/

# Utilisé pour la création de compte
NOM_UTILISATEUR_PAR_DEFAUT={login}
MOT_DE_PASSE_PAR_DEFAUT={mdp}

TEMPS_ATTENTE_APPLICATION_SECONDES=1
MODE_SANS_CONTROLE_SUR_SUITE=true

IMPLEMENTATION_DRIVER=com.efluid.ecore.selenium.ie.InternetExplorerDriverEcore
&lt;/source&gt;

- A lire aussi : [[Guide développeur Selenium|Le Guide du développeur Selenium]] 


* ''' Menu de gauche inexistant ''' : 
Bien vérifier que la valeur du paramètre HERMES_MENU_ID dans ael/properties/hermes2.properties (en V11) ou du ael-webapp/classes/Hermes.properties (en V12)
Pour Etineraire HERMES_MENU_ID=menuPortailRecrutement</text>
      <sha1>ilg89pqea3dljtgd5hwu7ui07h406me</sha1>
    </revision>
  </page>
  <page>
    <title>Règlement</title>
    <ns>0</ns>
    <id>9245</id>
    <revision>
      <id>62674</id>
      <parentid>62673</parentid>
      <timestamp>2013-09-01T19:38:11Z</timestamp>
      <contributor>
        <username>Flatres</username>
        <id>26</id>
      </contributor>
      <minor/>
      <origin>62674</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6379" sha1="qeu9ja6xatnhgkrhxmox6aln8qx1f48" xml:space="preserve">[[Category:domaine]]

=Documentation générale=
* [AFD du domaine]
*...

=Batchs =
==État des lieux==
Dans le domaine règlement nous avons aujourd’hui 7 grandes familles de batch, à savoir :
 
*1.	Création des encaissements à partir d’un fichier en entrée
*2.	Création des encaissements à partir des lignes de comptes débitrices (dettes)
*3.	Création des décaissements à partir des lignes de comptes créditrices (avoirs)
*4.	Gestions de retours banque (impayés bancaires, VNE et DCD)
*5.	Génération des flux sortants :
**a.	Génération des ordres de prélèvements
**b.	Génération des ordres de virements
**c.	Génération des flux remboursements divers
*6.	Créations des opérations diverses
*7.	Editions
 
==Orientation des nouveaux développement lot 12==
Dans le cadre des nouveaux développements ERDF (et pour lesquels vous êtes concernés)  nous allons nous intéresser aux familles 1, 2, 3, 4 et 5 uniquement.  Ci-dessous mes remarques :
===Remarque n° 1===
Pour certaines de ces 5 familles il existe aujourd’hui plusieurs versions de  batch (V1, V2, V3). La questions que l’on se pose donc aujourd’hui et de savoir vers où on va aller ? Et comment on va structurer nos batch pour qu’ils soient évolutifs (à moindre cout)  et  que l’on puis développer facilement des nouvelles interfaces et/ou batch de création des opération financières de manière générale.  Aujourd’hui nous avons deux solutions mises en place, à savoir :
 
====Solution 1==== 
*A chaque nouveau format de fichier on crée un nouveau code batch qui s’appuie sur une structure commune. 
*A chaque nouvelle méthode de création des encaissements à partir d’une ligne débitrice (par code banque, par offre produit, SEPA) on crée un nouveau code batch qui s’appuie sur une structure commune 
 
====Solution 2====
*A chaque nouveau format de fichier on crée un mappeur spécifique mais le code batch reste le même. Ils instancie des classes filles qui s’appuie sur des classes mères 
*A chaque méthode de création des décaissements à partir d’une ligne créditrice (par code banque, par offre produit, SEPA) on crée un JobDAO spécifique mais le code batch reste le même.
 
Chaque solution possède  ses avantages et ses inconvénients mais celle que l’on veut  privilégier aujourd’hui est la solution 2. En effet elle permet de ne gérer qu’un seul batch qui, selon le type de format à gérer ou selon la méthode d’affectation (paramètre en entré du batch), le batch  va instancier les bonnes classes filles. Ainsi aux yeux des tous les clients et de la recette il n’existera plus qu’un seul batch à gérer par famille.  Côté conception technique il y aura des classes filles de petite taille à créer à chaque nouveau développement.

===Remarque n° 2=== 
Les batch, quelques soient leur familles, ils ont besoin de deux socles communs , à savoir :
*Un socle commun qui est purement batch 
*Un socle commun qui relève des traitements
 
Socle commun batch : dans ce socle commun nous plaçons les requêtes communes de type SELECT, MAJ et/ou INSERT car il s’agit presque toujours de faire la même chose : MAJ du solde du compte client, MAJ du solde de la ligne lettre, création d’une ligne lettrante, création d’une transaction, etc.  Il existe aujourd’hui un socle commun batch V3 pour les batch de la famille numéro 1.  Pour les autres familles des classes mères ont été crées mais il reste encore à fignoler et/ou renforcer certaines parties. 
 
Socle commun traitement : il s’agit ici de factoriser les traitements communs entre le TP et le batch tout en mettant une couche « proceses » intermédiaire entre les batch les  « process » d’imputation comptable. Ce socle « traitement » permet au système non seulement de réaliser les imputations comptable CAC et IC mais aussi de gérer les méthodes d’affectation pour les batch de la famille 1.  Ce socle commun centralise l’intelligence (ou les règles) de la comptabilité. Il est disponibles pour toutes les familles de batch.  La seule chose qui manque pour la famille numéro 4 est la couche intermédiaire.

===Remarque n° 3=== 
Comment on voit le futur ?  Avec  l’arrivé du SEPA nous souhaiterons n’avoir qu’un seul bath par famille de batch qui géreront les trois spécificités suivantes : 
*Règles SEPA 
*Règles EDF 
*Règles ERDF

==CONCLUSION==
Les batch d’ERDF devront donc être conçus en se basant sur la solution 2. Ainsi :

*Pour la création d’encaissements à partir des lignes de compte débitrices on doit arriver à la même conception de ce que CGU a fait pour le REG024MT : le REG024MT peut gérer plusieurs type de formats de fichiers. Il suffit de lui passer  en paramètre du batch le format du fichier que l’on veut gérer. Dans notre cas il faudra lui passer en paramètre du batch la méthode d’affectation : Par code banque ? Par  offre produit ? SEPA ? ERDF ? . Puis le batch, en fonctionne de la méthode, va instancier les bonnes classes filles  Cette remarque concerne Tarik (evt 86445). Tarik une fois que nous aurions conçu ainsi le batch ERDF, ce batch deviendra, dans le futur, le seul batch de création des encaissements à partir d’une ligne débitrice. Nous pourrons donc nous séparer de autres vieux batch.

*Pour la création des décaissements à partir des lignes de compte créditrices : même remarque que la précédente. Cette remarque concerne Tarik (evt 86445)

*Pour la gestion des retours banque à partir de fichiers en entrée : même remarque que la remarque précédente. Dans cet cas de figure on devra passer en paramètre du batch le format du fichier (SEPA, EDF, ERDF) cette remarque concerne Jérôme et Xavier (evt 89665 et 89667).

*Pour la génération des flux de prélèvements et virements même remarque que la remarque précédente. Dans ce cas de figure on devra passer en paramètre du batch le format du fichier de sortie (SEPA, EDF, ERDF) cette remarque concerne Catherine et Tarik (evt 89663 et 89664).

*Pour la création d’encaissements via un fichier en entrée on doit arriver à la même conception de ce que CGU a fait pour le REG024MT : le REG024MT peut gérer plusieurs type de formats de fichiers. Il suffit de lui passer  en paramètre du batch le format. Cette remarque ne concerne pour le moment personne</text>
      <sha1>qeu9ja6xatnhgkrhxmox6aln8qx1f48</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine liste de gestion</title>
    <ns>0</ns>
    <id>12903</id>
    <revision>
      <id>4062461</id>
      <parentid>4053418</parentid>
      <timestamp>2020-12-23T09:00:52Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>4062461</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4440" sha1="p932ytjza6qzzmcpxnb1ugwrkenf20c" xml:space="preserve">{{Modèle:Domaine
 | nom = Liste De Gestion
}}
[[Category:domaine]][[Category:Liste de gestion]][[Category:pole composants transverses]]
= Documentation générale =
* [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_e8db AFD produit]
* [http://wperoom1/eRoom/Production/DocFonctionnelleEfluid/0_103713 AFD client]
* [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_104016 DCT]

= Concepts =
* type de rôle : "compétences" de l'agent

* poste de travail : différent du poste dans l'annuaire mais même notion

* Une tâche =&gt; Affecter du travail aux personnes
** avoir une vue globale des travaux dans plusieurs campagnes, plutôt que de devoir consulter chaque campagne, lot, relève ou intervention...

* Tâche perdue : une tâche n'a pas pu se faire
** la raison pour laquelle elle n'a pas pu se faire y est indiquée
** à la différence d'un EDP où s'il y a un problème à la création, rien n'est créé, pour une tâche on essaie toujours de la créer et si ça ne marche pas elle va dans une sorte de "poubelle" (=&gt; les tâches perdues)

* Nature de tâche
** =&gt; nature du travail à faire (avec des durées, des échéances, ...)
** paramétrée sur une étape workflow, en fonction du paramètre entreprise LDG
** on y affecte un type de rôle
** liée à un type d'anomalie, plutôt dans les campagne classiques : soit on l'affecte dans une grille via la nature sur l'étape, soit sur le type anomalie.

* Périmètres métiers
** sur un portefeuille, sur un modèle de campagne / de lot, ... (d'abord on regarde le lot et ensuite la campagne)
** ex : regarder l'objet traité de l'EDP pour déterminer le portefeuille
* Type de périmètre instancié via le même écran que le type de rôle métier
objectif =&gt; créer la tâche au bon endroit (dans le bon groupe, etc.)

* Une seule tâche pour 1 élément de travail : si on essaie de créer 1 tâche sur 1 élt de travail qui a déjà 1 tâche au statut à traiter (= en cours ou à faire) alors celle-ci est clôturée

* Le "faux" concept de tâche bloquante ou non bloquante
** une tâche bloquante est une tâche liée à une anomalie bloquante et idem pour une non bloquante.
** si plusieurs ano bloquantes : utiliser la priorité sur la nature de tâche

* Liens entre tâches et EDP
** une tache bloquante est liée directement à un EDP
** une tâche non bloquante est liée à l'ano non bloquante qui est liée à l'EDP, pour laisser vivre l'EDP en parallèle (et potentiellement avoir une tâche bloquante)

* Quand un edp change d'étape ou ano est levée =&gt; la tâche est clôturée automatiquement

* Ecrans
** lien "vérifier la cohérence" sur un périmètre =&gt; pour vérifier la cohérence du paramétrage
** bandeau des traitements non affiché si tâche à faire sur un EDP uniquement en consultant l'EDP depuis la tâche
** mes tâches (depuis menu) : pour voir les tâches affectées à l'agent connecté à un instant t
** Poste de travail : avoir le statut actif pour le trouver

* affectation de tâches
** Rôle : gestionnaire =&gt; gère un groupe de travail)
** Rôle Superviseur =&gt; supervise un rôle métier

* moteur LDG (= moteur des tâches) : spécifique à chaque domaine (ex. notable : intervention)

* Dans un évt d'ano qui arriverait : savoir quel utilisateur a effectué les tâches (ou se mettre en gestionnaire)

* A la création et au placement d'une tâche au bon endroit , le type de rôle par défaut quand on ne trouve pas ce qu'il faut

* Carnets de travail
** plutôt côté domaine Intervention (MSI, CDI, BDA)
** en lien avec mobefluid
** un carnet regroupe des tâches d'intervention ou de relève =&gt; matérialiser un regroupement de ses tâches pour une période donnée (comme agrafer un paquet de feuilles)

* type de tâche sur Type de rôle métier sur tâche
** le type de tâche de programmation concerne les carnets de travail

* modèle de carnet

* règle d'affectation sur groupe de travail : "avec ou sans carnet ..." =&gt; si pas de carnet :
** avec : crée le carnet automatiquement
** sans : pas créé

* Mobefluid
** la tâche représente la validation du chef et pas le boulot "unitaire" des agents

* Dans le code
** une Navig spécifique (via SPI) dans les différents domaines pour débrancher vers tout "type" d'objet rattaché à une tâche dans la recherche de tâche et dans le zoom d'une tâche (onglet traitement)
*** nécessite un type de chargement pour charger cet objet</text>
      <sha1>p932ytjza6qzzmcpxnb1ugwrkenf20c</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine BGE</title>
    <ns>0</ns>
    <id>266366</id>
    <revision>
      <id>4062313</id>
      <parentid>4062312</parentid>
      <timestamp>2020-12-10T08:38:20Z</timestamp>
      <contributor>
        <username>Grzejsz</username>
        <id>69</id>
      </contributor>
      <comment>/* Purge campagne de construction des courbes pour suppression définitive */</comment>
      <origin>4062313</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="16392" sha1="j7a3scf9qr0uk7ku7bptgouwg2ajcx3" xml:space="preserve">[[category:domaine]]
== Modèle simplifié ==
C'est un modèle simplifié qui n'a pas vocation à remplacer l'AFD.

{{Todo|ajouter un modèle statique}}

== Requêtes utiles ==
=== Purge campagne de construction des courbes pour suppression définitive ===
Le commit est fait par les instruction de fin (drop)

&lt;source lang="sql"&gt;

define LOT_ID = '30473164049';
 
BEGIN
   EXECUTE immediate 'DROP TABLE suppression_reinit_lot_cc';
EXCEPTION
   WHEN OTHERS THEN
      IF SQLCODE != -942 THEN
         RAISE;
      END IF;
END;
/
 
CREATE TABLE suppression_reinit_lot_cc (
	edp_id VARCHAR2(25),
	anomalie_id VARCHAR2(25),
	courbe_id VARCHAR2(25),
	grandeur_id VARCHAR2(25),
	partitionvaleurs_id VARCHAR2(25),
	diagnostic_id VARCHAR2(25),
	valeurcalcul_id VARCHAR2(25),
	anomalievaleurcalcul_id VARCHAR2(25),
	echange_id VARCHAR2(25));
 
INSERT INTO suppression_reinit_lot_cc
SELECT edp.id, ano.id, courbe.id, g.id, pv.id, d.id, val.id, anov.id, pub.id
FROM tlot l
INNER JOIN telementdepopulationwkf edp  ON (edp.lot_id = l.id)
LEFT JOIN tanomalie ano ON (ano.elementpopulation_id = edp.id)
LEFT JOIN tcourbeecore courbe ON (edp.objettraite_id = courbe.id AND objettraite_role = courbe.ROLE)
LEFT JOIN tgrandeur g ON (courbe.id = g.courbe_id)
LEFT JOIN tpartitionvaleurs pv ON (pv.grandeur_id = g.id)
LEFT JOIN tdiagnostic d ON (d.objetdiagnostique_id = g.id)
LEFT JOIN tvaleurcalcul val ON (val.diagnostic_id = d.id)
LEFT JOIN tanomalievaleurcalcul anov ON (anov.valeurcalcul_id = val.id)
LEFT JOIN techange pub ON (pub.objetmaitre_id=courbe.id AND pub.objetmaitre_role=courbe.role)
WHERE l.id = '&amp;LOT_ID' AND l.modeledelot_role='com.efluid.ecore.courbe.workflow.constructeurcourbe.businessobject.ModeleDeLotConstructeurCourbeWorkflow'
UNION ALL
SELECT edp.id, NULL, courbefille.id, g.id, pv.id, NULL, NULL, NULL, NULL
FROM tlot l
JOIN telementdepopulationwkf edp  ON (edp.lot_id = l.id)
JOIN tcourbeecore courbe ON (edp.objettraite_id = courbe.id AND edp.objettraite_role = courbe.ROLE)
JOIN courbeagregee_courbes lienmerefille ON lienmerefille.SOURCE = courbe.id
JOIN tcourbeecore courbefille ON lienmerefille.dest = courbefille.id
LEFT JOIN tgrandeur g ON (courbefille.id = g.courbe_id)
LEFT JOIN tpartitionvaleurs pv ON (pv.grandeur_id = g.id)
WHERE l.id = '&amp;LOT_ID' AND l.modeledelot_role='com.efluid.ecore.courbe.workflow.constructeurcourbe.businessobject.ModeleDeLotConstructeurCourbeWorkflow';
 
DELETE FROM techange pub WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE pub.id = echange_id);
DELETE FROM tanomalievaleurcalcul anov WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE anov.id = anomalievaleurcalcul_id);
DELETE FROM tvaleurcalcul val WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE val.id = valeurcalcul_id);
DELETE FROM tdiagnostic diag WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE diag.id = diagnostic_id);
DELETE FROM tpartitionvaleurs pv WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE pv.id = partitionvaleurs_id);
DELETE FROM tgrandeur g WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE g.id = grandeur_id);
DELETE FROM tcourbeecore courbe WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE courbe.id = courbe_id);
DELETE FROM tanomalie ano WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE ano.id = anomalie_id);
DELETE FROM tedpconstructeurcourbewkf edp WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE edp.id = edp_id);
DELETE FROM telementdepopulationwkf edp WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_cc WHERE edp.id = edp_id);
UPDATE tlot l SET l.selectionrealisee= 0, l.STATUT = 0 WHERE l.id = '&amp;LOT_ID';
 
-- le drop fait le commit!
TRUNCATE TABLE suppression_reinit_lot_cc;
DROP TABLE suppression_reinit_lot_cc;
&lt;/source&gt;

=== Purge campagne de BGE pour suppression définitive ===
{{info|texte=Il est maintenant possible de réinitialiser le lot en TP}}
Le commit est fait par les instruction de fin (drop)

script v14
&lt;source lang="sql"&gt;

define LOT_ID = '23087009023';
 
BEGIN
   EXECUTE immediate 'DROP TABLE suppression_reinit_lot_bge';
EXCEPTION
   WHEN OTHERS THEN
      IF SQLCODE != -942 THEN
         RAISE;
      END IF;
END;
/
 
CREATE TABLE suppression_reinit_lot_bge (
	edp_id VARCHAR2(25),
	anomalie_id VARCHAR2(25),
	courbebge_id VARCHAR2(25),
	grandeur_id VARCHAR2(25),
	partitionvaleurs_id VARCHAR2(25),
	diagnostic_id VARCHAR2(25),
	valeurcalcul_id VARCHAR2(25),
	anomalievaleurcalcul_id VARCHAR2(25),
	echange_id VARCHAR2(25));
 
INSERT INTO suppression_reinit_lot_bge
SELECT edp.id, ano.id, bge.id, g.id, pv.id, d.id, val.id, anov.id, pub.id
FROM tlot l
INNER JOIN telementdepopulationwkf edp  ON (edp.lot_id = l.id)
LEFT JOIN telementdepopulationbgewkf edpbge ON (edp.id = edpbge.id)
LEFT JOIN tanomalie ano ON (ano.elementpopulation_id = edp.id)
LEFT JOIN tcourbeecore bge ON (edp.objettraite_id = bge.id AND objettraite_role = bge.ROLE)
LEFT JOIN tgrandeur g ON (bge.id = g.courbe_id)
LEFT JOIN tpartitionvaleurs pv ON (pv.grandeur_id = g.id)
LEFT JOIN tdiagnostic d ON (d.objetdiagnostique_id = g.id)
LEFT JOIN tvaleurcalcul val ON (val.diagnostic_id = d.id)
LEFT JOIN tanomalievaleurcalcul anov ON (anov.valeurcalcul_id = val.id)
LEFT JOIN techange pub ON (pub.objetmaitre_id=bge.id AND pub.objetmaitre_role='com.hermes.itv.bge.businessobject.CourbeBilanGlobalEnergie')
WHERE l.id = '&amp;LOT_ID' AND l.modeledelot_role='com.hermes.itv.bge.businessobject.ModeleDeLotCalculBilanGlobalEnergieWorkflow'
UNION ALL
SELECT edp.id, NULL, bgefils.id, g.id, pv.id, NULL, NULL, NULL, NULL
FROM tlot l
JOIN telementdepopulationwkf edp  ON (edp.lot_id = l.id)
JOIN telementdepopulationbgewkf edpbge ON (edp.id = edpbge.id)
JOIN tcourbeecore bge ON (edp.objettraite_id = bge.id AND edp.objettraite_role = bge.ROLE)
JOIN courbeagregee_courbes lienperefils ON lienperefils.SOURCE = bge.id
JOIN tcourbeecore bgefils ON lienperefils.dest = bgefils.id
LEFT JOIN tgrandeur g ON (bgefils.id = g.courbe_id)
LEFT JOIN tpartitionvaleurs pv ON (pv.grandeur_id = g.id)
WHERE l.id = '&amp;LOT_ID' AND l.modeledelot_role='com.hermes.itv.bge.businessobject.ModeleDeLotCalculBilanGlobalEnergieWorkflow';
 
DELETE FROM ttracetraitementenmasse trace WHERE EXISTS (
SELECT 1 FROM telementdepopulationwkf edp INNER JOIN tlot l  ON edp.lot_id = l.id
WHERE l.id = '&amp;LOT_ID' and edp.id = trace.EDP_ID);

DELETE FROM techange pub WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE pub.id = echange_id);
DELETE FROM tanomalievaleurcalcul anov WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE anov.id = anomalievaleurcalcul_id);
DELETE FROM tvaleurcalcul val WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE val.id = valeurcalcul_id);
DELETE FROM tdiagnostic diag WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE diag.id = diagnostic_id);
DELETE FROM tpartitionvaleurs pv WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE pv.id = partitionvaleurs_id);
DELETE FROM tgrandeur g WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE g.id = grandeur_id);
DELETE FROM tcourbeecore bge WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE bge.id = courbebge_id);
DELETE FROM tanomalie ano WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE ano.id = anomalie_id);
DELETE FROM telementdepopulationbgewkf edp WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE edp.id = edp_id);
DELETE FROM telementdepopulationwkf edp WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE edp.id = edp_id);
UPDATE tlot l SET l.selectionrealisee= 0 WHERE l.id = '&amp;LOT_ID'; 

-- le drop fait le commit!
TRUNCATE TABLE suppression_reinit_lot_bge;
DROP TABLE suppression_reinit_lot_bge;
&lt;/source&gt;


script v13

&lt;source lang="sql"&gt;

-- id du lot à traiter
define LOT_ID = '951689321';
 
BEGIN
   EXECUTE immediate 'DROP TABLE suppression_reinit_lot_bge';
EXCEPTION
   WHEN OTHERS THEN
      IF SQLCODE != -942 THEN
         RAISE;
      END IF;
END;
/
 
CREATE TABLE suppression_reinit_lot_bge (
	edp_id VARCHAR2(25),
	anomalie_id VARCHAR2(25),
	courbebge_id VARCHAR2(25),
	grandeur_id VARCHAR2(25),
	partitionvaleurs_id VARCHAR2(25),
	diagnostic_id VARCHAR2(25),
	valeurcalcul_id VARCHAR2(25),
	anomalievaleurcalcul_id VARCHAR2(25),
	echange_id VARCHAR2(25),
	trace_id VARCHAR2(25));
 
INSERT INTO suppression_reinit_lot_bge
SELECT edp.id, ano.id, bge.id, g.id, pv.id, d.id, val.id, anov.id, pub.id, edpbge.tracecalcul_id
FROM tlot l
INNER JOIN telementdepopulationwkf edp  ON (edp.lot_id = l.id)
LEFT JOIN telementdepopulationbgewkf edpbge ON (edp.id = edpbge.id)
LEFT JOIN tanomalie ano ON (ano.elementpopulation_id = edp.id)
LEFT JOIN tcourbeecore bge ON (edp.objettraite_id = bge.id AND objettraite_role = bge.ROLE)
LEFT JOIN tgrandeur g ON (bge.id = g.courbe_id)
LEFT JOIN tpartitionvaleurs pv ON (pv.grandeur_id = g.id)
LEFT JOIN tdiagnostic d ON (d.objetdiagnostique_id = bge.id AND d.objetdiagnostique_role = bge.ROLE)
LEFT JOIN tvaleurcalcul val ON (val.diagnostic_id = d.id)
LEFT JOIN tanomalievaleurcalcul anov ON (anov.valeurcalcul_id = val.id)
LEFT JOIN techange pub ON (pub.objetmaitre_id=bge.id AND pub.objetmaitre_role='com.hermes.itv.bge.businessobject.CourbeBilanGlobalEnergie')
WHERE l.id = '&amp;LOT_ID' AND l.modeledelot_role='com.hermes.itv.bge.businessobject.ModeleDeLotCalculBilanGlobalEnergieWorkflow'
UNION ALL
SELECT edp.id, null, bgefils.id, g.id, pv.id, null, null, null, null, null
FROM tlot l
JOIN telementdepopulationwkf edp  ON (edp.lot_id = l.id)
JOIN telementdepopulationbgewkf edpbge ON (edp.id = edpbge.id)
JOIN tcourbeecore bge ON (edp.objettraite_id = bge.id AND edp.objettraite_role = bge.ROLE)
JOIN courbeagregee_courbes lienperefils on lienperefils.source = bge.id
JOIN tcourbeecore bgefils ON lienperefils.dest = bgefils.id
LEFT JOIN tgrandeur g ON (bgefils.id = g.courbe_id)
LEFT JOIN tpartitionvaleurs pv ON (pv.grandeur_id = g.id)
WHERE l.id = '&amp;LOT_ID' AND l.modeledelot_role='com.hermes.itv.bge.businessobject.ModeleDeLotCalculBilanGlobalEnergieWorkflow';
 
DELETE FROM techange pub WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE pub.id = echange_id);
DELETE FROM tanomalievaleurcalcul anov WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE anov.id = anomalievaleurcalcul_id);
DELETE FROM tvaleurcalcul val WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE val.id = valeurcalcul_id);
DELETE FROM tdiagnostic diag WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE diag.id = diagnostic_id);
DELETE FROM tpartitionvaleurs pv WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE pv.id = partitionvaleurs_id);
DELETE FROM tgrandeur g WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE g.id = grandeur_id);
DELETE FROM tcourbeecore bge WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE bge.id = courbebge_id);
DELETE FROM tanomalie ano WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE ano.id = anomalie_id);
DELETE FROM telementdepopulationbgewkf edp WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE edp.id = edp_id);
DELETE FROM telementdepopulationwkf edp WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE edp.id = edp_id);
DELETE FROM ttracetraitementenmasse trace WHERE EXISTS (SELECT 1 FROM suppression_reinit_lot_bge WHERE trace.id = trace_id);
 
-- le drop fait le commit!
TRUNCATE TABLE suppression_reinit_lot_bge;
DROP TABLE suppression_reinit_lot_bge;
&lt;/source&gt;

== Besoin fonctionnel ==
Un BGE (bilan global énergie) est une courbe qui représente une énergie ou une puissance calculée à partir de données réelles ou prévisionnelles. Ces courbes sont calculées à partir d’un workflow.

On a 3 grands processus :
=== Enercom ===
Ici le but est de faire des calcul prévisionnel d’énergie (à court terme ou long terme) à renvoyer vers Enercom pour un fournisseur donné, pour qu’Enercom puisse gérer les achat d’énergie. On calcul donc des énergies prévisionnelles (dans le futur), quotidiennement pour publier des données tous les jours.

=== Reconstitution des flux ===
Le GRD doit faire des calculs de reconstitution des flux sur sa concession. Cela consiste à attribuer, semaine par semaine, le total des consommations ou production de chaque responsable d’équilibre. Ces calculs se font a posteriori (sur une période passée). Pour cela on relève les courbes de charge ou on estime des courbes à partir des relèves (profilage) pour tous les clients au pas de temps donné (30 minutes). L’objectif est de remonter ces infos vers RTE pour qu’il agrège les données au niveau national. Cela a pour but d’inciter les responsable d’équilibre à équilibrer la production et la consommation, puisqu’ils sont pénalisés s’ils ne sont pas à l’équilibre.
Il faut donc pour chaque responsable d’équilibre (RE) attribut la somme des énergies :
	Consommées télérelevées
	Consommées profilées
	Produites télérelevées
	Produites profilées
	Energie des pertes (techniques et non techniques, calculées à partir de l’énergie totale sur le réseau, et attribué à un responsable d’équilibre désigné par le GRD).
=== Capacité ===
Similaire à la reconstitution des flux, l’objectif est ici de s’intéresser à la puissance appelée en pointe. L’acteur responsable des capacités s’appelle un acteur obligé (chaque fournisseur désigne son acteur obligé) pour lequel on doit calculer une puissance de référence. Cela obligera les acteurs obligés à prouver qu’il aurait été en mesure de fournir suffisamment d’énergie en cas d’hiver rigoureux. (par achat de certificat de capacité, ou en certifiant ses moyen de production, ou en justifiant de capacité d’effacement).
	
Les calculs se font sur une période d’une année de livraison (année civile, AL - 1 ou AL - 2). Après avoir calculé la consommation totale et réelle des clients d’un acteur obligé, on estime la consommation qui aurait eu lieu en cas de température extrême (hiver très froid), et on ne garde que certains jours particuliers (PP1 choisis par RTE). Cela permet de calculer la puissance de référence pour l'acteur obligé.

= Utilisation dans efluid =
Pour paramétrer une campagne BGE, il faut avoir en tête que c’est un workflow récurrent. Il est donc nécessaire de créer un planning et de déclencher les échanges pour créer les campagnes.

En créant un modèle de lot, on définit :
* Le type de processus concernée
* Les paramètres concernant la période à calculer.
* Le type d’objet connexe :
:Pour Enercom, on définit sur le modèle de lot la liste exhaustive des modeleBGE à utiliser. 
Le batch de sélection (BGE001MT) créera un EDP et un BGE sera cré par modèle BGE.
:Pour les autres traitements, on définit un type d’objet connexe (acteur obligé, RE, fournisseur), une concession, et un unique modèle BGE.
Le batch de sélection sélectionnera tous les PDS actifs de la concession, identifiera les acteurs actifs et créera pour chacun un EDP, rattaché à l’acteur connexe, et créer une grappe de BGE/courbe agrégée à l’image de la grappe de MBGE/MCC rattachée au modèle de lot.  Certains BGE de la grappe ne seront créés que sous certaines conditions (condition d’existence portée par MBGE)

== Prérequis ==

Pour les traitements prévisionnels, il faudra notamment :
* pour les courbes de charger, passer le batch PRJ001MT pour calculer les courbe d'énergie prévisionnelles. (utilisation d'un calendrier projection).
* pour les profilés, avoir sur la station météo les températures normales, la température prévisionnelle (si prévision court terme), les courbes de sous-profil brut préparé, les grandients de température préparé, et les sous-profil ajusté prévisionnels.  (calculés par worfklow de gestion des données climatiques GDC). Les profilés utilisent les consommations mensuelles (traitement H) pour définir une énergie, et utilise ces coefficient pour faire le profilage.

Pour les traitements se basant sur les données réel, il faut :
* les courbes de charge réelles sur les PDS actifs. (télérelève, import de courbe)
* pour les profilés, les courbes de températures normales et réelles, les gradients ajustés réels et les sous-profil ajustés réelles (calculée par workflow GDC). On exploite également les consommations des relèves validées sur les PDS.</text>
      <sha1>j7a3scf9qr0uk7ku7bptgouwg2ajcx3</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine edoc</title>
    <ns>0</ns>
    <id>311621</id>
    <redirect title="Edoc" />
    <revision>
      <id>590531</id>
      <parentid>590526</parentid>
      <timestamp>2015-01-16T13:34:31Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <comment>Page redirigée vers [[Edoc]]</comment>
      <origin>590531</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="42" sha1="pojciv6qq4xloctqfjy4qlmtc1u0xmb" xml:space="preserve">#REDIRECTION [[edoc]]
[[Category:domaine]]</text>
      <sha1>pojciv6qq4xloctqfjy4qlmtc1u0xmb</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine composant sw - jms</title>
    <ns>0</ns>
    <id>116886</id>
    <revision>
      <id>4053373</id>
      <parentid>2375524</parentid>
      <timestamp>2019-06-17T14:41:16Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>4053373</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="245" sha1="g6mu6owbhe2zk50sprj62u9jox3el80" xml:space="preserve">[[Category:domaine]][[Category:composant sw-jms]][[Category:pole composants transverses]]
[[Web Service]]
= liens =
== interne ==
* [http://wperoom1/eRoom/Prod4/ProjetsERDFEfluid/0_31b7 CR des points d'avancement nouvelle archi des services web]</text>
      <sha1>g6mu6owbhe2zk50sprj62u9jox3el80</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine composant requêteur</title>
    <ns>0</ns>
    <id>356588</id>
    <revision>
      <id>660601</id>
      <parentid>660416</parentid>
      <timestamp>2015-02-20T16:17:40Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>660601</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="588" sha1="huvl4ulrtd6y0x48izl1b6ln343j28d" xml:space="preserve">{{Modèle:Domaine
 | nom         = composant requêteur
 | responsable = [[CTH]]
}}
[[category:domaine]][[category:requêteur]]
Le domaine requêteur est composé de 2 types d’évènements géré par des domaines différents :
* Le [[domaine composant requêteur]] : pour assurer la maintenance du composant
* Et le [[domaine paramétrage requêteur]] : pour traiter le paramétrage du requêteur dans l’application [[efluid]]
(Pour les autres applications : [[suivefluid]], [[ethaque]], [[eldap]], ... ce paramétrage est assuré directement par le responsable de chaque application)</text>
      <sha1>huvl4ulrtd6y0x48izl1b6ln343j28d</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine paramétrage requêteur</title>
    <ns>0</ns>
    <id>1776</id>
    <revision>
      <id>4033878</id>
      <parentid>3944463</parentid>
      <timestamp>2018-11-23T09:44:39Z</timestamp>
      <contributor>
        <username>Grzejsz</username>
        <id>69</id>
      </contributor>
      <minor/>
      <comment>/* Stockage en base de données */</comment>
      <origin>4033878</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="21971" sha1="mj53d724phxcgrxkwzaqikphv1l9q1k" xml:space="preserve">{{Modèle:Domaine
 | nom         = paramétrage requêteur
}}
[[category:domaine]][[category:requêteur]]
&lt;p&gt;Cette page rassemble les informations générales concernant le paramétrage du requêteur pour l’application [[efluid]]. Sa maintenance est assurée par chaque domaine, en fonction de la vue principale.&lt;/p&gt;
&lt;p&gt;(Pour les autres applications : [[suivefluid]], [[ethaque]], [[eldap]], ... ce paramétrage est assuré directement par le responsable de chaque application).&lt;/p&gt;


= Correspondance Vue principale / Domaine en charge de la maintenance =
{| class="wikitable sortable"
|-
! Vue principale !! Domaine !! Développeur
|-
| acteur (VRP_Acteur.xml) || ref.acteur || Anthony BAINVILLE (ABAI)
|-
| action (VRP_Action.xml) || ref.affaireaction || Anthony BAINVILLE (ABAI)
|-
| affaire (VRP_Affaire.xml) || ref.affaireaction || Anthony BAINVILLE (ABAI)
|-
| compte client (VRP_CompteClient.xml) || rec.comptabilite || Lionel PRYBYLA (LPR)
|-
| contrat (VRP_Contrat.xml) || crm.contrat || Anthony BAINVILLE (ABAI)
|-
| courbe (VRP_Courbe.xml) (ecore) || ecore.courbe ||
|-
| demande prestation (VRP_DemandePrestation.xml) || crm.demandeprestation || Anthony BAINVILLE (ABAI)
|-
| devis (VRP_Devis.xml) || fac.devis || Alexandre HAFFNER (AHA) / Alexandre THIBAULT (ATH)
|-
| écriture (VRP_Ecriture.xml) || rec.interfacecomptable || Anthony BAINVILLE (ABAI)
|-
| espace de livraison (VRP_EspaceDeLivraison.xml) || ref.edl || Anthony BAINVILLE (ABAI)
|-
| facture (VRP_Facture.xml) || fac.facturation || Alexandre HAFFNER (AHA) / Alexandre THIBAULT (ATH)
|-
| facture principale (VRP_FacturePrincipale.xml) || fac.facturation || Alexandre HAFFNER (AHA) / Alexandre THIBAULT (ATH)
|-
| matériel (VRP_Materiel.xml) || ref.materiel || Mathieu GULDNER (MGU) / Brice DAMESTOY (BDA)
|-
| modèle bilan global énergie (VRP_ModeleBilanGlobalEnergie.xml) || itv.bge || Mathieu GULDNER (MGU) / Brice DAMESTOY (BDA)
|-
| offre produit (VRP_OffreProduit.xml) || ofp.offre || Alexandre HAFFNER (AHA) / Alexandre THIBAULT (ATH)
|-
| opération MDE (VRP_OperationMDE.xml) || ref.affairemde || Anthony BAINVILLE (ABAI)
|-
| point de service (VRS_PointDeService.xml) || ref.edl || Anthony BAINVILLE (ABAI)
|-
| point éclairage public (VRP_PointEclairagePublic.xml) || ref.edl || Anthony BAINVILLE (ABAI)
|-
| relève (VRP_Relève.xml) || itv.conso || Patrice FRANTZ (PFR)
|-
| simulation tarifaire (VRP_SimulationTarifaire.xml) || ecore.simulation || Alexandre HAFFNER (AHA) / Alexandre THIBAULT (ATH)
|-
| suivi connexion portail (VRP_SuiviConnexionPortail.xml) || ref.acteur || Anthony BAINVILLE (ABAI)
|}

= Ressources nécessaires =

== Fichiers DDL de création/modification de vue ==
&lt;p&gt;Ils se situent dans le dossier "sql &gt; database &gt; elfuid &gt; ddl &gt; create &gt; view &gt; requeteur &gt; [domaine] &gt; [sousDomaine]".&lt;/p&gt;
&lt;p&gt;Pour chaque fichier "VRP/S_NOMDELAVUE.ddl" de création à cet emplacement, il faut en correspondance un fichier "VRP/S_NOMDELAVUE_drop.ddl" de suppression dans le dossier "sql &gt; database &gt; elfuid &gt; ddl &gt; drop &gt; view &gt; requeteur &gt; [domaine] &gt; [sousDomaine]". Ce dernier ne contient que la commande "drop view VRP/S_NOMDELAVUE;"&lt;/p&gt;
&lt;p&gt;Si une vue est modifiée via SQLmigrator (voir plus loin), le fichier de création de la vue doit être modifié également.&lt;/p&gt;

== Fichiers XML de paramétrage ==
&lt;p&gt;Ils se situent dans le dossier "src &gt; main &gt; resources &gt; vuesRequeteur".&lt;/p&gt;

== Fichiers XML/SQL de modification de vue ==
&lt;p&gt;La modification d'une vue du requêteur (ajout, modification ou suppression d'un attribut) se fait par SQLmigrator, donc via un fichier changeLog.xml. Ce dernier pointera sur un fichier SQL contenant le code pour la création de la vue modifiée.&lt;/p&gt;
&lt;p&gt;Les deux fichiers se trouvent dans le dossier "sql &gt; database &gt; elfuid &gt; ddl &gt; upgrade &gt; [versionPrincipale] &gt; changelog &gt; view &gt; requeteur &gt; [domaine] &gt; [sousDomaine]".&lt;/p&gt;
&lt;p&gt;Il est important de vérifier que le fichier changeLog.xml de ce sous-dossier apparaît bien dans le fichier "sql/database/efluid/ddl/upgrade/[versionPrincipale]/changeLog.xml", et qu'il se situe à la fin (après les fichier changeLog.xml des domaines autres que le requêteur).&lt;/p&gt;


= Principe =
&lt;p&gt;A chaque élément disponible dans la liste déroulante "vue" de l'écran de recherche de requête correspond une vue principale. Cette vue principale est liée à une ou plusieurs vue(s) secondaire(s), disponible(s) dans les onglets "colonnes" et "critères" des écrans de consultation/modification de requête. Une vue secondaire peut avoir elle-même une ou plusieurs vue(s) secondaire(s).&lt;/p&gt;
&lt;p&gt;Le paramétrage d'une vue se fait par 2 fichiers :
&lt;ul&gt; 
&lt;li&gt;VRP_NOMDELAVUEPRINCIPALE.ddl (ou VRP_NOMDELAVUEPRINCIPALES.ddl)&lt;/li&gt;
&lt;li&gt;VRP_NomDeLaVuePrincipale.xml (ou VRS_NomDeLaVueSecondaire.xml)&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

== Fichier DDL de création/modification de vue ==
&lt;p&gt;Il contient la requête de création de la vue. Cette dernière remonte tous les attributs nécessaires à l'affichage des éléments dans les onglets "colonnes" et "critères", ainsi que ceux servant au jointures (par exemple REFERENCE_ID) ou au fonctionnement du requêteur (par exemple ID, CODEGRD, CODEFOURNISSEUR).&lt;/p&gt;
&lt;p&gt;Il est nommé VRP_ (pour une vue principale) et VRS_ (pour une vue secondaire) en majuscules, suivie d'un nom explicite et unique en majuscule. Idéalement, il porte le même nom que le fichier XML de paramétrage correspondant.&lt;/p&gt;
&lt;p&gt;Ci-dessous, un exemple de fichier DDL :&lt;/p&gt;
&lt;source lang="sql"&gt;
create or replace view VRP_NOMDELAVUE as (
  select A.ID,
         A.CODEGRD,
         A.CODEFOURNISSEUR,
         A.ATTRIBUT1,
         A.ATTRIBUT2,
         A.NOMDUNATTRIBUT as ATTRIBUT3,
         B.ATTRIBUT1 as ATTRIBUTDEB,
         ...
    from TTABLE A
      left join TAUTRETABLE B on B.ID = A.B_ID
    where ...
);
&lt;/source&gt;

== Fichier XML de paramétrage ==
&lt;p&gt;Le fichier XML décrit la structure de la vue, les caractéristiques générales (habilitations, lien vers la vue SQL, lien vers l'objet JAVA, attributs disponibles pour la clause SELECT et pour la clause WHERE, etc.).&lt;br /&gt;
Il sert à générer les pages IHM, soit les onglets "colonne" et "critère" de la page de zoom des requêtes, et à lier entre elles les vues SQL par des jointures.&lt;br /&gt;
Il est nommé VRP_ (pour une vue principale) et VRS_ (pour une vue secondaire) en majuscules, suivie d'un nom explicite et unique en "camelCase".&lt;br /&gt;
Plusieurs fichiers XML de paramétrage peuvent être liés à un même fichier DDL de vue.&lt;br /&gt;
Ci-dessous, un exemple de fichier XML.&lt;/p&gt;
&lt;source lang="xml"&gt;
&lt;?xml version="1.0" encoding="iso-8859-15"?&gt;
&lt;vue id="VuePrincipale1" &gt;
  &lt;libelle&gt;vue principale 1&lt;/libelle&gt;
  &lt;nomSQL&gt;VRP_VUEPRINCIPALE&lt;/nomSQL&gt;
  &lt;clePrimaire&gt;ID&lt;/clePrimaire&gt;
  &lt;typeJava&gt;com.hermes.[domaine].[sousDomaine].businessobject.MonObject&lt;/typeJava&gt;
  &lt;colonneRole&gt;ROLE&lt;/colonneRole&gt;
  &lt;selectionURL&gt;[sousDomaine].RechercherMonObjet&lt;/selectionURL&gt;
  &lt;confidentialite&gt;true&lt;/confidentialite&gt;
  &lt;risqueModifier&gt;[codeRisque]&lt;/risqueModifier&gt;
  &lt;risqueExecuter&gt;[codeRisque]&lt;/risqueExecuter&gt;
  &lt;colonnesSelectionnables&gt;
    &lt;colonne id="attribut1"&gt;
      &lt;libelle&gt;premier attribut&lt;/libelle&gt;
      &lt;nomSQL&gt;ATTR1&lt;/nomSQL&gt;
      &lt;typeJava&gt;[type]&lt;/typeJava&gt;
      &lt;obligatoire&gt;true&lt;/obligatoire&gt;
      &lt;affichageObligatoire&gt;true&lt;/affichageObligatoire&gt;
    &lt;/colonne&gt;
    &lt;colonne id="attribut2"&gt;
      &lt;libelle&gt;deuxième attribut&lt;/libelle&gt;
      &lt;nomSQL&gt;ATTR2&lt;/nomSQL&gt;
      &lt;typeJava&gt;[type]&lt;/typeJava&gt;
    &lt;/colonne&gt;
    ...
  &lt;/colonnesSelectionnables&gt;
  &lt;criteresPossibles&gt;
    &lt;critere id="attribut1"&gt;
      &lt;libelle&gt;premier attribut&lt;/libelle&gt;
      &lt;nomSQL&gt;ATTR1&lt;/nomSQL&gt;
      &lt;typeJava&gt;[type]&lt;/typeJava&gt;
    &lt;/critere&gt;
    &lt;critere id="attribut2"&gt;
      &lt;libelle&gt;deuxième attribut&lt;/libelle&gt;
      &lt;nomSQL&gt;ATTR2&lt;/nomSQL&gt;
      &lt;typeJava&gt;[type]&lt;/typeJava&gt;
      &lt;rechercheValeurColonne&gt;true&lt;/rechercheValeurColonne&gt;
    &lt;/critere&gt;
    ...
  &lt;/criteresPossibles&gt;
  &lt;jointuresPossibles&gt;
    &lt;jointure id="vueSecondaire1" &gt;
      &lt;libelle&gt;première vue secondaire&lt;/libelle&gt;
      &lt;dest&gt;VRS_PremiereVueSecondaire&lt;/dest&gt;
      &lt;typeJointure&gt;0-1&lt;/typeJointure&gt;
      &lt;colonnesSource&gt;REFERENCE_ID&lt;/colonnesSource&gt;
      &lt;jointureExterne&gt;true&lt;/jointureExterne&gt;
    &lt;/jointure&gt;
    &lt;jointure id="vueSecondaire2" &gt;
      &lt;libelle&gt;deuxième vue secondaire&lt;/libelle&gt;
      &lt;dest&gt;VRS_DeuxiemeVueSecondaire&lt;/dest&gt;
      &lt;typeJointure&gt;1-N&lt;/typeJointure&gt;
      &lt;colonnesSource&gt;REFERENCE_ID&lt;/colonnesSource&gt;
      &lt;jointureExterne&gt;false&lt;/jointureExterne&gt;
    &lt;/jointure&gt;
    &lt;jointure id="vueSecondaire3" &gt;
      &lt;libelle&gt;troisièmevue secondaire&lt;/libelle&gt;
      &lt;dest&gt;VRS_TroisiemeVueSecondaire&lt;/dest&gt;
      &lt;typeJointure&gt;0-N&lt;/typeJointure&gt;
      &lt;tableLien id="objet1_objets2"&gt;
        &lt;nomSQL&gt;OBJET1_OBJETS2&lt;/nomSQL&gt;
        &lt;colonnesSource&gt;DEST&lt;/colonnesSource&gt;
        &lt;colonnesDest&gt;SOURCE&lt;/colonnesDest&gt;
      &lt;/tableLien&gt;
      &lt;jointureExterne&gt;false&lt;/jointureExterne&gt;
    &lt;/jointure&gt;
    ...
  &lt;/jointuresPossibles&gt;
&lt;/vue&gt;
&lt;/source&gt;

=== Entête ===
&lt;p&gt;Dans &lt;tt&gt;/efluid/xml/VRP_Acteur.xml&lt;/tt&gt; et &lt;tt&gt;/efluid/xml/VRP_Affaire.xml&lt;/tt&gt;.&lt;/p&gt;
&lt;source lang="xml"&gt;
&lt;vue id="affaire" &gt;                                                        &lt;!-- L'ID de la vue, doit être unique --&gt;
  &lt;!-- ... --&gt;
  &lt;libelle&gt;affaire&lt;/libelle&gt;                                               &lt;!-- Le libelle tel qu'il apparaîtra dans les IHM --&gt;
  &lt;nomSQL&gt;VRP_AFFAIRE&lt;/nomSQL&gt;                                             &lt;!-- La vue SQL correspondante --&gt;
  &lt;description&gt;affaire&lt;/description&gt;                                       &lt;!-- La description telle qu'elle apparaîtra dans le tooltip de l'IHM --&gt;
  &lt;colonneRole&gt;ROLE&lt;/colonneRole&gt;                                          &lt;!-- La colonne role dans le cas d'un objet abstrait --&gt;
  &lt;clePrimaire&gt;ID&lt;/clePrimaire&gt;                                            &lt;!-- La clef primaire --&gt;
  &lt;typeJava&gt;com.hermes.ref.affaireaction.businessobject.Affaire&lt;/typeJava&gt; &lt;!-- Le type Java, abstrait si nécessaire, dans quel cas l'attribut "colonneRole" doit être renseigné --&gt;
  &lt;selectionURL&gt;affaireaction.RechercherAffaire&lt;/selectionURL&gt;             &lt;!-- L'URL de recherche, afin de pouvoir "zoomer" sur les objets retournés --&gt;
  &lt;risqueModifier&gt;246&lt;/risqueModifier&gt;                                     &lt;!-- Le risque de modifications des requêtes sur cette vue --&gt;
  &lt;risqueExecuter&gt;247&lt;/risqueExecuter&gt;                                     &lt;!-- Le risque d'exécution des requêtes sur cette vue --&gt;
  &lt;confidentialite&gt;false&lt;/confidentialite&gt;                                 &lt;!-- Activation de la confidentialité sur cette vue (ajoute les clauses par défaut) par défaut à "true" --&gt;
  &lt;suppressionLogique&gt;true&lt;/suppressionLogique&gt;                            &lt;!-- Activation de la vérification de la suppression logique sur cette vue (ajoute les clauses par défaut) par défaut à "true" --&gt;
  &lt;!-- ... --&gt;
&lt;/vue&gt;
&lt;/source&gt;

=== Colonne ===
&lt;p&gt;Dans &lt;tt&gt;/efluid/xml/VRP_Acteur.xml&lt;/tt&gt;.&lt;/p&gt;
&lt;source lang="xml"&gt;
    &lt;colonne id="intitule" &gt;                                     &lt;!-- L'ID pour l'IHM, doit être unique --&gt;
      &lt;libelle&gt;intitulé&lt;/libelle&gt;                                &lt;!-- Le libelle pour l'IHM --&gt;
      &lt;nomSQL&gt;INTITULE&lt;/nomSQL&gt;                                  &lt;!-- Nom de la colonne dans la vue --&gt;
      &lt;typeJava&gt;com.hermes.ref.acteur.type.EPIntitule&lt;/typeJava&gt; &lt;!-- Type de donnée pour l'IHM, soit (I) type Java (II) nombre (III) string (IV) date (V) datetime --&gt;
      &lt;obligatoire&gt;true&lt;/obligatoire&gt;                            &lt;!-- Sélection obligatoire ou non (si oui se retrouve automatiquement à droite dans l'IHM et impossible d'en changer) --&gt;
      &lt;affichageObligatoire&gt;true&lt;/affichageObligatoire&gt;          &lt;!-- Comme sélection obligatoire mais pour l'affichage (se retrouve dans l'IHM résultat / l'export Excel) --&gt;
    &lt;/colonne&gt;
&lt;/source&gt;

=== Critères ===
&lt;p&gt;Dans &lt;tt&gt;/efluid/xml/VRP_Acteur.xml&lt;/tt&gt;.&lt;/p&gt;
&lt;source lang="xml"&gt;
    &lt;critere id="intitule" &gt;                                      &lt;!-- L'ID du critère, doit être unique --&gt;
      &lt;libelle&gt;intitulé&lt;/libelle&gt;                                 &lt;!-- Le libelle qui apparaîtra dans l'IHM --&gt;
      &lt;nomSQL&gt;INTITULE&lt;/nomSQL&gt;                                   &lt;!-- La colonne dans la vue SQL --&gt;
      &lt;typeJava&gt;com.hermes.ref.acteur.type.EPIntitule&lt;/typeJava&gt;  &lt;!-- Le type pour l'IHM, voir colonne --&gt;
    &lt;/critere&gt;
&lt;/source&gt;

=== Jointures ===
&lt;p&gt;Les jointures apparaissent dans l'IHM comme des sous-niveaux du tableau hiérarchique. En général, les jointures doivent être déclarées comme "externes" dans le cas où l'objet lié est facultatif. '''''NB''' : Il existe une limitation du requêteur qui ne permet pas de faire une jointure externe sur la vue courante.''&lt;/p&gt;

==== 0-1 ====
&lt;p&gt;Ce type de jointure correspond aux cas où '''la clef étrangère est dans la table correspondante à la vue courante'''. Attention à la jointure externe qui varie en fonction de la nécessité de l'objet lié. De &lt;tt&gt;/xml/VRP_Acteur.xml&lt;/tt&gt; :&lt;/p&gt;
&lt;source lang="xml"&gt;
    &lt;jointure id="adresse"&gt;                               &lt;!-- L'ID pour l'IHM --&gt;
      &lt;libelle&gt;adresse de correspondance&lt;/libelle&gt;        &lt;!-- Le libelle qui apparaît dans le sous-niveau du tableau hiérarchique de l'IHM --&gt;
      &lt;dest&gt;VRS_AdressePostale&lt;/dest&gt;                     &lt;!-- Le nom de la vue XML pour afficher les éléments dans le sous-tableau --&gt;
      &lt;typeJointure&gt;0-1&lt;/typeJointure&gt;                    &lt;!-- Le type de jointure --&gt;
      &lt;colonnesSource&gt;ADRESSEPOSTALE_ID&lt;/colonnesSource&gt;  &lt;!-- La clef étrangère dans la table de la vue courante --&gt;
      &lt;jointureExterne&gt;true&lt;/jointureExterne&gt;             &lt;!-- Vrai pour la jointure externe --&gt;
    &lt;/jointure&gt;
&lt;/source&gt;

==== 1-N ====
&lt;p&gt;Ce type de jointure correspond aux cas où '''la clef étrangère est dans la table correspondante à la vue liée'''. Attention à la jointure externe qui varie en fonction de la nécessité de l'objet lié, donc la vue courante (ici, la majorité du temps, la jointure est externe !). De &lt;tt&gt;/xml/VRP_Acteur.xml&lt;/tt&gt; :&lt;/p&gt;
&lt;source lang="xml"&gt;
    &lt;jointure id="affaireResponsable"&gt;
      &lt;libelle&gt;affaire en tant que responsable&lt;/libelle&gt;
      &lt;dest&gt;VRP_Affaire_JExt&lt;/dest&gt;
      &lt;typeJointure&gt;1-N&lt;/typeJointure&gt;
      &lt;colonnesSource&gt;RESPONSABLE_ACTEUR_ID&lt;/colonnesSource&gt; &lt;!-- La clef étrangère dans la table de la vue liée --&gt;
      &lt;jointureExterne&gt;true&lt;/jointureExterne&gt;                &lt;!-- Vrai pour la jointure externe (la grande majorité du temps vrai) --&gt;
    &lt;/jointure&gt;
&lt;/source&gt;

==== 0-N ====
&lt;p&gt;Ce type de jointure correspond aux cas où '''la clef étrangère est dans la table de lien'''. Attention à la jointure externe qui varie en fonction de la nécessité de l'objet lié, donc la vue courante (ici, la majorité du temps, la jointure est externe !). De &lt;tt&gt;/xml/VRP_Contrat.xml&lt;/tt&gt; :&lt;/p&gt;
&lt;source lang="xml"&gt;
    &lt;jointure id="espaceDeLivraison" &gt;
      &lt;libelle&gt;espace de livraison&lt;/libelle&gt;
      &lt;libelleCourt&gt;edl&lt;/libelleCourt&gt;              &lt;!-- Je sais pas à quoi ça sert --&gt;
      &lt;dest&gt;VRP_EspaceDeLivraison_JExt&lt;/dest&gt;       &lt;!-- Le nom de la vue XML pour afficher les éléments dans le sous-tableau, voir "nomSQL" en bas pour la vue SQL --&gt;
      &lt;typeJointure&gt;0-N&lt;/typeJointure&gt;
      &lt;tableLien id="contrat_edl"&gt;                  &lt;!-- L'ID de la table de lien pour l'IHM, ne sert pas à grand-chose --&gt;
        &lt;nomSQL&gt;CONTRAT_ESPACESDELIVRAISON&lt;/nomSQL&gt; &lt;!-- Le nom de la vue SQL qui correspond à la table de lien --&gt;
        &lt;colonnesSource&gt;SOURCE&lt;/colonnesSource&gt;     &lt;!-- La colonne source dans la table de lien --&gt;
        &lt;colonnesDest&gt;DEST&lt;/colonnesDest&gt;           &lt;!-- La colonne destination dans la table de lien --&gt;
      &lt;/tableLien&gt;
    &lt;/jointure&gt;
&lt;/source&gt;

=== Types Java ===
&lt;p&gt;Les types Java sont soit le nom complet de la classe (pour les énumérés en particulier), soit ces valeurs spéciales :&lt;/p&gt;
* '''string''' : chaîne de caractères
* '''booleen''' : booléen
* '''entier''' : nombre entier
* '''nombre''' : nombre réel
* '''date''' : date (sans précision de l’heure)
* '''dateTime''' : date avec la précision sur l’heure
* '''ListEnum''' : liste d’énuméré

== Stockage en base de données ==
Les éléments d'une requête sont stockés dans 3 tables :
&lt;ul&gt;
&lt;li&gt;TREQUETE&lt;/li&gt;
&lt;li&gt;TCOLONNESELECTIONNEE&lt;/li&gt;
&lt;li&gt;TREQUETEELEMENTCLAUSEWHERE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;b&gt;TREQUETE&lt;/b&gt; contient les attributs de l'objet principal Requete : paramètres visibles dans le bandeau haut, dans l'onglet "généralités", dans l'onglet "complément", etc.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;TCOLONNESELECTIONNEE&lt;/b&gt; contient, par requête, tous les éléments sélectionnés dans l'onglet "colonne".&lt;/p&gt;
&lt;p&gt;&lt;b&gt;TREQUETEELEMENTCLAUSEWHERE&lt;/b&gt; contient, par requête, tous les critères sélectionnés dans l'onglet "critère", avec leurs valeurs.&lt;/p&gt;

= Opérations de base =
== Ajout d'un attribut ==
&lt;ul&gt;Ajout de l'attribut à la vue DDL
&lt;ol&gt;
&lt;li&gt;Modifier du fichier sql &gt; database &gt; sql &gt; database &gt; efluid &gt; ddl &gt; create &gt; view &gt; requeteur &gt; [domaine] &gt; [sousDomaine] &gt; VR[P-S]_NOMDELAVUE.ddl&lt;/li&gt;
&lt;li&gt;Créer le fichier sql &gt; database &gt; efluid &gt; ddl &gt; upgrade &gt; [version] &gt; changelog &gt; view &gt; requeteur &gt; [domaine] &gt; [sousDomaine] &gt; T_VR[P-S]_NOMDELAVUE_REPLACE_[numEvt].sql&lt;/li&gt;
&lt;li&gt;Modifier le fichier sql &gt; database &gt; efluid &gt; ddl &gt; upgrade &gt; [version] &gt; changelog &gt; view &gt; requeteur &gt; [domaine] &gt; [sousDomaine] &gt; changeLog.xml&lt;/li&gt;
&lt;li&gt;Vérifier l'existence de la référence au changeLog ci-dessus en fin de fichier sql&gt;database&gt;efluid&gt;ddl&gt;upgrade&gt;[version]&gt;changelog&gt;changeLog.xml&lt;/li&gt;
&lt;/ol&gt;
&lt;/ul&gt;
&lt;ul&gt;Ajout de l'attribut au fichier XML de paramétrage
&lt;ol&gt;
&lt;li&gt;Modifier le(s) fichier(s) src &gt; main &gt; ressources &gt; vuesRequeteur &gt; VR[P-S]_NomDeLaVue.xml&lt;/li&gt;
&lt;/ol&gt;
&lt;/ul&gt;

== Modification d'un attribut ==
&lt;p&gt;Les opérations à réaliser sont les mêmes que pour l'ajout d'un attribut si la vue (DDL) est impactée.&lt;br /&gt;
Sinon, modifier uniquement le fichier XML de paramétrage (correction d'un libellé par exemple).&lt;/p&gt;
&lt;p&gt;&lt;b&gt;ATTENTION : &lt;/b&gt;un script de migration est nécessaire si l'ID de l'attribut dans le fichier XML de paramétrage est modifié, car il correspond à la colonne REF_PARAMETRAGE des tables TCOLONNESELECTIONNEE et TREQUETEELEMENTCLAUSEWHERE.&lt;/p&gt;

== Suppression d'un attribut ==
&lt;p&gt;Les opérations à réaliser sont les mêmes que pour l'ajout d'un attribut.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;ATTENTION : &lt;/b&gt;un script de migration est nécessaire pour supprimer toutes les références à l'attribut supprimé dans la colonne REF_PARAMETRAGE des tables TCOLONNESELECTIONNEE et TREQUETEELEMENTCLAUSEWHERE.&lt;/p&gt;

== Ajout d'une vue secondaire ==
&lt;ul&gt;Créer la vue DDL
&lt;ol&gt;
&lt;li&gt;Créer le fichier sql &gt; database &gt; efluid &gt; ddl &gt; create &gt; view &gt; requeteur &gt; [domaine] &gt;  [sousDomaine] &gt; VRS_NOMDELAVUE.ddl&lt;/li&gt;
&lt;li&gt;Créer le fichier sql &gt; database &gt; efluid &gt; ddl &gt; upgrade &gt; [version] &gt; changelog &gt; view &gt; requeteur &gt; [domaine] &gt; [sousDomaine] &gt; T_VRS_NOMDELAVUE_CREATE_[numEvt].sql&lt;/li&gt;
&lt;li&gt;Ajouter un changeSet au fichier : sql &gt; database &gt; efluid &gt; ddl &gt; upgrade &gt; [version] &gt; changelog &gt; view &gt; requeteur &gt; [domaine] &gt; [sousDomaine] &gt; changeLog.xml&lt;/li&gt;
&lt;li&gt;Vérifier l’existence de la référence au changeLog ci-dessous à la fin du fichier : sql &gt; database &gt;   efluid &gt; ddl &gt; upgrade &gt; [version] &gt; changelog &gt; changeLog.xml&lt;/li&gt;
&lt;/ol&gt;
&lt;/ul&gt;
&lt;ul&gt;Créer le fichier XML de paramétrage
&lt;ol&gt;
&lt;li&gt;Créer le fichier de paramétrage : src &gt; main &gt; ressources &gt; vuesRequeteur &gt; VRS_NomDeLaVue.xml&lt;/li&gt;
&lt;/ol&gt;
&lt;/ul&gt;
&lt;ul&gt;Ajouter la jointure vers la nouvelle vue dans le(s) fichier(s) XML de paramétrage&lt;/ul&gt;

== Ajout d'une vue principale ==
&lt;ul&gt;Créer la vue DDL et le fichier XML de paramétrage
&lt;ul&gt;
&lt;li&gt;Idem vue secondaire, mais avec préfix VRP&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;ul&gt;Créer éventuellement les codes risque et habilitations nécessaires
&lt;ul&gt;
&lt;li&gt;Demander un découpage technique&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;ul&gt;Modifier framework.properties 
&lt;ul&gt;
&lt;li&gt;Ajouter la référence à la nouvelle vue principale pour l’attribut REQUETEUR_VUES_POSSIBLES&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;

= Documentation =
* '''Guide utilisateur requêteur''' : [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid efluid - Documentation Fonctionnelle Suite efluid] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_48b7 Guides Utilisateur] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_48c2 guides de paramétrage] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_278d7 V13 à rédiger] &gt; [http://WPEROOM3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_27bdf Guide utilisateur - domaines requêteur et exécutions différées.docx]

* '''AFD Requêteur''' : [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid efluid - Documentation Fonctionnelle Suite efluid] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_20a2 AFD suite efluid] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_3a AFD efluid] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_463 REQ - Requêteur] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2f3a AFD] &gt; [http://WPEROOM3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_3921 AFD - REQ - Requeteur.doc]

* '''Description des fichiers XML (paramétrage existant)''' : [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid efluid - Documentation Fonctionnelle Suite efluid] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_20a2 AFD suite efluid] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_3a AFD efluid] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_463 REQ - Requêteur] &gt; [http://wperoom3.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_2f3a AFD] &gt; paramétrageRequeteur vXX_X.xls
&lt;p&gt;Les descriptions des fichiers XML (paramétrage existant) sont tenus à jour par l'équipe expertise/recette (Valérie BECKER - VBE).&lt;/p&gt;</text>
      <sha1>mj53d724phxcgrxkwzaqikphv1l9q1k</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine service web sge</title>
    <ns>0</ns>
    <id>14036</id>
    <revision>
      <id>4069411</id>
      <parentid>4069410</parentid>
      <timestamp>2023-06-01T19:19:51Z</timestamp>
      <contributor>
        <username>Wehbe</username>
        <id>358</id>
      </contributor>
      <comment>/* Localiser un traitement d'après son code erreur */</comment>
      <origin>4069411</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="16836" sha1="lkrfr72ayl6g50choqouvoj6t7pcbwy" xml:space="preserve">{{Modèle:Domaine
 | nom=services web sge
 | responsable=[[VBO]]
 | developpeurs = [[VBO]], [[AWE]]
}}
[[Category:domaine]]
[[Category:domaine service web SGE]]

= Présentation =

[http://wperoom4.uem.lan/eRoom/Production/DocTechniqueEfluid/0_29fad1 Présentation des services web SGE]

= Liste des services =
== Domaine services web SGE ==
* [[SGE01]] : Créer une demande de prestation
* [[SGE02]] : Modifier une demande de prestation
* [[SGE03]] : Annuler une demande de prestation
* [[SGE05a]] : Consommer avancement affaire (création d'une action de suivie sur l'EDL d'une affaire SGE dans Efluid)
* [[SGE06]] : Relance distributeur (anomalie sur edp)
* [[SGE07]] (sortant - appel à un WS externe) : Demande de référence externe à SGE d'une affaire
* [[SGE08]] : Renvoie toutes les informations du PDS (getInfo)
* [[SGE012]] (SGE01a) : Récupération des périodes d'historiques de mesure disponible
* [[KGO01]] : Créer ou modifier acteur + rattacher au PASC (SMO)
* [[KGO02]] : Consulter client + PASC (SMO)
* [[KGO03]] : Consulter services SMO et les traces de mesure du point (SMO)

== Domaine échange ==
* [[SGE04]] : Flux d'avancement d'affaire (Jalon)
== Domaine consommation ==
* [[SGE05b]] : Intégrer notification de déclenchement d'ordre de pointe mobile

== Domaine référentiel ==
* [[PRM01]] : Création de point
* [[PRM02]] : Raccordement/PMES - Création de branchement
* [[PRM03 (ex SGE08)]] : Consultation Mesures et plages Heure Creuse

== Liste des services web exposés (WSDL) ==
http://localhost:8080/efluid/services-sge/

== Matrice des versions de services ==
[[Matrice des versions de services web SGE]]





= Appeler un service SOAP SGE / Soap over JMS =
== Fichier de paramétrage ==
* EDK2.properties
 INTERFACE_SGE_INBOUND_ACTIVE=true
 INTERFACE_SGE_OUTBOUND_ACTIVE=true
 NOEUD_WS_URL=http://localhost:8080/efluid
* framework2.properties
 webservices.security.status=NO_SECURITY
 JMS_ACTIVER=true
 INTIAL_CONTEXT_FACTORY=org.jnp.interfaces.NamingContextFactory
 PROVIDER_URL=jnp://localhost:16401
* hermes2.properties
 EMBEDDED_JNDI_PORT=16401
 EMBEDDED_JNDI_RMI_PORT=16402
 EMBEDDED_JNDI_BIND_ADDRESS=localhost
 EMBEDDED_ACTIVER_JORAM=true
 EMBEDDED_ACTIVER_MESSAGE_LISTENER=true
 EMBEDDED_JMS_BIND_ADDRESS=localhost
 EMBEDDED_JMS_PORT=16017
 #### AVANT 14.6 UNIQUEMENT ####
 JMS_ACCESS_LOGIN=sgeUser
 #JMS_ACCESS_PASSWORD=sgePassword$123
 JMS_ACCESS_PASSWORD=GINKO2014

* Entete SOAP
 Header = Echange-ID
 Value = NO-CHECK-DOUBLONS

== Authentification après 14.6 ==
Encoder USER:PASSWORD (sgeUser:sgePassword) via https://www.base64encode.org/ : c2dlVXNlcjpzZ2VQYXNzd29yZA== &lt;br /&gt;
Puis le transmettre via le header du flux :&lt;br /&gt;
* Clé : Authorization&lt;br /&gt;
* Valeur : Basic c2dlVXNlcjpzZ2VQYXNzd29yZA==&lt;br /&gt;
[[Fichier:header_authorization_sge.png]]&lt;br /&gt;

== Appel du service ==
* Démarrer le serveur d'application
* Lister tous les services disponibles : http://localhost:8080/efluid/services-sge/
** Clic droit copier le raccourci
[[Fichier:services_sge.jpeg]]
* Importer le WSDL dans SOAPUI
** Copier le raccourci dans "Initial WSDL" puis OK.
[[Fichier:WSDL_SOAPUI.jpeg]]
* Importer le flux dans la request du service SOAP
** Ne pas prendre PortBindingSOAPJMS mais PortBinding (WS sans file)
** ALT + F et ALT + V (pour formater et valider le flux)
** Flèche verte pour exécuter la requête
[[Fichier:request_SOAPUI.jpeg]]

= Documents conceptuels techniques =
* http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_e8242
= Développer un service web =
== Générer WebService à partir du wsdl et xsd [EDK] ==
* Dans l'AFD interface récupérer le zip des XSD&lt;br&gt;
* Copier dans les projets edk/ws/wsdl (les modifications ou la totalité)&lt;br&gt;
** Faire un draft pour vérifier les modifications&lt;br&gt;
* Ajouter si besoin dans le fichier edk/ws/codegen/cxf/pom.xml la conversion de package pour une nouvelle opération ou service&lt;br&gt;

== Développer service web [Efluid] ==
* Ajouter le service dans app/src/main/resources/webServices.xml s'il n'existe pas
* Compléter ou créer le WSMgr (exemple : CalculerRecevabiliteDemandePrestationWSMgr)
Lier le WsMgr avec le fichier wsdl qui se trouve dans le projet edk-ws-wsdl-serveur :&lt;br&gt;
 @WebResult (Retour du WS)
 name = "calculerRecevabiliteDemandePrestationModificationMesures" : nom de l'attribut OUTPUT
 targetNamespace = "http://www.erdf.fr/ginko/calculerrecevabilitemodificationmesures/v3" : namespace de l'attribut OUTPUT
 Idem pour @WebParam mais INPUT
* Créer un mappeur pour la "demande" SGE0xa, la "réponse" SGE0xa et la "demande" SGE0xb
* Référencer chaque mappeur dans MapperFactory qui hérite de GenericMapperFactory
* Créer un test TestMapperFactory qui hérite de TestGenericMapperFactory (cela permet de savoir ce qui n'est pas mappé)
* Pour tester chaque mappeur il faut : 
** Un test qui hérite de TestSGEMapper
** Un Builder pour générer les objets type (objets du WS)
** Une condition qui hérite de AbstractCondition qui permet de tester le mapping

== Générer un contexte depuis un test d'intégration ==
* Générer une base from scratch perso =&gt; http://usinelogicielle/job/FsuiteEfluid/job/Fefluid/job/efluid.drop-create-bdd-via-sqlmigrator-dynamic/
* Configurer le fichier framework2.properties
&lt;source lang='properties'&gt;
JDBC_CONNECT_STRING=jdbc:oracle:thin:@LPBDDEDT4:2483/PTECEDT2
JDBC_USER=VBO
JDBC_PASSWORD=ulonly
&lt;/source&gt;
* Lancer le test d'intégration avec le VM paramètre :
 -DtestIT.commit=true
* Requêtes de MAJ
&lt;source  lang='sql'&gt;
insert into TCODIFICATION (ID, ETATOBJET, TYPECODIFICATION, VALEURPARDEFAUTDECODIFICATION, CODEEXTERNE, LIBELLEEXTERNE, TYPE_CODIFIE, VALEUR, DATEMODIFICATION, ACTEURMODIFICATION, DATECREATION, ACTEURCREATION, DATESUPPRESSION, ACTEURSUPPRESSION) values ('SGE01_0085',0,1002,0,'SGE01_0085','SGE01_0085','java.lang.String','SGE01_0085',NULL,NULL,'21-06-2017','DEV001|DEV|test',NULL,NULL);
insert into TCODIFICATION (ID, ETATOBJET, TYPECODIFICATION, VALEURPARDEFAUTDECODIFICATION, CODEEXTERNE, LIBELLEEXTERNE, TYPE_CODIFIE, VALEUR, DATEMODIFICATION, ACTEURMODIFICATION, DATECREATION, ACTEURCREATION, DATESUPPRESSION, ACTEURSUPPRESSION) values ('VBO_CESS_SOUS_TYPE_AFF',0,1001,0,'CESSATION_SERVICE_MESURE','accueil','com.hermes.ref.affaireaction.type.EPSousTypeAffaire','ACCUEIL',NULL,NULL,'23-06-2017','DEV001|DEV|test',NULL,NULL);
insert into TCODIFICATION (ID, ETATOBJET, TYPECODIFICATION, VALEURPARDEFAUTDECODIFICATION, CODEEXTERNE, LIBELLEEXTERNE, TYPE_CODIFIE, VALEUR, DATEMODIFICATION, ACTEURMODIFICATION, DATECREATION, ACTEURCREATION, DATESUPPRESSION, ACTEURSUPPRESSION) values ('SGE01_0104',0,1002,0,'SGE01_0104','SGE01_0104','java.lang.String','SGE01_0104',NULL,NULL,'21-06-2017','DEV001|DEV|test',NULL,NULL);
insert into TCODIFICATION (ID, ETATOBJET, TYPECODIFICATION, VALEURPARDEFAUTDECODIFICATION, CODEEXTERNE, LIBELLEEXTERNE, TYPE_CODIFIE, VALEUR, DATEMODIFICATION, ACTEURMODIFICATION, DATECREATION, ACTEURCREATION, DATESUPPRESSION, ACTEURSUPPRESSION) values ('SGE01_0039',0,1002,0,'SGE01_0039','SGE01_0039','java.lang.String','SGE01_0039',NULL,NULL,'21-06-2017','DEV001|DEV|test',NULL,NULL);
insert into TCODIFICATION (ID, ETATOBJET, TYPECODIFICATION, VALEURPARDEFAUTDECODIFICATION, CODEEXTERNE, LIBELLEEXTERNE, TYPE_CODIFIE, VALEUR, DATEMODIFICATION, ACTEURMODIFICATION, DATECREATION, ACTEURCREATION, DATESUPPRESSION, ACTEURSUPPRESSION) values ('52003VBO',0,1002,0,'SGE01_0038','SGE01_0038','java.lang.String','SGE01_0038',NULL,NULL,'21-06-2017','DEV001|DEV|test',NULL,NULL);
insert into TCODIFICATION (ID, ETATOBJET, TYPECODIFICATION, VALEURPARDEFAUTDECODIFICATION, CODEEXTERNE, LIBELLEEXTERNE, TYPE_CODIFIE, VALEUR, DATEMODIFICATION, ACTEURMODIFICATION, DATECREATION, ACTEURCREATION, DATESUPPRESSION, ACTEURSUPPRESSION) values ('52001VBO',0,1002,0,'SGE01_0048','SGE01_0048','java.lang.String','SGE01_0048',NULL,NULL,'21-06-2017','DEV001|DEV|test',NULL,NULL);
insert into TCODIFICATION (ID, ETATOBJET, TYPECODIFICATION, VALEURPARDEFAUTDECODIFICATION, CODEEXTERNE, LIBELLEEXTERNE, TYPE_CODIFIE, VALEUR, DATEMODIFICATION, ACTEURMODIFICATION, DATECREATION, ACTEURCREATION, DATESUPPRESSION, ACTEURSUPPRESSION) values ('52000VBO',0,1002,0,'SW_0999','SW_0999','java.lang.String','SW_0999',NULL,NULL,'21-06-2017','DEV001|DEV|test',NULL,NULL);
update tacteur set referenceexterne= 'TRISTAN002' where id='2897995122';
update tacteur set EMAIL='v-bouthinon@uem-metz.fr' where id='2897995122';
insert into tpersonnephysique (id) values ('2897995122');
update tservicesouscrit set statut=1, dateeffet=current_date - 1  where reference = 270719773010123;
&lt;/source&gt;
* Flux de la demande :
&lt;source  lang='xml'&gt;
&lt;soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:v3="http://www.erdf.fr/ginko/calculerrecevabilitemodificationmesures/v3"&gt;
   &lt;soapenv:Header/&gt;
   &lt;soapenv:Body&gt;
      &lt;v3:calculerRecevabiliteModificationMesures&gt;
         &lt;demande&gt;
            &lt;donneesGenerales&gt;
               &lt;refFrn&gt;Test AME&lt;/refFrn&gt;
               &lt;refFrnRegroupement&gt;Test AME&lt;/refFrnRegroupement&gt;
               &lt;objetCode&gt;AME&lt;/objetCode&gt;
               &lt;pointId&gt;77770000007777&lt;/pointId&gt;
               &lt;affaireOrigineId&gt;1234569&lt;/affaireOrigineId&gt;
               &lt;dateHeure&gt;2017-05-07T14:42:28&lt;/dateHeure&gt;
               &lt;mediaCode&gt;B2B&lt;/mediaCode&gt;
               &lt;initiateur&gt;
                  &lt;loginUtilisateur&gt;tel@energem.fr&lt;/loginUtilisateur&gt;
               &lt;/initiateur&gt;
               &lt;dateEffetSouhaitee&gt;2017-06-15&lt;/dateEffetSouhaitee&gt;
               &lt;canalCode&gt;PCLI&lt;/canalCode&gt;
               &lt;acteurCrmId&gt;TRISTAN002&lt;/acteurCrmId&gt;
            &lt;/donneesGenerales&gt;
            &lt;cessationServiceMesures&gt;
               &lt;serviceSouscritId&gt;270719773010123&lt;/serviceSouscritId&gt;
               &lt;dateFin&gt;2017-11-29&lt;/dateFin&gt;
               &lt;declarationConsentement&gt;
                  &lt;autorisation&gt;false&lt;/autorisation&gt;
                  &lt;personnePhysique&gt;
                     &lt;civilite&gt;M&lt;/civilite&gt;
                     &lt;nom&gt;Bouthinon&lt;/nom&gt;
                     &lt;prenom&gt;vincent&lt;/prenom&gt;
                  &lt;/personnePhysique&gt;
               &lt;/declarationConsentement&gt;
               &lt;usageDistributeurCode&gt;AZERTY&lt;/usageDistributeurCode&gt;
            &lt;/cessationServiceMesures&gt;
         &lt;/demande&gt;
      &lt;/v3:calculerRecevabiliteModificationMesures&gt;
   &lt;/soapenv:Body&gt;
&lt;/soapenv:Envelope&gt;
&lt;/source &gt;

= Débug et tests =
== Simuler Batch 997 en déport depuis file JMS ==
&lt;source  lang='java'&gt;
package com.efluid.itf.ref.edl.businessprocess;

import static com.imrglobal.framework.factory.BusinessIdFactory.getInstance;

import org.junit.Test;

import com.hermes.arc.commun.businessprocess.EfluidBusinessProcess;

import com.hermes.itv.intervention.businessobject.*;
import com.hermes.ref.workflow.batch.businessprocess.TraitementWorkflowDeporteMDBProcess;
import com.hermes.ref.workflow.batch.utils.WorkflowBatchUtils;
import com.hermes.ref.workflow.businessprocess.WorkflowGestionSuiviProcess;
import com.hermes.ref.workflow.context.WorkflowContext;
import com.hermes.ref.workflow.type.EStatutTraitementWorkflow;

import test.hermes.arc.commun.test.AbstractTestIT;

public class TestITTraitementLeverConcurrenceDemandeCessation247134 extends AbstractTestIT {

  @Test
  public void traiterDonneesMessage() {
    WorkflowContext contexte = new WorkflowContext();
    ElementDePopulationInterventionWorkflow edp = (ElementDePopulationInterventionWorkflow) new EfluidBusinessProcess().actionOpen(new ElementDePopulationInterventionWorkflow((getInstance("hs4If"))));
    TraitementCRIAutomatique traitement = (TraitementCRIAutomatique) new EfluidBusinessProcess().actionOpen(new TraitementCRIAutomatique(getInstance("$d$41210")));
    TestTraitementWorkflowDeporteMDBProcess traitementWorkflowDeporteMDBProcess = new TestTraitementWorkflowDeporteMDBProcess();

    contexte.setElementDePopulationWorkflow(edp);
    contexte.setTraitementExecutionEtape(traitement);

    WorkflowGestionSuiviProcess workflowGestionSuiviProcess = new WorkflowGestionSuiviProcess();
    workflowGestionSuiviProcess.startSuiviTraitement(contexte);
    workflowGestionSuiviProcess.getSuivi().setObjetSuivi(edp);
    workflowGestionSuiviProcess.getSuivi().setStatutTraitementWorkflow(EStatutTraitementWorkflow.DEPORTE_ATTENTE);
    new EfluidBusinessProcess().actionSaveIfNotStored(workflowGestionSuiviProcess.getSuivi());

    contexte.setStatutSuivi(EStatutTraitementWorkflow.DEPORTE_ATTENTE);
    contexte.setTraitementExecutionEtape(traitement);
    contexte.setCommentaireSuivi(WorkflowBatchUtils.getCommentaireSuiviDeporte(traitement.getEtape(), true));

    traitementWorkflowDeporteMDBProcess.appelerTraiterDonneesMessage(contexte);
  }

  class TestTraitementWorkflowDeporteMDBProcess extends TraitementWorkflowDeporteMDBProcess {

    public void appelerTraiterDonneesMessage(WorkflowContext ctx) {
      traiterDonneesMessage(null, ctx);
    }
  }
}
&lt;/source&gt;

&lt;source lang='sql'&gt;
select * from TESPACEDELIVRAISON where reference='1200727399';
select * from taffaire where reference='1000109'; --hs4Ia
select edp.STATUT_ID from TELEMENTDEPOPULATIONWKF edp where edp.OBJETTRAITE_ID='hs4Ia' and lot_id='45992468151'; --$d$41110
select * from tlot where id='45992468151';
select * from TTRAITEMENTEXECUTIONETAPE  where role = 'com.hermes.itv.intervention.businessobject.TraitementCRIAutomatique' and etatobjet=0 and ETAPEDUTRAITEMENTUNITAIRE_ID= '$d$41110' -- $d$41210
&lt;/source&gt;

== Créer une demande de prestation à la volée ==
&lt;source  lang='sql'&gt;
INSERT INTO tdemandeprestation (id, etatobjet, COMMANDEDEMANDEPRESTATION_ID, CODEGRD, CODEFOURNISSEUR, idaffaire, NATUREPROVISOIRE, MOTIFANNULATION) VALUES ('1',0, '1','G-UEM', 'F-UEM', '1', '1' ,'ERRSAISIE');
INSERT INTO tcommandedemandeprestation (id, etatobjet, SOLDERACCORDEMENTPAYEPMS, RACCORDEMENTPROVISOIRE, INTERVENANTRACCORDEMENTPROVIS, MISEENSERVICECOURTEDUREE) VALUES ('1',0, 1, 1, 1, 1);
&lt;/source&gt;

== Tests unitaires ==
&lt;source lang="bash"&gt;mvn clean install -pl :efluid-interfaces -Ptest-unitaire&lt;/source&gt;
== Tests d'intégrations ==
=== Exécuter tous les tests ===
&lt;source lang="bash"&gt;
mvn clean integration-test -pl :efluid-interfaces -Ptest-integration -DefluidTestsReuseForks=false -DefluidTestsForkCount=1 -DefluidTestsForkMode=always -DuseLocalProperties2=true
&lt;/source&gt;

=== Exécuter un seul test ===
&lt;source lang="bash"&gt;
mvn clean install -pl :efluid-interfaces -Ptest-integration -DefluidTestsReuseForks=false -DefluidTestsForkCount=1 -DuseLocalProperties2=true -Dit.test=TestITSouscrireContrat
ou 
mvn -f app/pom.xml failsafe:integration-test -Dit.test="TestITGestionViaHibernateJourOuvre" -Ptest-integration
&lt;/source&gt;

Pour faire fonctionner mes tests sur la BDD des tests avec une application 12.10.*
&lt;source lang="sql"&gt;
-- Supression des anomalies suivantes (ne as oublier de les rajouter ensuite) 
update TPARAMTYPEANOMALIE
set etatobjet=0
where id in ('WKFPERMOB001', 'WKFPERMOB002', 'WKFPERMOB003', 'WKFPERMOB004');

update TPARAMETRE
set etatobjet=3
where code='modeExport';

update TVALEURDEPARAMETRE
set etatobjet=3
where parametre_id='modeExport';
&lt;/source&gt;

= SQL =
* [[Procédure_livraison_d'un_script_ponctuel]]&lt;br&gt;
* [[Script SQL SGE]]

= Paramétrage du workflow =

== Localiser un traitement de nature d'après son code erreur ==

&lt;source lang="sql"&gt;
SELECT WKF.LIBELLE                                   AS WORKFLOW,
       ETP.NUMEROETAPE || ' - ' || ETP.LIBELLE       AS ETAPE,
       NAT.CODE                                      AS NATURE,
       ACT.PRIORITEEXECUTION || ' - ' || ACT.LIBELLE AS TRAITEMENT
FROM TNATUREACTION NAT
JOIN TCVCNATURECONTEXTE CVC ON CVC.NATUREACTION_ID = NAT.ID
JOIN TACTIONPREDEFINIE ACT ON ACT.CVCNATURECONTEXTE_ID = CVC.ID
JOIN TTRAITEMENTDEMANDEPRESTATION TDP ON TDP.ID = ACT.ID
JOIN TTRAITEMENTEXECUTIONETAPE EXE ON DBMS_LOB.SUBSTR(EXE.COMPLEMENTJSON, 4000) = '{"natureAction":"' || NAT.ID || '|com.efluid.itf.crm.demandeprestation.businessobject.NaturePrestationControleRecevabilite"}'
JOIN TETAPEWORKFLOW ETP ON ETP.ID = EXE.ETAPEDUTRAITEMENTINIT
JOIN TWORKFLOW WKF ON WKF.ID = ETP.WORKFLOW_ID
WHERE EXE.ROLE = 'com.hermes.ref.workflow.businessobject.TraitementExecuterNatureAction'
AND EXE.ETATOBJET = 0
AND TDP.CODEERREUR = 'SGE01_XXXX';

&lt;/source&gt;

== Localiser un traitement workflow d'après son code erreur ==

&lt;source lang="sql"&gt;
SELECT WKF.LIBELLE                             AS WORKFLOW,
       ETP.NUMEROETAPE || ' - ' || ETP.LIBELLE AS ETAPE,
       EXE.PRIORITEEXECUTION                   AS PRIORITE,
       EXE.LIBELLE                             AS TRAITEMENT
FROM TTRAITEMENTEXECUTIONETAPE EXE
JOIN TETAPEWORKFLOW ETP ON ETP.ID = EXE.ETAPEDUTRAITEMENTINIT
JOIN TWORKFLOW WKF ON WKF.ID = ETP.WORKFLOW_ID
WHERE EXE.ETATOBJET = 0
AND EXE.COMPLEMENTJSON LIKE '%"codeErreur":"SGE01_XXXX"%';
&lt;/source&gt;

= Liens =
* [[Web service]]
= schéma =
*V13 : [[Fichier:SGE.png]]
*V12 : [[Fichier:SGE.gif|1000px]]</text>
      <sha1>lkrfr72ayl6g50choqouvoj6t7pcbwy</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine architecture</title>
    <ns>0</ns>
    <id>696786</id>
    <revision>
      <id>4062459</id>
      <parentid>4062458</parentid>
      <timestamp>2020-12-23T08:59:51Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <origin>4062459</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="307" sha1="0cz0f10cfl38ljyaperytfwmwvignae" xml:space="preserve">{{Modèle:Domaine
 | nom = architecture
}}
[[Category:domaine]]
[[Category:architecture]]
[[Category:pole composants transverses]]

composant [[Framework]]
composant [[Architecture]]

= Documentation générale =
* [http://wperoom2.uem.lan/eRoom/Production/DocFonctionnelleEfluid/0_960f3 écarts du domaine]</text>
      <sha1>0cz0f10cfl38ljyaperytfwmwvignae</sha1>
    </revision>
  </page>
  <page>
    <title>Edoc</title>
    <ns>0</ns>
    <id>821</id>
    <revision>
      <id>4066000</id>
      <parentid>4056785</parentid>
      <timestamp>2021-10-28T12:22:06Z</timestamp>
      <contributor>
        <username>Marcail</username>
        <id>58</id>
      </contributor>
      <origin>4066000</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3351" sha1="2ndmvtshxx6vin6jk59goeeomha23dd" xml:space="preserve">{{Modèle:Infobox Application
 | nom                  = edoc
 | developpeur          = [[Cyrille LAGARDE]]
 | responsable          = [[Cyrille LAGARDE]]
 | faq                  = [[FAQ edoc]]
 | guideDeDeveloppement = Guide de développement edoc
 | listesDeDiffusion    = edoc.dev@efluid.fr, edoc.recette@efluid.fr
 | lienAFD              = http://wperoom1/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_67b6
 | lienDCT              = http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_97d61
 | lienPTI              = http://wperoom1/eRoom/Production/GestionProjetEfluid/0_8fec6
 | lienAutreDocuments   = Edoc#documents
}}
[[Category:domaine]]
[[Category:application]]
[[Category:edoc]]
__NOTOC__
L'application [[edoc]] est basée sur le projet Open Source [http://lucene.apache.org/solr/ Solr].
Elle est divisée en 3 parties :
* Un batch [[EDC001MT]]
* Une base de données d'indexes [[edoc-solr]]
* Un connecteur [[efluid]] &amp;harr; [[edoc]] intégré à l'application [[efluid]]
&lt;br/&gt;
&lt;!-- Schéma archivé ici : "efluid - Documentation Technique &gt; DCT suite efluid &gt; DCT edoc &gt; schema_architecture_technique.ppt"  --&gt;
&lt;!-- URL : http://wperoom2.uem.lan/eRoom/Production/DocTechniqueEfluid/0_97d61 --&gt;
[[Fichier:Schema architecture edoc.png|400px|néant|vignette|Schéma d'architecture d'edoc '''2.X''']]
= versions d'edoc =

le [http://wikefluid/docInstalleur/edoc/develop/documentation/specific/release-notes.html bon de livraison] est documenté dans les sources.

&lt;s&gt;Le détail des évènements est disponible sous suivefluid et dans le [[edoc - bons de livraison | bon de livraison]]. (Version minimale en production 2.3.0)&lt;/s&gt;

= documents =
* documents disponible sous eRoom :
** [http://wperoom1/eRoom/Production/DocTechniqueEfluid/0_a0598 efluid - Documentation Technique &gt; Projets clients &gt; UEM &gt; 010 - dossier d'architecture technique &gt; edoc]
*** ''dtr_ArchitectureEdocsUEM.doc'' (dossier d'architecture technique pour le client uem)
** [http://WPEROOM3.uem.lan/eRoom/Prod13/ConduiteChangementEfluid/0_baac efluid - Conduite du changement &gt; 02 - formation &gt; 03 - formation interne &gt; contenus &gt; 02 - autres modules &gt; portail / transverse]
*** ''présentation efluid_edoc_Archives.pptx'' (présentation fonctionnelle d'[[edoc]])
*** ''présentation efluid_edoc_Archives_Technique.pptx'' (présentation orienté technique d'[[edoc]])
** [http://wperoom2.uem.lan/eRoom/Production/AnalyseBatchsEfluid/0_af962 efluid – Analyse des performances &gt; edoc - solr]
*** ''tests_performance_EDC001MT.docx''
** [http://wperoom2.uem.lan/eRoom/Prod11/DocFonctionnelleSuiteEfluid/0_9880 efluid - Documentation Fonctionnelle Suite efluid &gt; Guides Utilisateur &gt; edoc]
*** ''Guide utilisateur application edoc.docx''
*** ''Guide utilisateur paramétrage edoc.docx''
* documents d'exploitation : 
** &lt;tt&gt;documentation\docExploitationBatchs\edoc&lt;/tt&gt; sous [[git]] avec le DEX du batch (en cours de migration vers l'installeur ; évènement {{evt|ref=130145}})
* [[aide-mémoire requête edoc-solr]]

= Mise à jour de solr =

# déposer la nouvelle archive sous artifactory dans https://eartifact.efluid.uem.lan/artifactory/webapp/#/artifacts/browse/tree/General/ext-release-local 
# générer un nouvel rpm, par exemple https://gerrit.efluid.uem.lan/c/etools/+/191855
# mettre à jour la dépendance, par exemple https://gerrit.efluid.uem.lan/c/edoc/+/193238</text>
      <sha1>2ndmvtshxx6vin6jk59goeeomha23dd</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine composant batch</title>
    <ns>0</ns>
    <id>702155</id>
    <revision>
      <id>4062457</id>
      <timestamp>2020-12-23T08:58:10Z</timestamp>
      <contributor>
        <username>Dmytryk</username>
        <id>6</id>
      </contributor>
      <comment>Page créée avec « {{Modèle:Domaine  | nom = composants batchs }} [[Category:domaine]] [[Category:composants batchs]] [[Category:pole composants transverses]] »</comment>
      <origin>4062457</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="140" sha1="6y517hei1r8c142kr4p0ymnrzjvk6zp" xml:space="preserve">{{Modèle:Domaine
 | nom = composants batchs
}}
[[Category:domaine]]
[[Category:composants batchs]]
[[Category:pole composants transverses]]</text>
      <sha1>6y517hei1r8c142kr4p0ymnrzjvk6zp</sha1>
    </revision>
  </page>
  <page>
    <title>Domaine habilitations</title>
    <ns>0</ns>
    <id>702156</id>
    <revision>
      <id>4068922</id>
      <parentid>4062460</parentid>
      <timestamp>2023-04-05T12:13:18Z</timestamp>
      <contributor>
        <username>Delapor</username>
        <id>761</id>
      </contributor>
      <origin>4068922</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="559" sha1="clwlsn79lhgenhz7ts7onbe419oec0n" xml:space="preserve">Domaine correspondant à la gestion des risques/habilitations présents dans le code Efluid. Ces habilitations permettent de donner l'accès à certain type d'utilisateur (rôle) en fonction des besoins métiers. &lt;br&gt;
La mise en place de ces habilitations permet de limiter les failles de sécurité selon lesquelles un utilisateur malveillant pourrait accéder à certaines actions ou page sans avoir pour autant les droits.

{{Modèle:Domaine
 | nom = habilitations
}}
[[Category:domaine]]
[[Category:Habilitations]]
[[Category:pole composants transverses]]</text>
      <sha1>clwlsn79lhgenhz7ts7onbe419oec0n</sha1>
    </revision>
  </page>
  <page>
    <title>Catégorie:Domaine consommation</title>
    <ns>14</ns>
    <id>702452</id>
    <revision>
      <id>4069236</id>
      <parentid>4069233</parentid>
      <timestamp>2023-05-02T08:24:44Z</timestamp>
      <contributor>
        <username>Delapor</username>
        <id>761</id>
      </contributor>
      <origin>4069236</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="313" sha1="dypji2rvcsuu624xa88tjo83n9pgi9d" xml:space="preserve">[[category:Domaine]]

Page recensant différentes documentations plus ou moins spécifiques au domaine consommation. &lt;br&gt;

La page ''[[Domaine consommation|Domaine consommation]]'' permet notamment de faire un lien entre ces différentes pages.

A compléter nécessairement lors de mise à jour de l'application.</text>
      <sha1>dypji2rvcsuu624xa88tjo83n9pgi9d</sha1>
    </revision>
  </page>
  <page>
    <title>Catégorie:Domaine Intervention</title>
    <ns>14</ns>
    <id>701742</id>
    <revision>
      <id>4069230</id>
      <parentid>4068936</parentid>
      <timestamp>2023-05-02T08:17:37Z</timestamp>
      <contributor>
        <username>Delapor</username>
        <id>761</id>
      </contributor>
      <origin>4069230</origin>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="390" sha1="q88aogyrc1bxpe6pizllzi5lgcawuwe" xml:space="preserve">[[category:Domaine]]

Page recensant différentes documentations plus ou moins spécifiques au domaine Intervention. &lt;br&gt;
La page ''[[Domaine intervention|Domaine Intervention]]'' permet ainsi de faire un lien entre ces différentes pages en précisant aussi certains points tels que les lieux de stockages des documents.

A compléter nécessairement lors de mise à jour de l'application.</text>
      <sha1>q88aogyrc1bxpe6pizllzi5lgcawuwe</sha1>
    </revision>
  </page>
</mediawiki>
